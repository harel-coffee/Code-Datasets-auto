function_arg	and [arg_2] ||| [function_1] outputs [arg_2]	count=1
arg	from the inputs ||| inputs	count=1
function_arg	matrix [arg_2] ||| [arg_2] [function_1]	count=2
arg	es of a tensor ||| dtype	count=1
class	variable to ||| variable	count=1
function	the replacement if ||| replace all	count=1
function	function to roll ||| roll	count=1
function	would be a legal ||| is valid	count=1
function	struct [function_2] ||| [function_2] [function_1]	count=3
function	-> [function_2] ||| [function_1] dot22 to [function_2]	count=1
function_arg	[function_1] is inside ||| [function_1] [arg_2]	count=6
function	inner-most loop executes ||| make reordered loop	count=1
function	unroll the ||| code unroll	count=1
arg	return ||| node name sub	count=1
arg	converting to type2 ||| type2	count=1
function_arg	svd [arg_2] ||| [function_1] [arg_2]	count=2
arg	x is a matrix ||| x	count=1
function_arg	nodes [arg_2] ||| [function_1] [arg_2]	count=4
function	replace_all_validate revert the ||| validate	count=1
class	context_name ||| type	count=1
function	scan ||| scan	count=3
function	matrix of [function] ||| sp [function]	count=3
function	inner [function_2] ||| [function_1] [function_2]	count=4
module_class	[module_1] node ||| [module_1] [class_2]	count=2
function	module is ||| is	count=1
class	output of scan ||| scan	count=1
module	of ||| gof	count=1
function	the platform-dependent [function_2] ||| [function_2] [function_1]	count=2
function	apply to be inserted ||| apply	count=1
function	[function_1] time icluding ||| [function_2] [function_1]	count=1
function	deepcopy in ||| deepcopy	count=1
function	new ||| with new	count=1
function_arg	[function_1] none ||| [arg_2] [function_1]	count=2
class	reorder the ||| tensor py operators	count=1
function	gradient w r ||| conv2d grad	count=1
function	return a ||| get	count=1
function	[function] replaced ||| [function]	count=1
function	move the abs ||| abs	count=1
function	of thunk calls ||| callcount	count=1
function	[function_1] extract a ||| [function_1] [function_2]	count=1
function	graph of apply ||| sort apply	count=1
class	this variable optionally ||| tensor	count=1
class	see theano tensor ||| tensor py operators	count=11
arg	of a dense vector ||| x s	count=1
function	output shape of ||| output shape	count=2
module	nodes to ||| gof	count=1
arg	to zview [arg] zview ||| name x [arg]	count=1
module	of the ||| gof	count=1
function_arg	[function_1] function to ||| [arg_2] [function_1]	count=3
arg	fgraph outputs ||| fgraph	count=1
function	ones [function_2] ||| sparse sp [function_1] [function_2]	count=3
function_arg	[function_1] to target ||| [arg_2] [function_1]	count=1
arg	op without affecting the ||| op	count=1
arg	outputs of node ||| node	count=1
class	a module ||| module	count=1
function	the connection pattern ||| io connection pattern	count=2
function	in the graph and ||| in	count=1
arg	to the end ||| wrt end	count=1
arg	raise ||| storage_map	count=1
function	or [function] in ||| local add [function]	count=1
arg	interface to manipulate the ||| r new_r reason verbose	count=1
arg	encode [arg] json so ||| [arg]	count=1
function	only ||| sitsot only	count=1
function	unroll ||| gen conv code unroll	count=1
arg	the given axis ||| axis	count=4
arg	the original graph to ||| outputs copy_inputs_and_orphans memo	count=1
arg	this should return ||| name	count=1
arg	[arg_1] still ||| [arg_2] [arg_1]	count=9
function	struct [function_2] ||| [function_2] code [function_1]	count=1
arg	of node ||| node	count=1
arg	the input to ||| input	count=1
module_class	[module_1] destroyhandler wasn't ||| [module_1] [class_2]	count=4
function	a canonical ||| canonical	count=1
function	construct a variable ||| variable	count=1
module	optionally inserting broadcasted ||| tensor	count=1
function	[function] only ||| [function] and	count=3
function	in a new graph ||| clone with new inputs	count=1
module	apply_node if those nodes ||| gof	count=1
function	[function_1] pattern of ||| [function_2] [function_1]	count=4
arg	even of x ||| x	count=1
function	form that ||| form	count=1
function	a list to ||| list	count=1
function	of nodes ||| nodes	count=1
arg	in [arg] ||| a b [arg]	count=1
arg	[arg_1] outputs ||| [arg_2] [arg_1]	count=6
arg	for ||| value f	count=1
function	merge 2 profiles ||| merge	count=1
module	convert python litterals ||| tensor	count=1
function	diagonalsubtensor ||| get diagonal subtensor	count=1
arg	the specified outputs ||| fgraph	count=1
function_arg	[function_1] filters ||| [arg_2] [function_1]	count=3
function	remove subtensor/advancedsubtensor1 ||| local useless subtensor	count=1
function	a sparse format ||| sparse	count=1
arg	u and ||| o u	count=2
class	[class_1] wants to ||| [class_2] [class_1]	count=1
module	functiongraph that has ||| gof	count=1
function	c ||| shape c	count=1
arg	be used to upsample ||| ratio normalize	count=2
module_class	this apply instance ||| gof apply	count=1
function	kernel for bilinear ||| bilinear	count=2
class	the dimensions of ||| tensor	count=1
function	of this op ||| l op	count=1
function	function that ||| function	count=1
function	to make itself ||| to os environ pathlist	count=1
class	kinds of ||| tensor	count=1
module	their apply_node if ||| gof	count=1
function	a inner nit_sot ||| inner sitsot	count=1
class	in the cache and ||| cache	count=1
function	replace a leaf of ||| replace leaf	count=1
function	a comparator [function_2] ||| [function_2] [function_1]	count=2
module	in ||| tensor	count=3
function	axis=l) -> ||| local	count=1
arg	filters with a ||| signals filters	count=1
arg	[arg_1] haskell's ||| [arg_2] [arg_1]	count=1
function	by default that removes ||| local remove	count=1
function	unfortunately conda offers to ||| to	count=1
class	of the list ||| list type	count=1
function_arg	[function_1] node ||| [arg_2] [function_1]	count=2
module	special work if ||| gof	count=1
function	return connection ||| connection	count=1
function	[function_1] shape ||| [function_2] [function_1]	count=10
function	[function_1] of convolution ||| [function_2] [function_1]	count=6
function	detect if ||| gcc	count=1
arg	to type2 [arg_2] ||| [arg_2] [arg_1]	count=2
arg	input to [arg_2] ||| [arg_1] [arg_2]	count=4
module	that would ||| gof	count=1
function	to make itself ||| to os environ	count=1
arg	inputs [arg_2] ||| [arg_2] [arg_1]	count=5
function	arguments to ||| args	count=1
arg	manipulate ||| r new_r reason verbose	count=1
function	enabled change all sigmoid ||| sigmoid	count=1
arg	the subgraph contained between ||| copy_inputs	count=1
arg	low and ||| size low	count=1
function	depending how [function] ||| [function]	count=1
function	shape of [function_2] ||| [function_2] gradweights [function_1]	count=2
function	as replace_all_validate revert ||| validate remove	count=1
function	gradient updates for ||| grad	count=1
function_arg	and the [arg_2] ||| [function_1] outputs [arg_2]	count=2
module	profiles returned by this ||| gof	count=1
class	shared variable to ||| shared variable	count=2
function	scale each [function_2] ||| [function_2] [function_1]	count=2
arg	raise ||| node storage_map r_vals	count=1
function	a variable on the ||| as gpuarray variable	count=1
arg	kind of order v ||| v	count=2
module	this function compute ||| tensor nnet	count=2
arg	[arg] json ||| [arg]	count=1
function_arg	[function_1] if it ||| [arg_2] [function_1]	count=1
function	to generate c ||| specify shape c	count=1
function	the signature for ||| method decl	count=1
arg	computes ||| ishape kshape	count=1
function_arg	[function_1] from x ||| [function_1] [arg_2] tag dtype	count=2
function	sum of non nan ||| sum	count=1
function	total ||| total	count=1
function	return indices over each ||| indices	count=1
arg	v raises attributeerror if ||| v	count=1
class	this variable optionally ||| py operators	count=1
class	optionally inserting ||| tensor py	count=1
arg	if allow_override ||| allow_override	count=1
function	>= ||| ge	count=1
function	compile lock to ||| to	count=1
arg	between min and max ||| min max	count=1
arg	on [arg_2] ||| [arg_1] [arg_2]	count=1
function	canonical [function_2] ||| [function_2] [function_1]	count=4
class	types ||| type	count=2
function	as replace_all_validate revert ||| validate	count=1
function	a sparse matrix of [function_1] [function_2] ||| [function_1] [function_2]	count=2
function	a schedule [function_2] ||| [function_1] [function_2]	count=1
function_arg	[function_1] n_ones ||| [function_1] padleft t [arg_2]	count=2
function	cutils_ext ||| compile cutils	count=1
arg	[arg_1] and max ||| [arg_1] [arg_2]	count=5
class	list ||| list	count=1
function	object with debug ||| with op	count=1
arg	theano graphs represent the ||| xs ys in_xs in_ys	count=1
function	computations ||| equal computations	count=1
function	[function_1] string ||| [function_1] [function_2]	count=3
function	list to [function_2] ||| [function_2] idx [function_1]	count=4
arg	shape_i how to generate ||| check_input	count=1
class	unification ||| unification	count=1
class	mrg stream state and ||| mrg random streams	count=1
function_arg	[function_1] x ||| [function_1] [arg_2] tag dtype	count=2
function	arctan ||| arctan	count=1
module	a b u returns ||| gof	count=1
class	and dictionary data structures ||| out non seq scan	count=1
function	function to get the ||| get depth	count=1
arg	map old node ||| check_integrity	count=1
function	directory and return ||| name from dir	count=1
function	hash of ||| hash	count=1
class	graph and get ||| graph	count=1
module	input nodes to ||| gof	count=1
module	the type's ||| gpuarray	count=1
arg	vector and t ||| node input_storage	count=1
class	required ||| pure	count=1
function	struct initialization ||| init code struct	count=1
arg	if necessary update dr_vals ||| dr_vals	count=1
class	a shared [class_2] ||| [class_2] [class_1]	count=2
arg	tuple or none ||| i_shapes	count=1
arg	m1 ||| m1	count=1
class	dimensions of this variable ||| py operators	count=1
function	or more multinomial ||| multinomial	count=1
class	set ||| op from graph	count=2
arg	x [arg_2] ||| [arg_1] [arg_2]	count=7
class	the graph and get ||| graph	count=1
function	logsoftmax x ||| local logsoftmax	count=1
function	list of outputs and ||| and outputs	count=1
function_arg	matrix [arg_2] ||| sparse [function_1] sum x axis [arg_2]	count=1
function	maps ||| equiv	count=1
function_arg	[function_1] none for ||| [function_1] node [arg_2]	count=2
arg	given "group" (ie ||| inp out grads	count=1
function	kernel that ||| kernel	count=2
function	and return full ||| module name	count=1
class	matrix a ||| structured	count=1
class	exception class to raise ||| raise	count=1
function	arctanh ||| arctanh	count=1
function	op ||| get op params	count=1
function	a schedule ||| sort schedule	count=1
function	the -x pattern ||| neg	count=1
arg	to target ||| target	count=1
function	makes the folowing changes ||| local mul switch sink	count=1
class	mode ||| mode	count=3
module	to use ||| gpuarray	count=1
class	an op ||| clinker op	count=1
function	that unroll [function_2] ||| [function_2] [function_1]	count=3
function_arg	transfer function for ||| transfer fn	count=1
class	for corr3dmm ||| base corr3d mm	count=1
class	inserting ||| py operators	count=2
function	output gradient w r ||| conv3d grad	count=2
module_class	[module_1] [class_2] ||| [module_1] [class_2] graph	count=3
function	the output shape of ||| shape	count=1
arg	function tries ||| top_shape	count=4
function	graph of apply nodes ||| apply nodes	count=1
function_arg	[function_1] n_ones ||| [arg_2] [function_1]	count=2
class	broadcasted ||| tensor	count=1
function	one hot ||| one hot	count=1
arg	[arg_1] 4-d tensor ||| [arg_2] [arg_1]	count=1
function	number of nodes ||| nodes	count=2
function	and see whom can ||| can	count=1
module	other scalar op ||| scalar	count=2
arg	the given axis es ||| axis dtype	count=1
function	that removes all ||| local remove all	count=2
function	[function_1] apply ||| [function_2] [function_1]	count=4
arg	input vector and t ||| node input_storage	count=1
class	reorder ||| py	count=1
function	pattern of subfgraph defined ||| pattern	count=1
function	the stack [function_2] ||| [function_1] [function_2]	count=4
arg	[arg] tensor this ||| input [arg]	count=2
function	op ||| fusion op	count=1
function	new ||| with new inputs	count=2
arg	given an fgraph and ||| fgraph outputs_to_disown	count=1
function	that unroll the ||| gen conv code unroll	count=1
arg	an exception while annotating ||| thunk exc_info storage_map	count=1
arg	the [arg] ||| i node [arg]	count=1
function_arg	apply nodes [arg_2] ||| [arg_2] [function_1]	count=4
function	print the mflops ||| flops	count=1
function	kinds of useless reshape ||| local useless reshape	count=1
function_arg	[function_1] the url ||| [arg_2] [function_1]	count=3
function	return path to ||| get entry	count=1
function	convert degree ||| deg2rad	count=1
function	with a sparse matrix ||| sparse	count=1
function	last access of a ||| last access time	count=1
function	the mean value ||| mean	count=1
function	shorter version of platform ||| platform	count=1
module	this ||| tensor nnet	count=1
function	form that respects the ||| form	count=1
function	an alloc and only ||| local alloc	count=1
arg	to make code ||| code filename	count=1
function	to pass to helper_c_code ||| helper c code	count=1
function	a new variable ||| variable	count=1
function	context associated ||| context	count=1
function	of useless [function_2] ||| [function_2] [function_1]	count=1
function_arg	compare true [arg_2] ||| [function_1] [arg_2]	count=2
function	make sure [function] ||| update [function]	count=1
function	asserts from the ||| assert	count=1
module	return data ||| gof	count=1
arg	to be between min ||| min	count=1
function	only one client and ||| only	count=1
function	mean value ||| mean	count=1
function	[function_1] trace ||| [function_1] [function_2]	count=3
function_arg	clip x ||| clip x	count=1
arg	b [arg_2] ||| [arg_2] m1 [arg_1]	count=2
function	argmax ||| argmax	count=2
function	wrt, computes ||| subgraph grad	count=1
function	computes the output dimensions ||| get output	count=1
arg	sample from one or ||| random_state size	count=1
class	the type's :attr context_name ||| array type	count=1
function	[function_1] threads ||| [function_2] [function_1]	count=4
arg	the inputs and ||| inputs	count=1
function	suitable dummy values ||| provide inputs	count=1
function	make an inplace ||| inplace	count=1
arg	convolve spatio-temporal filters with ||| filters	count=1
function	headers that ||| headers	count=1
arg	end variables of ||| end	count=1
function	detect ||| gcc	count=1
class	variable ||| py operators	count=2
arg	none for the ||| i_shapes	count=1
function	helper ||| helper	count=4
function	updates ||| updates	count=1
function	connection pattern ||| connection pattern	count=2
arg	an array with more ||| node inputs outputs	count=2
arg	while annotating ||| exc_info storage_map	count=1
function	power ||| pow	count=1
function	variable on the gpu ||| as gpuarray variable	count=1
class	of tensortype ||| tensor	count=1
function_arg	multiplication [arg_2] ||| [function_1] [arg_2]	count=1
function	replacement if ||| replace	count=1
function	all sigmoid to ultra_fast_sigmoid ||| local ultra fast sigmoid	count=1
function	convert python ||| make	count=1
class	reorder the ||| py operators	count=1
function	how to generate c ||| specify shape c	count=1
class	to help the navigator ||| navigator	count=1
function	sure [function] is ||| update [function]	count=1
function	of suitable dummy values ||| provide inputs	count=1
class	for ||| base gpu	count=1
function	a triangular solve ||| tag solve triangular	count=2
function	dimshuffle ||| local dimshuffle	count=1
function_arg	config string [arg_2] ||| [function_1] [arg_2]	count=1
function	how to generate c ||| register shape i c	count=1
class	this variable optionally inserting ||| tensor py	count=1
function	c header for openblas ||| openblas	count=1
function	the output shape ||| shape	count=1
function	optimizer ||| optimizer	count=1
arg	[arg_1] y have ||| [arg_1] [arg_2]	count=3
arg	outputs from the ||| outputs mode	count=1
function	have [function] ||| [function]	count=2
class	use [class] ||| [class]	count=2
function	a module [function_2] ||| [function_2] [function_1]	count=2
class	and dictionary data structures ||| non seq scan	count=1
arg	the computation to be ||| node	count=1
function	the replacement ||| replace all	count=1
class	the dimensions of this ||| tensor py operators	count=1
function	a module from ||| module from	count=2
function	sinus ||| sin	count=1
arg	a [arg_2] ||| unify walk [arg_1] [arg_2]	count=3
function	>= 3 ||| 3d	count=1
class	navigator ||| navigator	count=1
function	a module ||| module	count=2
function	thunk calls ||| callcount	count=1
arg	es ||| dtype op	count=1
function_arg	value for [arg_2] ||| [function_1] [arg_2]	count=4
arg	[arg_1] [arg_2] ||| [arg_2] s [arg_1]	count=2
function_arg	convert degree a ||| deg2rad a	count=1
arg	will have ||| name	count=1
function	image shape of ||| shape 1axis	count=2
arg	min and max ||| min max	count=3
function	minimum ||| minimum	count=1
function	to generate c ||| register shape i c	count=1
arg	node by one ||| node output_indices alloc_ops	count=1
function	exception object with debug ||| raise with	count=1
arg	between i and o ||| i o	count=3
function	arguments [function_2] ||| [function_2] [function_1]	count=2
class	graph and get a ||| graph	count=1
function	for gpuincsubtensor ||| local inplace setsubtensor	count=1
function	inner [function_2] ||| [function_2] [function_1]	count=4
function	matrix of [function] sparsity ||| sp [function]	count=1
function	kinds of useless ||| local useless	count=1
function	constants from [function] arguments ||| [function]	count=1
function	the connection pattern of ||| io connection pattern	count=1
arg	the specified axis ||| axis sparse_grad	count=1
arg	x the same ||| x	count=1
function_arg	[function_1] a with ||| [function_1] [arg_2]	count=1
function_arg	a random [arg_2] ||| [arg_2] [function_1]	count=3
arg	change the value after ||| default	count=1
function	for elemwise and gpuelemwise ||| local elemwise	count=1
module	on wraplinker that ||| gof	count=1
function	gradient ||| grad	count=10
function	rel error of ||| rel	count=1
function	inplace ||| inplace check	count=1
arg	f [arg_2] ||| [arg_1] [arg_2]	count=2
function	openblas ||| openblas	count=1
function	modified bessel function ||| iv inplace	count=1
function_arg	[function_1] on cpu ||| [function_1] [arg_2]	count=4
module	scalar ||| scalar	count=3
function_arg	hot [arg_2] ||| [arg_2] [function_1]	count=5
function_arg	[function_1] y with ||| [function_1] x [arg_2]	count=1
arg	y with length ||| y	count=1
function	given a inner nit_sot ||| inner sitsot	count=1
arg	of cost and/or ||| cost	count=1
arg	version of var ||| var	count=1
function	in a new graph ||| new inputs	count=1
class	of the list ||| list	count=1
function	map ||| map	count=1
function	variables given input ||| variables	count=1
class	item from the cache ||| call cache	count=1
function	stats ||| stats	count=1
arg	fgraph and ||| fgraph outputs_to_disown	count=1
arg	the inputs and ||| node inputs	count=1
function	dimshuffle and index ||| local dimshuffle	count=1
function	convolution gradinputs ||| conv gradinputs	count=2
arg	x to [arg_2] ||| [arg_1] [arg_2]	count=3
arg	failure_callback for [arg_2] ||| [arg_2] [arg_1]	count=2
class	function should ||| matrix inverse	count=1
class	reorder the dimensions of ||| py operators	count=1
arg	respects the conventions imposed ||| theslice length	count=1
function	of this ||| dimshuffle	count=1
arg	an array ||| node inputs outputs	count=2
function	inner graph ||| scan	count=1
function	ger ||| ger or gemv	count=2
function	[function_1] threads interface ||| [function_2] [function_1]	count=4
function	of useless ||| local useless	count=1
function	[function_1] upcast ||| [function_2] [function_1]	count=1
function	the inner-most loop executes ||| reordered loop	count=1
function_arg	[function_1] function for ||| [function_1] [arg_2]	count=3
arg	for ||| value	count=1
arg	the end variables of ||| wrt end	count=1
arg	initializes py_name ||| r name sub	count=1
function	[function_1] with debug ||| [function_2] [function_1]	count=1
function	how [function] is implemented ||| [function]	count=1
function	function builds the 2d ||| 2d	count=1
module	of tensortype ||| tensor	count=1
function	[function_1] counter to ||| [function_2] [function_1]	count=1
function	integers indicating the version ||| version	count=3
function	output dimensions of ||| output	count=1
module	compute 2d kernel ||| tensor nnet	count=1
arg	between min and ||| min	count=1
module	raise ||| compile	count=1
arg	function tries ||| image_shape top_shape border_mode	count=2
function	[function_1] [function_2] sparse matrix ||| [function_2] [function_1]	count=1
class	in the cache ||| cache	count=1
function	of apply nodes ||| apply nodes	count=1
function	with the -x pattern ||| is neg	count=1
function	to the task ||| find task	count=1
function	add [function_2] ||| [function_2] [function_1]	count=3
arg	actual ||| actual	count=1
arg	node by ||| node output_indices alloc_ops	count=1
module	the g++ ||| gof	count=1
function	make sure [function_1] [function_2] is not true if ||| gof open mpop update [function_1] [function_2]	count=1
function	x -> ||| local	count=2
class	to ||| type	count=1
arg	data to ||| data	count=1
arg	optional return ||| name inputs outputs	count=1
function	shape [function_2] ||| [function_2] gradweights [function_1]	count=2
class	same kinds ||| tensor type	count=1
class	for matrix solve ||| solve	count=1
arg	value ||| value trace	count=1
function	op could be very ||| l op	count=1
arg	clients list of r ||| r client_to_remove reason	count=1
function	batched ||| batched	count=1
function	variable optionally ||| dimshuffle	count=1
function	[function] sparsity pattern ||| sp ones [function]	count=1
function	[function_1] the parents ||| [function_2] [function_1]	count=1
function	convert addsd to ||| local addsd	count=1
arg	required return c code ||| name sub	count=1
function	round half to ||| rint	count=1
arg	a leftdims ||| leftdims	count=1
arg	to [arg] to ||| [arg]	count=1
arg	a set of arrays ||| a choices out mode	count=1
arg	tensor variable r ||| r	count=1
class	create a new random ||| random	count=1
arg	[arg_1] [arg_2] ||| [arg_2] o [arg_1]	count=2
arg	elementwise ||| a b	count=2
function	exception ||| raise	count=1
function	a context ||| reg context	count=1
class	a mode ||| mode	count=1
module	broadcasted ||| tensor	count=1
function	performs batch normalization ||| dnn batch normalization	count=2
function	should be removed ||| compress outs	count=1
function	toposort return ||| toposort	count=1
function	load ||| load	count=3
arg	of x [arg_2] ||| [arg_1] [arg_2]	count=2
function	the shape feature ||| shape	count=1
module	compute 1d ||| tensor nnet	count=1
function_arg	new instance ||| clone link_kwargs optimizer	count=2
arg	compilation flags ||| libs flags libs_dir include_dir	count=1
function	a [function] ||| [function]	count=4
function_arg	[function_1] v ||| [function_1] [arg_2]	count=1
module	return those items of ||| gof	count=1
function	the platform-dependent [function_2] ||| [function_1] [function_2]	count=2
arg	x ||| x axes	count=1
function	[function_1] a package ||| [function_1] [function_2]	count=1
class	returns a module if ||| module	count=1
arg	inputs and [arg_2] ||| [arg_1] [arg_2] features clone	count=1
function	offers to make itself ||| to os environ pathlist	count=1
function	generates the c ||| c	count=3
arg	spatio-temporal filters with a ||| signals filters	count=1
function	form that respects ||| form	count=1
arg	from the shape or ||| shape	count=1
arg	we parametrize it to ||| max_input_fct maker	count=1
arg	slices in pvals ||| pvals	count=1
class	the theano enumeration types ||| type	count=1
function	the context associated ||| context	count=1
function_arg	[function_1] op without ||| [arg_2] [function_1]	count=6
function	elemwise and gpuelemwise ||| local elemwise	count=1
function	[function_1] upcast ||| [function_1] [function_2]	count=1
class	the same type ||| typed list type	count=1
function	if the g++ version ||| gcc	count=1
function	t [function] ||| local subtensor of [function]	count=1
arg	op a list of ||| op	count=1
function	a set of 3d ||| conv3d	count=1
arg	shape_i how ||| check_input	count=1
arg	[arg_1] rightdims ||| [arg_1] [arg_2]	count=6
arg	m1 and the ||| m1	count=1
function	the same computations ||| computations	count=1
class	scan return ||| push out scan	count=1
arg	according to a list ||| inputs outputs cmps	count=1
arg	[arg_1] and outputs ||| [arg_1] [arg_2] features clone	count=4
arg	required to compute ||| variable_list blockers	count=1
function_arg	one hot [arg_2] ||| [function_1] [arg_2]	count=1
function	[function_1] with the ||| sparse sp [function_1] [function_2]	count=1
function	gist ||| gist	count=1
function	output shape of ||| shape	count=1
class	to ||| gpu array	count=1
function	base 2 logarithm ||| log2	count=1
arg	value after ||| default	count=1
function	parse a ||| parse	count=1
arg	we ||| node	count=1
arg	[arg_1] n (n ||| [arg_1] [arg_2]	count=1
arg	required to ||| variable_list blockers	count=1
function	access of a given ||| access time	count=1
arg	failure_callback for navigatoroptimizer ||| exc nav repl_pairs local_opt	count=2
function_arg	after a [arg_2] ||| core warn [function_1] [arg_2]	count=1
arg	[arg_1] are ||| [arg_1] [arg_2]	count=4
module	compute ||| tensor nnet	count=19
function	scalar variable ||| scalar	count=1
function	inner-most loop ||| loop	count=1
function_arg	round_half_to_even_inplace [arg_2] ||| [arg_2] [function_1]	count=1
class	scan return true iff ||| out scan	count=1
function	translates t [function] b [idxs] ||| local subtensor of [function]	count=1
arg	from existing start gradients ||| start	count=1
function	make sure [function] is ||| update [function]	count=1
class	this type ||| type	count=2
function	the same computations ||| equal computations	count=1
function	integers indicating the version ||| cache version	count=3
arg	test a ||| n_tests	count=1
arg	specified axis ||| axis sparse_grad	count=1
arg	to the fgraph outputs ||| fgraph	count=1
class	gradient ||| grad	count=3
class	of scan return true ||| push out scan	count=1
arg	and dtype [arg_2] ||| [arg_2] [arg_1]	count=1
function	} b axis=l) -> ||| local	count=1
arg	haskell' ||| outputs_info non_sequences	count=1
function	in the graph ||| in	count=1
class	kinds ||| tensor type	count=1
module	move [module] computation ||| [module]	count=1
function	convolution gradweights ||| conv gradweights	count=1
arg	an apply_node recursively search ||| apply_node	count=1
function	schedule ||| schedule	count=1
function	generate c ||| register shape i c	count=1
function	on all device ||| device	count=1
function_arg	[function_1] fgraph to ||| [arg_2] [function_1]	count=2
arg	similar behaviour as python's ||| fn sequences non_sequences	count=1
class	variable optionally inserting broadcasted ||| py operators	count=1
function_arg	a ^ [arg_2] ||| [arg_2] [function_1]	count=1
class	normal ||| random streams base	count=1
function	make a [function_2] ||| [function_1] [function_2]	count=4
class	reorder ||| tensor	count=1
function	wrt, computes gradients of ||| subgraph	count=1
arg	filters ||| signals filters	count=1
class	dimensions ||| tensor py operators	count=4
function_arg	[function_1] [arg_2] ||| [function_1] r [arg_2]	count=9
function	op could be very ||| op	count=1
function	abs ||| abs	count=2
arg	initializes py_name ||| r	count=1
function	removes useless ||| local useless	count=1
function	assign the shape ||| shape	count=1
function	to detect ||| detect	count=1
arg	have [arg_2] ||| [arg_2] [arg_1]	count=4
function	sum of non ||| sum	count=1
function_arg	[function_1] addition ||| [function_1] cls alpha_in beta_in [arg_2]	count=2
function	a module ||| get module	count=1
function	use within the op ||| op	count=1
arg	test a ||| fun pt n_tests	count=1
class	gradient [class_2] ||| [class_2] [class_1]	count=2
function	"init_code" ||| struct	count=1
arg	[arg_1] [arg_2] ||| [arg_2] axis [arg_1]	count=12
arg	i [arg_2] ||| [arg_1] [arg_2]	count=1
module	compute the dot ||| tensor nnet	count=2
function	the gradient ||| grad	count=3
function	simplify a [function_2] ||| [function_1] [function_2]	count=1
function	gemm ||| gemm	count=2
arg	y with ||| y	count=1
module	[module] encapsulates ||| [module]	count=3
function_arg	inputs [arg_2] ||| [function_1] [arg_2]	count=4
arg	n (n ||| n	count=1
arg	was dumped to ||| f persistent_load	count=1
function	calculating the dot product ||| true dot	count=1
function_arg	[function_1] of cost ||| [arg_2] [function_1]	count=2
function_arg	[function_1] code ||| [arg_2] [function_1]	count=2
function	replace_all_validate revert the ||| all validate remove	count=1
class	connection ||| op from graph	count=1
class	apply instance in ||| apply	count=1
function	1/(1+exp x -> sigm ||| local inv 1 plus exp	count=1
function	:func images2neibs <theano tensor ||| images2neibs	count=1
function	some [function_2] ||| [function_1] [function_2] replacer	count=1
class	scan ||| scan	count=1
arg	should return [arg_2] ||| [arg_2] [arg_1]	count=2
function	translates t [function] b ||| local subtensor of [function]	count=1
function	the idx list to ||| idx list	count=1
function	canonical form that respects ||| canonical form	count=1
function	remove ||| useless	count=1
function	optional return [function] required by ||| c [function]	count=1
arg	a and [arg_2] ||| [arg_1] [arg_2]	count=1
function	of ||| dimshuffle	count=1
function	the dependence of nodes ||| dependence	count=1
function	directory and ||| from dir	count=1
arg	types of x ||| x	count=2
class	this function ||| ext function	count=1
arg	nodes in the original ||| outputs copy_inputs_and_orphans memo	count=1
class	of the type ||| tensor type	count=1
arg	s_i ||| s_i	count=1
function	lib directories that are ||| header dirs	count=1
function	that unroll ||| code unroll	count=1
function	perform the permutation by ||| perform	count=1
module	[module] matrix ||| [module]	count=1
function	to py_none ||| get c init	count=1
function_arg	[function_1] [arg_2] ||| [function_1] random_state size [arg_2]	count=1
class	help the navigator ||| navigator optimizer	count=1
class	[class_1] gpucorrmm ||| [class_1] [class_2]	count=1
arg	dtype ||| dtype	count=1
arg	end variables of ||| wrt end	count=1
function	the connection pattern of ||| connection pattern	count=1
function	gpuelemwise ||| local gpu elemwise	count=1
arg	[arg_1] op a ||| [arg_2] [arg_1]	count=4
function	with ||| like	count=1
arg	input ||| input	count=8
arg	from [arg] corresponds to ||| [arg]	count=1
function	print the following ||| print global	count=3
function	[function_1] directories ||| [function_1] [function_2]	count=4
function	dot product ||| dot	count=1
module	that must be evaluated ||| gof	count=1
arg	and a ||| a	count=1
module	of this variable ||| tensor	count=1
module	a dict that ||| gof	count=2
function	lib directories ||| lib dirs	count=2
class	the list ||| list type	count=1
function	[function_1] [function_2] replaced according to 'replacer' ||| [function_1] [function_2] replacer	count=1
arg	l operation on f ||| f	count=1
function	shape tuple ||| shape	count=1
class	[class_1] stream state ||| [class_2] [class_1]	count=4
arg	value has ||| value	count=1
function	of broadcastable ||| broadcastable	count=1
function	from [function] distribution centered ||| [function]	count=1
function	[function_1] [function_2] ||| [function_2] [function_1] node	count=2
arg	[arg_1] [arg_2] ||| [arg_1] [arg_2]	count=416
arg	[arg_1] * y ||| [arg_2] [arg_1]	count=1
function	shape ||| shape	count=18
function	with the ||| like	count=1
function	[function_1] [function_2] with the same dtype ||| sparse as [function_2] [function_1]	count=8
function_arg	wrt, computes [arg_2] ||| [arg_2] [function_1]	count=5
function	[function_1] inplace on ||| [function_2] [function_1]	count=3
function	graph have a stack ||| stack	count=1
arg	node ||| node	count=4
function_arg	[function_1] [arg_2] utility ||| [function_1] support code struct [arg_2]	count=1
arg	function computes ||| ishape kshape	count=1
class	from the cache ||| cache	count=1
function	output dimensions ||| output	count=1
function	the idx [function_2] ||| [function_2] [function_1]	count=1
function	a new ||| with new	count=1
function	all ||| all	count=1
function	where n >= 3 ||| 3d	count=1
arg	elemwise minimum of sparse [arg_1] [arg_2] ||| sparse structured minimum [arg_1] [arg_2]	count=1
function	connection [function_2] ||| [function_1] [function_2]	count=4
function_arg	[function_1] a name ||| [arg_2] [function_1]	count=2
function	of apply [function_2] ||| [function_1] [function_2]	count=1
arg	the input [arg_2] ||| [arg_1] [arg_2]	count=3
function	[function_1] [function_2] ||| [function_1] [function_2]	count=860
arg	and max ||| max	count=1
function	scalar 0-dimensional variable ||| hessian	count=1
function	the version ||| code cache version	count=3
function	copies the stack trace ||| copy stack trace	count=1
function	detect if the ||| gcc	count=1
arg	required return the ||| node name	count=1
arg	fgraph outputs that ||| fgraph expanded_inputs	count=1
class	of this type ||| pure type	count=1
arg	converting to type2 from ||| type2	count=1
function	ultra_fast_sigmoid ||| ultra fast	count=1
function	for diagonalsubtensor ||| get diagonal subtensor	count=1
module	this function compute the ||| nnet	count=2
function	stack ||| check stack	count=1
arg	list [arg] list ||| [arg]	count=1
class	inserting broadcasted dimensions ||| py operators	count=1
arg	raise baddestroymap ||| node storage_map r_vals	count=1
class	tensor ||| tensor py operators	count=1
arg	given axis es of ||| axis dtype	count=1
arg	will have separated maker ||| share_memory swap delete_updates name	count=1
class	of ||| tensor	count=3
arg	in array of ints ||| weights minlength assert_nonneg	count=1
function	[function_1] solve ||| [function_2] [function_1]	count=8
function	debug counter to ||| debug counter	count=2
arg	return ||| name sub	count=4
function	list of variables ||| variables	count=1
function	inplace on ||| inplace	count=11
function	function for diagonalsubtensor ||| get diagonal subtensor view	count=1
arg	an optimization ||| node	count=1
arg	fgraph and a ||| fgraph outputs_to_disown	count=1
function	value ||| value	count=3
function	that removes [function_2] ||| [function_1] [function_2]	count=5
arg	remove ||| remove	count=1
class	this variable optionally inserting ||| operators	count=1
function	[function] utility code ||| [function] support	count=1
function	code to the task ||| task	count=1
class	compute ||| tensor constant signature	count=1
function	for diagonalsubtensor and ||| diagonal subtensor	count=1
arg	return an ||| op	count=2
function_arg	[function_1] [arg_2] ||| [function_1] name [arg_2]	count=12
function	[function_1] form ||| [function_1] [function_2]	count=4
module	the function name to ||| gpuarray	count=2
function	the dependence ||| make dependence	count=1
module	output nodes ||| gof	count=1
function	transfer to a tensortype ||| transfer	count=1
function	inner nit_sot output of ||| inner sitsot	count=1
class	dimensions of this variable ||| tensor py operators	count=1
function_arg	value for a ||| value a	count=1
function	directory and ||| dir	count=1
function	the 1d ||| 1d	count=1
function	find broken ||| find	count=1
function_arg	diagonal [arg_2] ||| [arg_2] [function_1]	count=2
function	scale each columns ||| col scale	count=1
function	folowing changes ||| mul switch sink	count=1
arg	exists in [arg] ||| a b [arg]	count=1
arg	break aliasing of ||| wrapped_inputs wrapped_outputs	count=1
function	gradweights ||| gradweights	count=1
function	add two ||| add	count=1
function	diagonal set ||| diagonal	count=1
arg	specified axis ||| x axis sparse_grad	count=2
function	toposort return an ordering ||| toposort	count=1
function_arg	[function_1] a ||| [arg_2] [function_1]	count=25
function	symbolically cast ||| cast	count=1
arg	i and ||| i	count=1
function_arg	mean value [arg_2] ||| [function_1] input [arg_2]	count=5
arg	[arg_1] a movie ||| [arg_2] [arg_1]	count=3
function	[function_1] constant ||| [function_2] [function_1]	count=8
function	unroll the [function_2] ||| [function_1] [function_2]	count=3
module	to the ||| gpuarray	count=1
function	should be removed and ||| outs	count=1
function	the fortran blas ||| blas	count=1
class	the ||| gpu array type	count=2
function	[function_1] gradinputs ||| [function_2] [function_1]	count=4
function	[function_1] with debug ||| gof [function_1] [function_2]	count=1
function	output dimensions of convolving ||| output	count=1
function	inner nit_sot ||| inner	count=1
function	[floor] ||| int	count=1
function	[function_1] deepcopy ||| [function_2] [function_1]	count=1
function	the data ||| data	count=1
function	op code ||| op	count=1
function_arg	[function_1] x ||| [arg_2] [function_1]	count=9
function	apply nodes ||| apply nodes	count=1
function	single prod() ||| op of op	count=1
module	returned by [module] ||| [module]	count=4
arg	num and [arg] ||| num [arg]	count=2
function	draw random integers ||| random integers	count=1
arg	[arg_1] [arg_2] sets ||| [arg_1] [arg_2]	count=7
arg	a dense vector ||| x s	count=1
function	cosine ||| cos	count=2
function	in a sparse format ||| sparse	count=1
function_arg	matrix along [arg_2] ||| sparse [function_1] sum [arg_2]	count=1
function	[function_1] pattern ||| [function_1] [function_2]	count=6
function	connection [function_2] ||| [function_2] [function_1]	count=4
function	loop ||| make reordered loop	count=1
function	gradient ||| conv3d grad	count=2
arg	consider an expression ||| x	count=1
arg	[arg] tensor ||| input [arg]	count=2
function_arg	[function_1] inputs replaced ||| [function_1] idx [arg_2]	count=1
arg	apply_node recursively search from ||| apply_node check	count=1
function	functional inverses [function] them ||| [function] func	count=1
function	shape of convolution gradweights ||| conv gradweights shape	count=1
arg	half by b with ||| b	count=1
class	the ||| array type	count=2
class	to ||| gpu	count=1
function	a canonical [function_2] ||| [function_1] [function_2]	count=4
arg	[arg_1] b ||| [arg_1] [arg_2]	count=5
function_arg	symbolically cast [arg_2] ||| [arg_2] [function_1]	count=5
function	the output [function_2] ||| [function_2] [function_1]	count=3
function	constant [function_2] ||| [function_2] [function_1]	count=6
function	the output ||| get out	count=1
function	function for diagonalsubtensor and ||| get diagonal subtensor view	count=1
function	be removed from the ||| remove outs	count=1
class	this ||| tensor py operators	count=2
arg	to outdim ||| outdim	count=1
function	same computations ||| equal computations	count=1
class	type ||| cdata type	count=1
function	replace_all_validate revert the ||| validate remove	count=1
function	[function_1] the parents ||| [function_1] [function_2]	count=1
arg	return c code to ||| name sub	count=1
function	the inner-most loop executes ||| make reordered loop	count=1
function	were declared ||| init	count=1
arg	return [arg_1] [arg_2] ||| eq [arg_1] [arg_2]	count=1
arg	the output ||| output	count=1
function	shape feature ||| shape	count=1
function	from polar ||| from polar	count=1
arg	raise baddestroymap ||| r_vals	count=1
function	return the [elementwise] largest ||| largest	count=1
function	c [function_2] ||| [function_1] [function_2]	count=4
arg	apply_node recursively search ||| apply_node check reason	count=1
function	output ||| get output	count=1
arg	in array of ints ||| x weights minlength assert_nonneg	count=1
function_arg	constant [arg_2] ||| [function_1] idx [arg_2]	count=5
arg	[arg] with the ||| [arg] tag	count=2
function	copies the stack ||| stack	count=1
function_arg	we should warn about [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
arg	prior reduction of x ||| x	count=1
function	like ||| like	count=1
function	[function_1] stats ||| [function_2] [function_1]	count=3
function	conda offers to ||| to os environ pathlist	count=1
arg	sample from one or ||| random_state size n	count=1
arg	zview [arg] ||| name x [arg]	count=1
arg	[arg_1] with a ||| [arg_2] m1 [arg_1]	count=4
arg	new_r ||| new_r reason	count=1
function	output ||| out	count=1
function	bilinear upsampling this ||| bilinear	count=2
class	for gpucorrmm (direction="forward"), ||| gpu corr mm	count=1
arg	encode [arg] json ||| [arg]	count=1
arg	a [arg_2] ||| [arg_1] [arg_2]	count=6
function	to wrt, computes gradients ||| subgraph	count=1
function	the dependence of nodes ||| make dependence	count=1
class	type's :attr context_name ||| type	count=1
module	compute 1d kernel ||| nnet	count=1
function	-x pattern ||| is neg	count=1
function	get the ||| get	count=2
function	returns upper bound ||| bound	count=1
function	return the data ||| data	count=1
arg	x to a ||| x	count=1
function	a string ||| string	count=1
function	the confusion matrix of ||| confusion matrix	count=1
arg	expression ||| expression	count=1
function	return the abs and ||| abs	count=1
function	[function_1] dimshuffle ||| [function_1] [function_2]	count=2
arg	by the inputs ||| inputs	count=1
function	with debug info ||| with op	count=1
function	[function_1] unused ||| [function_2] [function_1]	count=1
function	inner nit_sot output ||| inner	count=1
arg	of r ||| r client_to_remove reason	count=1
function	modifies ||| give	count=1
function	respect to wrt, computes ||| subgraph grad	count=1
arg	fgraph to [arg_2] ||| [arg_2] [arg_1]	count=3
function	for diagonalsubtensor and ||| diagonal subtensor view	count=1
function	type ||| type	count=3
function	gist and return ||| gist	count=1
function_arg	[function_1] [arg_2] both inclusive ||| [function_1] integers [arg_2]	count=1
function	only one client and ||| sitsot only	count=1
function	the struct [function_2] ||| [function_2] [function_1]	count=3
class	reorder the dimensions ||| py operators	count=1
function	graph of apply ||| apply	count=1
function_arg	a multiplication tree ||| mul tree	count=1
function	loop over ||| loop	count=1
function	unique names ||| names	count=1
function	reorder the ||| dimshuffle	count=1
function	has any duplicates (according ||| has duplicates	count=1
module	u returns ||| gof	count=1
function	revert the replacement if ||| replace	count=1
arg	a 4-d tensor it ||| patch_size	count=1
arg	modulo of m1 and ||| m1	count=1
function	inputs to elemwise ||| elemwise constant inputs	count=2
function	to use dnn ||| safe no dnn	count=2
class	a new random stream ||| random streams	count=1
function	[function_1] nodes ||| [function_1] [function_2]	count=4
function_arg	to merge [arg_2] ||| [arg_2] [function_1]	count=1
function	get the 0 ||| get	count=1
class	and dictionary data structures ||| push out non	count=1
function	wrt, computes ||| subgraph	count=1
function	[function_1] trace from ||| [function_2] [function_1]	count=3
function	abs [function_2] ||| [function_2] [function_1]	count=2
module	is ||| gof	count=1
class	if the alloc ||| alloc	count=1
function	op scale [function_2] ||| [function_2] [function_1]	count=2
module	nodes such that ||| gof	count=1
class	data structures ||| push out non seq scan	count=1
function	and return full path ||| module name from	count=1
function	to generate c ||| shape i c	count=1
class	file ||| key data	count=2
arg	v given that v ||| v	count=1
arg	value ||| value	count=3
arg	to upsample ||| ratio normalize	count=2
function	bitwise a ^ ||| xor	count=1
arg	outputs ||| outputs mode accept_inplace	count=1
module	compute 2d kernel for ||| nnet	count=1
function	a transfer ||| transfer	count=1
function	output error ||| output	count=1
function	has ||| has	count=2
function	pattern for advancedsubtensor output ||| pattern	count=1
arg	parametrize it ||| max_input_fct maker	count=1
function	batch size ||| batch	count=1
arg	apply_node recursively search ||| apply_node	count=1
class	graph and get a ||| function graph	count=1
function	is not [function] ||| [function]	count=1
function	comparator to [function_2] ||| [function_2] [function_1]	count=4
function	this op scale ||| scale	count=1
module	of this ||| tensor	count=1
function_arg	add two [arg_2] ||| [arg_2] [function_1]	count=1
function	to make ||| to os	count=1
class	reorder the dimensions of ||| tensor	count=1
function	signature for ||| method decl	count=1
function	the ||| dimshuffle	count=1
class	type's :attr ||| gpu array type	count=1
arg	mini-batch of ||| input_shape filter_shape	count=3
arg	n-d tensor where ||| ws ignore_border stride	count=2
class	to the ||| array type	count=1
module	this variable ||| tensor	count=1
class	to split x ||| split	count=1
function	gradient the finite ||| grad	count=1
arg	[arg_1] tensor input ||| [arg_2] axis [arg_1]	count=3
function_arg	fill a with ||| second inplace a	count=1
module	to output nodes ||| gof	count=1
class	for same kinds ||| type	count=1
function_arg	roll tensortypes ||| roll x shift	count=1
class	this variable ||| tensor py	count=1
arg	existing start gradients up ||| start	count=1
function	translates t [function] ||| local subtensor of [function]	count=1
arg	instance of this ||| link_kwargs optimizer	count=2
function	register a context ||| context	count=1
function	as replace_all_validate ||| all validate remove	count=1
function	the updates ordereddict the ||| get updates	count=1
function	[function] sparsity ||| sp ones [function]	count=1
arg	by mapping it ||| ctx	count=1
class	the dimensions of ||| tensor py operators	count=1
function_arg	[function_1] for navigatoroptimizer ||| [function_1] exc [arg_2]	count=1
class	inserting broadcasted ||| tensor	count=1
arg	test a ||| pt n_tests	count=1
module	gradient of [module] variable ||| [module]	count=1
arg	one ||| x y	count=3
arg	in the original graph ||| outputs copy_inputs_and_orphans memo	count=1
function	[function_1] form ||| [function_2] [function_1]	count=4
arg	r sub ||| r name sub	count=1
function	the context associated with ||| context	count=1
arg	the contents ||| dirname err files	count=1
arg	4-d ||| patch_size	count=1
class	set ||| from graph	count=2
function	trace ||| trace	count=2
function	sure [function] is not ||| update [function]	count=1
function	[function_1] shp) ||| [function_1] [function_2]	count=2
function	the dimensions of ||| dimshuffle	count=1
arg	assert that x ||| x	count=1
function	tensor from ||| from	count=1
arg	if necessary update dr_vals ||| storage_map r_vals dr_vals	count=1
function	the dependence ||| dependence	count=1
function	[function_1] matrix ||| [function_2] [function_1]	count=2
function	a symbolic row ||| row	count=1
module	if ||| gof	count=5
arg	via dfs [arg] ||| [arg]	count=1
function_arg	a diff [arg_2] ||| [function_1] [arg_2]	count=1
arg	in the fgraph to ||| fgraph	count=1
arg	the input to a ||| input	count=1
arg	for seqoptimizer ||| optimizer	count=1
arg	fgraph [arg_2] ||| [arg_1] [arg_2]	count=2
arg	this function tries to ||| image_shape top_shape	count=2
function	removes useless dimshuffle ||| useless dimshuffle	count=1
function	supported [function] gpu? ||| [function]	count=1
class	theano enumeration types ||| params type	count=1
function	return full path ||| module name	count=1
function	a config string ||| config string	count=1
function_arg	[function_1] a ||| [function_1] y [arg_2]	count=1
module	by ||| gof	count=1
arg	dtype [arg_2] ||| [arg_2] [arg_1]	count=1
function	-> single prod() ||| local op of op	count=1
arg	of order v ||| v	count=2
function	[function_1] each columns ||| sparse [function_2] [function_1]	count=1
function	unroll the ||| conv code unroll	count=1
arg	to a specified ||| a	count=1
function	accept complex [function_2] ||| [function_2] [function_1]	count=2
function	[function_1] rel error ||| [function_2] [function_1]	count=3
class	cache or the ||| cache	count=1
function	return full ||| module name from	count=2
class	the navigator ||| navigator optimizer	count=1
function	[function_1] list to ||| [function_1] [function_2]	count=4
arg	return a symbolic ||| name dtype	count=3
function	[function_1] a file ||| [function_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] outs [arg_2]	count=4
arg	where [arg] ||| [arg]	count=2
module	compute ||| nnet	count=12
function	[function_1] -> ||| [function_2] [function_1]	count=2
function	shape tuple ||| infer shape	count=1
class	broadcasted dimensions ||| tensor	count=1
arg	to new_r ||| new_r	count=1
function_arg	deepcopy [arg_2] ||| [arg_2] [function_1]	count=5
arg	of x the ||| x	count=1
class	[class_1] variable to ||| [class_1] [class_2]	count=4
module	optionally ||| tensor	count=1
function	the broadcast pattern for ||| pattern	count=1
function	c_extract_out ||| get c extract out	count=1
function	offers to make ||| to os environ	count=1
function	to detect [function_2] ||| [function_1] macos sdot [function_2]	count=1
function	multinomial distributions ||| multinomial	count=2
module	broadcasted dimensions ||| tensor	count=1
function	[function_1] single prod() ||| [function_1] [function_2]	count=2
function_arg	[function_1] url ||| [function_1] [arg_2]	count=1
class	scan return ||| scan	count=1
function	module is a ||| is	count=1
function	from the [function_2] ||| [function_2] [function_1]	count=1
function	of convolution gradinputs ||| conv gradinputs	count=2
function	module initialization ||| init	count=1
class	copy of the type ||| tensor type	count=1
function	label of [function_2] ||| [function_2] [function_1]	count=2
class	matrix solve operation ||| solve	count=1
arg	the args ||| node args	count=2
function	[function_1] object with ||| gof [function_1] [function_2]	count=1
arg	vector and t is ||| node input_storage	count=1
function	add ||| add node	count=2
function	config ||| parse config	count=1
class	for corr3dmm (direction="forward"), ||| corr3d mm	count=1
function	[function] is implemented ||| [function]	count=1
arg	[arg_1] sub ||| [arg_2] [arg_1]	count=3
function	rebroadcast [function_2] ||| [function_1] [function_2]	count=1
module_class	[module_1] [class_2] graph ||| [module_1] [class_2]	count=3
arg	that gets a scan ||| not_required inputs	count=1
function	helper_c_code ||| helper c code	count=2
arg	to type2 from ||| type2	count=1
function	all [function_2] ||| [function_2] [function_1]	count=4
class	of ||| type	count=1
function	sum of ||| sum	count=1
class	for ||| base abstract	count=1
class	the ||| gpu array	count=2
function	none or a tensorvariable ||| as	count=1
function	a leaf ||| leaf	count=1
arg	filters with ||| filters	count=1
function	[function] required ||| c [function]	count=7
function_arg	new [arg_2] ||| [function_1] [arg_2] dtype	count=2
module	returns function ||| gof	count=1
function_arg	convert radian a ||| rad2deg a	count=1
arg	node ||| node output_indices alloc_ops	count=1
arg	if fgraph ||| fgraph	count=1
function	conv output gradient w ||| conv2d grad	count=1
function_arg	load a [arg_2] ||| [arg_2] [function_1]	count=1
function	the image ||| 1axis	count=1
class	inserting broadcasted dimensions ||| tensor	count=1
function	important note this function ||| process node	count=2
function	to recognize the updates ||| get updates	count=1
module	the ||| gof	count=5
module	implemented returns ||| gof	count=1
arg	denum ||| denum	count=1
class	turned into macros ||| cop	count=1
function	x -> x ||| local tensor	count=1
function	debug counter ||| debug counter	count=2
class	a shared [class_2] ||| [class_1] [class_2]	count=2
arg	the conventions imposed by ||| theslice length	count=1
function	that removes all asserts ||| local remove all assert	count=1
arg	transform is viewed as ||| inputs cost_grad	count=1
arg	start gradients up ||| start	count=1
arg	still ||| fgraph replacements	count=1
function	in the ||| in	count=1
arg	subgraph contained between ||| copy_inputs	count=1
arg	that ||| op	count=1
arg	output specs ||| input_specs output_specs accept_inplace	count=1
module	takes as ||| signal	count=1
function	inverse the gradient ||| grad	count=1
function_arg	[function_1] [arg_2] same type but with ||| [function_1] [arg_2]	count=4
arg	val ||| val	count=1
function	a poisson ||| poisson	count=1
arg	graphs ||| graphs	count=1
arg	a ||| a	count=66
function_arg	[function_1] required to ||| [arg_2] [function_1]	count=3
function	with ||| with	count=2
class	of this ||| tensor py	count=1
class	from ||| from	count=2
arg	matrix [arg] and ||| [arg]	count=1
function_arg	[function_1] a to ||| [function_1] [arg_2]	count=2
function_arg	diagonal set [arg_2] ||| [arg_2] [function_1]	count=3
function	[function_1] x and ||| [function_2] [function_1]	count=1
function_arg	[function_1] [arg_2] the same type but ||| [function_1] [arg_2]	count=4
arg	and t is a ||| node	count=1
module	to ||| gpuarray	count=4
class	a convolution with the ||| dnn conv	count=1
function	bitwise ~a [function_2] ||| [function_2] [function_1]	count=1
class	macros for use ||| cop	count=1
function	a nested loop over ||| loop	count=1
function	[function_1] access ||| [function_1] [function_2]	count=4
function	only used to determine ||| adv index broadcastable	count=1
function	on the ||| gpuarray	count=1
module	optionally inserting ||| tensor	count=1
arg	inputs ||| inputs outputs	count=1
function_arg	to wrt, [arg_2] ||| [arg_2] [function_1]	count=2
module	of nodes that must ||| gof	count=1
class	macros ||| cop	count=1
function	a >= ||| ge	count=1
class	types ||| params type	count=1
function	a sparse matrix of [function_1] [function_2] sparsity pattern ||| sparse sp [function_1] [function_2]	count=1
arg	up to the end ||| end	count=1
function	the image shape ||| shape 1axis	count=2
arg	theano graphs represent ||| xs ys in_xs in_ys	count=1
function	trace from one or ||| trace	count=1
arg	[arg_1] [arg_2] sets ||| [arg_1] [arg_2] features clone	count=7
arg	+ rightdims ||| rightdims	count=1
function	+ alpha * dot ||| gemv c	count=1
function_arg	[function_1] dimension axis ||| [function_1] t [arg_2]	count=1
function	parses a config ||| config	count=1
function_arg	a context [arg_2] ||| [arg_2] [function_1]	count=3
function	multiplication by a scalar ||| alpha	count=1
function	search through a ||| search	count=1
function_arg	[function_1] [arg_2] ||| [function_1] node [arg_2]	count=25
arg	to zview [arg] zview if ||| name x [arg]	count=1
arg	if ||| node storage_map r_vals	count=1
arg	between low and high ||| random_state size low high	count=1
function	shared ||| shared	count=1
function	defining the gradient the ||| grad	count=1
function	in a new graph ||| clone with new	count=1
function	dimshuffle and index the ||| local dimshuffle	count=1
function	list of header ||| header	count=1
module	the g++ version ||| gof	count=1
function	replacement if the ops ||| replace all	count=1
module	wrapper around c_extract that ||| gof	count=1
function_arg	a diff [arg_2] ||| [arg_2] [function_1]	count=1
function	[floor] division inverse of ||| int div	count=1
module	that are ||| gof	count=1
function_arg	input [arg_2] ||| [arg_2] [function_1]	count=3
class	enum ||| enum type	count=1
class	dimensions of this ||| tensor py operators	count=1
function_arg	[function_1] according to ||| [arg_2] [function_1]	count=5
arg	variable v ||| v	count=1
arg	[arg_1] [arg_2] is used to convert ||| [arg_1] [arg_2]	count=16
module	nodes of the graph ||| gof	count=1
function	output [function_2] ||| [function_1] [function_2]	count=3
function_arg	[function_1] [arg_2] ||| [function_1] idx [arg_2]	count=5
class	data structures ||| non seq	count=1
arg	start gradients ||| start	count=1
function	this op could ||| op	count=1
function	inner-most loop executes code ||| make reordered loop	count=1
arg	shape and dtype as ||| dtype	count=1
function	of lib directories ||| header dirs	count=1
function	replace a [function_2] ||| [function_1] [function_2]	count=4
class	for a ||| gpu dnn	count=1
function_arg	roll [arg_2] ||| [arg_2] [function_1]	count=2
module	the method that ||| gof	count=2
function	the op ||| get op params	count=1
function	the folowing changes in ||| local mul switch sink	count=1
function	functional inverses [function] ||| [function] func	count=1
function	a thunk that ||| thunk	count=1
function_arg	[function_1] [arg_2] ||| [function_1] outputs [arg_2]	count=3
function	is a ||| is	count=1
arg	will match self if ||| var	count=1
function_arg	upper [arg_2] ||| [function_1] [arg_2]	count=4
function_arg	shape tuple [arg_2] ||| [function_1] node [arg_2]	count=3
function_arg	[function_1] op ||| [function_1] [arg_2]	count=3
arg	inputs and ||| inputs	count=2
class	of mod ||| mod	count=1
function	unroll the ||| gen conv code unroll	count=1
class	for corr3dmm ||| corr3d mm	count=1
module	list ||| gof	count=1
arg	[arg_1] leftdims ||| [arg_1] [arg_2]	count=2
arg	named ||| fullname	count=1
function	hash from ||| hash from	count=2
module_class	[module_1] type ||| [module_1] [class_2]	count=4
function	performs the matrix ||| matrix	count=1
class	type ||| clinker type	count=2
function	deepcopy ||| deepcopy	count=1
function	arccosine ||| arccos	count=2
function	list of shape tuple ||| default infer shape	count=1
function	sample from [function] distribution ||| [function]	count=1
function	make ||| make	count=2
function	that broadcast them to ||| generate broadcasting	count=1
function	it with logsoftmax x ||| local logsoftmax	count=1
arg	[arg_1] is the ||| [arg_2] [arg_1]	count=1
class	apply_nodes to this graph ||| graph	count=1
arg	input a 4-d ||| input patch_size	count=2
function	label of ||| label	count=1
function	the output shape ||| get out shape	count=2
module	inserting broadcasted ||| tensor	count=1
module	for ||| tensor	count=1
function_arg	[function_1] dimension axis ||| [arg_2] [function_1]	count=1
function	loop over several ||| loop	count=1
arg	the end ||| end	count=1
arg	old ||| check_integrity	count=1
function_arg	[function_1] inputs ||| [arg_2] [function_1]	count=5
class	the ||| gpu	count=2
module	that has ever ||| gof	count=1
function	litterals ||| make constant	count=1
function	bugs fixed [function] ||| warn [function]	count=2
function	to detect [function_2] ||| [function_2] [function_1]	count=1
function	the name ||| name	count=1
function	make [function_2] ||| [function_1] [function_2]	count=3
arg	node by ||| node	count=1
arg	[arg_1] a movie ||| [arg_1] [arg_2]	count=3
class	to this graph ||| graph	count=1
arg	of x the same ||| x	count=1
function	:func neibs2images ||| neibs2images	count=1
function	str ||| to str	count=1
arg	function ||| random_state n shape	count=1
function_arg	the [function_1] [arg_2] ||| [function_1] hook type [arg_2]	count=3
function	removes all asserts ||| remove all assert	count=1
function	[function_1] division inverse ||| [function_2] [function_1]	count=2
class	same kinds of ||| tensor	count=1
function_arg	[function_1] [arg_2] ||| [function_1] offset [arg_2]	count=9
arg	the outputs from the ||| outputs mode accept_inplace	count=1
arg	a basic theano ||| itypes otypes infer_shape	count=1
arg	input [arg_2] ||| [arg_2] [arg_1]	count=9
function	the *args directly ||| local csm properties csm	count=1
arg	return true if a ||| a	count=1
arg	[arg_1] navigatoroptimizer ||| [arg_2] [arg_1]	count=2
class	to the ||| gpu	count=1
function_arg	[function_1] on ||| [function_1] [arg_2]	count=9
class	replacement ||| replace validate	count=1
class	kinds of ||| type	count=1
arg	r to new_r ||| r	count=1
function_arg	[function_1] [arg_2] ||| [function_1] input [arg_2]	count=103
class	optionally inserting broadcasted dimensions ||| tensor py	count=1
arg	out_idxs ||| out_idxs	count=1
arg	if allow_override is ||| allow_override	count=1
function	dnn ||| dnn	count=2
function	a dictionary of arguments ||| args	count=2
module	c_extract that ||| gof	count=1
arg	not in [arg] i ||| seq1 [arg]	count=1
function	tensorvariable of this ||| make variable	count=1
function_arg	[function_1] a x ||| [function_1] y [arg_2]	count=1
class	finite fourier ||| fourier	count=1
function	optionally inserting ||| dimshuffle	count=1
function	a random ||| random	count=1
arg	still in the graph ||| replacements	count=1
arg	between low and high ||| size low high	count=1
arg	baddestroymap if ||| storage_map r_vals	count=1
function	standard deviation ||| std	count=1
function	a | ||| or	count=1
function	try to ||| try	count=1
arg	failure_callback [arg_2] ||| [arg_2] [arg_1]	count=1
function	version ||| c code cache version apply	count=2
function	computes the sum along ||| sum	count=1
function	for openblas ||| openblas	count=1
arg	along the specified axis ||| x axis sparse_grad	count=1
arg	of compilation flags ||| libs flags libs_dir include_dir	count=1
arg	similar behaviour as haskell's ||| fn sequences outputs_info non_sequences	count=1
arg	a and b ||| a b	count=5
function	[function_1] directories ||| [function_2] [function_1]	count=4
function	and should be removed ||| compress outs	count=1
function	batch normalization ||| batch normalization	count=2
function	nodes ||| nodes	count=2
function	[function_1] of convolution ||| [function_2] gradinputs [function_1]	count=2
function	it into a gemm ||| gemm	count=1
arg	node by one which ||| node output_indices alloc_ops	count=1
function	[function] sparsity ||| sp [function]	count=1
function	[function_1] on the ||| [function_2] [function_1]	count=4
class	variable ||| py	count=1
function	symbolic integer scalar ||| unpack	count=1
function	to choose ||| choose	count=1
class	same kinds of tensortype ||| type	count=1
function	leaf of a multiplication ||| leaf	count=1
arg	seq1 ||| seq1	count=1
function	comparator to represent the ||| cmp	count=1
function	normalization of the given ||| normalization	count=2
function	this to expm1 a ||| local expm1	count=1
function	view ||| view tree	count=1
arg	[arg] list ||| [arg]	count=3
function	complex [function_2] ||| [function_2] [function_1]	count=2
function	has only one client ||| only	count=1
arg	leftdims [arg_2] ||| [arg_2] [arg_1]	count=1
class	macros for use within ||| cop	count=1
function	overwrite the full ||| useless inc subtensor	count=1
function	[function_1] [function_2] sparse matrix ||| sparse [function_2] [function_1]	count=1
function	kinds of useless ||| useless	count=1
arg	low and ||| random_state size low	count=1
function	[function_1] helper_c_code ||| [function_2] [function_1]	count=2
arg	modulo of m1 ||| m1	count=1
arg	from existing start ||| start	count=1
function	into a canonical form ||| canonical form	count=1
function	2d ||| 2d	count=1
function	return full path of ||| module name from	count=1
arg	and y have the ||| y	count=1
function	convolution gradweights ||| get conv gradweights	count=2
class	reorder the dimensions ||| py	count=1
function	[function_1] a transfer ||| [function_2] [function_1]	count=1
class	data structures ||| non seq scan	count=1
arg	cost [arg_2] ||| [arg_2] [arg_1]	count=2
arg	[arg_1] cost ||| [arg_2] [arg_1]	count=2
arg	function drawing from ||| random_state n pvals size	count=1
class	variable optionally inserting ||| operators	count=1
arg	to the fgraph ||| fgraph	count=1
arg	structured elemwise maximum of [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
module	for same ||| tensor	count=1
function	return connection pattern of ||| connection pattern	count=1
function	safely compute ceil(float_division ||| ceil intdiv	count=1
function	[function_1] [function_2] ||| [function_2] can [function_1]	count=4
function	reorder ||| dimshuffle	count=1
function	the module initialization ||| init	count=1
function	the inner graph ||| validate inner graph	count=2
arg	n-d tensor where n ||| ws ignore_border stride	count=2
function	subtraction ||| sub	count=1
function	version used ||| gcc	count=1
function	[function] with the ||| as [function]	count=3
function	new node a clone ||| clone	count=1
function	specific to the apply ||| apply	count=1
module	of [module] variable ||| [module]	count=1
function	extract test value from ||| get test value	count=1
function	optional return [function_1] [function_2] required by code returned ||| [function_1] [function_2]	count=1
function	construct a variable with ||| variable	count=1
function	bitwise ~a inplace on ||| invert inplace	count=1
function	within the op ||| op	count=1
arg	a modulo ||| a	count=1
function	the topooptimizer from the ||| in2out	count=1
function	the [elementwise] largest ||| largest	count=1
function	left-padding [function] with ||| [function]	count=1
function_arg	of shape [arg_2] ||| [arg_2] [function_1]	count=4
arg	a simple algorithm ||| order reasons r_vals	count=1
module	for a constant that ||| gof	count=1
class	type ||| list type	count=1
function	removes ||| remove	count=1
function	upgrade ||| upgrade	count=1
function	the version ||| version	count=3
function	to ultra_fast_sigmoid ||| local ultra fast	count=1
function	be inserted at struct ||| struct	count=1
function	directory and return full ||| module name from dir	count=1
function	returns the connection ||| connection	count=1
function	stack trace ||| copy stack trace	count=2
arg	elements in [arg] which ||| [arg]	count=1
arg	n_ones ||| n_ones	count=1
function_arg	[function_1] target ||| [arg_2] [function_1]	count=1
arg	x with ||| x	count=1
function	new graph ||| clone with new inputs	count=1
function_arg	[function_1] fgraph this ||| [arg_2] [function_1]	count=2
function	elemwise ||| elemwise	count=1
arg	list remove [arg_2] ||| [arg_1] [arg_2]	count=1
function	accept complex ||| complex	count=1
module	that must be ||| gof	count=1
arg	to manipulate the ||| r new_r reason verbose	count=1
arg	[arg_1] a n-d ||| [arg_1] [arg_2]	count=2
function	for diagonalsubtensor and incdiagonalsubtensor ||| get diagonal subtensor view	count=1
arg	necessary update dr_vals ||| storage_map r_vals dr_vals	count=1
class	for ||| gpu dnn	count=1
function	(inplace on a) ||| inplace	count=12
function	of [function] sparsity pattern ||| sp [function]	count=1
function_arg	diff [arg_2] ||| [function_1] [arg_2]	count=1
function	shp -> alloc(unary x ||| local	count=1
arg	if ||| r_vals	count=1
function	merge multiplication by ||| alpha merge	count=2
function	the updates ordereddict ||| get updates	count=1
function	[function_1] scalar ||| [function_2] [function_1]	count=12
function	a clone in a ||| clone	count=1
module	compute the ||| nnet	count=6
arg	[arg_1] break aliasing ||| [arg_1] [arg_2]	count=3
arg	es of a ||| dtype op	count=1
arg	reshapes the output ||| output input leftdims rightdims	count=1
function	all sigmoid ||| sigmoid	count=1
function	in the flattened version ||| flatnonzero	count=1
arg	main interface to manipulate ||| r new_r reason verbose	count=1
function	input ||| pool 2d same size	count=1
function	of header [function_2] ||| [function_2] [function_1]	count=1
function	removes [function_2] ||| [function_1] [function_2]	count=5
arg	with the ignore_trees-related functionality ||| importer pruner chin	count=1
function	removes all ||| remove all	count=1
arg	reps ||| reps	count=1
arg	and t ||| node input_storage output_storage	count=1
module	functiongraph that has ever ||| gof	count=1
function	[function] translates ||| [function] subtensor of	count=1
function	the [function] ||| [function] with	count=1
arg	sharedvariable constructor for ||| value name strict allow_downcast	count=1
function	the confusion matrix ||| confusion matrix	count=2
class	compute ||| constant signature	count=1
class	to this graph ||| function graph	count=1
arg	type2 from type1 ||| type1 type2	count=3
function	conv output gradient w ||| conv3d grad	count=2
arg	drawing [arg_2] ||| [arg_2] [arg_1]	count=1
function	none or [function] replace node ||| [function]	count=1
function	a list to ||| gemm from factored list	count=1
class	variable optionally ||| py	count=1
function	to determine the broadcast ||| adv index broadcastable	count=1
function	a config [function_2] ||| [function_1] [function_2]	count=1
function	macos ||| macos	count=1
function	[function] sparsity pattern ||| sp [function]	count=1
class	cache or ||| cache	count=1
function	performs the svd ||| svd	count=1
function	following ||| global	count=1
function	outputs [function_2] ||| [function_2] [function_1]	count=4
function	division ||| int div	count=1
function	convert python ||| make constant	count=1
function	reorder the dimensions ||| dimshuffle	count=1
module	to output nodes of ||| gof	count=1
function	the context associated ||| get context	count=1
function_arg	!= [arg_2] ||| [function_1] inplace a [arg_2]	count=1
class	variable ||| operators	count=1
class	this variable optionally inserting ||| tensor	count=1
function	[function_1] inputs ||| [function_2] [function_1]	count=6
arg	on types of x ||| x	count=2
class	the navigator deal ||| navigator optimizer	count=1
function_arg	remove subtensor/advancedsubtensor1 [arg_2] ||| [arg_2] [function_1]	count=3
class	optionally ||| tensor py operators	count=2
function	return the idx_list with ||| idx	count=1
function	supplied function as its ||| as	count=1
arg	list of r ||| r client_to_remove	count=1
function_arg	svd on ||| svd a	count=1
arg	will match ||| var	count=1
arg	code ||| code	count=1
module	[module] the ||| [module]	count=3
module	and [module] a function ||| [module]	count=1
arg	according ||| inputs outputs cmps	count=1
function	stack trace from one ||| stack trace	count=1
class	of tensortype ||| tensor type	count=1
arg	x ||| x name	count=1
arg	low ||| low	count=1
function	multiplication ||| mul	count=2
arg	data to ||| data strict	count=1
function	trace to an ||| trace	count=1
arg	none ||| i_shapes	count=1
class	the ||| operators	count=1
function	arcsine ||| arcsin	count=1
function	kernels of shape ||| shape	count=1
function	batch normalization ||| dnn batch normalization	count=2
arg	fgraph outputs that ||| fgraph	count=1
arg	code ||| code filename	count=1
arg	end variables ||| end	count=1
function_arg	matrix inverse [arg_2] ||| [arg_2] [function_1]	count=1
arg	the outputs from ||| outputs	count=1
function	[function_1] [function_2] ||| [function_1] dot22 to [function_2]	count=1
function_arg	[function_1] [arg_2] utility ||| [function_1] [arg_2]	count=1
function	deepcopy in the ||| deepcopy	count=1
arg	given an fgraph ||| fgraph outputs_to_disown	count=1
arg	input a [arg_2] ||| [arg_1] [arg_2]	count=12
function_arg	new [arg_2] ||| [function_1] [arg_2]	count=6
function_arg	[function_1] encoding ||| [arg_2] [function_1]	count=5
class	by [class_2] ||| [class_2] [class_1]	count=6
function	name the ||| name	count=1
function	3-d ||| tensor3	count=1
function	use dnn ||| dnn	count=2
arg	vector and t ||| node input_storage output_storage	count=1
function	< ||| lt	count=1
class	of tensortype ||| type	count=1
arg	start gradients [arg_2] ||| [arg_2] [arg_1]	count=2
module	tabs ||| misc hooks	count=1
function	a triangular solve ||| solve triangular	count=1
function	[function_1] code ||| [function_2] [function_1]	count=17
arg	from a with or ||| size a	count=1
class	that represents their unification ||| unification	count=1
arg	function tries to ||| top_shape border_mode	count=4
arg	name ||| name opt	count=1
function	same ||| same	count=1
class	the type's ||| gpu	count=1
arg	as the template ||| template	count=1
function	return full path of ||| module name	count=1
arg	[arg_1] y ||| sparse structured maximum [arg_1] [arg_2]	count=2
function	sample from a uniform ||| uniform	count=1
function_arg	[function_1] and ||| [arg_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] inplace a [arg_2]	count=16
function	move constants into ||| constants	count=1
function	new ||| clone with new inputs	count=2
function_arg	>= [arg_2] ||| [arg_2] [function_1]	count=1
class	optionally ||| tensor py	count=1
function	extract list of variables ||| variables	count=1
function	the mflops ||| flops	count=1
function	convenience function to roll ||| roll	count=1
arg	of v by ||| v	count=1
function	return label [function_2] ||| [function_2] [function_1]	count=2
class	[class] which ||| [class]	count=2
module	compute 1d kernel for ||| nnet	count=1
function	execute ||| execute	count=1
arg	set of 2d filters ||| input filters	count=2
arg	sample a ||| size	count=1
arg	is no ||| node	count=2
class	inserting ||| py	count=1
class	of this ||| py	count=1
function	to make itself the ||| to os environ	count=1
function	min ||| min	count=1
function	converts ||| from	count=1
function	openblas threads [function_2] ||| [function_1] [function_2]	count=1
function	canonical form ||| canonical form	count=1
function	variable on ||| as gpuarray variable	count=2
function_arg	a new [arg_2] ||| [function_1] [arg_2] tag dtype	count=1
function	if ||| gcc	count=1
function	x -> sigm -x ||| local	count=1
function	removes all ||| local remove all	count=2
module	is sparse ||| sparse	count=2
arg	[arg_1] a leftdims ||| [arg_2] [arg_1]	count=3
arg	[arg_1] start ||| [arg_2] [arg_1]	count=2
arg	input vector and t ||| node input_storage output_storage	count=1
arg	r [arg_2] ||| [arg_2] [arg_1]	count=1
arg	inputs [arg_2] ||| [arg_1] [arg_2] features clone	count=1
class	scan return true ||| out scan	count=1
arg	tries to ||| top_shape border_mode	count=4
function	of the last access ||| last access	count=1
function	get the right values ||| get	count=1
arg	start gradients up to ||| start	count=1
function	connection pattern of a ||| io connection pattern	count=1
function	dot a ||| dot	count=1
function	some requirements to the ||| requirements	count=1
function	idx [function_2] ||| [function_1] [function_2]	count=1
arg	change the value after ||| default filter	count=1
function	gpuincsubtensor ||| inplace setsubtensor	count=2
function	returns the signature for ||| method decl	count=1
arg	value after ||| default filter	count=1
module	the input nodes to ||| gof	count=1
arg	i [arg_2] ||| [arg_2] [arg_1]	count=1
function	convert addsd ||| local addsd	count=1
function	triangular solve ||| solve triangular	count=1
function	contains a ||| contains	count=1
function	inputs [function_2] ||| [function_2] [function_1]	count=1
arg	"kshp" ||| inshp kshp stride mode	count=1
class	broadcasted dimensions ||| py operators	count=1
arg	[arg] and ||| v o [arg]	count=3
function	the last access ||| last access	count=1
module	returns function to run ||| gof	count=1
function	reintroduces in ||| make keep dims	count=1
arg	[arg_1] n ||| [arg_1] [arg_2]	count=1
class	the same type ||| list type	count=1
function	with debug ||| with	count=1
arg	baddestroymap if ||| node	count=1
function	from [function] ||| [function]	count=1
function	returns the connection pattern ||| connection pattern	count=1
function_arg	[function_1] [arg_2] ||| [function_1] can remove outs [arg_2]	count=8
arg	raise baddestroymap if ||| node	count=1
function	symbolic row variable ||| row	count=1
function	the output dimensions of ||| get output	count=1
module	[module] a ||| [module]	count=1
function	max ||| local max	count=1
function	use dnn ||| safe no dnn	count=2
arg	along the given axis ||| axis	count=6
class	split x ||| split	count=1
arg	an ||| node	count=4
function	wrapper around sparsevariable constructor [function_1] [function_2] the same dtype and ||| sparse [function_2] [function_1]	count=1
class	[class] estimate ||| numeric [class]	count=1
function	make a schedule ||| sort schedule	count=1
function	header for openblas ||| openblas	count=1
arg	structured elemwise minimum of [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
function	set ||| set	count=2
function	constant inputs to ||| constant inputs	count=2
function	updates ||| get updates	count=1
function	cudnn ||| dnn	count=3
arg	[arg_1] n ||| [arg_2] [arg_1]	count=1
function	it with a triangular ||| triangular	count=1
module	of this variable optionally ||| tensor	count=1
function	sum ||| sum	count=4
function	inputs to ||| inputs	count=1
function	a cache directory ||| dir	count=1
function_arg	[function_1] op ||| [function_1] outs [arg_2]	count=1
function	a triangular [function_2] ||| [function_2] [function_1]	count=2
function_arg	shape [arg_2] ||| [function_1] node [arg_2]	count=2
function	of shape tuple ||| default infer shape	count=1
arg	kind of order v ||| v x	count=2
arg	y ||| y axis	count=1
arg	return ||| name x	count=1
class	a new random ||| random	count=1
arg	v raises attributeerror ||| v	count=1
function	of this variable optionally ||| dimshuffle	count=1
function_arg	to roll [arg_2] ||| [arg_2] [function_1]	count=2
function	of lib directories that ||| header dirs	count=1
arg	function ||| random_state low high size	count=1
function	convolution ||| conv	count=6
function	gives unique names to ||| names	count=1
arg	addition ||| out_in	count=1
function_arg	[function_1] [arg_2] ||| [function_1] a [arg_2]	count=5
class	for corrmm (direction="forward"), ||| base corr mm	count=1
arg	a specified ||| a	count=1
function	only on cpu here ||| pow specialize	count=1
module	this function compute ||| nnet	count=2
function	in a new graph ||| new	count=1
function	alloc of 0 ||| alloc	count=1
class	apply_nodes to this graph ||| function graph	count=1
function	wrapper around sparsevariable constructor [function_1] [function_2] with the same dtype ||| sparse as [function_2] [function_1]	count=1
function	graph have a stack ||| check stack	count=1
function	with ||| dims	count=1
arg	u [arg_2] ||| [arg_2] [arg_1]	count=8
function	print the following stats ||| print global stats	count=1
function	make a nested loop ||| make loop	count=1
function	tensorvariable ||| make variable	count=1
module_class	of this type ||| gof cdata type	count=1
function	detect a [function_2] ||| [function_2] [function_1]	count=1
arg	sample n (n ||| size n	count=2
module	code for [module] ||| [module]	count=1
function	argmin ||| argmin	count=1
function	object with debug ||| with	count=1
function	gradient is ||| grad	count=1
function	argmax [function_2] ||| [function_2] [function_1]	count=4
function	wrt, ||| subgraph	count=1
class	to the ||| gpu array	count=1
arg	from the shape ||| shape	count=1
arg	required return the ||| name	count=1
function	idx [function_2] ||| [function_2] [function_1]	count=1
function_arg	[function_1] was dumped ||| [function_1] [arg_2]	count=1
function	return a function that ||| function	count=1
module	that ||| gof	count=28
function	with the *args directly ||| local csm properties csm	count=1
arg	equivalent of var ||| var	count=1
class	structures ||| push out non seq scan	count=1
function	[function_1] to extract ||| [function_2] [function_1]	count=1
arg	spatio-temporal filters [arg_2] ||| [arg_1] [arg_2]	count=1
arg	[arg_1] outputs ||| [arg_1] [arg_2] features clone	count=3
function	lock ||| lock	count=1
function	roll ||| roll	count=1
function	parse ||| parse	count=1
arg	by given inputs and ||| inputs	count=1
function	only one client ||| sitsot only	count=1
function_arg	of variables [arg_2] ||| [arg_2] [function_1]	count=1
function	get a ||| get	count=1
function_arg	of a sparse [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
function	broadcast pattern ||| pattern	count=1
arg	this function tries ||| top_shape border_mode subsample	count=4
class	broadcasted dimensions ||| operators	count=1
arg	the outputs of node ||| node	count=1
function	find broken optimizations ||| find	count=1
function	used to determine ||| adv index broadcastable	count=1
function	the struct [function_2] ||| [function_2] code [function_1]	count=1
function	inner nit_sot output of ||| inner	count=1
function	simplify a ||| simplify	count=1
function_arg	[function_1] fgraph ||| [function_1] [arg_2]	count=5
arg	of var ||| var	count=2
function_arg	insert deepcopy [arg_2] ||| [arg_2] [function_1]	count=5
function	sigmoid to ultra_fast_sigmoid ||| local ultra fast sigmoid	count=1
arg	drawing [arg_2] ||| [arg_1] [arg_2]	count=1
arg	shape or the ||| shape	count=1
class	optionally inserting broadcasted ||| tensor	count=1
function_arg	new instance of ||| clone link_kwargs optimizer	count=2
arg	existing start gradients ||| start	count=1
class	cache directory structure ||| module cache	count=1
function	of this op ||| op	count=1
arg	true if a ||| a	count=1
module	to move [module] computation ||| [module]	count=1
function	/ [function_2] ||| [function_2] [function_1]	count=1
arg	the outputs ||| outputs	count=2
function	module from the ||| module from	count=2
arg	inputs replaced by ||| inputs allow_partial only_process_constants elemwise	count=1
function	[function_1] to ultra_fast_sigmoid ||| [function_2] [function_1]	count=8
function	name ||| name	count=1
function	return the platform-dependent ||| get	count=1
arg	a modulo of m1 ||| m1	count=1
function	form ||| form	count=1
function_arg	subtensor [arg_2] ||| [arg_2] [function_1]	count=3
function	create a new ||| clone	count=2
arg	input to ||| input	count=1
function_arg	sum [arg_2] ||| [function_1] input [arg_2]	count=5
class	for corrmm ||| corr mm	count=1
arg	reshapes the output ||| output	count=1
arg	expression ||| x	count=1
function	the batch size ||| batch	count=1
arg	a ||| a replace p	count=1
arg	[arg_1] haskell' ||| [arg_1] [arg_2]	count=1
function_arg	fill a ||| second inplace a	count=1
class	context_name ||| gpu array type	count=1
arg	that was dumped to ||| f persistent_load	count=1
function	[function_1] reshape ||| [function_2] [function_1]	count=4
function	from [function_2] ||| [function_2] can [function_1]	count=1
function	into a canonical ||| canonical	count=1
function	[function_1] bug ||| [function_2] [function_1]	count=3
function	apply the list ||| apply	count=1
function_arg	the svd [arg_2] ||| [arg_2] [function_1]	count=2
class	for corrmm (direction="forward"), corrmm_gradweights ||| base corr mm	count=1
module	abstractconv(gpu_from_host) ||| gpuarray	count=1
function	has [function_2] ||| [function_1] [function_2]	count=2
arg	[arg_1] from ||| [arg_2] [arg_1]	count=2
class	the dimensions of this ||| py operators	count=1
function	convert addsd ||| local addsd ccode	count=1
function	of useless reshape ||| local useless reshape	count=2
class	optionally inserting ||| operators	count=1
function_arg	[function_1] x is ||| [function_1] [arg_2]	count=1
function	add some requirements ||| add requirements	count=2
arg	x and y have ||| x y	count=1
function	[function_1] [function_2] and ||| [function_1] [function_2]	count=2
function	offers to make itself ||| to os environ	count=1
arg	[arg_1] [arg_2] ||| [arg_1] a [arg_2]	count=1
function	modifies input ||| give	count=1
module	c_init that ||| gof	count=1
arg	to r to ||| r	count=1
function	a hash ||| hash	count=1
class	of this variable ||| operators	count=1
arg	list remove are still ||| fgraph replacements remove reason	count=1
function	correspond to the one ||| one	count=1
arg	an unification where [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=7
function	broadcast pattern for ||| pattern	count=1
function	returns upper bound on ||| bound	count=1
function	to generate permutations from ||| permutation	count=1
function	upcasts constant inputs to ||| constant inputs	count=1
function	some requirements ||| requirements	count=1
function	a list to ||| factored list	count=1
arg	filters ||| input filters	count=3
function	[function_1] from the ||| [function_1] [function_2]	count=3
arg	check [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=4
function	modified bessel function ||| i1	count=1
module	list of nodes that ||| gof	count=1
function	modified bessel function ||| i0	count=1
function	a list to ||| from factored list	count=1
function	generate c ||| specify shape c	count=1
function	hash [function_2] ||| [function_1] [function_2]	count=1
arg	x to be between ||| x	count=1
function	a leaf of a ||| leaf	count=1
function	get ||| get depth	count=1
function	new variable ||| new	count=1
module_class	if this enum ||| gof enum type	count=1
function	output for ||| output	count=1
arg	[arg_1] min and ||| [arg_2] [arg_1]	count=1
function	[function_1] elemwise ||| [function_2] constant [function_1]	count=1
function	make a [function_2] ||| [function_2] [function_1]	count=4
module	uses ||| gof	count=1
function	litterals ||| make	count=1
arg	to a leftdims ||| leftdims	count=1
arg	compilation flags from config ||| libs flags libs_dir include_dir	count=1
function	computes the output dimensions ||| output	count=1
function	python litterals to ||| make	count=1
function	the standard deviation ||| std	count=1
class	navigator deal with ||| navigator	count=1
arg	called by ||| function_graph	count=1
function	replace a [function_2] ||| [function_2] [function_1]	count=4
class	shared variable ||| shared variable	count=2
module	to ||| gof	count=1
module	a that ||| gof	count=1
function_arg	of 3d [arg_2] ||| [function_1] [arg_2]	count=1
function	and the ||| and	count=1
function	the thunk ||| thunk	count=1
function	last access ||| last access time	count=2
arg	return true [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
function	litterals ||| constant	count=1
arg	out_shape ||| out_shape	count=1
function	variable ||| variable	count=4
class	apply instance ||| apply	count=2
function	time icluding the ||| times	count=1
arg	x and [arg_2] ||| [arg_2] [arg_1]	count=3
function	return indices ||| indices	count=1
function	search ||| search	count=1
function_arg	form that [arg_2] ||| [function_1] slice [arg_2]	count=1
arg	name r [arg_2] ||| [arg_1] [arg_2]	count=1
arg	still in the ||| fgraph replacements	count=1
function	gpuincsubtensor ||| setsubtensor	count=1
arg	return ||| name sub check_input	count=1
function	list of shape ||| infer shape	count=1
arg	node ||| node output_indices	count=1
class	to ||| gpu array type	count=1
module	the dimensions of ||| tensor	count=1
class	[class_1] stream ||| [class_1] [class_2]	count=10
function	at struct ||| struct	count=1
class	optionally inserting broadcasted dimensions ||| py operators	count=1
function	threads [function_2] ||| [function_1] [function_2]	count=1
function	only ||| only	count=1
arg	to manipulate ||| r new_r reason verbose	count=1
arg	the specified axis ||| x axis sparse_grad	count=2
arg	dimensions of x ||| x	count=1
module	that node inputs[i] is ||| gof	count=1
function	raise baddestroymap ||| check inputs	count=1
function	search ||| stack search	count=1
function_arg	the scan [arg_2] ||| [function_1] can remove outs [arg_2]	count=4
class	[class] of the ||| structured [class]	count=3
function_arg	[function_1] [arg_2] ||| [function_1] 1d [arg_2]	count=2
class	for a convolution with ||| gpu dnn conv	count=1
arg	iff other is ||| other	count=1
function_arg	a new instance ||| clone link_kwargs optimizer	count=2
function	and return ||| name from	count=1
function	the parents ||| parents	count=1
function	|a| ||| abs	count=1
arg	raise baddestroymap if ||| node storage_map r_vals	count=1
arg	function computes ||| ishape kshape border_mode	count=1
arg	[arg_1] still in ||| [arg_2] [arg_1]	count=9
arg	filters [arg_2] ||| [arg_1] [arg_2]	count=1
function	the op code ||| op params	count=1
function	context associated with a ||| context	count=1
function	return the [elementwise] smallest ||| smallest	count=1
function	a thunk ||| thunk	count=2
function	return a [function_2] ||| [function_1] [function_2]	count=1
function	the scan ||| scan	count=1
function	function to get ||| get depth	count=1
function	constant inputs ||| constant inputs	count=2
arg	along the specified ||| sparse_grad	count=1
function	or [function] replace ||| [function]	count=1
function	important note ||| process node	count=2
class	the type's :attr context_name ||| gpu	count=1
function	the g++ ||| gcc	count=1
module	scalar op ||| scalar	count=2
function	one [function_2] ||| [function_2] [function_1]	count=1
arg	fn ||| fn	count=1
arg	structured elemwise minimum of [arg_1] [arg_2] ||| sparse structured minimum [arg_1] [arg_2]	count=1
module	of a ||| tensor	count=3
function	inner graph [function_2] ||| [function_2] [function_1]	count=2
class	of scan return ||| push out scan	count=1
function	move constants into the ||| constants	count=1
function	trace to an node ||| trace	count=1
arg	return a ||| name	count=6
arg	the fgraph outputs ||| fgraph expanded_inputs	count=1
function_arg	warn about bugs fixed [function_1] [arg_2] ||| core warn [function_1] [arg_2]	count=3
arg	* y ||| y	count=1
function_arg	deepcopy in [arg_2] ||| [arg_2] [function_1]	count=5
function_arg	shape [arg_2] ||| [function_1] [arg_2]	count=3
class	the type's :attr ||| array	count=1
arg	should return an ||| node name	count=2
class	of ||| tensor type	count=1
function	with respect to wrt, ||| subgraph grad	count=1
function	determine the [function_2] ||| [function_1] [function_2]	count=3
function	the inner graph to ||| validate inner graph	count=1
class	[class_1] the eigensystem ||| [class_2] [class_1]	count=2
function	removes useless [function_2] ||| [function_1] [function_2]	count=1
function	module ||| module	count=2
function	given a inner ||| inner	count=1
function	standard deviation along the ||| std	count=1
arg	apply_node recursively search from ||| apply_node check reason	count=1
function	tensor from [function_2] ||| [function_2] [function_1]	count=1
function	list of libraries ||| libraries	count=1
function	of lib [function_2] ||| [function_1] [function_2]	count=4
function	leaf ||| leaf	count=1
class	merge ||| seq optimizer	count=1
function	the name the object ||| name	count=1
function	add some requirements to ||| add requirements	count=1
arg	function to ||| random_state low high size	count=1
arg	s [arg_2] ||| [arg_2] [arg_1]	count=1
function	represent the dependence of ||| dependence	count=1
function_arg	mean value [arg_2] ||| [arg_2] [function_1]	count=6
function	this op could be ||| op	count=1
function	context ||| reg context	count=1
function	a stack ||| stack	count=1
function	of suitable dummy values ||| provide	count=1
arg	es of a tensor ||| dtype keepdims	count=1
function_arg	[function_1] x to ||| [arg_2] [function_1]	count=2
arg	[arg_1] [arg_2] ||| [arg_2] y [arg_1]	count=1
function	in ||| in	count=1
class	matrix ||| structured	count=1
module	a that would ||| gof	count=1
arg	symbolic ||| ndim dtype	count=1
arg	v ||| v x	count=2
arg	if a [arg_2] ||| [arg_2] [arg_1]	count=1
arg	[arg_1] movie ||| [arg_1] [arg_2]	count=2
function	have the same ||| same	count=1
function	1 0/a ||| inv	count=1
function	openmp ||| openmp	count=1
arg	if [arg] ||| [arg]	count=2
function	graph to ensure ||| graph	count=1
function_arg	sum along [arg_2] ||| [arg_2] [function_1]	count=6
class	function ||| function	count=1
arg	type1 ||| type1	count=1
function	offers to ||| to os environ pathlist	count=1
arg	outputs from the inputs ||| inputs outputs mode	count=1
function	clone ||| clone	count=3
class	shape ||| shape	count=2
function	indicating the version ||| c code cache version apply	count=1
arg	and dtype as the ||| dtype	count=1
class	optionally inserting broadcasted dimensions ||| tensor	count=1
function	inverse ||| inverse	count=1
function	after a ||| default	count=1
arg	a symbolic ||| name dtype	count=3
class	to the type's ||| gpu array	count=1
function	a module from the ||| module from	count=1
arg	node by one ||| node output_indices	count=1
function_arg	[function_1] specified ||| [arg_2] [function_1]	count=3
module	of sparse ||| sparse	count=1
function	wrapper around sparsevariable constructor [function_1] [function_2] the same dtype and ||| [function_2] [function_1]	count=1
arg	and uses it ||| o	count=1
class	eigensystem ||| eigh	count=1
arg	function to ||| random_state a	count=1
function	within the op code ||| op params	count=1
function	important note this ||| process node	count=2
module	for scalar values default ||| scalar	count=1
arg	return a symbolic ||| ndim dtype	count=1
function	[function_1] multiplication ||| [function_2] [function_1]	count=5
function_arg	[function_1] tensortypes ||| [arg_2] [function_1]	count=4
arg	the value after ||| default	count=1
function	to draw random integers ||| random integers	count=1
module	a function that ||| gof	count=1
arg	a variable ||| a	count=1
function	a new ||| clone with new	count=1
function	comparator [function_2] ||| [function_2] [function_1]	count=2
function	[function_1] dot ||| [function_2] [function_1]	count=1
function	the ||| gcc	count=2
class	of this ||| py operators	count=1
function	tensorvariable whose ||| as	count=1
arg	exception while annotating ||| thunk exc_info storage_map	count=1
function	max ||| max	count=2
module	compute 2d kernel for ||| tensor nnet	count=1
arg	is inside ||| node	count=2
function	gradient ||| conv2d grad	count=1
class	random ||| random streams base	count=1
module	return ||| tensor	count=2
function	an [advanced]incsubtensor[1], whose increment ||| local useless inc subtensor	count=1
function_arg	dimshuffle [arg_2] ||| [function_1] [arg_2]	count=1
function	offers to make itself ||| to os	count=1
function	shape that broadcast them ||| generate broadcasting	count=1
module	graph ||| gof	count=1
function	batch normalization of ||| dnn batch normalization	count=2
function	images2neibs <theano tensor ||| images2neibs	count=1
module_class	[module_1] apply instance ||| [module_1] [class_2] clone	count=1
function	apply as ||| apply	count=1
arg	given axis es of ||| axis dtype keepdims	count=1
arg	navigatoroptimizer ||| nav repl_pairs local_opt	count=2
function	of this op could ||| op	count=1
arg	function to ||| random_state n shape	count=1
function	a multinomial ||| multinomial	count=1
function	within the op code ||| get op	count=1
function_arg	a scan [arg_2] ||| [arg_2] [function_1]	count=5
function	[function] replace ||| [function]	count=2
class	:attr context_name ||| type	count=1
arg	a symbolic ||| dtype	count=3
function	package ||| package	count=1
function	image [function_2] ||| [function_2] [function_1]	count=8
function	use ||| use	count=1
module	check that 1) this ||| gof	count=1
function	1d [function_2] ||| [function_2] [function_1]	count=6
class	dictionary data structures ||| non seq	count=1
function	a triangular ||| triangular	count=1
arg	tries to ||| image_shape top_shape border_mode subsample	count=2
class	type's :attr context_name ||| gpu array type	count=1
arg	the output ||| output input leftdims rightdims	count=1
function	update self rstate to ||| rstate	count=1
module	tensortype ||| tensor	count=1
function	a stack ||| check stack	count=1
function	[function_1] and only ||| [function_2] [function_1]	count=2
function	constant inputs [function_2] ||| [function_2] [function_1]	count=2
arg	this function tries to ||| image_shape top_shape border_mode	count=2
arg	type2 [arg_2] ||| [arg_2] [arg_1]	count=2
class	raise ||| raise	count=1
arg	encoding of each ||| nb_class dtype	count=1
arg	[arg] sets ||| inputs [arg] features	count=1
function	matrix along the ||| sp	count=1
function_arg	and the [arg_2] ||| [arg_2] [function_1]	count=2
function	function to get the ||| get	count=1
arg	of v ||| v	count=1
arg	first half of v ||| v	count=1
arg	still in the graph ||| fgraph replacements	count=1
arg	(comma-separated key=value components) into ||| config_string issue_warnings	count=1
function	context associated with ||| context	count=1
function	generate c ||| i c	count=1
function	parents ||| parents	count=1
function	use [function] ||| local max and [function]	count=1
function	this convert allocempty to ||| empty to zeros	count=1
arg	sample from ||| random_state size n	count=1
arg	required return ||| node name	count=1
arg	are [arg_2] ||| [arg_2] remove [arg_1]	count=4
arg	computes the ||| ishape kshape border_mode	count=1
function	helper ||| diagonal	count=1
arg	the inputs [arg_2] ||| [arg_2] [arg_1]	count=1
function	[function_1] a transfer ||| [function_1] [function_2]	count=1
arg	[arg_1] sub ||| [arg_1] [arg_2]	count=2
function	on ||| gpuarray	count=1
function	op could ||| op	count=1
function	deepcopyop how to generate ||| deep copy op	count=1
module	output nodes of ||| gof	count=1
function	[function_1] [function_2] replaced according to 'replacer' ||| [function_1] [function_2]	count=1
arg	with a name ||| name	count=1
arg	list of r ||| r	count=1
function_arg	a multiplication [arg_2] ||| [function_1] [arg_2]	count=1
arg	given axis es ||| axis dtype keepdims	count=2
arg	axis that was used ||| inputs g_outputs	count=1
arg	an array with ||| node inputs	count=2
class	type's ||| array type	count=1
function	[function_1] pattern for ||| [function_2] [function_1]	count=2
arg	or none ||| i_shapes	count=1
function	bitwise ~a [function_2] ||| [function_1] [function_2]	count=1
function	post some ||| post	count=1
function	recognize the updates ordereddict ||| updates	count=1
function	none or [function] replace ||| [function]	count=1
function	the updates ||| get updates	count=1
arg	[arg] from both ||| num [arg]	count=1
class	by an op ||| clinker op	count=2
arg	this function tries to ||| top_shape	count=4
arg	a given version ||| version	count=1
arg	of cost and/or from ||| cost	count=1
arg	function tries to ||| top_shape border_mode subsample	count=4
arg	indices out_idxs and ||| out_idxs	count=1
function	op ||| op params	count=1
function	version ||| version	count=3
function	the struct ||| struct	count=1
arg	variables in inputs ||| inputs	count=1
function	change all sigmoid to ||| sigmoid	count=1
module	g++ version ||| gof	count=1
function	default that removes ||| local remove	count=1
function	to a max ||| max	count=1
function	and ||| format as	count=1
class	this type ||| pure type	count=1
function	g++ version used ||| gcc	count=1
arg	the var ||| var	count=1
function	given a inner nit_sot ||| inner	count=1
function_arg	>= [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function	has [function_2] ||| [function_2] [function_1]	count=2
module	a [module] ||| [module]	count=1
function_arg	[function_1] conventions imposed ||| [arg_2] [function_1]	count=5
arg	in the original graph ||| inputs outputs copy_inputs_and_orphans memo	count=1
function	use with helper_c_code ||| get helper c code	count=1
class	of type ||| type	count=2
function	the compilation of cutils_ext ||| compile cutils	count=1
function	is a [function_2] ||| [function_2] [function_1]	count=1
class	this mode ||| mode	count=2
function_arg	transfer [arg_2] ||| [arg_2] [function_1]	count=4
class	same kinds of tensortype ||| tensor type	count=1
arg	value has ||| value trace	count=1
function	exception object with ||| raise with	count=1
function	loop executes code ||| reordered loop	count=1
class	random ||| random	count=3
module	of [module] ||| [module]	count=1
function	platform-dependent [function_2] ||| [function_1] [function_2]	count=2
arg	of type dtype ||| dtype	count=1
class	the ||| py	count=1
module	a dictionary that ||| gof	count=1
class	for the shape element ||| shape feature	count=1
arg	a to radian ||| a	count=1
function	replace ||| replace	count=1
function_arg	[function_1] return ||| [function_1] support code struct [arg_2]	count=1
function_arg	variables [arg_2] ||| [function_1] orphans [arg_2]	count=1
function	access ||| access	count=1
function	of [function] sparsity ||| sp [function]	count=1
function	[function_1] string ||| [function_2] [function_1]	count=3
function	of apply nodes ||| sort apply nodes	count=2
function	left-padding [function] ||| [function]	count=1
function	platform-dependent ||| get	count=1
class	structures ||| push out non seq	count=1
function	a sparse matrix of [function_1] [function_2] ||| sparse sp [function_1] [function_2]	count=2
module_class	of [module_1] [class_2] ||| [module_1] [class_2]	count=8
function	arcsinh ||| arcsinh	count=1
class	of this variable optionally ||| py operators	count=1
arg	input a n-d tensor ||| input ws ignore_border stride	count=2
function	upcasts constant [function_2] ||| [function_2] [function_1]	count=2
function	indicating the version ||| cache version apply	count=1
function	[function_1] initialization ||| [function_2] code [function_1]	count=4
function	the topooptimizer from ||| in2out	count=1
function	a cache directory ||| from dir	count=1
function	or a tensorvariable ||| as	count=1
arg	sample from ||| size	count=1
function	deepcopyop how ||| deep copy op	count=1
class	dictionary data structures ||| push out non seq	count=1
function	the one hot ||| to one hot	count=2
function_arg	matrix along [arg_2] ||| sparse [function_1] sum x axis [arg_2]	count=1
module	and only if this ||| gof	count=1
arg	remove are still in ||| fgraph replacements remove reason	count=1
module	compute 2d ||| nnet	count=1
arg	flags from ||| flags	count=1
function	of library search paths ||| lib dirs	count=1
class	other implementation of mod ||| mod	count=1
function	+ alpha * dot ||| gemv	count=1
class	dimensions of this ||| operators	count=1
function_arg	exception [arg_2] ||| [function_1] hook type [arg_2]	count=3
function	get the ||| get depth	count=1
arg	[arg_1] b ||| unify walk [arg_1] [arg_2]	count=1
function	the apply to ||| apply	count=1
function_arg	multiplication tree ||| mul tree	count=1
class	level of the list ||| list type	count=1
module	inputs that are ||| gof	count=1
class	mrg stream state ||| mrg random streams	count=2
function	generate permutations from ||| permutation	count=1
function	a variable [function_2] ||| sparse [function_2] [function_1]	count=2
arg	standard deviation std ||| std ndim	count=1
function_arg	[function_1] return ||| [function_1] support code apply [arg_2]	count=1
arg	denum removes ||| denum	count=1
function	op that will call ||| op	count=1
function	-a [function_2] ||| [function_2] [function_1]	count=1
function	return [function] ||| c [function]	count=2
function_arg	shape [arg_2] ||| [function_1] padleft [arg_2]	count=1
arg	dimensions of x ||| x axes	count=1
module_class	[module_1] [class_2] ||| [module_1] [class_2]	count=31
function	that removes ||| remove	count=1
function	[function_1] shape ||| [function_1] [function_2]	count=6
function	access of ||| access time	count=1
arg	gets a scan op ||| op not_required inputs	count=1
arg	min and [arg_2] ||| [arg_2] [arg_1]	count=1
function	how to generate c ||| shape c	count=1
function	[function_1] [function_2] b [idxs] into t ||| [function_1] [function_2]	count=2
function	diagonal ||| diagonal	count=1
module	this is ||| tensor nnet	count=1
arg	[arg_1] cpu ||| [arg_2] [arg_1]	count=1
function	orphans among them ||| orphans	count=1
function	transfer ||| transfer	count=2
arg	r ||| r client_to_remove reason	count=1
function_arg	[function_1] v raises ||| [function_1] [arg_2]	count=1
class	dimensions of this variable ||| operators	count=1
arg	specified [arg_2] ||| [arg_2] [arg_1]	count=2
arg	outputs from the inputs ||| inputs outputs mode accept_inplace	count=1
function	how [function] is ||| [function]	count=1
module	parameter as other scalar ||| scalar	count=2
function	to wrt, ||| subgraph	count=1
class	stream state and they ||| random streams	count=1
arg	[arg_1] a n-d ||| [arg_2] [arg_1]	count=2
arg	if a [arg_2] ||| [arg_1] [arg_2]	count=1
arg	structured elemwise maximum of [arg_1] [arg_2] ||| sparse structured maximum [arg_1] [arg_2]	count=1
function	[function] replace node ||| [function]	count=2
class	optionally ||| tensor	count=1
function	comparator to ||| cmp	count=1
function	deepcopyop how [function_2] ||| [function_1] [function_2]	count=1
function	sum(a axis=[]) ||| useless reduce	count=1
arg	wrt to wrt ||| wrt	count=2
arg	to a ||| a	count=1
module	this ||| nnet	count=1
arg	[arg_1] input ||| [arg_2] [arg_1]	count=21
class	navigator deal with the ||| navigator optimizer	count=1
function	the shape ||| set shape	count=1
class	and dictionary data structures ||| out non seq	count=1
class	broadcasted dimensions ||| py	count=1
function	[function_1] leaf ||| [function_2] [function_1]	count=2
arg	fgraph ||| fgraph outputs_to_disown	count=1
function_arg	the inputs [arg_2] ||| [function_1] [arg_2]	count=4
function	to merge multiplication by ||| alpha merge	count=1
function	blas ||| blas	count=1
function	diagonalsubtensor ||| diagonal subtensor view	count=2
function	add a ||| add	count=2
function	the output error ||| output	count=1
arg	[arg_1] min and ||| [arg_1] [arg_2]	count=1
function_arg	[function_1] given axis ||| [function_1] input [arg_2]	count=4
module	nodes of ||| gof	count=1
arg	bound by the inputs ||| inputs	count=1
arg	return true if [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=2
function	return label of apply ||| apply label	count=1
function	context object mapped ||| context	count=1
function	same shape ||| same shape	count=1
function	[function_1] full ||| [function_2] [function_1]	count=8
module	to move [module] computation to ||| [module]	count=1
module	that will be instantiated ||| gof	count=1
function	performs batch normalization of ||| batch normalization	count=2
arg	raise baddestroymap if ||| r_vals	count=1
class	variable optionally inserting ||| tensor py operators	count=1
arg	2d filters ||| filters	count=2
arg	between min ||| min	count=1
class	for same kinds of ||| type	count=1
function	performs the matrix inverse ||| matrix inverse	count=1
function	bitwise a | ||| or	count=1
function	c ||| c	count=13
arg	fgraph [arg_2] ||| [arg_2] [arg_1]	count=2
function	determine the name ||| name	count=1
function	return connection [function_2] ||| [function_2] [function_1]	count=4
function	string ||| patterns	count=1
function	of headers that ||| headers	count=1
function	of header [function_2] ||| object c [function_1] [function_2]	count=1
class	of scan return ||| out scan	count=1
function	multinomial distributions defined by ||| multinomial	count=1
function	has this ||| has	count=1
module_class	if this [class_2] ||| [module_1] [class_2]	count=8
module	that operates on ||| gof	count=1
class	:attr ||| gpu	count=1
arg	[arg_1] a ||| [arg_2] [arg_1]	count=5
function	py_none ||| init	count=1
module_class	of this node ||| gof node	count=1
function_arg	[function_1] s ||| [arg_2] [function_1]	count=3
arg	data ||| data strict	count=1
function_arg	[function_1] version ||| core [function_1] [arg_2]	count=2
class	for same kinds of ||| tensor type	count=1
function	argsort ||| argsort	count=1
function	[function_1] asserts ||| [function_1] [function_2]	count=5
arg	this should return an ||| node name	count=1
class	dictionary data structures ||| non seq scan	count=1
function	prod(prod()) -> [function_2] ||| [function_1] [function_2]	count=1
arg	variable from x ||| x	count=1
arg	we do it ||| node	count=1
class	the type's :attr context_name ||| gpu array type	count=1
class	broadcasted ||| py	count=1
class	is a mrg ||| mrg	count=1
arg	[arg_1] with a ||| [arg_2] [arg_1]	count=8
arg	used to upsample ||| ratio normalize	count=2
class	structures ||| non seq scan	count=1
function	the output dimensions of ||| output	count=1
function_arg	to wrt, [arg_2] ||| [function_1] wrt end start [arg_2]	count=1
arg	is inside a ||| node	count=1
function	on cpu here ||| pow specialize	count=1
arg	outputs from ||| outputs	count=1
function	label ||| label	count=1
function_arg	convert degree [arg_2] ||| [function_1] [arg_2]	count=3
arg	an input vector and ||| node input_storage output_storage	count=1
module	c_cleanup that ||| gof	count=1
function	[function_1] transfer ||| [function_1] [function_2]	count=1
function	that unroll [function_2] ||| [function_1] [function_2]	count=3
function	op whose incoming ||| softmax 1hot	count=1
function	unify ||| unify	count=1
function_arg	[function_1] coordinate specification ||| [arg_2] [function_1]	count=5
function_arg	a new [arg_2] ||| [arg_2] [function_1]	count=9
function	compute the numeric shape ||| shape	count=1
class	of scan return true ||| scan	count=1
arg	an fgraph and a ||| fgraph	count=1
arg	between low and high ||| low high	count=2
arg	a leftdims [arg_2] ||| [arg_2] [arg_1]	count=1
class	macros for ||| cop	count=1
function	min for the minimum ||| minimum	count=1
class	convolution with ||| dnn conv	count=1
function	initialization [function_2] ||| [function_2] [function_1]	count=1
function	this variable optionally ||| dimshuffle	count=1
function	function as ||| as	count=1
arg	this linker's fgraph ||| input_storage output_storage storage_map keep_lock	count=1
function	-> [function_2] ||| [function_1] [function_2]	count=1
function	1/(1+exp ||| inv 1 plus exp	count=2
function	a new graph ||| new inputs	count=1
class	help the navigator ||| navigator	count=1
class	:attr context_name ||| gpu	count=1
function	complex ||| complex	count=1
class	variable ||| tensor py	count=1
function	exception object ||| raise	count=1
arg	integer [arg] both ||| size [arg]	count=1
function	[function_1] full path ||| [function_2] [function_1]	count=8
arg	list remove are still ||| replacements remove reason	count=1
arg	sample from one or ||| size	count=1
class	the dimensions of this ||| tensor py	count=1
module	input nodes to output ||| gof	count=1
function	represent the dependence of ||| make dependence	count=1
class	the graph and ||| graph	count=2
class	updates for matrix solve ||| solve	count=1
function	[function_1] a bug ||| [function_1] macos sdot [function_2]	count=3
function	diagonalsubtensor and ||| diagonal subtensor view	count=1
function_arg	left-padding [function_1] [arg_2] ||| [function_1] padleft [arg_2]	count=1
function	helper function for diagonalsubtensor ||| get diagonal subtensor view	count=1
function	is ||| is	count=3
class	output of scan ||| out scan	count=1
class	fourier ||| fourier	count=1
function	[function_1] convolution gradweights ||| [function_2] [function_1]	count=6
function	offers to ||| to	count=1
function	inner graph [function_2] ||| [function_2] [function_1] node	count=1
arg	[arg_1] tensor input ||| [arg_2] [arg_1]	count=21
function_arg	< [arg_2] ||| [arg_2] [function_1]	count=1
module	returns ||| gof	count=10
function	is a package ||| is package	count=2
function_arg	| [arg_2] ||| [function_1] inplace a [arg_2]	count=1
arg	x is ||| x	count=1
function	convert addsd to ||| addsd ccode	count=1
function	unused ||| unused	count=1
function	don't accept complex ||| complex	count=1
arg	an optimization disabled by ||| node	count=1
function	modulo ||| mod	count=1
function	[function_1] generate c ||| [function_1] [function_2]	count=2
arg	a with ||| a replace p	count=1
function	[function_1] list to ||| [function_2] [function_1]	count=4
function	alloc of ||| alloc	count=1
function	inserting 1 at the ||| shape padaxis	count=1
function	[function_1] access of ||| [function_2] [function_1]	count=4
function	debug ||| debug	count=1
function	from a uniform ||| uniform	count=1
function	[function_1] of outputs ||| [function_2] [function_1]	count=1
function_arg	clip x to ||| clip x	count=1
function	[function_1] unused inputs ||| [function_2] [function_1]	count=1
module	tensor ||| tensor	count=1
arg	triangle ||| m k	count=2
arg	num and [arg] from both ||| num [arg]	count=1
function_arg	context [arg_2] ||| [function_1] name [arg_2]	count=2
arg	in the fgraph ||| fgraph	count=1
function	[function_1] gradinputs ||| [function_1] [function_2]	count=4
arg	by indices out_idxs and ||| out_idxs	count=1
function	get a scalar ||| scalar	count=1
function	returns the connection ||| io connection	count=1
function	a graph of apply ||| sort apply	count=1
class	for [class_2] ||| [class_2] [class_1]	count=3
class	broadcasted ||| operators	count=1
module	same ||| tensor	count=1
arg	was dumped ||| f persistent_load	count=1
function	/ x -> ||| local zero div	count=1
function	unused inputs ||| unused inputs	count=1
function	shape [function_2] ||| [function_2] [function_1]	count=12
function	returns a string ||| string	count=1
function_arg	[function_1] b ||| [function_1] a [arg_2]	count=5
arg	[arg_1] and b ||| eq [arg_1] [arg_2]	count=1
arg	end variables of a ||| wrt end	count=1
arg	[arg_1] n-d tensor ||| [arg_2] [arg_1]	count=2
class	are not in this ||| function	count=1
function	unroll the batch size ||| unroll batch	count=1
arg	return a string ||| name	count=1
class	of this mode ||| monitor mode	count=1
arg	standard deviation std ||| std	count=2
arg	haskell's ||| outputs_info non_sequences	count=1
function	gpuelemwise ||| elemwise	count=1
class	into macros ||| cop	count=1
arg	tensors ||| b rtol atol	count=1
function	maps from ||| get equiv	count=2
function	apply [function_2] ||| [function_2] [function_1]	count=1
function	updates ordereddict [function_2] ||| [function_1] [function_2]	count=2
function	variables given ||| variables	count=1
arg	b with [arg_2] ||| [arg_2] m1 [arg_1]	count=2
arg	is ||| node	count=2
arg	s_i ||| s_i var	count=1
arg	s to [arg_2] ||| [arg_1] [arg_2]	count=1
arg	function to ||| random_state low high	count=1
arg	formats the outputs ||| outputs	count=1
module	this ||| gpuarray	count=2
function	shape of convolution gradweights ||| get conv gradweights shape	count=1
module	that node inputs[i] ||| gof	count=1
arg	unification u ||| u	count=1
function	variable with [function_2] ||| sparse [function_2] [function_1]	count=2
function	-a inplace on ||| neg inplace	count=2
function	/ [function_2] ||| [function_2] zero [function_1]	count=1
function	as ||| as	count=1
function	to represent the dependence ||| dependence	count=1
function	exception object with debug ||| raise with op	count=1
function	as replace_all_validate revert the ||| all validate remove	count=1
function_arg	a subtensor [arg_2] ||| [arg_2] [function_1]	count=3
arg	s ||| s	count=1
function	a hash [function_2] ||| [function_1] [function_2]	count=1
arg	in a ||| a	count=1
function	inputs ||| inputs	count=5
arg	x and y ||| x y	count=3
function	the c code ||| c code	count=6
arg	value has a ||| value trace	count=1
arg	compiles this linker's fgraph ||| input_storage output_storage storage_map keep_lock	count=1
arg	according to ||| inputs outputs cmps	count=1
arg	reshapes the output ||| output input leftdims	count=1
function	copy ||| copy	count=1
module	variable optionally inserting ||| tensor	count=1
arg	sharedvariable constructor ||| value name strict allow_downcast	count=1
function	cache directory and ||| from dir	count=1
arg	outputs from ||| outputs mode	count=1
function	[function_1] x -> ||| [function_2] zero [function_1]	count=1
function	folowing changes in ||| local mul switch sink	count=1
arg	is ||| no_recycling	count=1
arg	[arg_1] an ||| [arg_2] [arg_1]	count=8
function	uniform distribution ||| uniform	count=1
class	of this variable ||| py	count=1
module	around c_extract that ||| gof	count=1
function	of a file ||| file	count=1
function	new ||| clone with new	count=1
arg	half by b ||| b	count=1
function_arg	> [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function	outputs and ||| and outputs	count=2
module	apply_node if ||| gof	count=1
class	cache or the ||| module cache	count=1
class	variable optionally ||| tensor py operators	count=1
arg	basic theano ||| itypes otypes infer_shape	count=1
module	tensors [module] sequence on ||| [module]	count=1
function_arg	[function_1] or none ||| [arg_2] [function_1]	count=3
function	print the [function_2] ||| [function_1] [function_2]	count=2
arg	none for the outputs ||| i_shapes	count=1
module	variant on wraplinker that ||| gof	count=1
function	[function_1] leaf ||| [function_1] [function_2]	count=2
function_arg	<= b ||| le a b	count=1
function	bound ||| bound	count=1
function	shape ||| infer shape	count=1
class	type's ||| type	count=1
class	of this variable optionally ||| operators	count=1
function_arg	[function_1] [arg_2] utility code for use ||| [function_1] [arg_2]	count=1
arg	url ||| content description filename auth	count=1
function	the sum along the ||| sum	count=1
class	register r's shape ||| shape	count=1
function	[function_1] convolution ||| [function_2] gradinputs [function_1]	count=2
function	to replace a leaf ||| replace leaf	count=1
function	[function_1] to extract ||| [function_1] [function_2]	count=1
class	type's ||| array	count=1
module	nnet ||| nnet	count=1
function	try ||| try	count=1
function	object with debug info ||| with	count=1
function	lib directories ||| header dirs	count=1
arg	specified ||| sparse_grad	count=1
function_arg	[function_1] required ||| [arg_2] [function_1]	count=3
arg	that v ||| v	count=1
function	transfer to a ||| transfer	count=1
function	variable to [function] list ||| [function]	count=1
arg	input vector and ||| node	count=1
arg	function tries to ||| image_shape top_shape border_mode subsample	count=2
module	this class ||| gof	count=5
arg	x with the ||| x	count=1
arg	upsample ||| ratio normalize	count=2
function	list to ||| gemm from factored list	count=1
arg	[arg_1] template ||| [arg_2] fgraph [arg_1]	count=2
function	in the module initialization ||| init	count=1
function	output for this ||| output	count=1
function	generate c ||| c	count=4
arg	[arg_1] / b ||| [arg_1] [arg_2]	count=1
function	variable [function_2] ||| [function_2] [function_1]	count=9
function	to helper_c_code ||| helper c code	count=1
function	dimensions of this variable ||| dimshuffle	count=1
arg	n (n needs ||| n	count=1
function	of arguments to pass ||| args	count=1
function	return complex-valued tensor from ||| from	count=1
function	[function_1] get ||| [function_2] idx [function_1]	count=1
function	header search paths ||| header dirs	count=1
arg	a n-d tensor ||| ws ignore_border stride	count=2
function_arg	uniform distribution [arg_2] ||| [arg_2] [function_1]	count=1
class	this variable optionally ||| py	count=1
function	[function_1] hot ||| [function_1] [function_2]	count=4
module	that can be specialized ||| gof	count=2
arg	the fgraph this ||| fgraph	count=1
module	that runs a ||| gof	count=1
function_arg	reintroduces in [arg_2] ||| [arg_2] [function_1]	count=4
arg	match a ||| var	count=1
function	complex-valued tensor from polar ||| complex from polar	count=1
arg	if fgraph is ||| fgraph no_recycling	count=1
function	max for the maximum ||| maximum	count=1
function	tanh ||| tanh	count=1
function_arg	[function_1] inputs ||| [function_1] [arg_2]	count=4
arg	ignore_trees-related functionality ||| fgraph importer pruner chin	count=1
function	[function_1] [function_2] ||| and [function_1] [function_2]	count=1
function	replace_all_validate revert ||| all validate remove	count=1
class	convolution with the ||| conv	count=1
arg	that x and ||| x	count=1
function	division inverse of ||| div	count=2
function_arg	[function_1] specified axis ||| sparse [function_1] sum [arg_2]	count=3
module	kinds ||| tensor	count=1
function_arg	to merge [arg_2] ||| [function_1] cls alpha_in beta_in [arg_2]	count=1
function	new ||| new inputs	count=2
arg	[arg_1] and o ||| [arg_1] [arg_2]	count=1
function_arg	a > [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function_arg	[function_1] "kshp" ||| [arg_2] [function_1]	count=4
function	from ||| complex from	count=1
function_arg	fill [arg_2] ||| [arg_2] [function_1]	count=3
function	value underlying variable ||| value	count=1
function	the output [function_2] ||| [function_1] [function_2]	count=3
arg	n ||| n	count=1
arg	x ||| x log2_exponent	count=1
function	to make ||| to os environ	count=1
function	to wrt, ||| subgraph grad	count=1
module	dimensions ||| tensor	count=2
function	for diagonalsubtensor and ||| get diagonal subtensor	count=1
function_arg	from polar [arg_2] ||| [function_1] [arg_2]	count=1
arg	the value after the ||| default filter	count=1
function	constant with value ||| constant	count=1
function	the constant [function_2] ||| [function_2] [function_1]	count=4
function_arg	round half [arg_2] ||| [arg_2] [function_1]	count=1
function	3-d variable ||| tensor3	count=1
module	to compute the ||| tensor nnet	count=4
function	a diff ||| diff	count=1
class	the dimensions ||| tensor py operators	count=1
class	of scan ||| out scan	count=1
function	the idx ||| idx	count=1
module	wraplinker that ||| gof	count=1
function_arg	[function_1] we do ||| [arg_2] [function_1]	count=4
class	transfer ||| py operators	count=1
class	is ||| six meta path importer	count=1
function	loop over several arrays ||| loop	count=1
function	module initialization [function_2] ||| [function_2] [function_1]	count=1
function_arg	variables [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] search paths ||| [function_2] [function_1]	count=6
function	upcasts constant inputs ||| constant inputs	count=2
function	conv2d interface ||| conv2d	count=1
function	[function_1] polar ||| [function_1] [function_2]	count=4
function_arg	[function_1] [arg_2] ||| [function_1] wrt end start [arg_2]	count=20
function	indicating the version ||| c code cache version	count=3
class	cache directory ||| module cache	count=1
function	indptr ||| indptr	count=1
function	canonical form that ||| canonical form	count=1
function_arg	[function_1] op without ||| [function_1] outs [arg_2]	count=1
function_arg	the shape [arg_2] ||| [arg_2] [function_1]	count=5
function	a inner ||| inner	count=1
arg	baddestroymap ||| storage_map r_vals	count=1
arg	if necessary update dr_vals ||| node storage_map r_vals dr_vals	count=1
function	convert ||| make	count=1
function	a list of header ||| header	count=1
function	inner-most loop executes code ||| loop	count=1
function	leaf of ||| leaf	count=1
function	[function_1] the scan ||| [function_2] can [function_1]	count=2
function	of outputs and ||| and outputs	count=2
module	dimensions of this ||| tensor	count=1
function	det ||| det	count=1
function_arg	to wrt, [arg_2] ||| [function_1] wrt end [arg_2]	count=1
class	the dimensions of ||| py	count=1
function	bessel function ||| j0	count=1
arg	cost and/or [arg_2] ||| [arg_2] [arg_1]	count=6
arg	if allow_override is false ||| filter allow_override	count=1
arg	output ||| output	count=1
function	to use dnn ||| dnn	count=2
function	raise ||| inputs	count=1
function_arg	[function_1] return ||| [arg_2] [function_1]	count=2
arg	the original graph ||| outputs copy_inputs_and_orphans memo	count=1
function	a tensorvariable whose type ||| as	count=1
function	uses the topooptimizer from ||| in2out	count=1
function	diff to make ||| diff	count=1
function	thunk that is ||| thunk	count=1
class	same ||| tensor	count=1
function	inserted in the struct ||| struct	count=1
arg	nesting ||| loop_orders dtypes loop_tasks sub	count=1
arg	set to a specified ||| a	count=1
class	dimensions ||| operators	count=2
function	[function_1] inverse ||| [function_1] [function_2]	count=4
module	dimensions of this variable ||| tensor	count=1
arg	drawing ||| n pvals	count=1
function	a sparse ||| sparse	count=1
class	:attr ||| type	count=1
arg	spatio-temporal filters ||| signals filters	count=1
arg	the inputs according ||| inputs	count=1
class	of the type ||| type	count=1
function	helper_c_code ||| get helper c code	count=2
function	as replace_all_validate revert ||| all validate	count=1
function	print ||| print	count=3
arg	node by one ||| node	count=1
function_arg	[function_1] [arg_2] ||| [function_1] padleft [arg_2]	count=2
class	output of scan return ||| out scan	count=1
arg	the template ||| template	count=1
function_arg	:func neibs2images [arg_2] ||| [arg_2] [function_1]	count=1
arg	variable [arg] returns ||| [arg]	count=1
function	[function] of a ||| [function]	count=4
arg	y ||| y	count=10
arg	list remove [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	a | [arg_2] ||| [function_1] inplace a [arg_2]	count=1
arg	an input vector and ||| node	count=1
arg	es of a tensor ||| dtype op	count=1
arg	i of ||| r i	count=1
arg	this ||| op	count=1
arg	[arg_1] the end ||| [arg_2] [arg_1]	count=4
arg	defined by indices out_idxs ||| out_idxs	count=1
arg	indices obtained by iterating ||| keepdims	count=1
class	[class] of ||| structured [class]	count=3
arg	return an ||| node name	count=2
function	constructor [function] ||| as sparse [function]	count=1
class	a mrg [class_2] ||| [class_2] [class_1]	count=4
class	to the ||| type	count=1
class	[class_1] an op ||| [class_1] [class_2]	count=2
function	some [function_2] ||| [function_2] [function_1]	count=1
function	time icluding the time ||| times	count=1
function	[function_1] graph to ||| [function_2] [function_1]	count=4
module	compute the dot product ||| tensor nnet	count=2
arg	of x ||| x axes	count=1
function	add an ||| add	count=1
function_arg	[function_1] instance of ||| [function_1] [arg_2]	count=6
function	3 ||| 3d	count=1
module	return those items ||| gof	count=1
function_arg	helper [arg_2] ||| [arg_2] [function_1]	count=9
function	its [function] ||| undefined [function]	count=2
arg	x to ||| x	count=2
arg	cpu ||| full_matrices compute_uv	count=1
function_arg	all device [arg_2] ||| [arg_2] [function_1]	count=4
function_arg	a dimshuffle [arg_2] ||| [function_1] [arg_2]	count=1
function	-a [function_2] ||| [function_1] [function_2]	count=1
class	of this variable optionally ||| tensor	count=1
function	returning the output error ||| output	count=1
function	to construct a variable ||| variable	count=1
function	unfortunately conda offers to ||| to os environ	count=1
arg	[arg] is ||| [arg]	count=3
arg	flags from config ||| flags	count=1
function_arg	[function_1] triangle of ||| [function_1] [arg_2]	count=2
class	shape ||| shape feature	count=1
function	[function_1] gradweights ||| [function_2] [function_1]	count=2
function	maps [function_2] ||| [function_2] [function_1]	count=8
arg	is the ||| no_recycling	count=1
class	reorder ||| operators	count=1
function	apply the list of ||| apply	count=1
function	computes the confusion ||| confusion	count=1
function	the c [function_2] ||| [function_1] [function_2]	count=3
arg	a n-d tensor where ||| ws ignore_border stride	count=2
arg	haskell' ||| outputs_info	count=1
arg	changes node ||| node	count=1
class	the initial value for ||| gpu	count=1
function	sinh ||| sinh	count=1
arg	x the ||| x	count=1
arg	in [arg] which ||| [arg]	count=1
arg	if a and ||| a	count=1
arg	have separated maker ||| share_memory swap delete_updates name	count=1
arg	none for ||| i_shapes	count=1
function	python ||| make constant	count=1
function	c code to initialize ||| c	count=1
arg	along a given axis ||| axis	count=1
function_arg	sum [arg_2] ||| [arg_2] [function_1]	count=6
arg	is unified to boundvariable(other_object) ||| fv o u	count=1
class	variable optionally inserting broadcasted ||| tensor py operators	count=1
arg	[arg_1] the inputs ||| [arg_2] [arg_1]	count=8
arg	an fgraph ||| fgraph	count=1
function	tries to [function] ||| [function]	count=2
arg	baddestroymap ||| node	count=1
function	the replacement if ||| replace	count=1
function	register a ||| register	count=1
function	more multinomial ||| multinomial	count=1
function	vector ||| vector	count=1
function_arg	[function_1] given version ||| core [function_1] [arg_2]	count=2
function	[function_1] [function_2] a sparse matrix ||| sparse [function_2] [function_1]	count=1
arg	by [arg] in ||| [arg]	count=1
function	a bug ||| bug	count=1
arg	function to ||| random_state low	count=1
function	row variable (ndim=2 ||| row	count=1
class	of this ||| tensor	count=2
function	c type ||| c	count=1
function	a canonical ||| get canonical	count=1
function	abs and [function_2] ||| [function_2] [function_1]	count=2
arg	this function tries to ||| top_shape border_mode	count=4
function	the updates ||| updates	count=1
function_arg	[function_1] the specified ||| sparse [function_1] sum x axis [arg_2]	count=3
function	module is a package ||| is package	count=1
class	optionally ||| py operators	count=2
function	get the 0 based ||| get	count=1
function	flattened version ||| flatnonzero	count=1
class	matrix a and matrix ||| structured	count=1
function	see whom can ||| can	count=1
function	performs batch [function_2] ||| [function_1] [function_2]	count=8
function	output ||| output	count=5
function_arg	concatenate tensortypes [arg_2] ||| [arg_2] [function_1]	count=1
arg	z <- beta * ||| z	count=1
function_arg	[function_1] b ||| [arg_2] [function_1]	count=21
function_arg	context [arg_2] ||| [arg_2] [function_1]	count=3
class	the dot product ||| dot	count=1
function	c code for this ||| init c code	count=1
function	import ||| import	count=2
arg	an unification where [arg_1] [arg_2] ||| unify walk [arg_1] [arg_2]	count=7
function	version ||| c code cache version	count=3
class	the type's :attr ||| gpu	count=1
arg	[arg_1] + rightdims ||| [arg_2] [arg_1]	count=6
function	for the minimum ||| minimum	count=1
function	pattern of subfgraph ||| pattern	count=1
arg	should decref ||| fail	count=1
function	[function_1] openmp ||| gof open mpop update [function_1] [function_2]	count=1
class	of scan ||| push out scan	count=1
arg	the fgraph outputs that ||| fgraph	count=1
module	dimensions of ||| tensor	count=1
module	:attr ||| gpuarray	count=1
function	replace_all_validate revert the replacement ||| replace all validate remove	count=1
arg	b [arg_2] ||| [arg_2] [arg_1]	count=4
arg	separated maker and ||| share_memory swap delete_updates	count=1
function	openblas threads ||| openblas threads	count=2
function	apply nodes ||| sort apply nodes	count=2
class	their unification ||| unification	count=1
function	[function_1] graph to ||| [function_1] [function_2]	count=4
function_arg	a >= [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function_arg	string [arg_2] ||| [arg_2] [function_1]	count=2
arg	override this should return ||| name	count=1
function	unroll the ||| unroll	count=1
arg	4-d tensor it sets ||| patch_size	count=1
arg	symbolic ||| name dtype	count=3
function	triangular solve ||| tag solve triangular	count=2
module	the dimensions of this ||| tensor	count=1
function	tensorvariable of ||| make variable	count=1
function	pattern ||| pattern	count=3
function	of convolution gradinputs ||| get conv gradinputs	count=4
function	a config [function_2] ||| [function_2] [function_1]	count=1
function	diagonalsubtensor ||| diagonal subtensor	count=1
class	the ||| py operators	count=2
arg	apply_node recursively search from ||| apply_node	count=1
function	prod(prod()) -> [function_2] ||| [function_2] [function_1]	count=1
arg	predicate ||| predicate	count=1
function	c [function_2] ||| [function_2] [function_1]	count=4
function	with logsoftmax x ||| local logsoftmax	count=1
function	deepcopyop [function_2] ||| [function_1] [function_2]	count=1
function_arg	[function_1] version ||| core warn [function_1] [arg_2]	count=1
arg	failure_callback ||| exc	count=2
arg	remove [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	[function_1] value has ||| [arg_2] [function_1]	count=1
function_arg	<= [arg_2] ||| [arg_2] [function_1]	count=2
function	broadcasted ||| dimshuffle	count=1
function_arg	[function_1] tree ||| [function_1] [arg_2]	count=3
function	from config blas ldflags ||| ldflags	count=1
function	module [function_2] ||| [function_2] [function_1]	count=2
function	the connection pattern ||| connection pattern	count=1
function	scale or inverse ||| scale	count=1
function	directories ||| dirs	count=1
function	[function_1] [function_2] sparse matrix by the ||| [function_2] [function_1]	count=1
function	inner-most loop ||| make reordered loop	count=1
function	the matrix [function_2] ||| [function_2] [function_1]	count=1
arg	in the list remove ||| remove	count=1
arg	operation on f ||| f	count=2
arg	unified to boundvariable(other_object) ||| fv o u	count=1
function	to the one hot ||| one hot	count=1
function	to get the 0 ||| get	count=1
function	[function_1] counter to ||| [function_1] [function_2]	count=1
arg	dfs [arg] ||| [arg]	count=1
function	code ||| code	count=7
arg	z ||| z	count=1
arg	may ||| fgraph	count=1
arg	simple algorithm ||| order reasons r_vals	count=1
arg	[arg] target index ||| [arg]	count=1
function	replace it with logsoftmax ||| logsoftmax	count=1
function	the connection [function_2] ||| [function_1] [function_2]	count=4
module	this ||| tensor	count=1
arg	y have ||| y	count=1
arg	test ||| fun pt n_tests rng	count=1
function	[function_1] [function_2] ||| [function_2] idx [function_1]	count=4
function_arg	outputs and [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg] zview if ||| name x [arg]	count=1
class	of scan ||| scan	count=1
function	data supported [function] gpu? currently ||| [function]	count=1
function_arg	diagonal set [arg_2] ||| [function_1] offset [arg_2]	count=3
arg	[arg_1] x ||| [arg_1] [arg_2]	count=1
arg	changed from r to ||| r	count=1
function	a scan ||| scan	count=1
function	normalization ||| normalization	count=2
function	header [function_2] ||| [function_2] [function_1]	count=1
arg	to reps ||| reps ndim	count=1
function	to [function] ||| [function]	count=2
function	[function_1] with ||| [function_2] [function_1]	count=2
function	to the apply ||| apply	count=1
function	ones with the ||| ones like	count=1
arg	the fgraph outputs ||| fgraph	count=1
function	from the ||| remove	count=1
function	op ||| get op	count=1
class	execute ||| function graph	count=1
function	determine [function_2] ||| [function_2] [function_1]	count=2
function	a cache directory and ||| dir	count=1
function	any duplicates (according to ||| duplicates	count=1
function	approximately ||| approx	count=1
class	gpucorrmm (direction="forward"), gpucorrmm_gradweights ||| corr mm	count=1
function	function :func neibs2images ||| neibs2images	count=1
function	connection pattern ||| io connection pattern	count=2
function	3d ||| conv3d	count=1
function_arg	optional [arg_2] ||| [function_1] support code struct [arg_2]	count=1
function_arg	context associated [arg_2] ||| [function_1] [arg_2]	count=1
function	unroll the [function_2] ||| [function_2] [function_1]	count=3
function	to ||| to	count=2
function	remove subtensor/advancedsubtensor1 ||| useless subtensor	count=1
module	es [module] a ||| [module]	count=1
class	the dimensions ||| tensor py	count=1
arg	[arg] the ||| [arg]	count=3
function	context associated with ||| get context	count=1
function	generate c ||| shape i c	count=1
module	uses the ||| gof	count=1
function	[function_1] [function_2] ||| [function_1] [function_2] node	count=2
function	tensor from polar ||| from polar	count=1
function	[function_1] convolution gradinputs ||| [function_2] [function_1]	count=4
function	to get the ||| get depth	count=1
class	the dimensions of this ||| operators	count=1
function	to replace a ||| replace	count=1
arg	z <- ||| z	count=1
function	complex-valued tensor from ||| complex from	count=1
function	[function_1] [function_2] the same dtype and ||| [function_2] [function_1]	count=8
function	stack [function_2] ||| [function_2] [function_1]	count=4
class	dimensions of ||| tensor py operators	count=1
function	removes all asserts from ||| remove all assert	count=1
class	for a convolution ||| gpu dnn conv	count=1
function	from [function] arguments ||| [function]	count=1
arg	in u and uses ||| o u	count=1
function	function as its ||| as	count=1
class	cache or ||| module cache	count=1
function	tensor from [function_2] ||| [function_1] [function_2]	count=1
arg	if ||| node storage_map	count=1
function	the output dimensions ||| get output	count=1
function	to determine [function_2] ||| [function_2] [function_1]	count=2
arg	check [arg] ||| [arg] no_recycling	count=1
function	proxy for either true_div ||| proxy	count=2
function	optionally inserting broadcasted dimensions ||| dimshuffle	count=1
arg	a specified scalar ||| a	count=1
class	convolution with ||| conv	count=1
arg	matrices at least one ||| x y	count=1
function	new graph ||| new inputs	count=1
arg	the named ||| fullname	count=1
arg	real and ||| real	count=1
class	the ||| tensor	count=1
arg	given an fgraph and ||| fgraph	count=1
arg	tensor input ||| input	count=4
arg	apply_node recursively search ||| apply_node check	count=1
class	type ||| tensor type	count=2
arg	given axis es of ||| axis ddof keepdims	count=1
arg	a variable of this ||| a	count=1
function	[function] is ||| update [function]	count=1
function	unfortunately conda offers to ||| to os	count=1
arg	:type ||| wrt consider_constant disconnected_inputs	count=2
arg	[arg] of ||| v [arg] m1	count=2
function	floor ||| floor	count=2
arg	i ||| r i	count=1
function	a new graph ||| new	count=1
function	to generate c ||| register specify shape c	count=1
class	the type's :attr context_name ||| array	count=1
arg	initializes py_name to ||| r	count=1
function	conda offers to ||| to os environ	count=1
function	compile lock to ||| add to	count=1
class	the cache directory structure ||| module cache	count=1
class	that ||| op	count=1
function_arg	a ^ [arg_2] ||| [function_1] inplace a [arg_2]	count=1
module	return data or ||| gof	count=1
function	search paths ||| dirs	count=1
arg	to r ||| r	count=1
function	[function_1] variables ||| [function_2] [function_1]	count=1
class	new random ||| random	count=1
function	raise ||| check inputs	count=2
class	reorder the ||| operators	count=1
function	[true] division inverse of ||| true div	count=1
arg	and t ||| node input_storage	count=1
function	[function] gpu? currently ||| [function]	count=1
function	[function_1] and the ||| [function_2] [function_1]	count=8
function	[function_1] and ||| [function_2] [function_1]	count=12
function	to choose from ||| choose	count=1
function	the [function_1] [function_2] ||| gof [function_1] [function_2]	count=6
function	inverses [function] them ||| [function] func	count=1
function	[function_1] x -> ||| [function_2] [function_1]	count=3
arg	true if l ||| l	count=1
function	perform the ||| perform	count=1
class	:attr ||| gpu array type	count=1
function	determine [function_2] ||| [function_1] [function_2]	count=2
arg	original graph ||| outputs copy_inputs_and_orphans memo	count=1
function	config string ||| parse config string	count=2
function	convert python litterals ||| constant	count=1
arg	[arg_1] movie ||| [arg_2] [arg_1]	count=2
class	dimensions ||| tensor	count=2
function	return complex-valued tensor from ||| complex from	count=1
function	diagonal set to ||| diagonal	count=1
function	bessel function ||| jv inplace	count=1
class	gradient for the ||| grad	count=1
arg	sample ||| size	count=2
class	of this variable ||| tensor	count=2
arg	up to the end ||| wrt end	count=1
arg	drawing from ||| n pvals size	count=2
class	local optimization [class_2] ||| [class_1] [class_2]	count=1
function	variable with a ||| variable	count=1
function	inserting broadcasted ||| dimshuffle	count=1
arg	and ||| node name inputs	count=1
function	builds the 1d ||| 1d	count=1
function_arg	[function_1] triangle ||| [arg_2] [function_1]	count=2
arg	message on ||| msg	count=1
function	complex otherwise call upgrade_to_float() ||| upgrade to float no complex	count=1
function	[function_1] from variable ||| [function_2] [function_1]	count=2
class	convolution ||| dnn conv	count=2
arg	of 2d filters ||| input filters	count=2
function	is a thunk ||| make thunk	count=1
arg	outputs [arg_2] ||| [arg_2] [arg_1]	count=2
module	first functiongraph that ||| gof	count=1
arg	return c code ||| name	count=2
function	exception ||| thunk	count=2
class	create an functiongraph ||| function graph	count=1
function	context associated ||| get context	count=1
function	represent the dependence ||| dependence	count=1
function	sign ||| sgn	count=2
arg	the computation to ||| node	count=1
function	import ||| import r	count=2
function	canonical ||| canonical	count=1
arg	for navigatoroptimizer ||| nav repl_pairs local_opt	count=2
function	a variable ||| variable	count=2
module	a zero-arguments function that ||| gof	count=1
module	apply_node if those ||| gof	count=1
arg	triangle of an ||| m k	count=2
function	inserting ||| dimshuffle	count=1
function	as replace_all_validate ||| validate remove	count=1
arg	given axis [arg_2] ||| [arg_2] [arg_1]	count=12
function	has only ||| only	count=1
class	random ||| mrg random	count=1
arg	and b ||| b	count=3
function	indicating the version ||| cache version	count=3
class	context_name ||| gpu array	count=1
class	cache ||| call cache	count=1
arg	an apply_node recursively search ||| apply_node check	count=1
function	any duplicates (according ||| duplicates	count=1
function	[function_1] value for ||| [function_2] [function_1]	count=4
module	if those ||| gof	count=1
arg	this node ||| node	count=1
function	computes the sum ||| sum	count=1
function_arg	!= [arg_2] ||| [arg_2] [function_1]	count=2
module	of ||| tensor	count=57
function	a canonical [function_2] ||| [function_2] [function_1]	count=4
class	type's :attr context_name ||| gpu	count=1
function	more multinomial distributions defined ||| multinomial	count=1
function	load a ||| load	count=1
function	idx_list with ||| idx	count=1
function	[function_1] broadcast pattern ||| [function_2] [function_1]	count=3
function	upcast ||| upcast	count=1
arg	remove are still ||| replacements remove reason	count=1
function	to generate c ||| shape c	count=1
arg	in [arg] i e ||| seq1 [arg]	count=1
function	variables given input shapes ||| variables	count=1
arg	a variable [arg] returns ||| [arg]	count=1
function_arg	[function_1] or none ||| [function_1] node [arg_2]	count=3
function	solve ||| solve	count=1
function	insert deepcopy in ||| insert deepcopy	count=2
arg	is the ||| no_recycling profile	count=1
function	new graph ||| with new	count=1
arg	[arg_1] [arg_2] ||| [arg_2] fgraph [arg_1]	count=9
function_arg	[function_1] given axis ||| [arg_2] [function_1]	count=4
function	merge multiplication by a ||| alpha merge	count=1
arg	by the inputs and ||| inputs	count=1
function	computes the confusion matrix ||| confusion matrix	count=1
function	optional return ||| c	count=1
function	try to compile ||| try	count=1
function	replacement ||| replace	count=1
arg	input vector and ||| node input_storage	count=1
arg	the output ||| output input leftdims	count=1
function	dimensions of ||| dimshuffle	count=1
arg	order v real ||| v x	count=2
arg	whether [arg] is ||| [arg]	count=1
function	of arguments to ||| args	count=1
function	confusion matrix of ||| confusion matrix	count=1
function	last [function_2] ||| [function_2] [function_1]	count=4
function_arg	[function_1] node ||| [function_1] inplace fgraph [arg_2]	count=2
function	make a schedule ||| schedule	count=1
function_arg	constant [arg_2] ||| [arg_2] [function_1]	count=5
function	this op ||| op	count=1
function	on the inner graph ||| validate inner graph	count=1
function	image ||| 1axis	count=1
function	of 3d ||| conv3d	count=1
module	return ||| d3viz	count=1
arg	fgraph and ||| fgraph	count=1
module	stack tensors [module] sequence ||| [module]	count=1
function	[function_1] matrix ||| [function_1] [function_2]	count=2
class	this variable optionally inserting ||| py	count=1
function	extract test value from ||| test value	count=1
arg	variable out for ||| out	count=1
function	module initialization [function_2] ||| [function_1] [function_2]	count=1
module	detect ||| gof	count=1
arg	similar behaviour as haskell' ||| fn sequences outputs_info non_sequences	count=1
function_arg	[function_1] of cost ||| [function_1] wrt end start [arg_2]	count=2
class	dimensions of ||| tensor py	count=1
function	signe ||| sgn	count=1
function	detect ||| detect	count=1
function	[function_1] graph ||| [function_2] [function_1]	count=4
function	to get the 0 ||| get depth	count=1
function	rebroadcast how [function_2] ||| [function_2] [function_1]	count=1
arg	with a modulo ||| a	count=1
class	dictionary data structures ||| out non	count=1
function	inserted at struct ||| struct	count=1
function_arg	[function_1] [arg_2] ||| [function_1] out [arg_2]	count=2
arg	convert x into ||| x context_name	count=1
arg	x is a ||| x	count=1
function	[function_1] [function_2] only ||| [function_2] [function_1]	count=2
function	idx list to ||| idx list	count=2
function	[function_1] sparse matrix ||| [function_2] [function_1]	count=2
function	insert deepcopy in the ||| insert deepcopy	count=1
function	and return full ||| module name from	count=2
function_arg	[function_1] y ||| [arg_2] [function_1]	count=1
class	of an op ||| clinker op	count=1
class	composite op ||| composite	count=1
arg	specifyshape how to ||| c_support_code_apply	count=1
function_arg	standard deviation [arg_2] ||| [function_1] [arg_2]	count=1
arg	of a compiled theano ||| fct	count=1
function	determine the [function_2] ||| [function_2] [function_1]	count=3
function	self ||| self	count=1
module	type's :attr context_name ||| gpuarray	count=1
function	performs batch [function_2] ||| [function_2] [function_1]	count=8
function	a uniform distribution ||| uniform	count=1
function	same on all device ||| device	count=1
function	c code [function_2] ||| [function_1] [function_2]	count=3
class	data structures ||| push out non seq	count=1
function	integers indicating the version ||| c code cache version	count=3
arg	that was used ||| inputs g_outputs	count=1
arg	flags ||| flags	count=2
function	matrix ||| sp	count=1
function	return ||| name from	count=1
module_class	of this type ||| gof clinker type	count=1
function	constant scalar ||| get scalar constant	count=2
arg	obj to ||| obj	count=1
module	within ||| gof	count=1
function	integers indicating the version ||| cache version apply	count=1
function	[function_1] nested loop ||| [function_1] [function_2]	count=1
function	pattern of ||| pattern	count=2
arg	fgraph outputs that will ||| fgraph expanded_inputs	count=1
function	optionally ||| dimshuffle	count=1
class	to the type's :attr ||| array	count=1
arg	outputs ||| outputs mode	count=1
function	[function_1] trace from ||| [function_1] [function_2]	count=3
arg	and a [arg_2] ||| [arg_1] [arg_2]	count=2
function	indicating the version ||| version	count=3
function	this variable ||| dimshuffle	count=1
function	unique names to an ||| names	count=1
function	dimshuffle ||| dimshuffle	count=3
function	upper bound on ||| bound	count=1
function	it to a max ||| max	count=1
function	[advanced]incsubtensor[1], whose increment ||| local useless inc subtensor	count=1
function	the constant scalar ||| scalar constant	count=3
class	see theano tensor ||| py operators	count=11
function	columns ||| col	count=1
arg	vector and t is ||| node	count=1
function	lower ||| tril	count=1
function_arg	of [function_1] [arg_2] ||| [function_1] [arg_2]	count=4
function	the inner-most loop ||| loop	count=1
function_arg	== [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function	baddestroymap ||| check	count=1
function	[function_1] batch size ||| [function_2] [function_1]	count=2
class	for ||| abstract	count=1
function	new variable from ||| new	count=1
arg	baddestroymap ||| storage_map	count=1
function	the c [function_2] ||| [function_2] [function_1]	count=3
function	dependence ||| dependence	count=1
arg	and ||| node name	count=2
function	sparse format instead of ||| sparse	count=1
function	0-d value underlying ||| value	count=1
arg	if fgraph is ||| fgraph no_recycling profile	count=1
function	two kinds of useless ||| local useless	count=1
function	hyperbolic arc sine ||| arcsinh	count=1
arg	remove are still in ||| replacements remove reason	count=1
arg	instance ||| link_kwargs optimizer	count=2
class	scan ||| out scan	count=1
function	convolution ||| get conv	count=4
function_arg	[function_1] cost and/or ||| [function_1] wrt end start [arg_2]	count=1
function	try to compile a ||| try	count=1
function	version ||| cache version apply	count=2
function	matrix ||| matrix	count=3
function	scale each [function_2] ||| sparse [function_2] [function_1]	count=2
arg	the inputs according to ||| inputs	count=1
module	initialize the variables that ||| gof	count=1
arg	none for [arg_2] ||| [arg_2] [arg_1]	count=2
class	nit_sot output of scan ||| out scan	count=1
function	the platform-dependent gcc ||| get gcc	count=2
function	c_extract_out ||| c extract out	count=1
function	[function_1] time icluding ||| [function_1] [function_2]	count=1
function	round half ||| rint	count=1
arg	convolving a mini-batch ||| input_shape filter_shape	count=3
function	module is [function_2] ||| [function_1] [function_2]	count=1
function	apply as many ||| apply	count=1
module	g++ version used ||| gof	count=1
function	folowing changes ||| local mul switch sink	count=1
function	return a [function_2] ||| [function_2] [function_1]	count=1
class	navigator deal ||| navigator	count=1
arg	inputs replaced by their ||| inputs allow_partial only_process_constants elemwise	count=1
function	fortran blas ||| blas	count=1
arg	if cond ||| cond	count=1
function	the inner-most loop ||| make reordered loop	count=1
function	return a thunk that ||| thunk	count=1
arg	shape_i ||| check_input	count=1
arg	the outputs from ||| outputs mode accept_inplace	count=1
function	convert python litterals ||| make constant	count=1
arg	a and [arg_2] ||| unify walk [arg_1] [arg_2]	count=4
function	find ||| find	count=1
function	output gradient w ||| grad	count=3
arg	compiled theano ||| fct	count=1
function	output dimensions ||| get output	count=1
function	the 1d kernel that ||| kernel 1d	count=1
function	the following [function_2] ||| [function_1] [function_2]	count=1
function	to detect a ||| detect	count=1
class	type's :attr ||| gpu array	count=1
class	destroyhandler wasn't ||| destroy handler	count=1
function	python litterals to ||| constant	count=1
function	[function_1] convolution ||| [function_2] gradweights [function_1]	count=4
module	the input nodes ||| gof	count=1
function	apply as many times ||| apply	count=1
arg	array and a ||| a	count=1
function_arg	< [arg_2] ||| [function_1] a [arg_2]	count=1
arg	and [arg] ||| num [arg]	count=2
function	string ||| string	count=2
arg	over given axis ||| x axis	count=1
function	and return full path ||| module name	count=1
function	unify values ||| unify	count=1
function	conv output gradient ||| grad	count=3
function	we have [function_1] [function_2] ||| [function_2] [function_1]	count=3
arg	input to a ||| input	count=1
function	apply ||| apply	count=6
arg	list of r ||| r client_to_remove reason	count=1
function	to ||| to os environ pathlist	count=2
function	*args directly ||| local csm properties csm	count=1
function	or inverse the gradient ||| grad	count=1
arg	gets a scan op ||| op not_required	count=1
class	optionally inserting broadcasted dimensions ||| operators	count=1
function	gradient w r ||| grad	count=3
function_arg	a transfer [arg_2] ||| [function_1] [arg_2]	count=4
function	to print the mflops ||| flops	count=1
module	neibs2images ||| tensor nnet	count=1
arg	seq2 ||| seq2	count=1
function_arg	input [arg_2] ||| [function_1] input [arg_2]	count=3
function	of headers ||| headers	count=1
function	[function_1] value for ||| [function_1] [function_2]	count=4
arg	type2 from [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] make code ||| [function_1] [arg_2]	count=3
arg	function tries to ||| image_shape top_shape border_mode	count=2
arg	cols ||| cols	count=1
function	if the g++ ||| gcc	count=1
function	thunk ||| thunk	count=3
function	normalization of ||| normalization	count=2
function	cache directory ||| from dir	count=1
function	times from a multinomial ||| multinomial	count=1
arg	a given axis ||| axis	count=1
function	tensorvariable whose type ||| as	count=1
arg	gradients of cost ||| cost	count=1
arg	tries ||| top_shape border_mode subsample	count=4
function	[function_1] hot ||| [function_2] [function_1]	count=4
function	with ||| with op	count=2
function_arg	to extract [arg_2] ||| [function_1] name [arg_2]	count=1
module	theano scalar scalar ||| scalar	count=1
function	helper function for diagonalsubtensor ||| diagonal subtensor view	count=1
class	kinds of ||| tensor type	count=1
function	deepcopyop [function_2] ||| [function_2] [function_1]	count=1
function	overwrite the ||| useless inc subtensor	count=1
module	scalar values ||| scalar	count=1
arg	inputs according to the ||| inputs	count=1
function_arg	[function_1] [arg_2] ||| [function_1] wrt end [arg_2]	count=20
function	setsubtensor(x x[idx], idx) ||| setsubtensor of constants	count=1
function	the inner graph to ||| inner graph	count=1
module	work if ||| gof	count=1
class	[class] graph ||| [class]	count=3
arg	function to ||| random_state	count=3
arg	[arg] target ||| [arg]	count=1
class	this ||| tensor	count=1
function	validations on the inner ||| validate inner	count=1
module	in ||| core	count=2
arg	[arg_1] for navigatoroptimizer ||| [arg_1] [arg_2]	count=1
module	object a that would ||| gof	count=1
function	and ||| local	count=3
function_arg	[function_1] we ||| [function_1] [arg_2]	count=4
function	to make itself the ||| to os	count=1
function	replacement if the ops ||| replace	count=1
function	gcc [function_2] ||| [function_2] [function_1]	count=1
arg	return ||| name	count=16
function	return indices over ||| indices	count=1
arg	and y ||| y	count=1
function	output dimensions of convolving ||| get output	count=1
class	dimensions of this variable ||| py	count=1
arg	and dtype as ||| dtype	count=1
class	structures ||| push out non	count=1
function	convert addsd to ||| addsd	count=1
function	legal ||| is valid	count=1
function	inner nit_sot output ||| inner sitsot	count=1
function	a inner nit_sot output ||| inner	count=1
class	the type's :attr context_name ||| type	count=1
function	on ||| gpu	count=1
module	global scope [module] ||| [module]	count=3
class	a convolution ||| conv	count=1
function	this function is ||| constant	count=1
class	and dictionary data structures ||| non	count=1
arg	from r to new_r ||| r	count=1
function_arg	a scan [arg_2] ||| [function_1] inplace [arg_2]	count=1
arg	the fgraph [arg_2] ||| [arg_1] [arg_2]	count=2
function	hash equal ||| hash	count=1
arg	convolution ||| border_mode subsample	count=1
class	a convolution with ||| dnn conv	count=1
function	c code to ||| c	count=3
arg	we do ||| node	count=1
class	context_name ||| array type	count=1
function	the platform-dependent ||| get	count=1
function	inner graph to ensure ||| inner graph	count=1
function	of useless reshape ||| useless reshape	count=1
function	be removed from ||| remove outs	count=2
class	inserting broadcasted dimensions ||| py	count=1
function	compute a batched ||| batched	count=1
arg	return a code string ||| node name sub	count=1
function	op code ||| get op params	count=1
function	conda offers to make ||| to os environ	count=1
arg	decorator to ||| cls alpha_in beta_in	count=1
function	replace a ||| replace	count=1
function	hyperbolic tangent ||| tanh	count=2
function	for bilinear ||| bilinear	count=2
function	output dimensions of ||| get output	count=1
function_arg	form that [arg_2] ||| [arg_2] [function_1]	count=1
function	for openblas threads interface ||| openblas threads text	count=1
class	[class] with inputs ||| [class]	count=1
function	vector 1-dimensional ||| jacobian	count=1
class	data structures ||| out non	count=1
class	same ||| tensor type	count=1
function	new ||| new	count=2
arg	match a variable with ||| var	count=1
arg	num and [arg] from ||| num [arg]	count=1
arg	required return ||| name sub	count=3
function	[function_1] threads ||| [function_1] [function_2]	count=4
function	convert addsd to ||| local addsd ccode	count=1
function	wrapper around sparsevariable constructor [function_1] [function_2] same dtype and ||| sparse [function_2] [function_1]	count=1
function	scale ||| scale	count=3
arg	required to compute the ||| variable_list blockers	count=1
function	[function_1] gradweights ||| [function_1] [function_2]	count=2
function	also work for gpuincsubtensor ||| inplace setsubtensor	count=1
arg	mini-batch of a stack ||| input_shape filter_shape	count=3
function	task ||| find task	count=1
function_arg	[function_1] according ||| [function_1] [arg_2]	count=5
function	kernel for bilinear upsampling ||| bilinear	count=2
arg	a / [arg_2] ||| [arg_2] [arg_1]	count=1
function	inner nit_sot ||| inner sitsot	count=1
function	value on the output ||| output	count=1
function	useless reshape ||| useless reshape	count=1
function	of convolution [function_2] ||| [function_1] [function_2]	count=3
arg	node by ||| node output_indices	count=1
arg	a rows ||| rows	count=1
function	variables ||| variables and	count=1
class	is a mrg stream ||| mrg random streams	count=1
function	apply the ||| apply	count=1
arg	sparse matrix [arg] by ||| [arg]	count=2
class	this variable ||| tensor	count=1
class	reorder ||| tensor py	count=1
function	and remove ||| local	count=1
function	with debug ||| with op	count=1
function_arg	string x ||| replace patterns x	count=1
class	the type's ||| type	count=1
class	for ||| tensor type	count=1
function	remove ||| remove	count=2
function	[function_1] inputs to ||| [function_1] [function_2]	count=4
function	transferred ||| transfer	count=1
class	this ||| py	count=1
module	of which is sparse ||| sparse	count=2
function	to determine the ||| adv index broadcastable	count=1
arg	the fgraph ||| fgraph	count=2
function	[function_1] x and ||| [function_2] [function_1] chol	count=1
function	apply [function_2] ||| [function_1] [function_2]	count=1
function	gpu ||| gpu	count=1
class	module ||| module	count=1
arg	es of a ||| dtype keepdims	count=1
function	attempting to use dnn ||| safe no dnn	count=2
class	for gpucorrmm ||| base gpu corr mm	count=1
function	this op could be ||| l op	count=1
function	a new graph ||| clone with new	count=1
function_arg	polar [arg_2] ||| [function_1] [arg_2]	count=1
function	of inplace ||| inplace check	count=1
function	and return ||| name	count=1
class	feature ||| feature	count=1
function	c ||| register specify shape c	count=1
arg	[arg_1] b are ||| [arg_2] [arg_1]	count=1
class	mrg stream ||| mrg random streams	count=2
function_arg	merge [arg_2] ||| [arg_2] [function_1]	count=1
function	a function that ||| function	count=1
module	nodes that must ||| gof	count=1
arg	of order v real ||| v x	count=2
arg	[arg_1] [arg_2] ||| [arg_2] [arg_1]	count=427
function	rebroadcast ||| rebroadcast	count=1
arg	tries to ||| image_shape top_shape	count=2
class	from ||| op from	count=2
arg	if l ||| l	count=1
function	with a triangular solve ||| solve triangular	count=1
arg	input a ||| input	count=3
function	useless dimshuffle ||| local useless dimshuffle	count=2
arg	gradients of cost and/or ||| cost	count=1
function_arg	[function_1] x ||| [function_1] out [arg_2]	count=2
function	1 0/a inplace on ||| inv inplace	count=1
function	must return a thunk ||| thunk	count=1
function	upper ||| triu	count=1
function	bilinear upsampling ||| bilinear	count=2
function_arg	inverse [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	[function_1] is inside ||| [arg_2] [function_1]	count=6
function	return a thunk ||| thunk	count=1
function	were declared by self ||| init	count=1
class	every node ||| graph	count=1
class	the graph and get ||| function graph	count=1
function	remove ||| local useless	count=1
class	toposort ||| function graph	count=1
function	function as its implementation ||| as	count=1
class	feature should remove any ||| feature	count=1
arg	end variables of a ||| end	count=1
module	of the graph ||| gof	count=1
function_arg	nodes [arg_2] ||| [arg_2] [function_1]	count=4
class	and dictionary data structures ||| push out non seq scan	count=1
function	lib directories that ||| lib dirs	count=2
arg	to zview [arg] ||| name x [arg]	count=1
module	functiongraph that ||| gof	count=1
function	folowing changes in the ||| mul switch sink	count=1
function	lib directories that are ||| lib dirs	count=1
module	detect if the ||| gof	count=1
module	this is ||| nnet	count=1
function	removes all [function_2] ||| [function_2] [function_1]	count=4
arg	to assert that x ||| x	count=1
function	the lock is removed ||| lock	count=1
function	for small or builtin ||| is simple	count=1
arg	inputs and ||| node inputs	count=1
arg	return the ||| name	count=1
function	has only one client ||| sitsot only	count=1
arg	variable out for occurrences ||| out	count=1
arg	list of compilation flags ||| libs flags libs_dir include_dir	count=1
arg	y with length ||| y axis	count=1
class	node ||| graph	count=1
function	from a uniform distribution ||| uniform	count=1
class	inserting broadcasted ||| py	count=1
function	[function_1] asserts from ||| [function_2] [function_1]	count=5
function	total time icluding ||| compute total times	count=2
function	the version ||| cache version	count=3
function	bitwise ~a ||| invert	count=1
arg	initializes py_name to ||| r name	count=1
function	insert deepcopy ||| insert deepcopy	count=2
function	the connection ||| connection	count=1
module	type's :attr ||| gpuarray	count=1
function	batch ||| dnn batch	count=1
function	[function_1] be removed ||| [function_1] remove [function_2]	count=2
arg	[arg_1] i ||| [arg_2] o [arg_1]	count=2
class	feature should ||| feature	count=1
module	that can ||| gof	count=2
arg	sample from ||| random_state size	count=1
function	return [function_2] ||| [function_2] [function_1]	count=8
module	to the type's ||| gpuarray	count=1
function_arg	[function_1] function to ||| [function_1] [arg_2]	count=3
function	nonzero_values ||| nonzero values	count=1
function	diagonalsubtensor and ||| diagonal subtensor	count=1
module	constant that ||| gof	count=1
function	lock to ||| to	count=1
function	and [function_1] [function_2] ||| [function_1] constants and [function_2]	count=1
function_arg	a transfer function ||| transfer fn	count=1
class	mrg ||| mrg	count=1
arg	shape or ||| shape	count=1
function	a [function_1] [function_2] ||| [function_1] [function_2]	count=8
arg	was dumped to a ||| f persistent_load	count=1
arg	and t is a ||| node input_storage output_storage	count=1
module	by [module] ||| [module]	count=4
function	topooptimizer from ||| in2out	count=1
arg	if a and b ||| a b	count=1
function	the folowing changes ||| local mul switch sink	count=1
arg	vector and ||| node input_storage output_storage	count=1
function_arg	matrix [arg_2] ||| sparse [function_1] sum [arg_2]	count=1
function_arg	convert radian [arg_2] ||| [arg_2] [function_1]	count=3
function	integers indicating the version ||| code cache version apply	count=1
function_arg	[function_1] node by ||| [function_1] inplace fgraph [arg_2]	count=2
function	lib directories that ||| header dirs	count=1
function	abs and ||| abs	count=1
arg	sample from one ||| random_state size	count=1
function	the dependence of ||| dependence	count=1
function	builds the 2d ||| 2d	count=1
arg	to make code ||| code	count=1
function	ger ||| ger or	count=1
function	an alloc ||| alloc	count=2
class	for [class_2] ||| [class_1] [class_2]	count=3
class	dimensions of ||| operators	count=1
function	a thunk ||| make thunk	count=1
function	scalar [function_2] ||| [function_1] constant [function_2]	count=1
function	upcasts constant [function_2] ||| [function_1] [function_2]	count=2
function	the svd ||| svd	count=1
class	type's :attr ||| gpu	count=1
module	reorder the dimensions ||| tensor	count=1
function	unfortunately conda offers to ||| to os environ pathlist	count=1
function	sure [function] ||| update [function]	count=1
arg	be between min ||| min	count=1
module	only if this ||| gof	count=1
class	functiongraph ||| function graph	count=2
function	find broken ||| find bad optimizations2	count=1
arg	a version of var ||| var	count=1
arg	if fgraph is the ||| fgraph no_recycling profile	count=1
function	[function_1] [function_2] same dtype and ||| sparse [function_2] [function_1]	count=8
arg	one tensor ||| y	count=2
function	find ||| find bad	count=1
function	be removed ||| outs	count=2
module	version used is ||| gof	count=1
arg	return a symbolic ||| dtype	count=3
arg	is the first functiongraph ||| no_recycling profile	count=1
function	from ||| get	count=1
module	return ||| gof	count=10
arg	its idx_list reorders ||| idx_list get_count	count=1
arg	r ||| r client_to_remove	count=1
function	with logsoftmax ||| logsoftmax	count=1
module	used ||| gof	count=1
function	y ||| c code	count=1
function	"init_code" together ||| code struct	count=1
arg	of nesting ||| loop_orders dtypes loop_tasks sub	count=1
class	this ||| function	count=1
function	[function_1] search paths ||| object [function_1] [function_2]	count=2
function	total ||| compute total	count=1
function	arctangent ||| arctan	count=1
function	optional return [function] required ||| c [function]	count=1
function_arg	[function_1] [arg_2] 1s ||| [function_1] padleft t [arg_2]	count=1
class	of this mode ||| mode	count=2
function	lib [function_2] ||| [function_2] [function_1]	count=4
function	on the inner graph ||| inner graph	count=1
arg	of 2d filters ||| filters	count=2
class	type's :attr context_name ||| array type	count=1
function	on ||| as gpuarray	count=1
arg	f [arg_2] ||| [arg_2] [arg_1]	count=2
function	on cpu here ||| local pow specialize	count=1
function	sparse ||| sparse	count=1
function	that unroll ||| gen conv code unroll	count=1
class	gradient for the eigensystem ||| eigh grad	count=1
function	graph to ||| graph	count=1
function	-> [function_2] ||| [function_2] [function_1]	count=2
class	inserting ||| operators	count=1
function	recognize the updates ||| updates	count=1
function	broadcast them ||| generate broadcasting	count=1
function	optional return [function] ||| c [function]	count=2
function_arg	[function_1] for navigatoroptimizer ||| [arg_2] [function_1]	count=1
function	idx_list with constant ||| get constant idx	count=2
function	ignore all errors ||| warn ignore	count=1
function	in a sparse ||| sparse	count=1
function	[function] and ||| and unused inputs [function]	count=2
class	new random [class_2] ||| [class_2] [class_1]	count=1
function	in defining the gradient ||| grad	count=1
function_arg	after [arg_2] ||| core warn [function_1] [arg_2]	count=1
arg	orv(list1 \ list2) ||| o n	count=1
function	of shape ||| infer shape	count=1
function	performs batch ||| batch	count=2
function	the 2d [function_2] ||| [function_2] [function_1]	count=6
arg	v by a with ||| v	count=1
arg	array of ints ||| x weights minlength assert_nonneg	count=1
class	to the type's ||| array	count=1
function	the task ||| find task	count=1
class	of scan return ||| scan	count=1
function	gradinputs ||| gradinputs	count=2
function	full path of the ||| module	count=1
arg	axis ||| x axis	count=1
module	scalar scalar ||| scalar	count=1
arg	x to [arg_2] ||| [arg_2] [arg_1]	count=3
class	for ||| type	count=1
class	[class_1] variable ||| [class_1] [class_2]	count=4
function	[function_1] [function_2] required by code returned ||| object [function_1] [function_2]	count=1
arg	this function tries ||| image_shape top_shape border_mode	count=2
function	list of lib ||| lib	count=1
function	[function] of a ||| sp [function]	count=2
function	pattern for advancedsubtensor ||| pattern	count=1
arg	fgraph and a list ||| fgraph	count=1
function	lock to ||| add to	count=1
arg	parametrize it to make ||| max_input_fct maker	count=1
function	the constant ||| constant	count=2
function	of useless [function_2] ||| [function_1] [function_2]	count=1
arg	each level of nesting ||| loop_orders dtypes loop_tasks	count=1
function_arg	a gist [arg_2] ||| [arg_2] [function_1]	count=1
function	a slice [start ||| slice	count=1
function	[function_1] object with ||| [function_2] [function_1]	count=1
function	used ||| gcc	count=1
function	unroll ||| unroll	count=1
module	that node ||| gof	count=1
function	[function] integer ||| [function]	count=1
arg	and ||| node	count=4
function	[function] gpu? ||| [function]	count=1
arg	to [arg] to the ||| [arg]	count=1
arg	a tensor input ||| input	count=3
function_arg	scan [arg_2] ||| [arg_2] [function_1]	count=9
class	[class_1] eigensystem ||| [class_2] [class_1]	count=2
function	the version ||| version apply	count=1
arg	sample from ||| size n	count=1
function_arg	scan [arg_2] ||| [function_1] inplace fgraph [arg_2]	count=4
function	one ||| one	count=1
arg	[arg_1] input ||| [arg_2] axis [arg_1]	count=3
class	solve ||| solve	count=1
class	level of the list ||| list	count=1
function	the batch size loop ||| batch	count=1
module	node ||| d3viz	count=1
arg	then ift else iff ||| ift iff	count=1
function_arg	shape tuple [arg_2] ||| [function_1] [arg_2]	count=1
function	fixed [function] ||| warn [function]	count=2
function_arg	transferred [arg_2] ||| [arg_2] [function_1]	count=1
arg	by b with ||| b	count=1
arg	[arg_1] replaced by ||| [arg_2] [arg_1]	count=1
function	inner-most loop executes ||| reordered loop	count=1
function	function is a thunk ||| make thunk	count=1
function	or more multinomial distributions ||| multinomial	count=1
arg	considered to [arg] to ||| [arg]	count=1
arg	a / ||| a	count=1
function	on the inner ||| inner	count=1
function	within the op ||| get op	count=1
arg	var2 ||| var2	count=1
function	each columns ||| col	count=1
function	arguments ||| args	count=2
arg	interface to manipulate ||| r new_r reason verbose	count=1
class	variable optionally inserting broadcasted ||| tensor py	count=1
function	register a context ||| reg context	count=1
function	c code ||| c	count=3
module	wraplinker that runs a ||| gof	count=1
class	the dimensions of ||| py operators	count=1
function	list of shape ||| shape	count=1
function	-> alloc(unary x ||| local	count=1
function	unused [function_2] ||| [function_2] [function_1]	count=1
arg	and t is ||| node input_storage	count=1
arg	new [arg] based on ||| replacer [arg]	count=1
module_class	this [class_2] ||| [module_1] [class_2] clone	count=3
function	2d kernel that can ||| kernel 2d	count=1
function	[function_1] loop over ||| [function_1] [function_2]	count=1
function	elementwise conjugate ||| conj	count=1
class	shared ||| shared	count=1
arg	type dtype ||| dtype	count=1
function	change all sigmoid ||| sigmoid	count=1
function	[function_1] [function_2] required by code returned ||| [function_1] [function_2]	count=4
function	[function_1] a value ||| [function_2] [function_1]	count=1
function	and rel error of ||| rel	count=1
arg	given axis ||| axis	count=8
arg	dtype as [arg_2] ||| [arg_2] fgraph [arg_1]	count=1
function	sparse format ||| sparse	count=1
function	register a transfer ||| register transfer	count=3
function	the last access ||| last access time	count=2
class	random [class_2] ||| [class_2] [class_1]	count=3
class	a shared ||| shared	count=1
class	matrix a and ||| structured	count=1
function	with the same ||| like	count=1
function	the apply ||| apply	count=1
arg	name in ||| name	count=1
arg	and its idx_list reorders ||| idx_list get_count	count=1
function	logsoftmax ||| logsoftmax	count=1
function	[function] is not ||| update [function]	count=1
class	mrg [class_2] ||| [class_1] [class_2]	count=4
arg	sample from one ||| size	count=1
class	variable optionally inserting ||| tensor py	count=1
function	and rel error ||| rel	count=1
module_class	[module_1] enum ||| [module_1] [class_2]	count=6
arg	of x [arg_2] ||| [arg_2] [arg_1]	count=2
function	2d [function_2] ||| [function_2] [function_1]	count=6
arg	between min [arg_2] ||| [arg_1] [arg_2]	count=1
function	return the abs ||| abs	count=1
arg	spatio-temporal filters with a ||| filters	count=1
class	variable optionally inserting broadcasted ||| operators	count=1
module	to output ||| gof	count=1
arg	contents ||| dirname err files	count=1
module	the type's :attr context_name ||| gpuarray	count=1
function	crossentropysoftmax1hotwithbiasdx op whose incoming ||| useless crossentropy softmax 1hot with bias dx	count=1
function	get the right ||| get	count=1
function	[function_1] directories that ||| [function_1] [function_2]	count=4
function	code to ||| code	count=1
arg	function for alternative targets ||| fn	count=1
module	baddestroymap if ||| compile	count=1
function_arg	some requirements [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	[function_1] a b ||| [function_1] [arg_2]	count=1
function	a view ||| view	count=1
function	inverses [function] ||| [function] func	count=1
arg	half of v by ||| v	count=1
arg	test ||| n_tests	count=1
function	hash equal for ||| hash	count=1
arg	the input [arg_2] ||| [arg_2] [arg_1]	count=3
arg	if the named module ||| fullname	count=1
function	to the task ||| task	count=1
function	rest ||| rest	count=1
function	pass to helper_c_code ||| helper c code	count=1
class	new random stream ||| random streams	count=2
arg	if fgraph [arg_2] ||| vm linker accept [arg_1] [arg_2]	count=4
function	that unroll the batch ||| code unroll batch	count=1
function_arg	[function_1] the url ||| [function_1] [arg_2]	count=3
function	return the constant scalar ||| scalar constant	count=2
arg	failure_callback [arg_2] ||| [arg_1] [arg_2]	count=1
arg	[arg_1] y ||| sparse structured minimum [arg_1] [arg_2]	count=2
function	[function_1] [function_2] ||| [function_1] and [function_2]	count=6
arg	over given axis ||| axis	count=2
function	upper bound ||| bound	count=1
function_arg	diff to [arg_2] ||| [function_1] [arg_2]	count=1
arg	computes the specified outputs ||| fgraph	count=1
function	the inner ||| inner	count=1
function	x y -> x ||| local	count=1
function	to make itself ||| to	count=1
arg	elemwise minimum of sparse [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
arg	this function tries ||| image_shape top_shape	count=2
function	to ||| make constant	count=1
function	inner ||| inner sitsot	count=1
function_arg	compare true [arg_2] ||| [arg_2] [function_1]	count=2
function	insert [function_2] ||| [function_2] [function_1]	count=3
function	[function_1] elemwise ||| [function_2] [function_1]	count=9
arg	the stopping condition returned ||| ls	count=1
function	image shape ||| shape 1axis	count=2
function	[function] key ||| [function]	count=1
class	shared [class_2] ||| [class_1] [class_2]	count=2
function	canonical ||| get canonical	count=1
class	a module if ||| module	count=1
module	variables that ||| gof	count=1
class	of ||| tensor py operators	count=2
arg	or none for the ||| i_shapes	count=1
function_arg	the sum [arg_2] ||| [function_1] input [arg_2]	count=5
arg	function tries ||| image_shape top_shape border_mode subsample	count=2
function	connection pattern of ||| io connection pattern	count=2
arg	of order v ||| v x	count=2
function	generate a diff ||| diff	count=1
function	v ||| tree set	count=1
class	type ||| typed list type	count=1
class	dimensions ||| py operators	count=4
arg	name r ||| r name	count=2
arg	[arg] tensor ||| input leftdims [arg]	count=1
module	takes as ||| tensor signal	count=1
function	offers to ||| to os	count=1
arg	the value after ||| default filter	count=1
function_arg	of shape [arg_2] ||| [function_1] node [arg_2]	count=2
function	that unroll ||| conv code unroll	count=1
function	were declared by ||| init	count=1
class	normal ||| streams base	count=1
class	tensor ||| py operators	count=1
arg	replace a symbol ||| symbol	count=1
function_arg	multiplication [arg_2] ||| [arg_2] [function_1]	count=1
function	"init_code" together ||| init code struct	count=1
arg	function ||| fn	count=1
function	make a nested ||| make	count=1
arg	outputs from [arg_2] ||| [arg_2] [arg_1]	count=2
function	shape ||| default infer shape	count=1
module	this op ||| gof	count=1
function	dnn ||| safe no dnn	count=2
arg	the conventions imposed ||| theslice length	count=1
arg	the shape or the ||| shape	count=1
function	[function_1] from ||| [function_1] [function_2]	count=6
arg	a compiled theano ||| fct	count=1
function	platform-dependent gcc [function_2] ||| [function_2] [function_1]	count=1
function	the [function_1] [function_2] ||| [function_1] [function_2]	count=6
class	dimensions of this variable ||| tensor py	count=1
module	that operates ||| gof	count=1
arg	contents of a ||| dirname err files	count=1
class	optionally inserting broadcasted ||| py	count=1
class	reorder the dimensions of ||| tensor py operators	count=1
function	outputs and the ||| and outputs	count=2
class	by ||| clinker type	count=1
function_arg	config string [arg_2] ||| [arg_2] [function_1]	count=1
function	total time icluding ||| total times	count=1
function	pattern for ||| pattern	count=1
function	dict ||| dict	count=1
arg	assert that x and ||| x	count=1
function	is ||| gcc	count=1
class	variable optionally inserting ||| py operators	count=1
function	platform ||| platform	count=1
function_arg	transferred [arg_2] ||| [function_1] var [arg_2]	count=1
function	kinds of useless reshape ||| useless reshape	count=1
arg	to the end variables ||| end	count=1
arg	to the end variables ||| wrt end	count=1
function	turn softmax(sum_of_stuff) -> ||| local	count=1
arg	input a n-d ||| input ws ignore_border stride	count=2
function	with a ||| with	count=1
function	all sigmoid [function_2] ||| [function_2] [function_1]	count=2
arg	op a list ||| op	count=1
function	access of a ||| access	count=1
class	random [class_2] ||| [class_1] [class_2]	count=3
function_arg	upper triangle ||| triu m k	count=1
function	logsoftmax x 's ||| local logsoftmax	count=1
function	poisson ||| poisson	count=1
arg	this function tries ||| top_shape	count=4
function	mean value along the ||| mean	count=1
function	conv output gradient w ||| grad	count=3
arg	inputs [arg_2] ||| [arg_1] [arg_2]	count=4
class	scan return true ||| push out scan	count=1
arg	failure_callback for ||| exc	count=2
function	broadcast them to match ||| generate broadcasting	count=1
module_class	of this op ||| gof clinker op	count=1
function_arg	inplace on [arg_2] ||| [function_1] [arg_2]	count=10
function_arg	[function_1] a with ||| [arg_2] [function_1]	count=1
arg	that x ||| x	count=1
function	in a new ||| new inputs	count=1
class	dimensions of this ||| py operators	count=1
function	inputs [function] arbitrary ||| pad [function]	count=1
function_arg	left-padding [function_1] [arg_2] 1s ||| [function_1] [arg_2]	count=1
module	variable ||| tensor	count=1
class	to the ||| gpu array type	count=1
function	metaclass ||| add metaclass	count=1
module	g++ version used is ||| gof	count=1
function	stack ||| copy stack	count=1
arg	x to a tensor ||| x	count=1
function	constant scalar [function_2] ||| [function_1] [function_2]	count=1
function	stack ||| stack	count=2
function	explicitly upcasts constant ||| constant	count=1
function_arg	hot [arg_2] ||| [function_1] [arg_2]	count=1
function	headers ||| headers	count=1
function	interface ||| text	count=1
function	graph ||| graph	count=2
function	optionally inserting broadcasted ||| dimshuffle	count=1
function	dimensions ||| dimshuffle	count=2
function	[function_1] trace ||| [function_2] [function_1]	count=3
arg	on ||| a	count=3
function	inverses [function] them from ||| [function] func	count=1
function	has only ||| sitsot only	count=1
function	loop ||| loop	count=2
function	the op code ||| op	count=1
function	detect [function_2] ||| [function_1] macos sdot [function_2]	count=1
function	wrt, computes gradients ||| subgraph grad	count=1
function	/ ||| div	count=1
arg	reshapes the input ||| input	count=1
class	this variable optionally ||| tensor py operators	count=1
function_arg	sum along [arg_2] ||| [function_1] input [arg_2]	count=5
class	of ||| py operators	count=2
arg	[arg_1] [arg_2] of ||| [arg_2] [arg_1]	count=13
module	version used ||| gof	count=1
arg	array of ints ||| weights minlength assert_nonneg	count=1
arg	unification where [arg] ||| [arg]	count=2
arg	of a dense vector ||| s	count=1
arg	[arg_1] [arg_2] tensor this helper function ||| [arg_1] [arg_2]	count=34
function	object with ||| with	count=1
module	version ||| gof	count=1
arg	dense vector ||| s	count=1
arg	b with [arg_2] ||| [arg_2] [arg_1]	count=4
function	dot product ||| true dot	count=1
function	the g++ version used ||| gcc	count=1
function	be a legal ||| is valid	count=1
function	[function_1] inputs ||| and [function_1] [function_2]	count=1
module	that runs ||| gof	count=1
function	to helper_c_code ||| get helper c code	count=1
arg	will have [arg_2] ||| [arg_2] [arg_1]	count=4
class	data structures ||| out non seq	count=1
function	[function_1] scan ||| [function_2] [function_1]	count=6
function	gist and return the ||| gist	count=1
class	reorder ||| tensor py operators	count=2
function	"init_code" ||| init code struct	count=1
function_arg	of [function_1] [arg_2] ||| sparse [function_1] sum [arg_2]	count=2
class	the dimensions ||| operators	count=1
arg	reshapes the input to ||| input	count=1
arg	order v ||| v x	count=2
arg	[arg_1] [arg_2] ||| [arg_1] name [arg_2]	count=1
function	epoch of the last ||| last	count=1
function	sum along the ||| sum	count=1
function	or [function] replace node ||| [function]	count=1
class	same ||| shape feature	count=1
arg	a and [arg_2] ||| eq [arg_1] [arg_2]	count=1
function	partition a ||| scalarconsts	count=1
arg	op ||| op	count=2
function	the op ||| get op	count=1
function_arg	all device we ||| device node	count=1
arg	name in mode ||| name opt	count=1
function	infer the ||| infer	count=1
function	the mean value along ||| mean	count=1
arg	the original graph to ||| inputs outputs copy_inputs_and_orphans memo	count=1
arg	a [arg] ||| [arg] axis dtype	count=1
function	unroll the batch ||| unroll batch	count=1
function	of a cache directory ||| from dir	count=1
class	[class] with ||| [class]	count=1
function	[function_1] to helper_c_code ||| [function_2] [function_1]	count=4
function	of theano gof graph ||| graph	count=1
class	mflops ||| conv op	count=1
function	last access of a ||| last access	count=1
function_arg	[function_1] inputs ||| [function_1] idx [arg_2]	count=1
class	for ||| tensor	count=1
class	cache or the disk ||| module cache	count=1
function	shape of convolution gradinputs ||| get conv gradinputs shape	count=2
function	the apply to be ||| apply	count=1
arg	y with length one ||| y	count=1
function	return the inputs ||| inputs	count=1
function	get the 0 ||| get depth	count=1
function	some requirements to ||| requirements	count=1
class	random ||| streams base	count=1
class	copy of the type ||| type	count=1
function_arg	<= [arg_2] ||| [function_1] inplace a [arg_2]	count=1
arg	mean ||| mean	count=2
function	output error and ||| output	count=1
class	a mrg stream ||| mrg random streams	count=2
function	unroll ||| conv code unroll	count=1
function_arg	[function_1] [arg_2] utility code for use ||| [function_1] support code apply [arg_2]	count=1
function	to replace [function_2] ||| [function_2] [function_1]	count=3
arg	variables in inputs to ||| inputs	count=1
function	replacement if the ||| replace	count=1
function	utility [function] ||| c support [function]	count=1
arg	[arg_1] a ||| [arg_2] m1 [arg_1]	count=3
arg	required return c code ||| name	count=1
function_arg	[function_1] of x ||| [arg_2] [function_1]	count=1
class	dictionary data structures ||| push out non seq scan	count=1
class	variable optionally ||| tensor	count=1
function	the output shape of ||| output shape	count=1
function	the task ||| task	count=1
module	[module] an unification ||| [module]	count=3
function	matrix [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] [function_2] ||| [function_1] from [function_2]	count=3
function	copies the stack ||| copy stack	count=1
function	stack trace from one ||| copy stack trace	count=1
function	the confusion [function_2] ||| [function_1] [function_2]	count=2
arg	es [arg_2] ||| [arg_2] axis [arg_1]	count=3
arg	return ||| name inputs	count=1
class	is ||| path importer	count=1
function	also work for gpuincsubtensor ||| local inplace setsubtensor	count=1
class	dot product ||| dot	count=1
class	an functiongraph ||| function graph	count=1
function	if a dimshuffle ||| dimshuffle	count=1
class	types ||| clinker type	count=2
function	gradient w r ||| conv3d grad	count=2
function_arg	clip [arg_2] ||| [function_1] [arg_2]	count=7
function	names to an ||| names	count=1
arg	[arg_1] leftdims ||| [arg_2] [arg_1]	count=2
arg	filters with a movie ||| filters signals_shape filters_shape	count=1
module	nnet ||| tensor nnet	count=1
arg	to break aliasing of ||| wrapped_inputs wrapped_outputs	count=1
function	to the idx ||| idx	count=1
function	e^a ||| exp	count=1
function	the last ||| last	count=1
arg	whether [arg] is always ||| [arg]	count=1
arg	r to ||| r	count=2
function	the output error and ||| output	count=1
module	reorder ||| tensor	count=1
function_arg	[function_1] a x ||| [arg_2] [function_1]	count=1
function	the list of outputs ||| outputs	count=1
function	[function_1] [function_2] a sparse matrix ||| [function_2] [function_1]	count=1
function	debug [function_2] ||| [function_2] [function_1]	count=2
arg	basic slow python 2d ||| img kern mode dilation	count=1
module	g++ ||| gof	count=1
arg	and t is ||| node	count=1
arg	on cpu ||| a full_matrices compute_uv	count=2
class	dictionary data structures ||| out non seq	count=1
arg	message on the first ||| msg	count=1
module	optional return ||| gof	count=1
module	scalar values default ||| scalar	count=1
function	load a file that ||| load	count=1
arg	tries ||| image_shape top_shape border_mode	count=2
arg	sample [arg_2] ||| [arg_2] [arg_1]	count=4
function	[function_1] declare variables ||| [function_1] [function_2]	count=1
function	for openblas [function_2] ||| [function_1] [function_2]	count=2
function	[function_1] following ||| [function_2] [function_1]	count=1
class	same kinds of ||| tensor type	count=1
function_arg	helper function to ||| helper random_state a	count=1
class	structures ||| out non seq	count=1
function	with constant ||| constant idx	count=1
function	[function_1] single prod() ||| [function_2] [function_1]	count=2
function	[function_1] columns ||| sparse [function_2] [function_1]	count=1
function	return a list ||| get	count=1
function	to generate permutations ||| permutation	count=1
function	comparator ||| cmp	count=1
function	batch ||| batch	count=3
class	mod ||| mod	count=1
function_arg	[function_1] [arg_2] the same type but ||| [function_1] [arg_2] dtype	count=4
arg	is ||| no_recycling profile	count=1
function	[function_1] batch ||| [function_2] [function_1]	count=2
function	following [function_2] ||| [function_2] [function_1]	count=1
class	same type ||| type	count=1
arg	necessary update dr_vals ||| r_vals dr_vals	count=1
function	replace_all_validate ||| validate	count=1
function	functional inverses [function] them from ||| [function] func	count=1
arg	tensor of type dtype ||| dtype	count=1
function	a variable on ||| gpuarray variable	count=1
arg	[arg] is not ||| [arg]	count=3
module	with ||| scan_module	count=1
function	t [function] b [idxs] ||| local subtensor of [function]	count=1
class	use [class_1] [class_2] ||| [class_1] [class_2]	count=6
class	the sparse [class] ||| [class] dot	count=3
arg	return a ||| name x	count=1
class	optionally inserting broadcasted dimensions ||| py	count=1
module	same kinds of ||| tensor	count=1
arg	level of nesting ||| loop_orders dtypes loop_tasks	count=1
class	:attr context_name ||| gpu array	count=1
arg	ints ||| x weights minlength assert_nonneg	count=1
function	connection pattern of ||| connection pattern	count=2
function	the version ||| c code cache version apply	count=1
function	[function_1] asserts ||| [function_2] [function_1]	count=5
function	structured ||| structured	count=1
arg	a / b ||| a b	count=3
function	convert ||| make constant	count=1
function	load a file ||| load	count=1
function	find ||| find bad optimizations2	count=2
arg	in this node ||| node	count=1
class	gpucorrmm (direction="forward"), ||| corr mm	count=1
function	the inner-most loop ||| reordered loop	count=1
function	last [function_2] ||| [function_1] [function_2]	count=4
class	for matrix solve operation ||| solve	count=1
function_arg	extract a [arg_2] ||| [arg_2] [function_1]	count=1
class	this variable ||| py	count=1
arg	given axis [arg_2] ||| [arg_1] [arg_2]	count=12
function	set of 3d ||| conv3d	count=1
arg	indicating whether [arg] is ||| [arg]	count=1
function	folowing changes in ||| mul switch sink	count=1
function	determine ||| adv index broadcastable	count=1
function	a sparse [function] ||| [function]	count=2
function	from variable and apply ||| get	count=1
module	if this ||| gof	count=2
arg	orv(list1 \ list2) ||| o n u	count=1
function	declare variables ||| declare	count=1
arg	old_r to new_r ||| old_r	count=1
function	the stack trace ||| copy stack trace	count=2
arg	raise baddestroymap if ||| node storage_map	count=1
function_arg	transferred to [arg_2] ||| [arg_2] [function_1]	count=1
function	if ||| check inputs	count=2
function	softmax ||| softmax	count=1
function	small or builtin ||| is simple	count=1
class	the dimensions ||| tensor	count=1
function	insert ||| insert	count=1
function	[function_1] [function_2] and ||| [function_1] and unused inputs [function_2] node	count=2
function	list to get ||| get idx list	count=1
arg	function ||| random_state	count=4
arg	initializes py_name to ||| r name sub	count=1
class	variable ||| variable	count=2
arg	sample from one or ||| size n	count=1
function	idx_list with [function_2] ||| [function_2] [function_1]	count=2
function	optional ||| c	count=4
function	has only one ||| only	count=1
class	to the type's ||| type	count=1
function	subtract ||| sub	count=1
arg	matrix [arg] by scalar ||| [arg]	count=2
function	an inplace ||| inplace	count=1
arg	[arg_1] and y ||| [arg_2] [arg_1]	count=4
class	of ||| py	count=1
function	it with logsoftmax ||| logsoftmax	count=1
function_arg	gist and [arg_2] ||| [function_1] [arg_2]	count=1
class	is ||| meta path importer	count=1
function	conv output gradient ||| conv3d grad	count=2
function	[function_1] batch size ||| [function_1] [function_2]	count=2
function	[function_1] [function_2] required by code returned ||| object c [function_1] [function_2]	count=3
function	partition a list of ||| scalarconsts	count=1
class	structures ||| out non	count=1
function	inserting broadcasted dimensions ||| dimshuffle	count=1
function	all asserts from ||| all assert	count=2
function	infer the number ||| infer	count=1
class	inserting ||| tensor py operators	count=2
class	the ||| array	count=2
function	change [function] only ||| [function] and	count=1
function_arg	[function_1] out_shape ||| [arg_2] [function_1]	count=1
function	a ^ ||| xor	count=1
arg	s [arg_2] ||| [arg_1] [arg_2]	count=1
function	constants from [function] arguments and ||| [function]	count=1
function	thunk that ||| thunk	count=1
module	sparse matrix multiplication ||| sparse	count=1
arg	tries ||| image_shape top_shape	count=2
function	and the rest ||| rest	count=1
function	config blas ldflags ||| ldflags	count=1
function	have a stack ||| check stack	count=1
class	op ||| clinker op	count=2
function	unused inputs ||| and unused inputs	count=1
class	the ||| type	count=2
class	of this variable ||| tensor py	count=1
function	to ||| add to	count=1
function	context ||| context	count=1
arg	[arg_1] x ||| [arg_2] [arg_1]	count=1
function	sigmoid to ultra_fast_sigmoid ||| ultra fast sigmoid	count=1
class	help the navigator deal ||| navigator optimizer	count=1
function	this op ||| l op	count=1
class	[class_1] stream state ||| [class_1] [class_2]	count=4
function	of lib [function_2] ||| [function_2] [function_1]	count=4
arg	inputs according to ||| inputs	count=1
function	baddestroymap ||| inputs	count=1
function	diagonalsubtensor and ||| get diagonal subtensor	count=1
arg	is associated to ||| failure_code	count=1
function	output [function_2] ||| [function_2] [function_1]	count=3
function	the indptr ||| indptr	count=1
function	diff to ||| diff	count=1
function_arg	[function_1] [arg_2] same type but with ||| [function_1] [arg_2] dtype	count=4
class	scan ||| push out scan	count=1
arg	from [arg] corresponds ||| [arg]	count=1
function_arg	[function_1] given version ||| core warn [function_1] [arg_2]	count=1
class	to the ||| array	count=1
arg	[arg_1] template ||| [arg_2] [arg_1]	count=2
arg	return a ||| name sub	count=1
arg	if fgraph [arg_2] ||| [arg_2] [arg_1]	count=4
class	sparse [class] ||| [class] dot	count=3
arg	required return c ||| name	count=1
function	to extract a ||| extract	count=1
arg	[arg_1] es of ||| [arg_2] [arg_1]	count=9
class	[class] which operates ||| [class]	count=2
arg	and/or from existing start ||| start	count=1
arg	[arg_1] max ||| [arg_2] [arg_1]	count=4
function_arg	[function_1] [arg_2] ||| [function_1] orphans [arg_2]	count=4
arg	symbolic ||| dtype	count=3
function	apply to ||| apply	count=1
arg	set in a ||| a	count=1
function_arg	a <= [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function	[function_1] sparse matrix ||| sparse as [function_2] [function_1]	count=2
function	the replacement ||| replace	count=1
function	performs batch normalization of ||| dnn batch normalization	count=1
module	[module] an ||| [module]	count=3
function	label of apply ||| apply label	count=3
function_arg	[function_1] a name ||| [function_1] [arg_2]	count=2
function	thunk ||| make thunk	count=1
class	returns a module ||| module	count=1
function	output gradient ||| conv2d grad	count=1
arg	matrix [arg] by ||| [arg]	count=2
arg	computes the ||| ishape kshape border_mode subsample	count=1
function	replace a leaf ||| replace leaf	count=2
function	and only adds ||| local	count=1
arg	[arg_1] between min ||| [arg_2] [arg_1]	count=1
module	the g++ version used ||| gof	count=1
function	tensor_from_scalar(scalar_from_tensor ||| scalar	count=1
function_arg	the scan [arg_2] ||| [arg_2] [function_1]	count=4
arg	returns true if l ||| l	count=1
function	scale [function_2] ||| sparse [function_2] [function_1]	count=6
function_arg	[function_1] a 4-d ||| [arg_2] [function_1]	count=1
class	for gpucorrmm (direction="forward"), gpucorrmm_gradweights ||| base gpu corr mm	count=1
class	to ||| optimizer	count=1
arg	this function returns val ||| val	count=1
function	py_none ||| get c init	count=1
function_arg	exception [arg_2] ||| [arg_2] [function_1]	count=3
class	type's :attr ||| array	count=1
function	threads interface ||| threads text	count=2
function_arg	to roll tensortypes ||| roll x shift	count=1
function	stack trace from ||| stack trace	count=1
function	[function_1] variables ||| [function_1] [function_2] replacer	count=1
function	the confusion ||| confusion	count=1
function	this op scale or ||| scale	count=1
function	[function_1] extract ||| [function_2] [function_1]	count=1
arg	b ||| b	count=23
function	hash of a ||| hash	count=1
module	the type's :attr ||| gpuarray	count=1
function	scalar ||| scalar	count=4
function	object with debug info ||| with op	count=1
arg	outputs ||| fgraph	count=1
module	of [module] variable undefined ||| [module]	count=1
function	to a gist and ||| gist	count=1
class	optionally inserting ||| py operators	count=1
function	module ||| get module	count=1
class	dimensions of ||| py operators	count=1
module	that can be ||| gof	count=2
function	[function_1] [function_2] of ||| [function_1] [function_2]	count=10
function	[elementwise] smallest ||| smallest	count=1
function	1d kernel for bilinear ||| bilinear	count=1
function	function for diagonalsubtensor and ||| diagonal subtensor view	count=1
function	[function_1] [function_2] a sparse matrix by ||| [function_2] [function_1]	count=1
class	inserting broadcasted ||| operators	count=1
module	will be created if ||| gof	count=1
function	leaf of a ||| leaf	count=1
function	return the op ||| op	count=1
function_arg	lower [arg_2] ||| [function_1] [arg_2]	count=4
function	version ||| cache version	count=3
function_arg	of a sparse [function_1] [arg_2] ||| sparse [function_1] sum x axis [arg_2]	count=3
function	the image shape of ||| shape 1axis	count=1
function	[function_1] the following ||| [function_2] [function_1]	count=1
function	a graph of apply ||| apply	count=1
function	x -> sigm ||| local	count=1
arg	function computes ||| ishape kshape border_mode subsample	count=1
arg	tensortypes [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	with constant [arg_2] ||| [function_1] [arg_2]	count=5
function	[function_1] counter ||| [function_1] [function_2]	count=1
function	exception [function_2] ||| [function_2] [function_1]	count=3
class	a function ||| function	count=1
function	[function_1] extract a ||| [function_2] [function_1]	count=1
arg	fgraph ||| fgraph no_recycling	count=1
function_arg	[function_1] a ||| [function_1] [arg_2]	count=22
function	assign the shape ||| set shape	count=1
function	useless ||| local useless	count=2
function_arg	transferred to target ||| transfer var target	count=2
arg	x to be ||| x	count=1
function	from polar ||| complex from polar	count=2
class	reorder the dimensions of ||| operators	count=1
function	output gradient ||| conv3d grad	count=2
function	2d kernel that ||| kernel 2d	count=2
arg	[arg] to ||| [arg] x	count=1
function	[function_1] batch ||| [function_1] [function_2]	count=2
arg	[arg] both inclusive ||| size [arg]	count=1
function	the batch ||| batch	count=1
function	to py_none ||| c init	count=1
function	names to ||| names	count=1
arg	an optimization disabled ||| node	count=1
module	scalar values default int64 ||| scalar	count=1
class	reorder the dimensions ||| tensor	count=1
arg	list remove are ||| remove reason	count=2
arg	optional return ||| name inputs	count=1
arg	[arg_1] a modulo ||| [arg_2] [arg_1]	count=5
class	the type's :attr ||| gpu array type	count=1
function_arg	[function_1] [arg_2] ||| [function_1] validate remove [arg_2]	count=4
function_arg	[function_1] x ||| [function_1] [arg_2]	count=5
function_arg	[function_1] value ||| [function_1] hook type [arg_2]	count=1
arg	between low and high ||| low high ndim	count=1
function_arg	| [arg_2] ||| [arg_2] [function_1]	count=1
function	new graph ||| new	count=1
function	updates ordereddict ||| get updates	count=1
function	unroll the batch size ||| code unroll batch	count=1
function	from variable ||| get	count=1
arg	-> list of variables ||| variables	count=1
function	compare true ||| eq	count=1
class	the type's ||| array type	count=1
arg	sample [arg_2] ||| [arg_1] [arg_2]	count=4
arg	specifyshape how ||| c_support_code_apply	count=1
function	all asserts ||| all assert	count=2
function	loop executes code ||| loop	count=1
function	platform-dependent gcc [function_2] ||| [function_1] [function_2]	count=1
arg	function computes the ||| ishape kshape border_mode	count=1
function	list of shape ||| default infer shape	count=1
function_arg	a != [arg_2] ||| [arg_2] [function_1]	count=1
function	return full ||| module name	count=1
function	the replacement if the ||| replace	count=1
arg	list [arg] ||| [arg]	count=1
function	input ||| same size	count=1
function	loop ||| reordered loop	count=1
class	apply instance in a ||| apply	count=1
class	:attr ||| gpu array	count=1
function	inner ||| validate inner	count=1
arg	construct new [arg] based ||| replacer [arg]	count=1
function	^ ||| xor	count=1
function	hash of [function_2] ||| [function_1] from [function_2]	count=1
function	determine the ||| adv index broadcastable	count=1
arg	drawing from ||| pvals size	count=1
function	the *args directly ||| csm properties csm	count=1
function	proxy for either ||| proxy	count=2
function	prod(prod()) -> single prod() ||| local op of op	count=1
arg	[arg_1] existing start ||| [arg_2] [arg_1]	count=4
function	in a new graph ||| with new inputs	count=1
function	determine the broadcast pattern ||| adv index broadcastable pattern	count=1
module	if ||| compile	count=1
arg	the ignore_trees-related functionality ||| fgraph importer pruner chin	count=1
arg	sparse matrix [arg] by scalar ||| [arg]	count=2
class	the module file ||| key data	count=1
function_arg	== [arg_2] ||| [arg_2] [function_1]	count=2
class	turned into macros for ||| cop	count=1
arg	test ||| fun pt n_tests	count=1
function	topooptimizer from the ||| in2out	count=1
function_arg	[function_1] a specified ||| [function_1] offset [arg_2]	count=1
function_arg	[function_1] function ||| [arg_2] [function_1]	count=7
function	make sure [function_1] [function_2] is not true if ||| [function_1] [function_2]	count=1
function	the matrix inverse ||| matrix inverse	count=2
arg	[arg_1] a leftdims ||| [arg_1] [arg_2]	count=3
arg	map old node to ||| check_integrity	count=1
arg	[arg_1] in y ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] instance ||| [arg_2] [function_1]	count=6
function	replace_all_validate ||| all validate remove	count=2
function	a legal [function_2] ||| [function_2] [function_1]	count=1
module	a constant that ||| gof	count=1
function	py_none ||| c init	count=1
function	[function_1] loop ||| [function_1] [function_2]	count=1
arg	triangle of ||| m k	count=2
function	alloc of 0 ||| local alloc	count=1
function	== ||| eq	count=2
function	pooling inputs [function] arbitrary ||| pad [function]	count=1
class	type's :attr context_name ||| gpu array	count=1
class	data structures ||| push out non	count=1
arg	[arg_1] and ||| [arg_2] [arg_1]	count=8
function	shape of [function_2] ||| [function_2] gradinputs [function_1]	count=2
class	the type's :attr ||| type	count=1
arg	cost and/or from ||| cost	count=1
function	"init_code" ||| code struct	count=1
arg	exception while annotating ||| exc_info storage_map	count=1
function	[function_1] shp) ||| [function_2] [function_1]	count=2
arg	-> ||| node	count=1
function	[function_1] [function_2] of a sparse matrix ||| [function_2] [function_1]	count=4
arg	data ||| data	count=2
class	this graph ||| function graph	count=1
function	normalization of the ||| normalization	count=2
arg	boundvariable(other_object) ||| fv o u	count=1
function	bound on ||| bound	count=1
arg	shape and dtype ||| dtype	count=1
module	method that ||| gof	count=2
function_arg	[function_1] a ||| [function_1] offset [arg_2]	count=1
arg	[arg_1] replaced by ||| [arg_1] [arg_2]	count=1
function	replace_all_validate revert the replacement ||| replace all validate	count=1
arg	of ints ||| weights minlength assert_nonneg	count=1
arg	node by one which ||| node	count=1
function_arg	[function_1] given version ||| [arg_2] [function_1]	count=3
class	the type's ||| gpu array type	count=1
function	should be removed ||| outs	count=1
function	choose ||| choose	count=1
function	apply to be ||| apply	count=1
function_arg	we should warn about [function_1] [arg_2] ||| core [function_1] [arg_2]	count=2
arg	the outputs ||| outputs mode accept_inplace	count=1
function	the folowing changes in ||| mul switch sink	count=1
function	-a ||| neg	count=1
function	have the same shape ||| same shape	count=1
module	optionally inserting broadcasted dimensions ||| tensor	count=1
class	variable optionally inserting broadcasted ||| tensor	count=1
arg	element in y ||| y	count=1
function	the -x pattern ||| is neg	count=1
function	ger ||| ger	count=1
function	parses a config ||| parse config	count=1
function	is a [function_2] ||| [function_1] [function_2]	count=1
arg	[arg_1] a name ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] [arg_2] 1s ||| [function_1] [arg_2]	count=1
arg	cond [arg_2] ||| [arg_2] [arg_1]	count=1
arg	[arg_1] es ||| [arg_1] [arg_2]	count=9
function	idx list to get ||| get idx list	count=1
function	openblas threads [function_2] ||| [function_2] [function_1]	count=1
arg	construct new [arg] based on ||| replacer [arg]	count=1
function	c code for this ||| c code	count=1
class	convolution ||| conv	count=1
function	ceil ||| ceil	count=1
arg	of compilation flags from ||| libs flags libs_dir include_dir	count=1
function_arg	[function_1] name ||| [function_1] [arg_2]	count=1
function	as its implementation ||| as	count=1
function	python ||| make	count=1
function	of convolution [function_2] ||| [function_2] [function_1]	count=3
function	for diagonalsubtensor and incdiagonalsubtensor ||| diagonal subtensor view	count=1
arg	min [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	[function_1] version ||| [arg_2] [function_1]	count=3
arg	return a ||| node name sub	count=1
function	module initialization code ||| init code	count=2
function_arg	[function_1] function drawing ||| [arg_2] [function_1]	count=1
module	that 1) this ||| gof	count=1
arg	set to a ||| a	count=1
function	values identical with ||| forced replace	count=1
arg	[arg_1] is ||| vm linker accept [arg_1] [arg_2]	count=1
arg	the input ||| input	count=1
arg	and dtype [arg_2] ||| [arg_2] fgraph [arg_1]	count=1
function	and ||| out	count=2
function	to roll ||| roll	count=1
arg	an expression ||| x	count=1
function	image shape [function_2] ||| [function_2] gradweights [function_1]	count=1
arg	into a basic theano ||| itypes otypes infer_shape	count=1
function	config ||| config	count=1
arg	if allow_override is ||| filter allow_override	count=1
class	the cache ||| cache	count=3
class	optionally inserting broadcasted ||| operators	count=1
arg	on f [arg_2] ||| [arg_2] [arg_1]	count=2
function	[function_1] normalization of ||| [function_1] [function_2]	count=3
module	elemwise ||| sparse	count=3
arg	and uses ||| o	count=1
arg	match ||| var	count=1
arg	from r to ||| r	count=1
function	[function_1] row ||| [function_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] inplace [arg_2]	count=3
function_arg	dimshuffle is inside ||| dimshuffle node	count=1
function	partition ||| scalarconsts	count=1
function	a normal ||| normal	count=2
function_arg	wrt, [arg_2] ||| [arg_2] [function_1]	count=2
function	register [function_2] ||| [function_2] [function_1]	count=1
function	with kernels of shape ||| shape	count=1
class	the dimensions ||| py	count=1
arg	true if the named ||| fullname	count=1
arg	a with ||| a	count=2
class	add ||| key data	count=1
function	the output dimensions ||| output	count=1
function	hyperbolic sine ||| sinh	count=1
function	1d kernel that ||| kernel 1d	count=2
function	canonical form ||| get canonical form	count=2
class	solve operation c = ||| solve	count=1
class	dictionary data structures ||| push out non	count=1
arg	while annotating ||| node thunk exc_info storage_map	count=1
function_arg	svd [arg_2] ||| [arg_2] [function_1]	count=2
function	a tensorvariable of this ||| make variable	count=1
arg	level of nesting ||| loop_orders dtypes loop_tasks sub	count=1
function_arg	^ [arg_2] ||| [arg_2] [function_1]	count=1
module	compute conv output ||| nnet	count=3
function	row ||| row	count=2
class	for use [class] ||| [class]	count=2
function	connection ||| io connection	count=1
function	[function_1] [function_2] ||| [function_1] remove [function_2]	count=2
arg	this function tries to ||| top_shape border_mode subsample	count=4
class	the type's :attr context_name ||| gpu array	count=1
function	replacement if ||| replace all	count=1
function_arg	should warn about bugs [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
function	1/(1+exp x -> ||| local inv 1 plus exp	count=1
class	for corrmm (direction="forward"), ||| corr mm	count=1
class	optionally inserting broadcasted ||| tensor py	count=1
function	list to ||| from factored list	count=1
arg	value through ||| value	count=1
function	matrix inverse ||| matrix inverse	count=2
function	version ||| gcc	count=1
class	item from the cache ||| cache	count=1
function	make [function_2] ||| [function_2] [function_1]	count=3
class	a convolution ||| dnn conv	count=1
class	a mrg ||| mrg	count=1
module	litterals to ||| tensor	count=1
function	from ||| from	count=3
class	and dictionary data structures ||| out non	count=1
arg	b are unified ||| b	count=1
arg	remove are still ||| fgraph replacements remove reason	count=1
function	of values identical with ||| forced replace	count=1
function	version ||| code cache version	count=3
function	insert [function_2] ||| [function_1] [function_2]	count=3
function	of outputs [function_2] ||| [function_2] [function_1]	count=4
function	[function_1] ger ||| [function_2] [function_1]	count=2
function	default that removes all ||| local remove all	count=1
function	[function_1] to elemwise ||| [function_2] constant [function_1]	count=1
arg	[arg_1] haskell' ||| [arg_2] [arg_1]	count=1
function	shape tuple or ||| infer shape	count=1
class	cache or the disk ||| cache	count=1
function	hot ||| hot	count=1
module	variable optionally ||| tensor	count=1
function	header ||| header	count=2
function_arg	deepcopy [arg_2] ||| [function_1] [arg_2]	count=5
arg	[arg_1] the template ||| [arg_2] fgraph [arg_1]	count=3
class	dictionary data structures ||| non	count=1
function	replace_all_validate ||| all validate	count=1
function	convert python litterals to ||| make	count=1
function	a variable on the ||| gpuarray variable	count=1
function	proxy for ||| proxy	count=2
function	integers indicating the version ||| code cache version	count=3
function	to represent the dependence ||| make dependence	count=1
function	baddestroymap ||| check inputs	count=2
function_arg	of 3d filters ||| conv3d input filters	count=1
module	wrapper around c_cleanup that ||| gof	count=1
function	x x -> ||| local	count=1
function_arg	[function_1] url ||| [arg_2] [function_1]	count=1
function	if ||| check	count=1
arg	the original ||| outputs copy_inputs_and_orphans memo	count=1
class	mode ||| monitor mode	count=1
arg	raise baddestroymap ||| node storage_map	count=1
arg	variable v if v ||| v	count=1
class	cache and none otherwise ||| cache	count=1
function_arg	of a sparse [function_1] [arg_2] ||| sparse [function_1] sum [arg_2]	count=3
arg	baddestroymap if ||| r_vals	count=1
arg	if a ||| a	count=1
function	variable optionally inserting ||| dimshuffle	count=1
arg	nodes in the original ||| inputs outputs copy_inputs_and_orphans memo	count=1
arg	the [arg_2] ||| [arg_1] [arg_2]	count=1
function	row variable (ndim=2 broadcastable=[true ||| row	count=1
function	clone the ||| clone	count=2
function	tensor_from_scalar(scalar_from_tensor ||| scalar tensor	count=2
arg	each level of nesting ||| loop_orders dtypes loop_tasks sub	count=1
function	unused [function_2] ||| and [function_1] [function_2]	count=1
function	tensor from ||| complex from	count=1
module	if the g++ version ||| gof	count=1
function	return path to the ||| get entry	count=1
arg	leftdims + rightdims ||| leftdims rightdims	count=1
function_arg	== b ||| eq a b	count=1
function	use [function] change ||| local max and [function]	count=1
function_arg	[function_1] filters ||| [function_1] [arg_2]	count=3
arg	variable v is positive ||| v	count=1
function	a slice ||| slice	count=1
module	duplicate this ||| gof	count=1
class	to the type's :attr ||| gpu	count=1
arg	es of ||| dtype	count=1
function	on the ||| as gpuarray	count=1
function	implements the "reverse-mode" ||| perform	count=2
function_arg	load a [arg_2] ||| [function_1] [arg_2]	count=1
module	theano utilization [module] numpy linalg ||| [module]	count=1
function	division inverse of multiplication ||| div	count=2
function	given a slice ||| slice	count=1
function	[function_1] broadcast pattern ||| [function_1] [function_2]	count=3
arg	es of ||| dtype keepdims	count=1
function	scale or [function_2] ||| [function_2] [function_1]	count=2
arg	old_r to ||| old_r	count=1
function	the updates ordereddict ||| updates	count=1
class	this variable ||| operators	count=1
arg	if cond [arg_2] ||| [arg_1] [arg_2]	count=1
function	otherwise call upgrade_to_float() ||| upgrade to float no	count=1
class	for gpucorrmm (direction="forward"), ||| base gpu corr mm	count=1
class	for corr3dmm (direction="forward"), corr3dmm_gradweights ||| corr3d mm	count=1
class	reorder the ||| py	count=1
function	legal [function_2] ||| [function_1] [function_2]	count=1
function	1 0/a [function_2] ||| [function_1] [function_2]	count=1
function_arg	a >= [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] asserts from ||| [function_1] [function_2]	count=5
function	that unroll the ||| unroll	count=1
function	asserts from ||| assert	count=1
function	remove [function_2] ||| [function_1] constants [function_2]	count=1
class	values of a shared ||| shared	count=1
function	gcc ||| gcc	count=1
function	device ||| device	count=1
function	module [function_2] ||| [function_1] [function_2]	count=2
arg	inputs replaced ||| inputs allow_partial only_process_constants elemwise	count=1
class	for corr3dmm (direction="forward"), ||| base corr3d mm	count=1
class	stream ||| streams	count=3
function	constant scalar [function_2] ||| [function_2] [function_1]	count=1
function	det [function_2] ||| [function_2] [function_1] chol	count=3
arg	op a ||| op	count=1
arg	input a 4-d tensor ||| input patch_size	count=1
arg	function tries ||| top_shape border_mode	count=4
function	has only one ||| sitsot only	count=1
arg	[arg_1] break aliasing ||| [arg_2] [arg_1]	count=3
arg	to convert x into ||| x context_name	count=1
function	from ||| remove	count=1
arg	function tries ||| image_shape top_shape	count=2
function	to wrt, computes ||| subgraph	count=1
function	the op code ||| get op params	count=1
arg	a pyobject * instance ||| sub check_input	count=1
function	transferred to ||| transfer	count=1
function	directories that ||| dirs	count=1
module	compute conv ||| nnet	count=3
class	navigator deal with the ||| navigator	count=1
function	useless reshape ||| local useless reshape	count=2
arg	[arg_1] separated maker ||| [arg_2] [arg_1]	count=4
arg	dtype [arg_2] ||| [arg_2] fgraph [arg_1]	count=1
function	that unroll ||| unroll	count=1
function	upcasts constant ||| constant	count=1
arg	op without ||| op	count=1
function	retrive the context associated ||| get context	count=1
function	batch size loop ||| batch	count=1
arg	var ||| var	count=4
function	on the output ||| output	count=1
function	to make itself the ||| to os environ pathlist	count=1
function	directory ||| from dir	count=1
function	list of shape tuple ||| infer shape	count=1
arg	rows ||| rows	count=1
arg	[arg_1] and uses ||| [arg_2] [arg_1]	count=8
function	make a value ||| make value	count=1
function	solve ||| tag solve	count=1
function	topooptimizer from the input ||| in2out	count=1
class	enumeration types ||| params type	count=1
arg	the list remove ||| remove	count=1
function	the one ||| one	count=1
arg	matrix [arg] and scalar ||| [arg]	count=1
arg	can be a 1-d ||| random_state size a	count=1
function	node a clone ||| clone	count=1
module	some special work if ||| gof	count=1
arg	if it takes ||| node	count=1
function	the folowing changes ||| mul switch sink	count=1
function	it into a canonical ||| canonical	count=1
arg	the fgraph [arg_2] ||| [arg_2] [arg_1]	count=2
class	string for ||| gpu	count=1
function	neibs2images ||| neibs2images	count=1
class	optionally ||| py	count=1
class	the type's ||| gpu array	count=1
function	[function_1] all ||| [function_1] [function_2]	count=4
arg	of [arg] ||| [arg]	count=6
function	graph to ensure that ||| graph	count=1
function	are ||| check	count=1
function	extract ||| extract	count=1
function	replace_all_validate revert ||| all validate	count=1
function	to expm1 a ||| local expm1	count=1
function	connection pattern of a ||| connection pattern	count=1
function_arg	[function_1] according to ||| [function_1] [arg_2]	count=5
module	for [module] ||| [module]	count=1
function	expm1 ||| local expm1	count=2
class	to the type's :attr ||| type	count=1
class	the dimensions of ||| tensor py	count=1
module_class	[module_1] local optimization ||| [module_1] [class_2]	count=2
function	[function_1] with the ||| [function_2] [function_1]	count=1
function	to theano config ||| config	count=1
function	proxy for ||| div proxy	count=2
function_arg	[function_1] [arg_2] ||| [function_1] slice [arg_2]	count=30
arg	a name ||| name	count=2
function	concatenate tensortypes ||| join	count=1
arg	in pvals ||| pvals	count=1
function	get the 0 based ||| get depth	count=1
function	a schedule ||| schedule	count=1
arg	cost ||| cost	count=2
class	to the type's ||| gpu	count=1
function_arg	upper [arg_2] ||| [arg_2] [function_1]	count=4
function	a config ||| parse config	count=1
arg	op without affecting ||| op	count=1
function_arg	[function_1] op ||| [arg_2] [function_1]	count=6
function	of [function] ||| sp [function]	count=3
function	python litterals ||| make	count=1
arg	a leftdims + ||| leftdims	count=1
arg	:type [arg_2] ||| [arg_2] [arg_1]	count=4
class	the dimensions of this ||| tensor	count=1
function	prod(prod()) -> ||| local	count=1
arg	estimate [arg] must be ||| [arg]	count=1
function	view ||| view tree set	count=1
function	one ||| to one	count=1
arg	fgraph outputs that will ||| fgraph	count=1
arg	x [arg_2] ||| [arg_2] [arg_1]	count=7
function	kernel that can be ||| kernel	count=2
arg	raise baddestroymap ||| storage_map	count=1
module	compute the ||| tensor nnet	count=6
function	convert python litterals ||| make	count=1
function	performs batch ||| dnn batch	count=1
function	[function] change ||| local max and [function]	count=1
function	a sparse matrix ||| sparse	count=1
arg	fgraph to ||| fgraph	count=1
arg	and t is a ||| node input_storage	count=1
module	raise baddestroymap ||| compile	count=1
function	one hot ||| to one hot	count=2
arg	of order v real ||| v	count=2
function	op could be ||| op	count=1
function_arg	the [function_1] [arg_2] ||| [function_1] [arg_2]	count=3
arg	spatio-temporal filters ||| filters	count=1
module	context_name ||| gpuarray	count=1
function	[function_1] [function_2] of a sparse matrix ||| sparse [function_2] [function_1]	count=4
arg	instance of ||| link_kwargs optimizer	count=2
function	nan ||| nan	count=1
function	into a gemm ||| gemm	count=1
class	cache and ||| cache	count=1
module_class	duplicate [module_1] [class_2] inputs = self inputs ||| [module_1] [class_2] clone	count=1
module	batch ||| tensor nnet	count=1
function	gradient w ||| conv3d grad	count=2
function	canonical form that respects ||| get canonical form	count=1
function	[function_1] convolution ||| [function_2] [function_1]	count=6
class	this variable optionally ||| tensor py	count=1
class	the type's :attr ||| array type	count=1
module	compute conv output ||| tensor nnet	count=3
function_arg	apply nodes [arg_2] ||| [function_1] [arg_2]	count=4
function	and [function_1] [function_2] ||| [function_1] [function_2]	count=2
function	threads ||| threads	count=1
module	name to ||| gpuarray	count=2
class	matrix solve ||| solve	count=1
arg	template ||| template	count=1
arg	along given axis ||| x axis	count=1
function	simplify a [function_2] ||| [function_2] [function_1]	count=1
class	output has ||| output	count=1
function	generate c ||| shape c	count=1
module	compute 1d kernel ||| tensor nnet	count=1
function	integers indicating the version ||| version apply	count=1
function_arg	[function_1] on ||| [arg_2] [function_1]	count=9
function	[function_1] graph ||| [function_1] [function_2]	count=4
function	[true] [function_2] ||| [function_2] [function_1]	count=3
arg	and the output specs ||| input_specs output_specs accept_inplace	count=1
function	offers to make ||| to os	count=1
function	view ||| view	count=1
function_arg	lower triangle ||| tril m k	count=1
function_arg	a == [arg_2] ||| [function_1] inplace a [arg_2]	count=1
arg	the inputs [arg_2] ||| [arg_1] [arg_2] features clone	count=1
function	constitutes an [function_2] ||| [function_2] [function_1]	count=1
function	shape of [function_2] ||| [function_2] [function_1]	count=10
module	apply nodes such that ||| gof	count=1
arg	[arg_1] y ||| [arg_2] [arg_1]	count=15
function_arg	[function_1] [arg_2] ||| [function_1] equiv [arg_2]	count=1
class	dimensions of ||| tensor	count=1
function	constitutes an upcast ||| is an upcast	count=2
function	code to the task ||| find task	count=1
arg	elemwise maximum of sparse [arg_1] [arg_2] ||| sparse structured maximum [arg_1] [arg_2]	count=1
function	x and there is ||| local	count=1
function	as replace_all_validate revert the ||| all validate	count=1
class	this variable ||| py operators	count=1
class	of ||| sparse	count=2
function	print the ||| print	count=1
function_arg	helper function ||| helper random_state n	count=1
class	tensortype ||| type	count=1
class	for a ||| gpu	count=1
arg	tuple list [arg] ||| [arg]	count=1
module	variable optionally inserting broadcasted ||| tensor	count=1
function	unroll the batch size ||| gen conv code unroll batch	count=1
function	with [function_2] ||| [function_2] [function_1]	count=2
class	kinds of tensortype ||| type	count=1
function	[function_1] loop over ||| [function_2] [function_1]	count=1
arg	an input vector and ||| node input_storage	count=1
arg	in y ||| y	count=1
function	list of variables ||| variables and	count=1
arg	function drawing [arg_2] ||| [arg_1] [arg_2]	count=1
function	[function_1] pattern of ||| [function_1] [function_2]	count=4
function_arg	!= [arg_2] ||| [function_1] a [arg_2]	count=1
function_arg	[function_1] from x ||| [arg_2] [function_1]	count=2
function	platform-dependent gcc ||| get gcc	count=2
function_arg	wrt, computes [arg_2] ||| [function_1] wrt end start [arg_2]	count=2
class	output of scan ||| push out scan	count=1
arg	[arg_1] for navigatoroptimizer ||| [arg_2] [arg_1]	count=1
function	useless [function_2] ||| [function_2] [function_1]	count=2
arg	pvals ||| pvals ndim	count=1
function	normal ||| normal	count=2
function	within the op ||| op params	count=1
function	the op code ||| get op	count=1
function	compilation of cutils_ext ||| compile cutils	count=1
function	the idx [function_2] ||| [function_1] [function_2]	count=1
arg	[arg_1] 4-d ||| [arg_2] [arg_1]	count=1
function	supported [function] ||| [function]	count=1
function	data supported [function] gpu? ||| [function]	count=1
function	remove [function_2] ||| [function_2] [function_1]	count=2
function	as replace_all_validate revert ||| all validate remove	count=1
arg	list remove ||| remove	count=1
function	the last access of ||| last access time	count=1
arg	[arg_1] r ||| [arg_2] [arg_1]	count=8
function	dimensions of this ||| dimshuffle	count=1
function	confusion ||| confusion	count=1
module	detect if ||| gof	count=1
function_arg	value for [arg_2] ||| [arg_2] [function_1]	count=4
function	rel error ||| rel	count=1
function	[function_1] with ||| sparse sp [function_1] [function_2]	count=1
class	gradient for [class_2] ||| [class_2] [class_1]	count=2
class	type's :attr ||| type	count=1
function	a list of shape ||| infer shape	count=1
arg	a mini-batch of ||| input_shape filter_shape	count=3
module	raise baddestroymap if ||| compile	count=1
class	dimensions of this ||| py	count=1
function	explicitly upcasts constant inputs ||| constant inputs	count=1
arg	inputs and [arg_2] ||| [arg_1] [arg_2]	count=1
function	a diff to ||| diff	count=1
function	to elemwise ||| elemwise	count=1
arg	[arg_1] outputs ||| [arg_1] [arg_2]	count=3
arg	of nesting ||| loop_orders dtypes loop_tasks	count=1
function	a new ||| new inputs	count=1
arg	in u and ||| o u	count=2
arg	half of v ||| v	count=1
function	initialization [function_2] ||| [function_1] [function_2]	count=1
function	a hash from ||| hash from	count=2
function	type ||| has type	count=1
function	ones ||| ones	count=1
arg	list of variables ||| variables	count=1
module	reorder the dimensions of ||| tensor	count=1
arg	fgraph and a list ||| fgraph outputs_to_disown	count=1
class	into macros for use ||| cop	count=1
function_arg	the sum [arg_2] ||| [arg_2] [function_1]	count=6
function_arg	of shape [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	standard deviation [arg_2] ||| [function_1] input [arg_2]	count=5
class	that ||| conv op	count=1
function	str [function_2] ||| [function_2] [function_1]	count=2
arg	a simple algorithm ||| reasons r_vals	count=1
function	make sure [function] is not ||| update [function]	count=1
function_arg	inputs required to ||| inputs variable_list blockers	count=1
class	gpucorrmm ||| corr mm	count=1
function	rebroadcast how [function_2] ||| [function_1] [function_2]	count=1
arg	given axis es ||| axis ddof keepdims	count=2
function	a file ||| file	count=1
function	default that removes all ||| remove all	count=1
arg	v real ||| v x	count=2
function_arg	[function_1] on cpu ||| [arg_2] [function_1]	count=4
arg	convolve spatio-temporal filters with ||| signals filters	count=1
function_arg	[function_1] addition ||| [arg_2] [function_1]	count=2
function	indicating the version ||| code cache version apply	count=1
function	only on cpu here ||| local pow specialize	count=1
arg	spatio-temporal filters with ||| filters	count=1
function	[function_1] the following ||| [function_1] [function_2]	count=1
class	scan return ||| out scan	count=1
function	attempting to use dnn ||| no dnn	count=2
arg	an array with ||| node inputs outputs	count=2
module	gof ||| gof	count=1
function	compiled module [function_2] ||| [function_2] [function_1]	count=2
arg	[arg_1] the template ||| [arg_2] [arg_1]	count=3
class	kinds of tensortype ||| tensor	count=1
class	and dictionary data structures ||| push out non seq	count=1
module_class	duplicate [module_1] [class_2] = self inputs ||| [module_1] [class_2]	count=1
class	[class_1] gpucorrmm (direction="forward"), ||| [class_1] [class_2]	count=1
arg	f to ||| f	count=1
arg	return a code string ||| node name	count=2
arg	previously un-shaped variable ||| override	count=1
class	[class_1] gpucorrmm ||| [class_2] [class_1]	count=1
function	diagonalsubtensor and incdiagonalsubtensor ||| diagonal subtensor	count=1
arg	a / [arg_2] ||| [arg_1] [arg_2]	count=1
function	fetch a compiled module ||| module	count=1
arg	convert x into a ||| x context_name	count=1
function_arg	diff [arg_2] ||| [arg_2] [function_1]	count=1
arg	f wrt to wrt ||| f wrt	count=2
module	for scalar values ||| scalar	count=1
arg	tries to ||| top_shape	count=4
function	product between several dots ||| matrix dot	count=1
function	names ||| names	count=1
arg	dummy file with these ||| cls flag_list preambule body	count=1
function	arguments to pass ||| args	count=1
function	the gradient the finite ||| grad	count=1
function	for diagonalsubtensor and ||| get diagonal subtensor view	count=1
function	constructor ||| constructor	count=1
function	replace_all_validate revert the ||| all validate	count=1
arg	[arg] with ||| [arg] tag	count=2
module	clone this ||| gof	count=1
function	self [function_2] ||| [function_2] [function_1]	count=1
function	mean value along ||| mean	count=1
module	created if ||| gof	count=1
function	[function_1] remove ||| [function_2] constants [function_1] node	count=2
class	broadcasted ||| tensor py operators	count=2
arg	value through it ||| value	count=1
function	arctangent ||| arctan2	count=1
arg	raise baddestroymap ||| storage_map r_vals	count=1
function	to merge multiplication ||| alpha merge	count=2
function	correspond to the one ||| to one	count=1
function	the one [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] normalization of ||| [function_2] [function_1]	count=3
function	context object mapped to ||| context	count=1
class	inserting broadcasted ||| py operators	count=1
arg	reshape t by ||| t	count=2
function	return a hash ||| hash	count=1
arg	are ||| reason	count=1
function	one or more multinomial ||| multinomial	count=1
arg	original graph to a ||| outputs copy_inputs_and_orphans memo	count=1
function	shp) ||| alloc unary	count=2
arg	[arg_1] and b ||| [arg_2] [arg_1]	count=6
function	[function] scope ||| c support code [function]	count=3
arg	is no change in ||| node	count=2
function	return the indices ||| indices	count=1
function	the stack trace from ||| copy stack trace	count=1
function	represent the dependence ||| make dependence	count=1
function	parses a config string ||| parse config string	count=1
function_arg	a > [arg_2] ||| [arg_2] [function_1]	count=1
arg	z <- [arg_2] ||| [arg_2] a x [arg_1]	count=1
arg	return the url ||| content description filename auth	count=1
function	for diagonalsubtensor ||| diagonal subtensor	count=1
function_arg	[function_1] [arg_2] inclusive ||| [function_1] integers [arg_2]	count=2
arg	break aliasing ||| wrapped_inputs wrapped_outputs	count=1
function	total [function_2] ||| [function_1] [function_2]	count=3
function_arg	[function_1] none ||| [function_1] node [arg_2]	count=2
arg	return a ||| name x z	count=1
function	the one hot ||| one hot	count=1
function_arg	broadcast them [arg_2] ||| [arg_2] [function_1]	count=1
arg	of m1 and the ||| m1	count=1
function	indicating the version ||| version apply	count=1
function	mul ||| local mul	count=1
function	overwrite ||| useless inc subtensor	count=1
function	the output ||| output	count=4
function	a new ||| with new inputs	count=1
function	in a new graph ||| with new	count=1
arg	required return c ||| name sub	count=1
function	last access ||| last access	count=1
function	utility [function] use ||| c support [function]	count=1
function	full path ||| module	count=1
function	can be considered exactly ||| values	count=1
function	that removes ||| local remove	count=1
arg	index array and a ||| a	count=1
class	this graph ||| graph	count=1
function	this optimization ||| local	count=1
function	the same shape ||| same shape	count=2
function	return the platform-dependent gcc ||| get gcc	count=1
function	list to [function_2] ||| [function_2] [function_1]	count=4
function	a gradient ||| grad	count=1
function	variable with [function_2] ||| sparse as [function_2] [function_1]	count=1
function	inner graph to ||| validate inner graph	count=2
function	used to determine the ||| adv index broadcastable	count=1
arg	unification in u and ||| o u	count=1
arg	and uses it instead ||| o	count=1
function	list of lib directories ||| lib dirs	count=1
function	[function_1] each row ||| [function_2] [function_1]	count=1
function	[function] replaced according ||| [function]	count=1
arg	[arg_1] min ||| [arg_2] [arg_1]	count=1
arg	and return the url ||| content description filename auth	count=1
function_arg	optional [arg_2] ||| [function_1] support code apply [arg_2]	count=1
function	inputs [function_2] ||| [function_2] constant [function_1]	count=1
function_arg	the inputs required ||| inputs variable_list blockers	count=1
function	diagonalsubtensor and incdiagonalsubtensor ||| diagonal subtensor view	count=1
arg	computes ||| ishape kshape border_mode	count=1
function	c type of ||| c	count=1
arg	[arg_1] cpu ||| [arg_1] [arg_2]	count=1
arg	symbolic ||| name ndim dtype	count=1
module_class	duplicate [module_1] [class_2] = self inputs ||| [module_1] [class_2] clone	count=1
arg	is node ||| node	count=1
arg	return ||| node name	count=5
arg	use a simple algorithm ||| reasons r_vals	count=1
function	return a list of ||| get	count=1
class	enumeration types ||| type	count=1
arg	unification in u ||| u	count=2
arg	dense vector ||| x s	count=1
arg	considered to [arg] to the ||| [arg]	count=1
arg	[arg] es ||| input [arg] dtype	count=3
arg	if true ||| verbose m	count=1
function	detect a ||| detect	count=1
function_arg	[function_1] a ||| [function_1] inplace [arg_2]	count=1
function	[function_1] alloc ||| [function_2] [function_1]	count=2
arg	gpu convolution ||| border_mode subsample	count=1
module	python litterals ||| tensor	count=1
arg	new [arg] based ||| replacer [arg]	count=1
arg	on f [arg_2] ||| [arg_1] [arg_2]	count=2
arg	of m1 and ||| m1	count=1
function	exception [function_2] ||| gof [function_1] [function_2]	count=3
class	theano enumeration types ||| type	count=1
arg	the variable v is ||| v	count=1
function_arg	[function_1] and ||| [function_1] [arg_2]	count=1
function	grad ||| grad	count=2
arg	return a code string ||| name	count=2
arg	tries ||| top_shape border_mode	count=4
function	[function] is ||| [function]	count=1
function	fuse consecutive [function] or ||| local [function] mul	count=1
function	with the -x pattern ||| neg	count=1
function_arg	[function_1] a variable ||| [function_1] [arg_2]	count=5
function	asserts from the graph ||| assert	count=1
function_arg	one hot [arg_2] ||| [arg_2] [function_1]	count=5
function	write ||| write	count=1
arg	thunk fn ||| fn	count=1
function	if we don't use [function_1] [function_2] only ||| [function_2] [function_1]	count=2
module	version used is the ||| gof	count=1
function	a optimizer ||| optimizer	count=1
function_arg	shape [arg_2] ||| [function_1] r [arg_2]	count=3
function	convert addsd ||| addsd ccode	count=1
function	op could be ||| l op	count=1
arg	given an fgraph ||| fgraph	count=1
function	[function_1] a file ||| [function_1] from [function_2]	count=1
function	to generate c ||| i c	count=1
function	vector 1-dimensional variable ||| jacobian	count=1
function_arg	[function_1] [arg_2] with the same type ||| [function_1] [arg_2]	count=6
function	sine ||| sin	count=1
function	[function_1] loop ||| [function_2] [function_1]	count=1
module	nodes ||| gof	count=2
function	function performs the matrix ||| matrix	count=1
function	to make ||| to os environ pathlist	count=1
arg	and ||| o	count=1
module	wrapper around c_init that ||| gof	count=1
class	stream state ||| random streams	count=1
arg	to break aliasing ||| wrapped_inputs wrapped_outputs	count=1
function	to use dnn ||| no dnn	count=2
function	the name the ||| name	count=1
function	numpy typenum ||| dtype specs	count=1
function	[function_1] of apply ||| [function_2] [function_1]	count=4
function	convert addsd to faster ||| local addsd ccode	count=1
function	| ||| or	count=1
arg	conventions imposed by ||| theslice length	count=1
arg	an fgraph and a ||| fgraph outputs_to_disown	count=1
function	gpuelemwise ||| gpu elemwise	count=1
arg	code for ||| code	count=1
function	bartlett spectral window in ||| bartlett	count=1
class	shared [class_2] ||| [class_2] [class_1]	count=2
arg	ift ||| ift	count=1
function_arg	[function_1] fgraph to ||| [function_1] [arg_2]	count=2
function	schedule function from comparators ||| sort schedule fn	count=1
function	two kinds of useless ||| useless	count=1
function	lib ||| lib	count=1
class	register r's shape in ||| shape	count=1
function	the struct initialization code ||| init code struct	count=1
class	of this type ||| type	count=2
function	[function_1] transfer ||| [function_2] [function_1]	count=1
arg	a mini-batch ||| input_shape filter_shape	count=3
function	to declare variables ||| declare	count=1
arg	baddestroymap ||| node storage_map r_vals	count=1
class	be turned into macros ||| cop	count=1
arg	in the original ||| outputs copy_inputs_and_orphans memo	count=1
function	initialization ||| init	count=1
function_arg	[function_1] a b ||| [arg_2] [function_1]	count=1
function	over ||| over	count=1
class	of this variable ||| tensor py operators	count=1
function	function performs the svd ||| svd	count=1
class	of gradient ||| grad	count=1
function	access ||| access time	count=2
arg	raise ||| r_vals	count=1
function	only one client ||| only	count=1
function	scalar [function_2] ||| [function_2] [function_1]	count=1
function	the c ||| c	count=4
function	replace_all_validate revert ||| validate	count=1
function	variables ||| variables	count=4
function	the idx_list with constant ||| constant idx	count=1
function	to a max ||| local max	count=1
arg	the contents of a ||| dirname err files	count=1
function	of platform ||| platform	count=1
arg	return a new ||| name	count=1
function	symbolic row variable (ndim=2 ||| row	count=1
function_arg	left-padding [function_1] [arg_2] ||| [function_1] [arg_2]	count=1
arg	separated maker ||| share_memory swap delete_updates	count=1
function_arg	inputs [arg_2] ||| [arg_2] [function_1]	count=4
module	is the ||| gof	count=1
arg	a symbolic ||| ndim dtype	count=1
function_arg	[function_1] code ||| [function_1] [arg_2]	count=2
arg	to name [arg_2] ||| [arg_2] [arg_1]	count=2
function	g++ version used is ||| gcc	count=1
arg	inputs according ||| inputs	count=1
function	this to expm1 ||| local expm1	count=1
class	module if the ||| module	count=1
function	stack trace from ||| copy stack trace	count=2
arg	the dimension axis ||| axis	count=1
function	the dot product ||| dot	count=1
arg	to boundvariable(other_object) ||| fv o u	count=1
function_arg	to roll [arg_2] ||| [function_1] [arg_2]	count=2
arg	integer [arg] both inclusive ||| size [arg]	count=1
arg	function tries ||| top_shape border_mode subsample	count=4
arg	value after the ||| default filter	count=1
class	reorder the ||| tensor	count=1
arg	original graph ||| inputs outputs copy_inputs_and_orphans memo	count=1
function	helper function for diagonalsubtensor ||| get diagonal subtensor	count=1
function	with debug info ||| with	count=1
function	recognize the updates ordereddict ||| get updates	count=1
arg	set of arrays ||| choices out mode	count=1
arg	is no change ||| node	count=2
arg	still ||| replacements	count=1
function	bound on the ||| bound	count=1
arg	the given axis es ||| axis dtype keepdims	count=1
function	exception object with ||| raise with op	count=1
module	variables in inputs that ||| gof	count=1
arg	tuple list [arg] list ||| [arg]	count=1
function	with respect to wrt, ||| subgraph	count=1
function	the struct initialization ||| init code struct	count=1
function	add ||| add	count=8
arg	b with a ||| a m1 b	count=2
class	r's shape in the ||| shape	count=1
arg	encapsulates [arg] ||| [arg] storage_map compute_map	count=3
function	to ||| to os	count=1
module	compute the dot ||| nnet	count=2
arg	node by one which ||| node output_indices	count=1
class	to the type's :attr ||| gpu array	count=1
function	broadcast them to ||| generate broadcasting	count=1
class	of this variable optionally ||| tensor py	count=1
function	of arguments ||| args	count=2
arg	type2 ||| type2	count=1
function_arg	new variable [arg_2] ||| [arg_2] [function_1]	count=3
function	of inplace ||| inplace	count=1
arg	this function tries ||| image_shape top_shape border_mode subsample	count=2
function_arg	[function_1] was dumped ||| [arg_2] [function_1]	count=1
arg	indicating whether [arg] is always ||| [arg]	count=1
arg	[arg_1] n-d ||| [arg_2] [arg_1]	count=2
function	scale or ||| scale	count=1
function	standard deviation along ||| std	count=1
function	dependence of nodes ||| dependence	count=1
function	to determine [function_2] ||| [function_1] [function_2]	count=2
function	schedule [function_2] ||| [function_2] [function_1]	count=1
function	of outputs and the ||| and outputs	count=1
function	function for diagonalsubtensor ||| diagonal subtensor view	count=1
function	optimization ||| local	count=1
function_arg	wrt, computes [arg_2] ||| [function_1] [arg_2]	count=1
arg	of cost ||| cost	count=1
arg	z <- beta ||| z	count=1
arg	original graph to ||| outputs copy_inputs_and_orphans memo	count=1
class	for same kinds of ||| tensor	count=1
function	fill ||| second inplace	count=1
function	only one ||| sitsot only	count=1
function	lock is ||| lock	count=1
arg	in the original ||| inputs outputs copy_inputs_and_orphans memo	count=1
function	a module [function_2] ||| [function_1] [function_2]	count=2
function	inplace ||| inplace	count=4
class	reorder ||| py operators	count=2
function	a context ||| context	count=1
class	:attr context_name ||| array type	count=1
arg	the outputs from the ||| outputs	count=1
function	theano config ||| config	count=1
function_arg	[function_1] fgraph ||| [arg_2] [function_1]	count=5
function_arg	[function_1] cost ||| [arg_2] [function_1]	count=1
class	same kinds ||| tensor	count=1
module	raised [module] raise_with_op ||| [module]	count=1
function	op scale ||| scale	count=1
arg	filters with a ||| filters	count=1
function	a hash [function_2] ||| [function_2] [function_1]	count=1
class	the type's :attr ||| gpu array	count=1
function	tensor_from_scalar(scalar_from_tensor ||| tensor scalar	count=1
module	we clone this ||| gof	count=1
function	to ||| make	count=1
function	[function_1] some requirements ||| [function_2] [function_1]	count=1
function	batch normalization of ||| batch normalization	count=2
arg	sample from one ||| size n	count=1
arg	[arg] must be ||| [arg]	count=1
function_arg	upper triangle of ||| triu m k	count=1
function	same computations ||| computations	count=1
function	update self rstate ||| rstate	count=1
arg	return ||| name inputs outputs	count=1
function	output gradient w r ||| grad	count=3
arg	to val ||| val	count=1
function	config string ||| config string	count=1
arg	test ||| n_tests rng	count=1
function	raise baddestroymap ||| check	count=1
arg	fgraph ||| fgraph	count=6
function	merge [function_2] ||| [function_2] [function_1]	count=8
function	computes the standard deviation ||| std	count=1
function	for diagonalsubtensor and incdiagonalsubtensor ||| diagonal subtensor	count=1
function	failure_callback ||| warn inplace	count=1
function	module is [function_2] ||| [function_2] [function_1]	count=1
module	kinds of ||| tensor	count=1
function	offers to make ||| to os environ pathlist	count=1
class	of this variable optionally ||| py	count=1
function	work for gpuincsubtensor ||| inplace setsubtensor	count=1
arg	scan the contents of ||| dirname err files	count=1
arg	x with the given ||| x	count=1
function	parse ||| parse mul	count=1
function	tangent ||| tan	count=2
function	batch [function_2] ||| [function_2] [function_1]	count=4
arg	a ||| a replace	count=2
function	that unroll the batch ||| gen conv code unroll batch	count=1
function	[function_1] code ||| [function_1] [function_2]	count=17
function	[function_1] stats ||| [function_1] [function_2]	count=3
arg	[arg] from ||| num [arg]	count=1
function	[function_1] value ||| [function_1] [function_2]	count=1
module	move [module] computation to ||| [module]	count=1
function	of a cache directory ||| dir	count=1
function	[function_1] access ||| [function_2] [function_1]	count=4
class	an op ||| op	count=3
class	row is a mrg ||| mrg	count=1
arg	[arg] json so ||| [arg]	count=1
function	of variables ||| variables	count=1
function	remove [function_2] ||| [function_1] constants and [function_2]	count=1
function	offers to make itself ||| to	count=1
function	this generates the c ||| c	count=3
module	compute the dot product ||| nnet	count=2
function	[function_1] declare variables ||| [function_2] [function_1]	count=1
function	a tensorvariable ||| as	count=1
arg	[arg_1] min ||| [arg_1] [arg_2]	count=1
arg	low and ||| low	count=2
module	zero-arguments function that ||| gof	count=1
function	from dict ||| dict	count=1
function	release lock on compilation ||| release lock	count=1
function	convolution [function_2] ||| [function_2] [function_1]	count=3
arg	n-d ||| ws ignore_border stride	count=2
function	a subtensor ||| subtensor	count=1
function	a canonical form that ||| canonical form	count=1
arg	message on the ||| msg	count=1
function	last ||| last	count=1
class	this variable optionally ||| operators	count=1
class	theano ||| py	count=11
module	that will ||| gof	count=1
function	conda offers to make ||| to os	count=1
function_arg	matrix inverse on ||| matrix inverse a	count=1
function	decrefs ||| cleanup	count=1
arg	filters with [arg_2] ||| [arg_1] [arg_2]	count=1
function	[function_1] initialization code ||| [function_2] [function_1]	count=8
function	recognize the updates ||| get updates	count=1
function	unversioned ||| unversioned	count=1
function	inner-most loop executes ||| loop	count=1
function	c_extract_out ||| extract out	count=1
function	is ||| constant	count=1
class	the cache ||| call cache	count=1
class	same type ||| typed list type	count=1
function	[function_1] [function_2] ||| [function_2] gradweights [function_1]	count=8
module	return a dictionary that ||| gof	count=1
function	computes the output ||| get output	count=1
function	a new graph ||| clone with new inputs	count=1
function	text to a gist ||| gist	count=1
function	the orphans among them ||| orphans	count=1
arg	indices out_idxs ||| out_idxs	count=1
function	1/(1+exp [function_2] ||| [function_2] [function_1]	count=6
arg	break aliasing of outputs ||| wrapped_inputs wrapped_outputs	count=1
arg	the ignore_trees-related functionality ||| importer pruner chin	count=1
arg	of ints ||| x weights minlength assert_nonneg	count=1
class	for same kinds ||| tensor	count=1
arg	given axis es of ||| axis dtype op	count=1
module_class	duplicate [module_1] [class_2] with inputs = self ||| [module_1] [class_2] clone	count=1
function	self openmp ||| self openmp	count=1
function	convert ||| constant	count=1
function	to merge ||| merge	count=2
class	kinds ||| tensor	count=1
class	enum ||| enum	count=1
function_arg	symbolically cast [arg_2] ||| [function_1] [arg_2]	count=5
arg	x ||| x	count=38
arg	baddestroymap ||| r_vals	count=1
arg	name r [arg_2] ||| [arg_2] [arg_1]	count=1
arg	elements obtained by iterating ||| keepdims	count=1
arg	[arg_1] and o ||| [arg_2] [arg_1]	count=1
arg	variable v is ||| v	count=1
function	c ||| register shape i c	count=1
module	to compute ||| tensor nnet	count=4
module	scope [module] ||| [module]	count=6
function	function to concatenate tensortypes ||| join	count=1
module	to the type's :attr ||| gpuarray	count=1
arg	tries to ||| image_shape top_shape border_mode	count=2
arg	by b [arg_2] ||| [arg_2] [arg_1]	count=4
function	initialization code ||| init code	count=2
function	use with helper_c_code ||| helper c code	count=1
function	determine the broadcast ||| adv index broadcastable	count=1
function	of lib directories that ||| lib dirs	count=1
arg	filters [arg_2] ||| [arg_2] [arg_1]	count=1
function	a comparator to represent ||| cmp	count=1
arg	the contents of ||| dirname err files	count=1
function	grad of this op ||| op	count=1
function	[function_1] directories that ||| [function_2] [function_1]	count=4
function	variable with ||| variable	count=1
function_arg	new variable [arg_2] ||| [function_1] [arg_2] dtype	count=2
function	variable [function_2] ||| sparse as [function_2] [function_1]	count=1
class	to help the navigator ||| navigator optimizer	count=1
arg	the end variables ||| end	count=1
class	variable optionally inserting broadcasted ||| py	count=1
function	op that will ||| op	count=1
function	performs batch normalization ||| batch normalization	count=3
arg	travesal and ||| i o	count=1
class	the eigensystem ||| eigh	count=1
function_arg	should warn about bugs [function_1] [arg_2] ||| core [function_1] [arg_2]	count=2
class	variable optionally inserting ||| tensor	count=1
module	parse ||| tensor nnet	count=1
arg	min and [arg_2] ||| [arg_1] [arg_2]	count=1
arg	spatio-temporal filters with ||| signals filters	count=1
function	[function_1] following stats ||| [function_1] [function_2]	count=1
function_arg	[function_1] inputs replaced ||| [function_1] [arg_2]	count=4
arg	the computation ||| node	count=1
function	convert addsd to faster ||| local addsd	count=1
arg	given inputs and outputs ||| inputs outputs	count=1
function	threads [function_2] ||| [function_2] [function_1]	count=1
function	a canonical form ||| canonical form	count=1
function	converts this to expm1 ||| local expm1	count=1
class	variable of this type ||| type	count=1
arg	in pvals ||| n pvals	count=1
function	unify values of ||| unify	count=1
function	and return [function_2] ||| [function_2] [function_1]	count=8
function	expm1 a ||| expm1	count=1
arg	necessary update dr_vals ||| dr_vals	count=1
function	-x pattern ||| neg	count=1
function	merge ||| merge	count=3
arg	function drawing ||| random_state n pvals	count=1
function	replace_all_validate ||| validate remove	count=2
function	the gradient the ||| grad	count=1
function	dictionary of arguments to ||| args	count=1
class	same kinds of tensortype ||| tensor	count=1
function	degree ||| deg2rad	count=1
arg	required return ||| name sub check_input	count=1
module	used is ||| gof	count=1
function	unroll the batch ||| conv code unroll batch	count=1
function	or -exp ||| is	count=1
arg	beta * y ||| y	count=1
module	theano utilization [module] numpy ||| [module]	count=1
function	[function_1] from the ||| [function_2] [function_1]	count=5
function	[true] [function_2] ||| [function_1] [function_2]	count=3
function	flags ||| flags	count=1
function	[function_1] openmp ||| [function_2] [function_1]	count=1
arg	an fgraph ||| fgraph outputs_to_disown	count=1
function	return ||| name	count=2
class	dimensions of this ||| tensor	count=1
function	conda offers to ||| to os	count=1
function_arg	deepcopy in [arg_2] ||| [function_1] [arg_2]	count=5
function	the "reverse-mode" ||| perform	count=2
function	raise baddestroymap if ||| check	count=1
function	[function_1] of convolution ||| [function_2] gradweights [function_1]	count=4
arg	a and [arg_2] ||| [arg_2] [arg_1]	count=6
function	[function_1] deepcopy in ||| [function_1] [function_2]	count=1
module_class	[module_1] [class_2] graph ||| [module_1] [class_2] graph	count=3
function	get ||| get	count=3
function	addition ||| add	count=1
function	alloc of ||| local alloc	count=1
function	slice [start stop ||| slice	count=1
class	same ||| type	count=1
function	[function_1] inputs to ||| [function_2] [function_1]	count=4
arg	message ||| msg	count=1
function	from the loaded ||| get	count=1
function	constant ||| constant	count=5
function	bound on the largest ||| bound	count=1
function_arg	[function_1] inputs replaced ||| [arg_2] [function_1]	count=5
class	the graph and ||| function graph	count=2
arg	of cost [arg_2] ||| [arg_2] [arg_1]	count=2
module	input nodes ||| gof	count=1
function	of convolution ||| conv	count=4
class	a string for ||| gpu	count=1
arg	this function tries ||| top_shape border_mode	count=4
function	the replacement if the ||| replace all	count=1
arg	an ||| node inputs outputs	count=2
function	make a ||| make	count=2
function	all device ||| device	count=1
function	tensor from polar ||| complex from polar	count=2
function	scalar 0-dimensional ||| hessian	count=1
class	random stream ||| mrg random streams	count=2
function_arg	[function_1] op without ||| [function_1] can remove outs [arg_2]	count=2
function	unique names to ||| names	count=1
class	type's ||| gpu	count=1
module	in inputs that are ||| gof	count=1
arg	of a tensor input ||| input	count=3
function_arg	mean value [arg_2] ||| [function_1] [arg_2]	count=1
class	this function ||| function	count=1
function_arg	a context [arg_2] ||| [function_1] name [arg_2]	count=2
arg	make code ||| code filename	count=1
module	this variable optionally ||| tensor	count=1
function_arg	add two [arg_2] ||| [function_1] [arg_2]	count=1
function	for the maximum ||| maximum	count=1
function	the context object mapped ||| context	count=1
function	for elemwise and gpuelemwise ||| local elemwise fusion	count=1
function_arg	[function_1] x to ||| [function_1] [arg_2]	count=2
function	none or [function] ||| [function]	count=1
function	zeros ||| of zeros	count=2
function	updates ordereddict the ||| get updates	count=1
function	[function] b [idxs] ||| local subtensor of [function]	count=1
function	[function] with ||| as [function]	count=3
class	dimensions of this variable ||| tensor	count=1
class	in this ||| function	count=1
arg	fgraph and a ||| fgraph	count=1
function	c code to ||| c code	count=1
function	variable on the gpu ||| gpuarray variable	count=1
function	add an item to ||| add	count=1
class	to the type's ||| array type	count=1
function	if ||| inputs	count=1
function	post some [function_2] ||| [function_1] [function_2]	count=1
function	respect to wrt, computes ||| subgraph	count=1
arg	the named module ||| fullname	count=1
function	function builds the 1d ||| 1d	count=1
class	inserting broadcasted dimensions ||| tensor py operators	count=1
function	exception object [function_2] ||| [function_2] [function_1]	count=3
arg	a mini-batch of a ||| input_shape filter_shape	count=3
arg	from r ||| r	count=1
arg	a b ||| a b	count=2
function	maps from variable and ||| get equiv	count=1
class	op ||| profile stats	count=1
arg	[arg_1] y ||| [arg_1] [arg_2]	count=11
arg	an ||| node inputs	count=2
function	object with ||| with op	count=1
function_arg	[function_1] op ||| [function_1] can remove outs [arg_2]	count=2
arg	use a simple algorithm ||| order reasons r_vals	count=1
function	[function] of ||| sp [function]	count=2
class	broadcasted ||| py operators	count=2
function	function is ||| constant	count=1
function	find broken optimizations ||| find bad	count=1
module	of trailing spaces tabs ||| misc hooks	count=1
function	foldl ||| foldl	count=1
arg	required ||| variable_list blockers	count=1
function	the last access of ||| last access	count=1
function	the stack [function_2] ||| [function_2] [function_1]	count=4
arg	the original graph ||| inputs outputs copy_inputs_and_orphans memo	count=1
arg	on the inputs and ||| node inputs	count=1
function	into a canonical ||| get canonical	count=1
class	reorder the dimensions ||| tensor py	count=1
function_arg	[function_1] the fgraph ||| [function_1] [arg_2]	count=4
function	c code ||| c code	count=9
function	of apply ||| sort apply	count=1
function	[function_1] each row ||| sparse [function_2] [function_1]	count=1
function	[function_1] a leaf ||| [function_2] [function_1]	count=1
arg	shape_i how to ||| check_input	count=1
function_arg	[function_1] op without ||| [function_1] [arg_2]	count=3
arg	specified [arg] ||| random_state size avg [arg]	count=1
arg	s to ||| s	count=1
function	total time icluding the ||| total times	count=1
class	reorder the dimensions ||| operators	count=1
class	nit_sot output of scan ||| push out scan	count=1
function	node from dict ||| dict	count=1
arg	[arg] and ||| [arg]	count=3
arg	that was dumped ||| f persistent_load	count=1
module	this function ||| gpuarray	count=1
function	of outputs ||| outputs	count=1
function_arg	[function_1] triangle of ||| [arg_2] [function_1]	count=2
arg	tries to ||| top_shape border_mode subsample	count=4
arg	axes ||| axes	count=1
function_arg	[function_1] fgraph this ||| [function_1] [arg_2]	count=2
arg	if it ||| node	count=1
function	the inner ||| validate inner	count=1
function	[function_1] [function_2] same dtype and ||| [function_2] [function_1]	count=8
class	module if ||| module	count=1
arg	an ||| op	count=2
function	c code [function_2] ||| [function_2] [function_1]	count=3
function	use dnn ||| no dnn	count=2
function	headers that are ||| headers	count=1
function_arg	matrix along [arg_2] ||| [arg_2] [function_1]	count=2
function	lib [function_2] ||| [function_1] [function_2]	count=4
module_class	[module_1] apply instance ||| [module_1] [class_2]	count=5
arg	cond ||| cond	count=1
function	the [elementwise] smallest ||| smallest	count=1
function_arg	[function_1] [arg_2] ||| [function_1] ndim bcast ndim [arg_2]	count=1
function	sort ||| sort	count=1
function	a list of shape ||| default infer shape	count=1
arg	by indices out_idxs ||| out_idxs	count=1
arg	the dimensions of x ||| x	count=1
arg	movie ||| signals_shape filters_shape	count=1
function_arg	subtensor is inside ||| subtensor node	count=1
arg	the end ||| wrt end	count=1
function	idx ||| idx	count=1
function	[function_1] dot a ||| [function_2] [function_1]	count=1
arg	a dense vector ||| s	count=1
arg	if allow_override ||| filter allow_override	count=1
function	[function_1] all asserts ||| [function_2] [function_1]	count=4
function	directories that are ||| dirs	count=1
arg	tensortypes ||| x shift	count=1
function	as replace_all_validate revert the ||| validate	count=1
class	structures ||| out non seq scan	count=1
arg	outputs from the ||| outputs	count=1
arg	basic slow python ||| img kern mode dilation	count=1
arg	of this node ||| node	count=1
arg	to a specified scalar ||| a	count=1
function	revert the replacement ||| replace	count=1
function	to expm1 ||| local expm1	count=1
function	would be useless ||| call	count=1
function	[function_1] c ||| [function_2] [function_1]	count=6
function	batch normalization of the ||| batch normalization	count=2
function	ones with ||| ones like	count=1
function_arg	a <= [arg_2] ||| [arg_2] [function_1]	count=1
function	last access of ||| last access	count=1
arg	[arg_1] b ||| [arg_2] [arg_1]	count=9
function	openblas [function_2] ||| [function_1] [function_2]	count=2
arg	[arg_1] is ||| [arg_2] [arg_1]	count=1
arg	we do it only ||| node	count=1
arg	a to ||| a	count=3
class	type's ||| gpu array	count=1
function	a legal [function_2] ||| [function_1] [function_2]	count=1
function	shape tuple or ||| shape	count=1
module	on wraplinker that runs ||| gof	count=1
function	config [function_2] ||| [function_2] [function_1]	count=1
class	local optimization [class_2] ||| [class_2] [class_1]	count=1
function	[floor] [function_2] ||| [function_1] [function_2]	count=3
function	slice ||| slice	count=1
function	the complex conjugate ||| conj	count=1
function	after pad_dims ||| unpad dims	count=1
function	a tensorvariable ||| make variable	count=1
function	inner-most loop ||| reordered loop	count=1
arg	linker's fgraph ||| input_storage output_storage storage_map keep_lock	count=2
function_arg	the sum [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	[function_1] required to ||| [function_1] [arg_2]	count=3
function	print the [function_2] ||| [function_2] [function_1]	count=2
function	elemwise and gpuelemwise ||| local elemwise fusion	count=1
function	list of headers ||| headers	count=1
arg	leftdims + ||| leftdims	count=1
function	sparse [function] ||| [function]	count=2
arg	one-dimensional slices in pvals ||| n pvals	count=1
function	the inner graph ||| scan	count=1
function	broadcast pattern for advancedsubtensor ||| pattern	count=1
function	dictionary of arguments ||| args	count=2
function	optional return [function_1] [function_2] required by code returned ||| object c [function_1] [function_2]	count=1
function_arg	[function_1] a to ||| [arg_2] [function_1]	count=2
function	input ||| max pool 2d same size	count=1
function_arg	lower triangle of ||| tril m k	count=1
function	abs and rel error ||| abs rel	count=1
arg	a given "group" (ie ||| inp out grads	count=1
function	a leaf of ||| leaf	count=1
arg	of v by a ||| v	count=1
function	list to ||| factored list	count=1
arg	cost and/or ||| cost	count=1
function	a variable with ||| variable	count=1
arg	on [arg_2] ||| [arg_2] [arg_1]	count=1
function	[elementwise] largest ||| largest	count=1
function	that removes [function_2] ||| [function_2] [function_1]	count=5
arg	x ||| x y	count=1
function	[floor] division inverse ||| int div	count=2
function	find broken optimizations ||| find bad optimizations2	count=1
arg	vector and ||| node	count=1
function	[function_1] a gist ||| [function_2] [function_1]	count=1
class	output of scan return ||| scan	count=1
arg	graphs ||| graphs additional_inputs	count=1
arg	test ||| pt n_tests rng	count=1
arg	called by remove_feature ||| function_graph	count=1
function	[function_1] form that ||| [function_1] [function_2]	count=4
function	square root ||| sqrt	count=2
class	the shape ||| shape	count=1
function	the rest ||| rest	count=1
function	change [function] ||| [function] and	count=1
class	broadcasted dimensions ||| tensor py operators	count=1
class	this ||| operators	count=1
function	function for diagonalsubtensor and ||| diagonal subtensor	count=1
function	version of platform ||| platform	count=1
module	gradient of [module] variable undefined ||| [module]	count=1
arg	of r ||| r	count=1
function	[function_1] access of ||| [function_1] [function_2]	count=4
arg	return ||| name x z	count=1
function	a legal ||| is valid	count=1
function_arg	[function_1] to a ||| [function_1] offset [arg_2]	count=1
function	[function_1] from ||| [function_2] [function_1]	count=10
module	of nodes that ||| gof	count=1
arg	[arg_1] [arg_2] ||| [arg_2] m1 [arg_1]	count=7
arg	4-d tensor ||| patch_size	count=1
function_arg	a context [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	wrt, computes [arg_2] ||| [function_1] wrt end [arg_2]	count=2
function	that unroll the ||| conv code unroll	count=1
arg	a movie ||| signals_shape filters_shape	count=1
function	return label ||| label	count=1
arg	s to [arg_2] ||| [arg_2] [arg_1]	count=1
arg	output ||| output input	count=1
module	spaces tabs ||| misc hooks	count=1
arg	raise baddestroymap if ||| storage_map r_vals	count=1
arg	[arg_1] max ||| [arg_1] [arg_2]	count=4
function	print [function_2] ||| [function_1] [function_2]	count=2
arg	a leftdims + rightdims ||| leftdims rightdims	count=1
arg	a 4-d tensor ||| patch_size	count=1
function	2^a ||| exp2	count=1
function	loop executes ||| reordered loop	count=1
class	optionally inserting broadcasted ||| py operators	count=1
function	degree to radian ||| deg2rad	count=1
function	bilinear upsampling this function ||| bilinear	count=2
arg	y with length one ||| y axis	count=1
class	inserting ||| tensor	count=1
arg	existing start ||| start	count=1
arg	is inside a dimshuffle ||| node	count=1
function	try to detect a ||| detect	count=1
class	structures ||| non	count=1
module	convert python litterals to ||| tensor	count=1
function	a view ||| view tree set	count=1
function	from [function] distribution ||| [function]	count=1
arg	computes gradients of cost ||| cost	count=1
function	header for openblas threads ||| openblas threads	count=1
function	useless ||| useless	count=2
function	convert addsd ||| addsd	count=1
module	the dimensions ||| tensor	count=1
function	a clone in ||| clone	count=1
function	diagonalsubtensor ||| get diagonal subtensor view	count=2
arg	the given axis es ||| axis dtype op	count=1
function	and ||| as	count=1
function_arg	[function_1] encoding ||| [function_1] y [arg_2]	count=5
function	of variable type ||| type	count=1
function_arg	after [arg_2] ||| [arg_2] [function_1]	count=1
arg	the unification u ||| u	count=1
class	variable ||| tensor py operators	count=2
function	remove ||| local subtensor remove	count=1
arg	return the ||| node name	count=1
arg	a x ||| a x	count=2
function	x and ||| local	count=1
function	the idx_list with constant ||| get constant idx	count=1
function	with a triangular ||| triangular	count=1
function	litterals to ||| constant	count=1
function	the abs [function_2] ||| [function_1] [function_2] errors	count=2
class	tensortype ||| tensor type	count=1
module	that this opt applies ||| gof	count=1
function_arg	roll [arg_2] ||| [function_1] [arg_2]	count=2
arg	var1 ||| var1	count=1
arg	of x ||| x	count=6
function	the constant scalar ||| get scalar constant	count=2
module	same kinds ||| tensor	count=1
function	for bilinear upsampling ||| bilinear	count=2
arg	f_node ||| f_node	count=1
function	abs and [function_2] ||| [function_1] [function_2] errors	count=2
class	an op that will ||| op	count=2
arg	of m1 ||| m1	count=1
module	inputs that ||| gof	count=1
function	a new variable ||| new	count=1
arg	the shape ||| shape	count=1
function	register [function_2] ||| [function_1] [function_2]	count=1
function	openblas threads interface ||| openblas threads text	count=3
function	raise baddestroymap ||| inputs	count=1
function	the module initialization code ||| init code	count=1
class	reorder the dimensions ||| tensor py operators	count=1
class	the navigator deal with ||| navigator	count=1
function_arg	the shape [arg_2] ||| [function_1] r [arg_2]	count=3
class	type ||| type	count=9
arg	msg ||| msg	count=1
arg	filters ||| filters	count=4
function	a dimshuffle ||| dimshuffle	count=1
function	the 2d ||| 2d	count=1
arg	r [arg_2] ||| [arg_1] name [arg_2]	count=1
class	this variable optionally inserting ||| tensor py operators	count=1
function	std ||| std	count=1
arg	tensortypes [arg_2] ||| [arg_1] [arg_2]	count=1
class	and dictionary data structures ||| non seq	count=1
arg	not in [arg] i e ||| seq1 [arg]	count=1
function	[function] of ||| get [function]	count=3
class	convolution with the ||| dnn conv	count=1
function	merge 2 ||| merge	count=1
arg	contents of ||| dirname err files	count=1
function	return a module from ||| module from	count=1
arg	by mapping it to ||| ctx	count=1
function	add an item ||| add	count=1
module	such that ||| gof	count=1
function	conda offers to ||| to	count=1
arg	outputs ||| outputs	count=4
arg	[arg_1] a modulo ||| [arg_2] m1 [arg_1]	count=3
function	python litterals to ||| make constant	count=1
function	subtensor ||| subtensor	count=1
function	if we don't use [function_1] [function_2] ||| [function_2] [function_1]	count=2
function	headers that are needed ||| headers	count=1
arg	same shape and dtype ||| dtype	count=1
class	stream state and ||| random streams	count=1
arg	[arg_1] inputs ||| [arg_2] [arg_1]	count=6
function	"theano config compiledir" ||| compiledir content	count=1
function	nested loop over several ||| loop	count=1
function	gradient w ||| conv2d grad	count=1
function	tensor_from_scalar(scalar_from_tensor x -> x ||| local tensor scalar	count=1
function	[function] them ||| [function] func	count=1
module	same kinds of tensortype ||| tensor	count=1
arg	particular ||| item	count=1
class	inserting broadcasted dimensions ||| operators	count=1
class	broadcasted ||| tensor py	count=1
function	argument for shared libraries ||| shared library arg	count=1
arg	an fgraph and ||| fgraph outputs_to_disown	count=1
function	"code_cleanup" together ||| cleanup	count=1
arg	[arg_1] / b ||| [arg_2] [arg_1]	count=1
function	op code ||| op params	count=1
function	if the ||| gcc	count=1
function	the last [function_2] ||| [function_2] [function_1]	count=4
function	degree to ||| deg2rad	count=1
function	[function] equal ||| [function]	count=1
arg	[arg_1] n (n ||| [arg_2] [arg_1]	count=1
arg	on f ||| f	count=2
module	first functiongraph that has ||| gof	count=1
function	logsoftmax x 's grad ||| local logsoftmax grad	count=1
function_arg	device [arg_2] ||| [function_1] [arg_2]	count=4
function	orphans among them ||| and orphans	count=1
function	object into its key_pkl ||| save pkl	count=1
function	replacement if the ||| replace all	count=1
arg	[arg_1] navigatoroptimizer ||| [arg_1] [arg_2]	count=2
function	dot22 computing an outer-product ||| dot22 to	count=1
function	calculating the dot product ||| dot	count=1
arg	return a code ||| name sub	count=1
class	for corrmm ||| base corr mm	count=1
function	ones [function_2] ||| [function_2] [function_1]	count=3
function	b axis=l) -> ||| local	count=1
function	inputs to [function_2] ||| [function_2] [function_1]	count=1
function_arg	wrt, [arg_2] ||| [function_1] wrt end [arg_2]	count=1
arg	remove are ||| remove reason	count=2
arg	raise ||| storage_map r_vals	count=1
class	transfer ||| tensor py operators	count=1
function	work for gpuincsubtensor ||| local inplace setsubtensor	count=1
function	cache directory and return ||| name from dir	count=1
arg	raise baddestroymap ||| node	count=1
function	[function_1] dependence of ||| [function_2] [function_1]	count=2
arg	required return ||| name	count=5
arg	-> a ||| node	count=1
class	a shared variable ||| shared variable	count=2
class	poisson ||| random streams base	count=1
function	n >= 3 ||| 3d	count=1
function	message ||| msg	count=1
function_arg	polar coordinate specification ||| polar abs angle	count=1
arg	sub ||| sub	count=1
function	[function_1] a value ||| [function_1] [function_2]	count=1
function	conda offers to make ||| to os environ pathlist	count=1
arg	b with ||| b	count=1
module_class	[module_1] op ||| [module_1] [class_2]	count=2
function	for openblas threads ||| openblas threads	count=2
function	[function_1] kernel that ||| [function_2] [function_1]	count=16
module	3d ||| tensor nnet	count=1
function_arg	convert degree [arg_2] ||| [arg_2] [function_1]	count=3
function	unroll ||| code unroll	count=1
function_arg	[function_1] of x ||| [function_1] [arg_2]	count=1
function	a config string ||| parse config string	count=2
function	value underlying ||| value	count=1
function	[function_1] [function_2] ||| [function_2] inputs [function_1] node	count=2
arg	if fgraph is the ||| fgraph no_recycling	count=1
function_arg	failure_callback [arg_2] ||| [function_1] exc [arg_2]	count=1
module	the ||| gpuarray	count=2
arg	reshapes the output ||| output input	count=1
function	the compile lock to ||| add to	count=1
function_arg	a new [arg_2] ||| [function_1] [arg_2]	count=6
module	memo a dict that ||| gof	count=1
arg	[arg_1] [arg_2] ||| [arg_2] remove [arg_1]	count=4
function_arg	[function_1] [arg_2] ||| [function_1] x [arg_2]	count=4
function	return a symbolic row ||| row	count=1
module	function that ||| gof	count=2
function	optional [function_1] [function_2] required by code returned ||| [function_1] [function_2]	count=1
function	folowing changes in the ||| local mul switch sink	count=1
arg	shape ||| shape	count=1
function	parses a config string ||| config string	count=1
arg	inputs ||| inputs	count=6
function	trace to ||| trace	count=1
arg	[arg_1] [arg_2] ||| [arg_2] a x [arg_1]	count=2
function	to turn softmax(sum_of_stuff) -> ||| local	count=1
function	respect to wrt, ||| subgraph grad	count=1
arg	[arg_1] and y ||| [arg_1] [arg_2]	count=4
function	[function] required by ||| c header [function]	count=1
function	gradient is taken ||| grad	count=1
function	struct initialization code ||| init code struct	count=2
class	scan return true iff ||| push out scan	count=1
function	multiplication by ||| alpha	count=1
arg	computes ||| ishape kshape border_mode subsample	count=1
arg	out for ||| out	count=1
function	offers to ||| to os environ	count=1
function_arg	device [arg_2] ||| [arg_2] [function_1]	count=4
module	for theano scalar scalar ||| scalar	count=1
function	"reverse-mode" ||| perform	count=2
module	that initializes ||| gof	count=1
module	which is sparse ||| sparse	count=2
function_arg	subtensor [arg_2] ||| [function_1] [arg_2]	count=3
arg	pvals ||| pvals	count=2
function	id ||| id	count=1
function	removes all [function_2] ||| [function_1] [function_2]	count=4
function	[function_1] following stats ||| [function_2] [function_1]	count=1
arg	elements in [arg] which are ||| [arg]	count=1
function	subprocess_popen returning the output ||| output	count=1
function	removes useless ||| useless	count=1
class	solve operation c ||| solve	count=1
function	diagonalsubtensor and ||| get diagonal subtensor view	count=1
function	given a slice [start ||| slice	count=1
function_arg	[function_1] [arg_2] ||| [function_1] y [arg_2]	count=22
class	the finite fourier ||| fourier	count=1
arg	raise baddestroymap if ||| storage_map	count=1
function	of convolution gradweights ||| get conv gradweights	count=2
arg	x y ||| x y	count=4
function	with ||| idx	count=1
function	[true] division inverse ||| true div	count=2
function	rebroadcast how to generate ||| rebroadcast	count=1
function	try to detect ||| detect	count=1
arg	of the var ||| var	count=1
function_arg	round_half_to_even_inplace [arg_2] ||| [function_1] inplace [arg_2]	count=1
function	a tensorvariable whose ||| as	count=1
arg	to even of x ||| x	count=1
arg	return a code ||| node name sub	count=1
class	variable optionally inserting ||| py	count=1
function	to merge [function_2] ||| [function_2] [function_1]	count=8
arg	u and uses it ||| o u	count=1
module	also their apply_node if ||| gof	count=1
function	platform-dependent [function_2] ||| [function_2] [function_1]	count=2
arg	still in the ||| replacements	count=1
class	[class_1] wants to ||| [class_1] [class_2]	count=1
function	this explicitly upcasts constant ||| constant	count=1
class	dimensions ||| tensor py	count=2
function	tensor_from_scalar(scalar_from_tensor ||| tensor scalar tensor	count=2
function	reduce ||| reduce	count=1
function	removes useless [function_2] ||| [function_2] [function_1]	count=1
function	a batched ||| batched	count=1
function	revert the replacement ||| replace all	count=1
function	dependence of nodes in ||| dependence	count=1
function	constant ||| get constant	count=1
function	input ||| 2d same size	count=1
function	removes ||| local remove	count=1
function	raise baddestroymap if ||| inputs	count=1
module	sparse ||| sparse	count=5
function	c ||| shape i c	count=1
arg	es ||| ddof keepdims	count=1
function	the abs and ||| abs	count=1
function_arg	[function_1] [arg_2] ||| [function_1] t [arg_2]	count=2
function	a slice [start stop ||| slice	count=1
arg	return a code ||| node name	count=2
arg	exception while annotating ||| node thunk exc_info storage_map	count=1
class	the dimensions of this ||| py	count=1
function	true ||| is	count=2
function_arg	[function_1] specified ||| sparse [function_1] sum x axis [arg_2]	count=3
function	shape tuple ||| default infer shape	count=1
arg	an array with ||| node	count=2
arg	replaced ||| allow_partial only_process_constants elemwise	count=1
arg	fgraph this is ||| fgraph	count=1
module	compute 2d ||| tensor nnet	count=1
function	matrix of [function] sparsity pattern ||| sp [function]	count=1
class	poisson ||| streams base	count=1
arg	[arg_1] between min ||| [arg_1] [arg_2]	count=1
function	this to expm1 ||| expm1	count=1
arg	specifyshape ||| c_support_code_apply	count=1
arg	dtype as the ||| dtype	count=1
function	inner graph ||| validate inner graph	count=2
function	on the ||| gpu	count=1
function	returns the connection pattern ||| io connection pattern	count=1
arg	match out_shape ||| out_shape	count=1
function	[function_1] pattern ||| [function_2] [function_1]	count=6
function	a clone ||| clone	count=1
function	use within the op ||| get op params	count=1
function	the output ||| out	count=1
arg	out for occurrences ||| out	count=1
function	have a stack ||| stack	count=1
function_arg	device we do ||| device node	count=1
function	[function] distribution centered ||| [function]	count=1
function	directories that are needed ||| dirs	count=1
function	wrt, ||| subgraph grad	count=2
arg	target ||| target	count=1
function	loop executes code ||| make reordered loop	count=1
function_arg	remove subtensor/advancedsubtensor1 [arg_2] ||| [function_1] [arg_2]	count=3
arg	:type cost ||| cost wrt consider_constant disconnected_inputs	count=1
arg	an array with more ||| node inputs	count=2
module	nodes to output ||| gof	count=1
class	dimensions ||| py	count=2
arg	an fgraph and ||| fgraph	count=1
arg	and a [arg_2] ||| [arg_2] [arg_1]	count=2
function	access of a given ||| access	count=1
function	of apply ||| apply	count=2
function	to wrt, computes gradients ||| subgraph grad	count=1
function	be removed [function_2] ||| [function_2] [function_1]	count=6
function	output shape ||| shape	count=1
class	[class_1] an op ||| [class_2] [class_1]	count=2
class	reorder the dimensions of ||| py	count=1
function	some ||| map	count=1
function	hash [function_2] ||| [function_1] from [function_2]	count=1
function_arg	matrix inverse [arg_2] ||| [function_1] [arg_2]	count=1
arg	from type1 ||| type1	count=1
function	as replace_all_validate ||| all validate	count=1
function	the dimshuffle and index ||| local dimshuffle	count=1
function	choice ||| choice	count=1
function	the standard deviation along ||| std	count=1
function	constant scalar ||| scalar constant	count=3
class	type's :attr context_name ||| array	count=1
arg	flags from config blas ||| flags	count=1
function	gcc [function_2] ||| [function_1] [function_2]	count=1
function	for gpuincsubtensor ||| setsubtensor	count=1
function	crossentropysoftmax1hotwithbiasdx op whose incoming ||| crossentropy softmax 1hot with bias dx	count=1
function	retrive the context associated ||| context	count=1
function	dependence ||| make dependence	count=1
function	x ||| local	count=2
function	inner graph to ensure ||| validate inner graph	count=1
function	to ||| constant	count=1
function	convert radian ||| rad2deg	count=1
function	integers indicating the version ||| c code cache version apply	count=1
function	a max ||| max	count=1
arg	to new_r ||| new_r reason	count=1
function	inner graph ||| inner graph	count=1
function	of lib directories ||| lib dirs	count=2
arg	es of ||| dtype op	count=1
arg	point ||| entry_1 entry_2	count=1
function	matrix along ||| sp	count=1
function_arg	wrt, [arg_2] ||| [function_1] wrt end start [arg_2]	count=1
arg	leftdims ||| leftdims	count=1
function	the "theano config compiledir" ||| compiledir content	count=1
function	struct ||| struct	count=2
arg	n-d tensor ||| ws ignore_border stride	count=2
function	data ||| data	count=1
function_arg	> b ||| gt a b	count=1
function	the sum ||| sum	count=2
function	canonical [function_2] ||| [function_1] [function_2]	count=4
function	inf ||| inf	count=1
arg	reduction of x ||| x	count=1
function	proxy ||| div proxy	count=2
function	more multinomial distributions ||| multinomial	count=1
module	the input ||| gof	count=1
arg	an array with more ||| node	count=2
module	function ||| tensor	count=1
arg	that x and y ||| x y	count=1
function	a new ||| clone with new inputs	count=1
function	for gpuincsubtensor ||| inplace setsubtensor	count=1
function	the inputs ||| inputs	count=1
function	print ||| print fn	count=1
function	gist and ||| gist	count=1
arg	function ||| random_state low	count=1
class	the cache ||| module cache	count=2
function	generate permutations ||| permutation	count=1
function_arg	[function_1] s to ||| [function_1] r [arg_2]	count=3
function	the stack trace from ||| stack trace	count=1
arg	[arg_1] replaced ||| [arg_2] [arg_1]	count=1
arg	sample n ||| size n	count=2
function	to make itself the ||| to	count=1
module	this variable optionally inserting ||| tensor	count=1
function	source ||| compile cmodule	count=1
function_arg	uniform distribution [arg_2] ||| [function_1] [arg_2]	count=1
module	nodes that must be ||| gof	count=1
arg	new_r ||| new_r	count=1
arg	elemwise maximum of sparse [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
function	be removed and ||| outs	count=1
class	local optimization wants ||| local	count=1
arg	return c ||| name	count=2
class	for same kinds ||| tensor type	count=1
arg	with a particular ||| item	count=1
arg	v ||| v	count=6
class	broadcasted dimensions ||| tensor py	count=1
function	maps from variable ||| get equiv	count=2
function	from the ||| from	count=1
arg	line ||| line	count=1
function	the 1d [function_2] ||| [function_2] [function_1]	count=6
function	library search paths ||| lib dirs	count=1
function	prod ||| prod	count=1
arg	where [arg] ||| [arg] b	count=1
function	time icluding ||| times	count=1
function	as replace_all_validate ||| validate	count=1
arg	symbolic variables in inputs ||| inputs	count=1
arg	[arg_1] op ||| [arg_2] [arg_1]	count=4
function	constant ||| python constant	count=1
class	a module if the ||| module	count=1
function	sigmoid ||| sigmoid	count=2
function	given a inner ||| inner sitsot	count=1
function	[function_1] interface ||| [function_1] [function_2]	count=5
function_arg	[function_1] "kshp" ||| [function_1] [arg_2]	count=4
arg	a [arg_2] ||| [arg_2] [arg_1]	count=10
function	indices ||| indices	count=1
module	the graph ||| gof	count=1
function	the idx_list with ||| idx	count=1
module	compute 1d kernel for ||| tensor nnet	count=1
function_arg	!= b ||| neq a b	count=1
arg	v by a ||| v	count=1
arg	the given axis es ||| axis ddof keepdims	count=1
function_arg	scan [arg_2] ||| [function_1] can remove outs [arg_2]	count=4
function_arg	round half [arg_2] ||| [function_1] [arg_2]	count=1
function	llvm one or not ||| llvm	count=1
arg	similar behaviour as haskell' ||| fn sequences outputs_info	count=1
arg	a and ||| a	count=3
arg	value after the ||| default	count=1
function_arg	[function_1] [arg_2] ||| [function_1] var [arg_2]	count=2
arg	should return ||| name	count=1
function	image shape [function_2] ||| [function_2] [function_1]	count=3
function	for diagonalsubtensor and incdiagonalsubtensor ||| get diagonal subtensor	count=1
function_arg	left-padding [function_1] [arg_2] 1s ||| [function_1] padleft t [arg_2]	count=1
arg	b are ||| b	count=1
function	dnn ||| no dnn	count=2
function	updates ordereddict the list ||| updates	count=1
class	inserting broadcasted ||| tensor py operators	count=1
function	convolution gradinputs ||| get conv gradinputs	count=4
arg	zview [arg] zview if ||| name x [arg]	count=1
function	to extract ||| extract	count=1
function	multiplication by a ||| alpha	count=1
arg	dimensions from the shape ||| shape	count=1
module	as other scalar ||| scalar	count=2
module	if the g++ ||| gof	count=1
arg	end ||| end	count=1
arg	encoding of ||| nb_class dtype	count=1
arg	is the first ||| no_recycling profile	count=1
function	after ||| default	count=1
function	inner graph [function_2] ||| [function_2] inputs [function_1] node	count=1
arg	idx_list ||| idx_list	count=1
function	[function_1] dimshuffle ||| [function_2] [function_1]	count=2
class	output of scan return ||| push out scan	count=1
arg	remove are [arg_2] ||| [arg_2] [arg_1]	count=8
function_arg	[function_1] cost ||| [function_1] wrt end start [arg_2]	count=1
function	the following ||| global	count=1
function_arg	[function_1] value ||| [arg_2] [function_1]	count=1
function	a symbolic row variable ||| row	count=1
arg	compilation flags from ||| libs flags libs_dir include_dir	count=1
arg	and t ||| node	count=1
arg	<theano sandbox neighbours neibs2images> ||| neibs neib_shape original_shape mode	count=1
arg	function to ||| random_state n	count=1
function	stack [function_2] ||| [function_1] [function_2]	count=4
arg	filters with a movie ||| signals filters signals_shape filters_shape	count=1
function	of convolution gradweights ||| conv gradweights	count=1
arg	es of [arg_2] ||| [arg_2] [arg_1]	count=3
function	contains ||| contains	count=1
function	c ||| specify shape c	count=1
function	of this op could ||| l op	count=1
function_arg	[function_1] if it ||| [function_1] [arg_2]	count=1
function	deepcopyop how [function_2] ||| [function_2] [function_1]	count=1
function	search through ||| stack search	count=1
module	this method ||| gof	count=1
class	to raise ||| raise	count=1
function	[function_1] all asserts ||| [function_1] [function_2]	count=4
function	[function_1] the batch ||| [function_2] [function_1]	count=2
module	for same kinds ||| tensor	count=1
class	a mrg [class_2] ||| [class_1] [class_2]	count=4
class	reorder the dimensions of ||| tensor py	count=1
arg	[arg_1] leftdims + ||| [arg_2] [arg_1]	count=2
function	foldr ||| foldr	count=1
function_arg	:func neibs2images [arg_2] ||| [function_1] [arg_2]	count=1
function	already attached to some ||| on attach	count=1
function	the output shape ||| out shape	count=1
function	trace from one ||| trace	count=1
function	return connection [function_2] ||| [function_1] [function_2]	count=4
class	cache ||| cache	count=5
function	variable type ||| type	count=1
function	a inner nit_sot ||| inner	count=1
function	mflops ||| flops	count=1
class	navigator deal ||| navigator optimizer	count=1
class	reorder the ||| tensor py	count=1
arg	type2 from ||| type2	count=1
function	[function_1] grad ||| [function_1] [function_2]	count=2
function	round half to even ||| rint	count=1
function	baddestroymap if ||| check inputs	count=1
function	into a canonical form ||| get canonical form	count=1
function	transfer to ||| transfer	count=1
arg	name in ||| name opt	count=1
function	a canonical form ||| get canonical form	count=2
arg	replaced by their ||| allow_partial only_process_constants elemwise	count=1
function	-> x ||| local	count=1
function_arg	broadcast them [arg_2] ||| [function_1] indices [arg_2]	count=1
function	a scalar ||| scalar	count=1
function	bug ||| bug	count=1
function_arg	symbolically cast x ||| cast x	count=1
class	mrg [class_2] ||| [class_2] [class_1]	count=4
module	to compute ||| nnet	count=4
function	for bilinear upsampling this ||| bilinear	count=2
arg	different ||| tag	count=1
function	scale [function_2] ||| [function_2] [function_1]	count=8
function	the broadcast pattern ||| pattern	count=1
function	broadcasted dimensions ||| dimshuffle	count=1
function	helper function for diagonalsubtensor ||| diagonal subtensor	count=1
arg	return a ||| node name	count=2
function	convert python litterals to ||| make constant	count=1
function_arg	[function_1] instance of ||| [arg_2] [function_1]	count=6
function	connection pattern of subfgraph ||| connection pattern	count=1
arg	[arg_1] i ||| [arg_2] [arg_1]	count=2
function_arg	helper [arg_2] ||| [function_1] [arg_2]	count=9
arg	the [arg_2] ||| [arg_2] [arg_1]	count=1
function	the argmax [function_2] ||| [function_2] [function_1]	count=4
function_arg	extract [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] inputs ||| [function_1] [function_2]	count=5
arg	inputs[i] is r ||| r	count=1
arg	be a 1-d ||| random_state size a replace	count=1
function_arg	insert deepcopy [arg_2] ||| [function_1] [arg_2]	count=5
arg	data to ||| data strict allow_downcast	count=1
function	[function] translates t ||| [function] subtensor of	count=1
function	list of the parents ||| parents	count=1
arg	and set in a ||| a	count=1
function	node a clone in ||| clone	count=1
arg	tuple or none for ||| i_shapes	count=1
function_arg	extract a [arg_2] ||| [function_1] name [arg_2]	count=1
arg	[arg_1] [arg_2] of ||| [arg_2] m1 [arg_1]	count=7
arg	return a symbolic ||| name ndim dtype	count=1
arg	in u [arg_2] ||| [arg_2] [arg_1]	count=8
function	shape tuple or ||| default infer shape	count=1
function_arg	[function_1] the fgraph ||| [arg_2] [function_1]	count=4
function	to recognize the updates ||| updates	count=1
arg	function tries to ||| top_shape	count=4
class	the ||| tensor py	count=1
arg	vector and t ||| node	count=1
arg	outputs from the inputs ||| inputs outputs	count=1
arg	replaced by their python ||| allow_partial only_process_constants elemwise	count=1
function	list to ||| list	count=2
arg	[arg_1] and b ||| [arg_1] [arg_2]	count=4
function	to make ||| to	count=1
arg	an axis ||| axis	count=1
function_arg	a != [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function	convert python litterals to ||| constant	count=1
function	to expm1 a ||| expm1	count=1
function	create a comparator to ||| cmp	count=1
class	r's shape in ||| shape	count=1
function	sparsevariable constructor [function] ||| as sparse [function]	count=1
function	from [function_2] ||| [function_1] [function_2]	count=1
function	expm1 ||| expm1	count=1
function	[function_1] [function_2] a sparse matrix by ||| sparse [function_2] [function_1]	count=1
function_arg	a dimshuffle [arg_2] ||| [arg_2] [function_1]	count=1
function	a tensorvariable of ||| make variable	count=1
function_arg	the svd [arg_2] ||| [function_1] [arg_2]	count=2
function	of shape tuple or ||| shape	count=1
arg	name ||| name	count=6
arg	es of [arg_2] ||| [arg_2] axis [arg_1]	count=3
module	their apply_node if those ||| gof	count=1
function	makes the folowing changes ||| mul switch sink	count=1
module	for scalar ||| scalar	count=1
arg	or broadcastable pattern ||| broadcastable	count=1
function	[function_1] a package ||| [function_2] [function_1]	count=1
function	a inner nit_sot output ||| inner sitsot	count=1
function	[function_1] multiplication ||| [function_1] [function_2]	count=1
arg	sample from one ||| random_state size n	count=1
function	to get ||| get	count=1
function	return the indptr ||| indptr	count=1
arg	es ||| dtype	count=1
function	to generate c ||| c	count=4
function	matrix bias ||| bias	count=1
arg	outputs from ||| outputs mode accept_inplace	count=1
class	:attr context_name ||| gpu array type	count=1
function	[function_1] gcc ||| [function_1] [function_2]	count=3
function_arg	[function_1] x is ||| [arg_2] [function_1]	count=1
function	label [function_2] ||| [function_2] [function_1]	count=2
arg	function ||| random_state n	count=2
module_class	duplicate this [class_2] ||| [module_1] [class_2]	count=6
arg	stopping condition returned ||| ls	count=1
arg	return [arg_2] ||| [arg_2] [arg_1]	count=2
function	choice function ||| choice	count=1
arg	es of a tensor ||| ddof keepdims	count=1
arg	the specified [arg_2] ||| [arg_2] [arg_1]	count=2
module	type's ||| gpuarray	count=1
function	to wrt, computes ||| subgraph grad	count=1
function_arg	context associated [arg_2] ||| [arg_2] [function_1]	count=1
class	convolution with the specified ||| conv	count=1
module	the first functiongraph that ||| gof	count=1
arg	input vector and t ||| node	count=1
function_arg	[function_1] [arg_2] ||| [function_1] 2d [arg_2]	count=2
function_arg	concatenate tensortypes [arg_2] ||| [function_1] [arg_2]	count=1
class	new random [class_2] ||| [class_1] [class_2]	count=1
class	of a shared variable ||| shared variable	count=1
arg	[arg_1] from ||| [arg_1] [arg_2]	count=2
arg	function computes the ||| ishape kshape border_mode subsample	count=1
function	that broadcast them ||| generate broadcasting	count=1
arg	[arg_1] 4-d ||| [arg_1] [arg_2]	count=1
function	unroll [function_2] ||| [function_2] [function_1]	count=3
function	to the one ||| to one	count=1
arg	the original ||| inputs outputs copy_inputs_and_orphans memo	count=1
function	[function_1] dot ||| [function_1] [function_2]	count=1
function	a <= ||| le	count=1
arg	i of ||| i	count=1
function	modified bessel function ||| i0 inplace	count=1
arg	a symbol ||| symbol	count=1
arg	remove [arg_2] ||| [arg_1] [arg_2]	count=1
arg	file that was dumped ||| f persistent_load	count=1
arg	i and o ||| i o	count=2
function	[function_1] [function_2] ||| [function_2] constant [function_1]	count=2
function	[function_1] shape of ||| [function_2] [function_1]	count=6
class	the cache directory ||| module cache	count=1
function	dot ||| dot	count=2
function	the one [function_2] ||| [function_1] [function_2]	count=1
function	rebroadcast how ||| rebroadcast	count=1
function	hash ||| hash	count=3
arg	dtype as [arg_2] ||| [arg_2] [arg_1]	count=1
module	return a function that ||| gof	count=1
function	[function_1] the scan ||| [function_2] [function_1]	count=6
function_arg	optional [arg_2] ||| [arg_2] [function_1]	count=2
function	to the one hot ||| to one hot	count=1
function	that unroll the ||| code unroll	count=1
function	self [function_2] ||| gof open mpop update [function_1] [function_2]	count=1
function	a gist ||| gist	count=1
class	[class_1] to ||| [class_1] [class_2]	count=1
function	clip ||| clip	count=1
arg	the variable out for ||| out	count=1
function	shape of ||| shape	count=6
arg	coordinate specification ||| abs angle	count=1
class	the list ||| list	count=1
function	[function_1] [function_2] ||| [function_1] kernel [function_2]	count=6
arg	tree ||| tree	count=1
function	return [function] required ||| c [function]	count=1
function	[function_1] the gradient ||| [function_2] [function_1]	count=4
function_arg	[function_1] the specified ||| [arg_2] [function_1]	count=3
arg	along given axis ||| axis	count=1
function_arg	of 3d [arg_2] ||| [arg_2] [function_1]	count=1
arg	leftdims + [arg_2] ||| [arg_1] [arg_2]	count=1
arg	and b are unified ||| b	count=1
function_arg	extract [arg_2] ||| [function_1] name [arg_2]	count=1
function	partition a list ||| scalarconsts	count=1
arg	baddestroymap if ||| node storage_map	count=1
function	small or builtin c ||| c is simple	count=1
arg	return a rows ||| rows	count=1
class	initial value for ||| gpu	count=1
arg	is the first ||| no_recycling	count=1
function	with logsoftmax x 's ||| local logsoftmax	count=1
function	determine the name the ||| name	count=1
function	a new graph ||| with new inputs	count=1
function_arg	[function_1] tree ||| [arg_2] [function_1]	count=3
function	from a multinomial ||| multinomial	count=1
module	wraplinker that runs ||| gof	count=1
function	useless dimshuffle ||| useless dimshuffle	count=1
function	a new variable from ||| new	count=1
arg	fgraph this is the ||| fgraph	count=1
function	on the gpu ||| gpuarray	count=1
function	consecutive [function] or ||| local [function] mul	count=1
module	to compute the ||| nnet	count=4
function	of shape tuple ||| shape	count=1
function	[function_1] package ||| [function_1] [function_2]	count=2
function	with a triangular solve ||| tag solve triangular	count=1
function	generate permutations from integers ||| permutation	count=1
function	pass to helper_c_code ||| get helper c code	count=1
function	[function_1] each columns ||| [function_2] [function_1]	count=1
arg	attempt to ||| arg leaves new_leaves op	count=1
function	a diff to make ||| diff	count=1
module	compute conv ||| tensor nnet	count=3
arg	along an axis ||| axis	count=1
function	register a [function_2] ||| [function_1] [function_2]	count=1
arg	rightdims ||| rightdims	count=1
function	complex conjugate ||| conj	count=2
function	the updates ordereddict the ||| updates	count=1
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2]	count=1237
arg	encoding of each element ||| nb_class dtype	count=1
arg	x and [arg_2] ||| [arg_1] [arg_2]	count=3
class	node ||| node	count=1
arg	and ||| node name inputs outputs	count=1
arg	to match out_shape ||| out_shape	count=1
module	addition [module] ||| [module]	count=1
function	asserts ||| assert	count=1
class	cache ||| module cache	count=3
function	stack trace ||| stack trace	count=1
module	structured addition [module] matrix ||| [module]	count=1
function	return the shape ||| shape	count=1
function	the same [function_2] ||| [function_2] [function_1]	count=1
function	computations ||| computations	count=1
class	by ||| clinker	count=3
function	overwrite the full inputs ||| useless inc subtensor	count=1
function	a new graph ||| with new	count=1
class	of this variable ||| py operators	count=1
function	with helper_c_code ||| get helper c code	count=1
function	output gradient ||| grad	count=3
function	convolution [function_2] ||| [function_1] [function_2]	count=3
function	outputs ||| outputs	count=1
arg	return a code ||| name	count=2
class	the type's ||| array	count=1
arg	a n-d ||| ws ignore_border stride	count=2
function	[function_1] deepcopy ||| [function_1] [function_2]	count=1
arg	the end variables of ||| end	count=1
module	python litterals to ||| tensor	count=1
arg	checks code for ||| code	count=1
arg	the fgraph to ||| fgraph	count=1
arg	inputs of ||| inputs	count=1
module	compute 2d kernel ||| nnet	count=1
module	that would be ||| gof	count=1
arg	variable [arg] returns a ||| [arg]	count=1
function	new ||| clone	count=2
class	an op that ||| op	count=2
class	distribution ||| streams	count=1
function_arg	new [arg_2] ||| [function_1] [arg_2] tag dtype	count=1
arg	symbol ||| symbol	count=1
function_arg	shape [arg_2] ||| [arg_2] [function_1]	count=9
function_arg	inplace on a ||| inplace a	count=10
arg	function for alternative ||| fn	count=1
arg	the variable v ||| v	count=1
function	should be removed and ||| compress outs	count=1
function	x and there ||| local	count=1
module	output ||| gof	count=1
function	shape of convolution gradinputs ||| conv gradinputs shape	count=2
function	return label of ||| label	count=1
function	python litterals ||| constant	count=1
function	[function_1] [function_2] ||| [function_1] macos sdot [function_2]	count=6
function	scalar ||| get scalar	count=1
class	data structures ||| non	count=1
function	expm1 a ||| local expm1	count=1
module	using ||| gpuarray	count=1
function	advancedincsubtensor1(x x[ilist]+other ilist set_instead_of_inc=true) ||| set to inc subtensor	count=1
arg	[arg_1] args ||| [arg_2] [arg_1]	count=1
function	on the gpu ||| as gpuarray	count=1
arg	of variables ||| variables	count=1
function	of shape tuple ||| infer shape	count=1
arg	that gets a scan ||| not_required	count=1
class	structures ||| non seq	count=1
function	to get the ||| get	count=1
arg	changed from r ||| r	count=1
arg	reps ||| reps ndim	count=1
class	[class_1] to ||| [class_2] [class_1]	count=1
class	optionally inserting ||| tensor py operators	count=1
arg	r ||| r	count=8
arg	estimate [arg] must ||| [arg]	count=1
function	and tensorvariable ||| as common dtype	count=1
function	of shape ||| shape	count=2
function	that unroll the batch ||| conv code unroll batch	count=1
arg	function ||| random_state low high	count=1
class	tensortype ||| tensor	count=1
function	inner ||| inner	count=2
function	of convolution ||| get conv	count=4
module	input ||| gof	count=1
arg	a to degree ||| a	count=1
arg	fgraph this ||| fgraph	count=1
module	other scalar ||| scalar	count=2
function	output gradient w ||| conv2d grad	count=1
arg	data ||| data strict allow_downcast	count=1
arg	and dtype ||| dtype	count=1
arg	[arg_1] start gradients ||| [arg_2] [arg_1]	count=2
arg	spatio-temporal filters [arg_2] ||| [arg_2] [arg_1]	count=1
function	simplify a multiplication ||| simplify mul	count=2
function	apply ||| sort apply	count=1
function	[function_1] some requirements ||| [function_1] [function_2]	count=1
function	a variable on ||| as gpuarray variable	count=2
function	perform the permutation ||| perform	count=1
arg	input a [arg_2] ||| [arg_2] [arg_1]	count=12
arg	[arg_1] b are ||| unify walk [arg_1] [arg_2]	count=1
function	arguments to [function_2] ||| [function_2] [function_1]	count=2
function	numpy-compatibility method if ||| diag	count=1
function	-> alloc(unary x shp) ||| local alloc unary	count=1
arg	to type2 ||| type2	count=1
function_arg	[function_1] a specified ||| [arg_2] [function_1]	count=1
function_arg	sum along [arg_2] ||| [function_1] [arg_2]	count=1
arg	es ||| dtype keepdims	count=1
function	following stats ||| global stats	count=2
arg	[arg_1] replaced ||| [arg_1] [arg_2]	count=1
arg	es of a ||| dtype	count=1
arg	function computes the ||| ishape kshape	count=1
function	legal value for ||| is valid value	count=2
function_arg	[function_1] [arg_2] both inclusive ||| [function_1] integers size [arg_2]	count=1
function	up [function] ||| is [function]	count=3
function	be removed and ||| compress outs	count=1
function	libraries ||| libraries	count=1
arg	to the fgraph this ||| fgraph	count=1
function	list of shape tuple ||| shape	count=1
function	conv output gradient ||| conv2d grad	count=1
function	dependence of nodes ||| make dependence	count=1
function	the op ||| op	count=3
arg	given version ||| version	count=1
function	replace_all_validate revert ||| validate remove	count=1
class	to the type's :attr ||| gpu array type	count=1
function_arg	the shape [arg_2] ||| [function_1] [arg_2]	count=1
function	+ alpha * dot ||| gemv c code	count=1
arg	to name ||| name	count=1
module	this function compute the ||| tensor nnet	count=2
module	be created if ||| gof	count=1
function	access of ||| access	count=1
function	this ||| dimshuffle	count=1
arg	manipulate the ||| r new_r reason verbose	count=1
function	clone in ||| clone	count=1
function	generates the c code ||| c code	count=3
arg	version ||| version	count=1
arg	one tensor ||| x y	count=2
arg	and [arg] from ||| num [arg]	count=1
function	reorder the dimensions of ||| dimshuffle	count=1
arg	to name r ||| r name	count=2
arg	image ||| kernel_shape	count=1
function	how to generate c ||| i c	count=1
function	module from ||| module from	count=2
arg	backpropagation ||| x multiplier	count=1
function	is a thunk ||| thunk	count=1
function_arg	dimshuffle [arg_2] ||| [arg_2] [function_1]	count=1
arg	the fgraph outputs that ||| fgraph expanded_inputs	count=1
arg	to a name ||| name	count=1
function	cache directory and ||| dir	count=1
class	optionally ||| operators	count=1
arg	of r ||| r client_to_remove	count=1
arg	convolve spatio-temporal filters ||| signals filters	count=1
function	constant inputs to elemwise ||| elemwise constant inputs	count=1
module	convert ||| tensor	count=1
function	the supplied function as ||| as	count=1
function	t [function] b ||| local subtensor of [function]	count=1
arg	n (n needs to ||| n	count=1
arg	the dimensions of x ||| x axes	count=1
class	this type ||| tensor type	count=1
function	a symbolic integer scalar ||| unpack	count=1
function	cache directory ||| dir	count=1
arg	function drawing [arg_2] ||| [arg_2] [arg_1]	count=1
arg	m1 and ||| m1	count=1
function	new graph ||| clone with new	count=1
arg	gets a scan ||| not_required	count=1
function	[function_1] generate c ||| [function_2] [function_1]	count=2
function	hyperbolic arc tangent ||| arctanh	count=1
function_arg	[function_1] match out_shape ||| [arg_2] [function_1]	count=2
arg	optional return ||| name	count=1
function	[function_1] remove ||| [function_2] [function_1]	count=4
function	the numeric shape ||| shape	count=1
function	gof graph ||| graph	count=1
class	the type ||| type	count=1
function_arg	[function_1] encoding of ||| [arg_2] [function_1]	count=5
function	[function_1] the batch ||| [function_1] [function_2]	count=2
function	the connection ||| io connection	count=1
arg	contents of a cache ||| dirname err files	count=1
arg	make code ||| code	count=1
arg	if ||| storage_map r_vals	count=1
function	diagonalsubtensor and incdiagonalsubtensor ||| get diagonal subtensor view	count=1
arg	filters with ||| signals filters	count=1
arg	z <- [arg_2] ||| [arg_2] [arg_1]	count=1
function	function for diagonalsubtensor and ||| get diagonal subtensor	count=1
function	c ||| i c	count=1
function	variable [function_2] ||| sparse [function_2] [function_1]	count=2
module	function name to ||| gpuarray	count=2
arg	test a ||| n_tests rng	count=1
function	proxy for either true_div ||| div proxy	count=2
module	directory ||| gof	count=1
function	square ||| sqr	count=2
function	wrapper around sparsevariable constructor [function_1] [function_2] same dtype and ||| [function_2] [function_1]	count=1
function	and [function_1] [function_2] ||| [function_1] constants [function_2]	count=1
function	[function] with ||| [function]	count=1
function	a != ||| neq	count=1
arg	with a ||| a	count=1
class	[class_1] gpucorrmm (direction="forward"), ||| [class_2] [class_1]	count=1
class	the type ||| tensor type	count=1
arg	inputs and [arg_2] ||| [arg_2] [arg_1]	count=2
arg	original ||| inputs outputs copy_inputs_and_orphans memo	count=1
function	hyperbolic cosine ||| cosh	count=2
arg	from a with or ||| size a replace	count=1
function	usmm ||| usmm	count=1
function	variable on the ||| gpuarray variable	count=1
module	and [module] a ||| [module]	count=1
arg	vector and ||| node input_storage	count=1
function	and only ||| local	count=1
function	the dimensions ||| dimshuffle	count=1
arg	[arg_1] * y ||| [arg_2] a x [arg_1]	count=1
function	of header ||| header	count=1
arg	max ||| max	count=1
function	python ||| constant	count=1
function	output shape ||| get out shape	count=2
function_arg	<= [arg_2] ||| [function_1] a [arg_2]	count=1
function	proxy ||| proxy	count=2
function	gives unique names ||| names	count=1
function	[function_1] threads interface ||| [function_1] [function_2]	count=4
arg	use_list ||| use_list	count=1
function	detect [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] search paths ||| object c [function_1] [function_2]	count=4
function	convert addsd to faster ||| addsd ccode	count=1
function	theano gof graph ||| graph	count=1
arg	have separated maker and ||| share_memory swap delete_updates name	count=1
function	with the *args directly ||| csm properties csm	count=1
function	maximum ||| maximum	count=1
class	to the type's :attr ||| array type	count=1
module	tensors [module] sequence ||| [module]	count=1
arg	return true [arg_1] [arg_2] ||| eq [arg_1] [arg_2]	count=1
function	[function_1] get the ||| [function_2] idx [function_1]	count=1
function_arg	a multiplication [arg_2] ||| [arg_2] [function_1]	count=1
arg	the image ||| kernel_shape	count=1
function	context associated with a ||| get context	count=1
module	python ||| tensor	count=1
class	graph and ||| graph	count=2
function	*args directly ||| csm properties csm	count=1
function_arg	and [arg_2] ||| [arg_2] [function_1]	count=1
function	ldflags ||| ldflags	count=1
function	from [function_2] ||| [function_2] [function_1]	count=2
function	it to a max ||| local max	count=1
arg	ints ||| weights minlength assert_nonneg	count=1
function	list of headers that ||| headers	count=1
arg	the url ||| content description filename auth	count=1
function	blas ldflags ||| ldflags	count=1
function	uniform ||| uniform	count=1
arg	baddestroymap if ||| storage_map	count=1
function_arg	[function_1] to a ||| [arg_2] [function_1]	count=1
arg	if theano graphs represent ||| xs ys in_xs in_ys	count=1
function	return a module ||| module	count=1
class	shape in ||| shape	count=1
arg	a particular ||| item	count=1
function	[function_1] form that ||| [function_2] [function_1]	count=4
class	random stream ||| random streams	count=5
class	this ||| tensor py	count=1
class	of scan return true ||| out scan	count=1
class	of the dot product ||| dot	count=1
function	[function_1] a gist ||| [function_1] [function_2]	count=1
function	gpuincsubtensor ||| local inplace setsubtensor	count=2
arg	the output specs ||| input_specs output_specs accept_inplace	count=1
function	[function] required by ||| c [function]	count=7
function	respect to wrt, ||| subgraph	count=1
arg	is associated ||| failure_code	count=1
module	nodes of the ||| gof	count=1
function	pattern of a subgraph ||| pattern	count=1
class	by [class_2] ||| [class_1] [class_2]	count=6
arg	function tries to ||| image_shape top_shape	count=2
arg	this function tries to ||| image_shape top_shape border_mode subsample	count=2
function_arg	transfer [arg_2] ||| [function_1] [arg_2]	count=4
function	compiled module ||| module	count=1
function	replacement ||| replace all	count=1
function	crossentropysoftmax1hotwithbiasdx op whose incoming ||| local useless crossentropy softmax 1hot with bias dx	count=1
function	convert addsd to faster ||| addsd	count=1
class	for every node ||| graph	count=1
arg	fgraph ||| fgraph no_recycling profile	count=1
function	op scale or ||| scale	count=1
function	op whose incoming gradient ||| softmax 1hot	count=1
function_arg	[function_1] node by ||| [arg_2] [function_1]	count=2
module	zip ||| misc	count=1
function_arg	a == [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	reintroduces in [arg_2] ||| [function_1] x [arg_2]	count=4
function_arg	a new [arg_2] ||| [function_1] [arg_2] dtype	count=2
function	abs [function_2] ||| [function_1] [function_2] errors	count=2
arg	variables ||| variables	count=1
function_arg	gist [arg_2] ||| [function_1] [arg_2]	count=1
arg	a symbolic ||| name ndim dtype	count=1
class	a shared variable to ||| shared variable	count=1
function	a list of shape ||| shape	count=1
module_class	duplicate [module_1] [class_2] with inputs = self ||| [module_1] [class_2]	count=1
function	removes all asserts ||| local remove all assert	count=1
function	to replace ||| replace	count=1
arg	failure_callback for [arg_2] ||| [arg_1] [arg_2]	count=2
function	within the op ||| get op params	count=1
arg	stopping condition returned by ||| ls	count=1
function	baddestroymap if ||| inputs	count=1
arg	still in ||| replacements	count=1
arg	if ||| node	count=4
function	confusion matrix ||| confusion matrix	count=1
arg	variable r ||| r	count=1
function	division ||| true div	count=1
function	[function_1] grad ||| [function_2] [function_1]	count=2
arg	given inputs and ||| inputs	count=1
arg	specified outputs ||| fgraph	count=1
function	this op could ||| l op	count=1
arg	end ||| wrt end	count=1
arg	the fgraph this is ||| fgraph	count=1
class	optionally inserting ||| py	count=1
function	alloc ||| local alloc	count=1
function	[function_1] of outputs ||| [function_1] and [function_2]	count=1
class	gradient for ||| grad	count=1
arg	similar behaviour as python's ||| fn sequences non_sequences truncate_gradient	count=1
function_arg	a random [arg_2] ||| [function_1] integers [arg_2]	count=3
function	[function_1] nested loop ||| [function_2] [function_1]	count=1
arg	mini-batch ||| input_shape filter_shape	count=3
arg	will match self ||| var	count=1
function	[function_1] normalization ||| [function_2] [function_1]	count=3
function	[function_1] unused ||| [function_1] constants and [function_2]	count=1
class	for gpucorrmm (direction="forward"), gpucorrmm_gradweights ||| gpu corr mm	count=1
function	search through ||| search	count=1
arg	[arg_1] still in ||| [arg_2] remove [arg_1]	count=1
function	constitutes an ||| is an	count=1
arg	unification where [arg] ||| [arg] b	count=1
function_arg	of a [function_1] [arg_2] ||| [function_1] [arg_2]	count=4
function	of apply [function_2] ||| [function_2] [function_1]	count=1
function	& ||| and	count=1
function	inserting 1 at ||| shape padaxis	count=1
function	infer ||| infer	count=1
function	raise baddestroymap if ||| check inputs	count=1
function	that removes all ||| remove all	count=1
arg	given that v ||| v	count=1
function	of the last access ||| last access time	count=1
function	[function_1] get ||| [function_2] [function_1]	count=9
function	add a optimizer ||| optimizer	count=1
arg	if necessary update dr_vals ||| r_vals dr_vals	count=1
function	[function_1] unused inputs ||| [function_1] constants [function_2]	count=1
arg	similar behaviour as haskell's ||| fn sequences outputs_info	count=1
module	that operates on the ||| gof	count=1
function	don't use [function] change ||| local max and [function]	count=1
function	a gist and return ||| gist	count=1
function_arg	[function_1] v raises ||| [arg_2] [function_1]	count=1
module	zip file ||| misc	count=1
function	hash [function_2] ||| [function_2] [function_1]	count=2
class	to ||| array type	count=1
arg	and [arg] from both ||| num [arg]	count=1
arg	in u ||| u	count=2
function	merge some gpucareducecuda ||| careduce	count=1
function	output shape ||| output shape	count=2
class	by an op that ||| clinker op	count=2
arg	value after the import ||| default	count=1
arg	[arg_1] 4-d tensor ||| [arg_1] [arg_2]	count=1
class	local optimization ||| local	count=1
function	reshape ||| reshape	count=1
function	generate a diff to ||| diff	count=1
function	each row ||| row	count=1
function	a thunk that is ||| thunk	count=1
function	op scale or inverse ||| scale	count=1
module	to ||| tensor	count=1
function	this to expm1 a ||| expm1	count=1
arg	and ||| node input_storage output_storage	count=1
function	[function_1] polar ||| [function_2] [function_1]	count=4
function	sample from [function] distribution centered ||| [function]	count=1
function	litterals to ||| make	count=1
function_arg	> [arg_2] ||| [arg_2] [function_1]	count=2
function	the orphans among them ||| and orphans	count=1
function	[function_1] a bug ||| [function_2] [function_1]	count=3
arg	simple algorithm ||| reasons r_vals	count=1
arg	[arg_1] still ||| [arg_2] remove [arg_1]	count=1
function_arg	[function_1] [arg_2] with the same type ||| [function_1] [arg_2] tag dtype	count=6
function	pattern of a ||| pattern	count=1
function_arg	the inputs [arg_2] ||| [arg_2] [function_1]	count=4
function	to [function] list ||| [function]	count=1
function	how [function] ||| [function]	count=1
module	baddestroymap ||| compile	count=1
function	[function_1] a leaf ||| [function_1] [function_2]	count=1
function_arg	[function_1] out_shape ||| [function_1] indices [arg_2]	count=1
function	[function_1] reshape ||| [function_1] [function_2]	count=4
class	type's ||| gpu array type	count=1
function	all sigmoid to ||| sigmoid	count=1
class	the ||| tensor py operators	count=2
function	we have [function_1] [function_2] ||| [function_2] [function_1] chol	count=3
arg	a 4-d ||| patch_size	count=1
function	updates ordereddict the list ||| get updates	count=1
module	that must ||| gof	count=1
function	lock is removed ||| lock	count=1
arg	if true ||| verbose	count=1
function	nested loop over ||| loop	count=1
class	alloc ||| alloc	count=1
function	hash equal for same ||| hash	count=1
module	dump this ||| gof	count=1
class	for debugmode ||| abstract	count=1
function	is the ||| gcc	count=1
arg	axis ||| axis	count=3
function	[function_1] ger ||| [function_1] dot22 to [function_2]	count=1
function	or a tensorvariable whose ||| as	count=1
arg	:type expression ||| expression wrt consider_constant disconnected_inputs	count=1
arg	convolve spatio-temporal filters ||| filters	count=1
arg	whether it ||| node	count=1
function	string ||| replace patterns	count=1
class	context_name ||| array	count=1
function_arg	device we ||| device node	count=1
class	op ||| op	count=1
function	of useless ||| useless	count=1
arg	a and b are ||| a b	count=1
function	a sparse format instead ||| sparse	count=1
function	a new ||| new	count=2
function	add [function_2] ||| [function_1] [function_2]	count=3
class	not in this ||| function	count=1
function	to make itself ||| to os	count=1
function	file ||| file	count=1
class	graph ||| function graph	count=2
arg	from ||| size	count=1
function	a sparse matrix of [function_1] [function_2] sparsity pattern ||| [function_1] [function_2]	count=1
function_arg	a transfer [arg_2] ||| [arg_2] [function_1]	count=4
function	directory ||| dir	count=1
arg	output ||| output input leftdims rightdims	count=1
function	sparse matrix ||| sparse	count=1
function	last access of ||| last access time	count=2
function	idx_list with constant ||| constant idx	count=1
class	for same ||| tensor	count=1
arg	if implemented ||| node	count=1
function_arg	[function_1] make code ||| [arg_2] [function_1]	count=3
module	if present ||| gof	count=1
function	all [function_2] ||| [function_1] [function_2]	count=4
module	trailing spaces tabs ||| misc hooks	count=1
function	vector variable ||| vector	count=1
module	inserting broadcasted dimensions ||| tensor	count=1
arg	the outputs from ||| outputs mode	count=1
arg	and ||| node input_storage	count=1
function	matrix [function_2] ||| [function_1] [function_2]	count=1
class	distribution defined ||| streams	count=1
function	wrapper around sparsevariable constructor [function_1] [function_2] with the same dtype ||| [function_2] [function_1]	count=1
module	sparse matrix ||| sparse	count=1
class	same type ||| list type	count=1
class	matrix solve operation c ||| solve	count=1
function_arg	[function_1] coordinate specification ||| [function_1] [arg_2]	count=5
function	output gradient w ||| conv3d grad	count=2
module	python object a that ||| gof	count=1
function	of the last ||| last	count=1
arg	node inputs[i] is r ||| r	count=1
arg	according to a ||| inputs outputs cmps	count=1
function	[function] of ||| [function]	count=13
arg	value of [arg] ||| [arg]	count=6
arg	output ||| output input leftdims	count=1
class	for the eigensystem ||| eigh	count=1
class	inserting ||| tensor py	count=1
module	that this ||| gof	count=1
function	[function_1] [function_2] with the same dtype ||| [function_2] [function_1]	count=8
module	stack tensors [module] sequence on ||| [module]	count=1
function	1 0/a [function_2] ||| [function_2] [function_1]	count=1
function	some variables ||| map variables	count=1
function	in the struct ||| struct	count=1
arg	[arg_1] y have ||| [arg_2] [arg_1]	count=3
function	in a new ||| new	count=1
function	copies the stack trace ||| stack trace	count=1
module	return those ||| gof	count=1
arg	cond [arg_2] ||| [arg_1] [arg_2]	count=1
module	used is the ||| gof	count=1
function	post some [function_2] ||| [function_2] [function_1]	count=1
function	loop executes ||| loop	count=1
function	output shape ||| out shape	count=1
function	complex-valued tensor from ||| from	count=1
function	goes up [function] ||| is [function]	count=3
arg	one ||| y	count=3
arg	the shape or ||| shape	count=1
function	multiplication ||| alpha	count=1
function_arg	[function_1] [arg_2] ||| [function_1] inplace fgraph [arg_2]	count=8
class	class to raise ||| raise	count=1
function_arg	helper function ||| helper random_state a	count=1
function	detect a [function_2] ||| [function_1] macos sdot [function_2]	count=1
arg	v real ||| v	count=2
function	[function_1] rel error ||| [function_1] [function_2] errors	count=3
function_arg	[function_1] target ||| [function_1] var [arg_2]	count=1
function	code for ||| code	count=2
arg	min [arg_2] ||| [arg_1] [arg_2]	count=1
class	shape in the ||| shape	count=1
arg	b are unified given ||| b	count=1
function	conda offers to make ||| to	count=1
function	of shape tuple or ||| default infer shape	count=1
arg	or none for ||| i_shapes	count=1
class	of an op ||| op	count=1
function	ignore all errors ||| ignore	count=1
arg	the outputs [arg_2] ||| [arg_2] [arg_1]	count=2
function	[function] of ||| make [function]	count=1
function	unroll the batch size ||| conv code unroll batch	count=1
arg	a with ||| a replace	count=1
arg	outputs from the ||| outputs mode accept_inplace	count=1
arg	to name r sub ||| r name sub	count=1
function	1d ||| 1d	count=1
module	returned by this ||| gof	count=1
function	version ||| version apply	count=2
function	unroll the batch ||| code unroll batch	count=1
arg	the inputs ||| inputs	count=3
arg	return c ||| name sub	count=1
function_arg	[function_1] s to ||| [arg_2] [function_1]	count=3
function	to ultra_fast_sigmoid ||| ultra fast	count=1
function_arg	[function_1] none for ||| [arg_2] [function_1]	count=2
arg	necessary update dr_vals ||| node storage_map r_vals dr_vals	count=1
function	[function_1] matrix of ||| [function_1] [function_2]	count=2
function_arg	transferred to [arg_2] ||| [function_1] var [arg_2]	count=1
function	return ||| get	count=1
arg	the inputs and outputs ||| inputs outputs	count=1
function	only one ||| only	count=1
function	[function_1] file ||| [function_2] [function_1]	count=1
arg	are [arg_2] ||| [arg_2] [arg_1]	count=4
arg	graph from [arg] corresponds ||| [arg]	count=1
function	for diagonalsubtensor ||| diagonal subtensor view	count=1
function	a list of libraries ||| libraries	count=1
module	:attr context_name ||| gpuarray	count=1
function	proxy for either ||| div proxy	count=2
module	that will be ||| gof	count=1
function	variable on ||| gpuarray variable	count=1
function	full path of ||| module	count=1
function	[function_1] deepcopy in ||| [function_2] [function_1]	count=1
function_arg	[function_1] y with ||| [arg_2] [function_1]	count=1
module	the variables that ||| gof	count=1
arg	4-d tensor it ||| patch_size	count=1
function	deepcopyop ||| deep copy op	count=1
function	the output shape ||| output shape	count=2
function	"init_code" together ||| struct	count=1
function	[function_1] initialization ||| [function_2] [function_1]	count=4
function	return connection pattern ||| connection pattern	count=2
arg	[arg_1] axis ||| [arg_2] [arg_1]	count=6
arg	[arg] left-padding ||| [arg]	count=1
class	variable optionally ||| tensor py	count=1
function_arg	[function_1] encoding of ||| [function_1] y [arg_2]	count=5
function	from the scan ||| scan can remove	count=2
function	wrt, computes gradients of ||| subgraph grad	count=1
arg	one-dimensional slices in pvals ||| pvals	count=1
function	the dependence of ||| make dependence	count=1
class	of this ||| tensor py operators	count=1
function	[function_1] [function_2] ||| [function_2] gradinputs [function_1]	count=4
class	same kinds of ||| type	count=1
function	the flattened version ||| flatnonzero	count=1
function	a variable [function_2] ||| [function_2] [function_1]	count=9
function	sparse format instead ||| sparse	count=1
function	the 2d kernel that ||| kernel 2d	count=1
function	total [function_2] ||| [function_2] [function_1]	count=3
function	indicating the version ||| code cache version	count=3
arg	i ||| i	count=6
function	in a new ||| with new	count=1
function	a comparator to ||| cmp	count=1
arg	in [arg] i ||| seq1 [arg]	count=1
function	!= ||| neq	count=2
arg	return c code to ||| name	count=1
function_arg	a | [arg_2] ||| [arg_2] [function_1]	count=1
function	the compile lock to ||| to	count=1
function	c code to extract ||| c extract	count=1
arg	the output ||| output input	count=1
arg	an array ||| node	count=2
arg	outdim ||| outdim	count=1
module	for same kinds of ||| tensor	count=1
arg	similar behaviour as python's ||| fn sequences outputs_info non_sequences	count=1
arg	out_idxs and ||| out_idxs	count=1
class	a convolution with the ||| conv	count=1
arg	[arg_1] r ||| [arg_2] s [arg_1]	count=2
function_arg	a subtensor [arg_2] ||| [function_1] [arg_2]	count=3
arg	[arg_1] es of ||| [arg_1] [arg_2]	count=9
class	utility code for use [class_1] [class_2] ||| [class_1] [class_2]	count=6
function	tensor_from_scalar(scalar_from_tensor x -> x ||| local tensor scalar tensor	count=1
module	dictionary that ||| gof	count=1
function	to pass to helper_c_code ||| get helper c code	count=1
function	[function_1] pattern for ||| [function_1] [function_2]	count=2
function	slice [start stop step] ||| slice	count=1
class	a convolution with ||| conv	count=1
function_arg	inverse [arg_2] ||| [function_1] [arg_2]	count=1
module	dict that ||| gof	count=2
function	a config ||| config	count=1
function	inner graph to ||| inner graph	count=1
function	removes useless dimshuffle ||| local useless dimshuffle	count=2
function_arg	[function_1] a variable ||| [arg_2] [function_1]	count=5
function	the dimensions of this ||| dimshuffle	count=1
function	an alloc [function_2] ||| [function_2] [function_1]	count=8
function	baddestroymap if ||| check	count=1
class	a mrg stream state ||| mrg random streams	count=1
function	within the op code ||| op	count=1
function	function for diagonalsubtensor ||| get diagonal subtensor	count=1
function	of variables ||| variables and	count=1
arg	name in mode ||| name	count=1
function	[function_1] to elemwise ||| [function_2] [function_1]	count=9
function	as its ||| as	count=1
function	[function_1] inner graph ||| [function_1] and unused inputs [function_2] node	count=1
module	returns function to ||| gof	count=1
function	updates ordereddict the ||| updates	count=1
function	or [function] ||| [function]	count=1
class	add ||| inc subtensor	count=1
function	post some text ||| post	count=1
class	navigator ||| navigator optimizer	count=2
function	[function_1] be removed ||| [function_2] [function_1]	count=2
function	computes the mean value ||| mean	count=1
function	sample from [function] ||| [function]	count=1
function	2d kernel for bilinear ||| bilinear	count=1
function	a cache directory and ||| from dir	count=1
module	simplify ||| tensor nnet	count=1
arg	baddestroymap ||| node storage_map	count=1
function	constants and the rest ||| rest	count=1
function_arg	after a [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] the dependence ||| [function_2] [function_1]	count=4
arg	to previously un-shaped variable ||| override	count=1
function	version used is the ||| gcc	count=1
function	a == ||| eq	count=1
class	:attr context_name ||| array	count=1
function	used is the ||| gcc	count=1
function	variable optionally inserting broadcasted ||| dimshuffle	count=1
function	nested loop ||| loop	count=1
module	x ||| tensor nnet	count=2
function	numeric shape ||| shape	count=1
function	[function_1] columns ||| [function_2] [function_1]	count=1
function_arg	[function_1] required ||| [function_1] [arg_2]	count=3
function	[function_1] leaf of ||| [function_2] [function_1]	count=2
module	to use with ||| gpuarray	count=1
function	print [function_2] ||| [function_2] [function_1]	count=2
class	optionally inserting ||| tensor	count=1
function	the version ||| c code cache version	count=3
function	returning the output ||| output	count=1
arg	[arg_1] inputs according ||| [arg_2] [arg_1]	count=2
function	a gist and ||| gist	count=1
arg	map old ||| check_integrity	count=1
arg	end variables ||| wrt end	count=1
function	-> ||| local	count=7
function	value for ||| value	count=1
function_arg	convert radian [arg_2] ||| [function_1] [arg_2]	count=3
function	output for this node ||| output	count=1
arg	each element in y ||| y	count=1
function	updates ordereddict ||| updates	count=1
function	grad of this op ||| l op	count=1
arg	y have the ||| y	count=1
function	return [function] required by ||| c [function]	count=1
arg	an unification in u ||| u	count=2
arg	true if [arg] ||| [arg]	count=2
arg	if we are able ||| dim_x dim_y	count=1
module	always ||| gpuarray	count=1
function	[function_1] row ||| sparse [function_2] [function_1]	count=1
arg	name r sub ||| r name sub	count=2
function	deepcopyop how to ||| deep copy op	count=1
function	[function_1] counter ||| [function_2] [function_1]	count=1
arg	[arg_1] haskell's ||| [arg_1] [arg_2]	count=1
function	[function_1] with ||| gof [function_1] [function_2]	count=1
function	all asserts from the ||| all assert	count=1
class	represents their unification ||| unification	count=1
function	multinomial distributions defined ||| multinomial	count=1
function	a value ||| value	count=1
arg	input to [arg_2] ||| [arg_2] [arg_1]	count=4
class	output ||| output	count=1
class	for corr3dmm (direction="forward"), corr3dmm_gradweights ||| base corr3d mm	count=1
function_arg	[function_1] value has ||| [function_1] hook type [arg_2]	count=1
function	how to generate c ||| shape i c	count=1
arg	test a ||| fun pt n_tests rng	count=1
function	merge multiplication ||| alpha merge	count=2
arg	return c code ||| name sub	count=1
arg	leftdims + [arg_2] ||| [arg_2] [arg_1]	count=1
function	of this variable ||| dimshuffle	count=1
function	from [function] arguments and ||| [function]	count=1
function	list of lib directories ||| header dirs	count=1
function	broadcastable ||| broadcastable	count=2
arg	ignore_trees-related functionality ||| importer pruner chin	count=1
arg	a specified scalar value ||| a	count=1
module	to ||| compile	count=1
module	kinds of tensortype ||| tensor	count=1
module	in inputs that ||| gof	count=1
arg	[arg_1] type1 ||| [arg_2] [arg_1]	count=6
arg	[arg_1] expression ||| [arg_2] [arg_1]	count=2
arg	to a leftdims + ||| leftdims	count=1
arg	graph from [arg] corresponds to ||| [arg]	count=1
class	r's shape ||| shape	count=1
function_arg	from polar [arg_2] ||| [arg_2] [function_1]	count=1
arg	slices in pvals ||| n pvals	count=1
function	for openblas [function_2] ||| [function_2] [function_1]	count=2
arg	reverse-mode ||| inputs output_gradients	count=1
function	[floor] [function_2] ||| [function_2] [function_1]	count=3
arg	we parametrize it ||| max_input_fct maker	count=1
function_arg	the svd on ||| svd a	count=1
function_arg	[function_1] we do ||| [function_1] [arg_2]	count=4
class	this variable optionally inserting ||| py operators	count=1
class	of this type ||| tensor type	count=1
arg	parametrize it to ||| max_input_fct maker	count=1
function	openblas [function_2] ||| [function_2] [function_1]	count=2
class	connection ||| from graph	count=1
function	the following stats ||| global stats	count=2
arg	if it takes the ||| node	count=1
arg	be between min and ||| min	count=1
arg	x and ||| x	count=1
function	ultra_fast_sigmoid ||| local ultra fast	count=1
module	to a [module] ||| [module]	count=1
class	variable of this type ||| pure type	count=1
function	trunc ||| trunc	count=1
function	[function] key to ||| [function]	count=1
function_arg	hot [arg_2] ||| [function_1] y [arg_2]	count=4
function	diff ||| diff	count=1
arg	associated with a particular ||| item	count=1
arg	from x ||| x	count=1
function	of shape ||| default infer shape	count=1
function	upper bound on the ||| bound	count=1
function	optional [function_1] [function_2] required by code returned ||| object [function_1] [function_2]	count=1
function	raise ||| check	count=1
arg	[arg_1] and max ||| [arg_2] [arg_1]	count=5
function	shape and ||| out shape	count=3
arg	be a 1-d ||| random_state size a	count=1
function	the image [function_2] ||| [function_2] [function_1]	count=8
module	if those nodes are ||| gof	count=1
function	round_half_to_even_inplace ||| round half to even	count=1
arg	l ||| l	count=1
arg	the specified ||| sparse_grad	count=1
arg	return true if [arg_1] [arg_2] ||| eq [arg_1] [arg_2]	count=2
function_arg	a gist [arg_2] ||| [function_1] [arg_2]	count=1
function	to the one ||| one	count=1
module	utilization [module] numpy linalg ||| [module]	count=1
function	dependence of ||| dependence	count=1
function	the last [function_2] ||| [function_1] [function_2]	count=4
function_arg	[function_1] s ||| [function_1] r [arg_2]	count=3
function	the connection [function_2] ||| [function_2] [function_1]	count=4
class	dimensions of this ||| tensor py	count=1
function	a canonical form that ||| get canonical form	count=1
function_arg	of a [function_1] [arg_2] ||| sparse [function_1] sum x axis [arg_2]	count=2
arg	name [arg_2] ||| [arg_2] [arg_1]	count=2
arg	gets a scan ||| not_required inputs	count=1
function	[function] use ||| c support [function]	count=1
function	[function_1] following ||| [function_1] [function_2]	count=1
function	if a subtensor ||| subtensor	count=1
class	help the navigator deal ||| navigator	count=1
class	[class_1] stream ||| [class_2] [class_1]	count=10
function	function from comparators ||| fn	count=1
function	get a dict ||| get	count=1
function	of headers that are ||| headers	count=1
function	clone in a ||| clone	count=1
function_arg	shape tuple [arg_2] ||| [arg_2] [function_1]	count=4
function_arg	< b ||| lt a b	count=1
function	depending how [function] is ||| [function]	count=1
function_arg	[function_1] tensortypes ||| [function_1] [arg_2]	count=4
function	a max ||| local max	count=1
class	:attr ||| array	count=1
class	graph ||| graph	count=1
function	[function] utility ||| [function] support	count=1
arg	pvals ||| n pvals	count=1
function	a package ||| package	count=1
function	version used is ||| gcc	count=1
class	the cache and none ||| cache	count=1
function	real ||| real	count=1
function	choose from ||| choose	count=1
function	converts ||| char from	count=1
module	reorder the ||| tensor	count=1
function	following [function_2] ||| [function_1] [function_2]	count=1
function_arg	^ [arg_2] ||| [function_1] inplace a [arg_2]	count=1
function	op that ||| op	count=1
function	post some text to ||| post	count=1
arg	have ||| name	count=1
function	[function_1] [function_2] ||| [function_2] code [function_1]	count=5
module	b u returns ||| gof	count=1
arg	for convolving a mini-batch ||| input_shape filter_shape	count=3
function	bilinear ||| bilinear	count=3
function	also work for gpuincsubtensor ||| setsubtensor	count=1
class	[class_1] [class_2] ||| [class_1] [class_2]	count=70
function	on the inner ||| validate inner	count=1
function	rebroadcast [function_2] ||| [function_2] [function_1]	count=1
function_arg	all device [arg_2] ||| [function_1] [arg_2]	count=4
arg	different ||| outputs tag	count=1
function	extract list of variables ||| variables and	count=1
class	value for ||| gpu	count=1
function	[function_1] interface ||| [function_2] [function_1]	count=5
class	[class_1] variable to ||| [class_2] [class_1]	count=4
module	that has ever been ||| gof	count=1
module	this ||| core	count=1
arg	tries ||| top_shape	count=4
function_arg	[function_1] v ||| [arg_2] [function_1]	count=1
class	the theano enumeration types ||| params type	count=1
arg	[arg_1] and b ||| unify walk [arg_1] [arg_2]	count=1
module	compute 1d ||| nnet	count=1
function	[function_1] scan ||| [function_2] can [function_1]	count=2
arg	baddestroymap if ||| node storage_map r_vals	count=1
arg	of x y ||| x y	count=4
function_arg	some requirements [arg_2] ||| [arg_2] [function_1]	count=2
function	ones with the same ||| ones like	count=1
arg	[arg] must ||| [arg]	count=1
function	after pad_dims ||| unpad	count=1
module	that this opt ||| gof	count=1
arg	a variable [arg] returns a ||| [arg]	count=1
function	[function_1] value ||| [function_2] [function_1]	count=1
function_arg	scan [arg_2] ||| [function_1] inplace [arg_2]	count=1
module	function that ||| scan_module	count=1
function	data supported [function] ||| [function]	count=1
function_arg	gist [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	sum [arg_2] ||| [function_1] [arg_2]	count=1
function	a > ||| gt	count=1
function_arg	diff to [arg_2] ||| [arg_2] [function_1]	count=1
function	with constant ||| get constant idx	count=2
function	[function_1] gcc ||| [function_2] [function_1]	count=3
function	the matrix [function_2] ||| [function_1] [function_2]	count=1
arg	if true ||| verbose m n	count=1
arg	real ||| real	count=1
function	[function_1] [function_2] ||| [function_1] [function_2] errors	count=12
arg	[arg] and uses ||| v o [arg]	count=3
function	connection ||| connection	count=2
function	division inverse ||| div	count=2
arg	input vector and ||| node input_storage output_storage	count=1
function	computes the output ||| output	count=1
function	infer the number of ||| infer	count=1
class	this variable ||| tensor py operators	count=1
arg	an array ||| node inputs	count=2
arg	return a code string ||| name sub	count=1
function	counter to ||| counter	count=1
module	this is a ||| nnet	count=1
class	into macros for ||| cop	count=1
function	a variable [function_2] ||| sparse as [function_2] [function_1]	count=1
class	to a mode ||| mode	count=1
function	mul ||| mul	count=2
arg	y with ||| y axis	count=1
function_arg	merge [arg_2] ||| [function_1] cls alpha_in beta_in [arg_2]	count=1
class	the navigator deal ||| navigator	count=1
module	replace ||| tensor nnet	count=1
function	a uniform ||| uniform	count=1
function	calculate the sum ||| sum	count=1
function	of the parents ||| parents	count=1
arg	and y have ||| y	count=1
function	constitutes an [function_2] ||| [function_1] [function_2]	count=1
function	extract a ||| extract	count=1
arg	given axis ||| x axis	count=2
arg	raise ||| node storage_map	count=1
function	svd ||| svd	count=1
function	[function_1] get the ||| [function_2] [function_1]	count=9
function	to py_none ||| init	count=1
function	to the apply to ||| apply	count=1
function_arg	[function_1] conventions imposed ||| [function_1] slice [arg_2]	count=5
arg	m1 and the second ||| m1	count=1
class	nit_sot output of scan ||| scan	count=1
function_arg	[function_1] [arg_2] inclusive ||| [function_1] [arg_2]	count=2
module	around c_init that ||| gof	count=1
function	as replace_all_validate revert the ||| validate remove	count=1
function	to concatenate tensortypes ||| join	count=1
function	inputs to [function_2] ||| [function_2] constant [function_1]	count=1
function	search through a ||| stack search	count=1
function	subtensor(setsubtensor ||| subtensor inc subtensor	count=2
function_arg	context [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	inputs required ||| inputs variable_list blockers	count=1
function	offers to make ||| to	count=1
function	variable with [function_2] ||| [function_2] [function_1]	count=3
function	diagonalsubtensor and incdiagonalsubtensor ||| get diagonal subtensor	count=1
function_arg	[function_1] instance ||| [function_1] [arg_2]	count=6
function_arg	[function_1] specified axis ||| [arg_2] [function_1]	count=3
function	[function_1] gradient ||| [function_2] [function_1]	count=2
arg	with [arg] 1s ||| t [arg]	count=1
function	how to generate c ||| c	count=4
arg	decorator ||| cls alpha_in beta_in	count=1
function	1d kernel that can ||| kernel 1d	count=1
function	scale each row ||| row scale	count=1
function	in ||| replace	count=1
function	[function_1] ger ||| [function_1] [function_2]	count=1
class	dimensions of ||| py	count=1
function	schedule [function_2] ||| [function_1] [function_2]	count=1
arg	an exception while annotating ||| exc_info storage_map	count=1
function	is found ||| is	count=1
function	in a new ||| clone with new inputs	count=1
function_arg	[function_1] [arg_2] ||| [function_1] cls alpha_in beta_in [arg_2]	count=2
function	with helper_c_code ||| helper c code	count=1
class	the same type ||| type	count=1
function_arg	[function_1] y ||| [function_1] x [arg_2]	count=1
arg	v by ||| v	count=1
function_arg	string [arg_2] ||| [function_1] [arg_2]	count=2
arg	value after the import ||| default filter	count=1
function	pooling ||| pool	count=1
function	supported [function] gpu? currently ||| [function]	count=1
function	perform ||| perform	count=1
function	litterals to ||| make constant	count=1
arg	dimension axis ||| axis	count=1
function	post ||| post	count=1
function_arg	new variable [arg_2] ||| [function_1] [arg_2] tag dtype	count=1
arg	inside ||| node	count=1
function	shape [function_2] ||| [function_2] gradinputs [function_1]	count=2
function	sigmoid to [function_2] ||| [function_2] [function_1]	count=2
arg	if the named ||| fullname	count=1
function	function to get ||| get	count=1
function	comparator to represent ||| cmp	count=1
arg	haskell's ||| outputs_info	count=1
class	dictionary data structures ||| out non seq scan	count=1
arg	[arg_1] are ||| [arg_2] [arg_1]	count=4
function	sigmoid to ||| sigmoid	count=1
function	to determine ||| adv index broadcastable	count=1
class	of ||| operators	count=1
class	type ||| pure type	count=2
function	[function_1] [function_2] ||| [function_2] [function_1]	count=450
function	to get ||| get depth	count=1
function	[function_1] inplace on ||| [function_1] [function_2]	count=3
function	adds new optimization instances ||| register	count=1
module	nodes to output nodes ||| gof	count=1
module	output nodes of the ||| gof	count=1
function	symbolic row ||| row	count=1
function_arg	inplace on [arg_2] ||| [arg_2] [function_1]	count=10
arg	called whenever ||| function_graph	count=1
class	variable optionally ||| py operators	count=1
function	op could ||| l op	count=1
arg	vector and t is ||| node input_storage output_storage	count=1
arg	args ||| args	count=1
arg	specifyshape how to generate ||| c_support_code_apply	count=1
function	return the complex conjugate ||| conj	count=1
function	register a [function_2] ||| [function_2] [function_1]	count=1
module_class	this [class_2] ||| [module_1] [class_2]	count=17
arg	[arg_1] from type1 ||| [arg_2] [arg_1]	count=8
module	structured addition [module] ||| [module]	count=1
function	row variable ||| row	count=1
function	on a) ||| inplace	count=1
function_arg	outputs and [arg_2] ||| [arg_2] [function_1]	count=1
function	y -> x ||| local	count=1
function	don't use [function] ||| local max and [function]	count=1
arg	with the ignore_trees-related functionality ||| fgraph importer pruner chin	count=1
function	rebroadcast how to ||| rebroadcast	count=1
function_arg	[function_1] [arg_2] ||| [function_1] flags [arg_2]	count=1
function	convert python ||| constant	count=1
module_class	duplicate [module_1] [class_2] inputs = self inputs ||| [module_1] [class_2]	count=1
arg	[arg_1] sub ||| [arg_1] name [arg_2]	count=1
arg	a variable of ||| a	count=1
arg	in ||| node	count=1
function_arg	one hot [arg_2] ||| [function_1] y [arg_2]	count=4
arg	if cond [arg_2] ||| [arg_2] [arg_1]	count=1
function	that unroll the batch ||| unroll batch	count=1
function	unroll the batch ||| gen conv code unroll batch	count=1
function	random ||| random	count=2
function	a multiplication ||| mul	count=1
function_arg	[function_1] [arg_2] ||| [function_1] indices [arg_2]	count=6
arg	sample n (n needs ||| size n	count=1
function	arguments to pass to ||| args	count=1
function	in a new ||| clone with new	count=1
function	one [function_2] ||| [function_1] [function_2]	count=1
class	c ||| clinker op	count=1
arg	to the end ||| end	count=1
function	output gradient w r ||| conv2d grad	count=1
function	to ||| to os environ	count=1
function	[function_1] nodes ||| [function_2] [function_1]	count=4
class	for gpucorrmm ||| gpu corr mm	count=1
arg	[arg_1] and outputs ||| [arg_2] [arg_1]	count=4
function	[function_1] matrix of ||| [function_2] [function_1]	count=2
arg	fgraph to [arg_2] ||| [arg_1] [arg_2]	count=3
class	for ||| gpu	count=4
function	the stack trace ||| stack trace	count=1
arg	with a movie ||| signals_shape filters_shape	count=1
function	[function_1] shape of ||| [function_1] [function_2]	count=2
class	from the cache ||| call cache	count=1
arg	is r ||| r	count=1
function_arg	to extract [arg_2] ||| [arg_2] [function_1]	count=1
arg	and o ||| o	count=1
class	to ||| array	count=1
arg	[arg_1] es ||| [arg_2] [arg_1]	count=9
function	how to generate c ||| register specify shape c	count=1
function	softmax(sum_of_stuff) -> ||| local	count=1
class	graph and ||| function graph	count=2
function	[function_1] file ||| [function_1] from [function_2]	count=1
arg	in [arg] which are ||| [arg]	count=1
function	[function_1] ultra_fast_sigmoid ||| [function_2] [function_1]	count=6
module	this is a ||| tensor nnet	count=1
function	the abs [function_2] ||| [function_2] [function_1]	count=2
function	removes [function_2] ||| [function_2] [function_1]	count=5
function	after a given ||| default	count=1
arg	min ||| min	count=1
class	the alloc ||| alloc	count=1
module	addition [module] matrix ||| [module]	count=1
function	constant [function_2] ||| [function_1] [function_2]	count=2
function_arg	failure_callback [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] multiplication by ||| [function_2] [function_1]	count=4
function	it into a canonical ||| get canonical	count=1
class	data structures ||| out non seq scan	count=1
function	and should be removed ||| outs	count=1
function	return full path ||| module name from	count=2
function	g++ version ||| gcc	count=1
arg	drawing ||| pvals	count=1
class	[class_1] [class_2] ||| [class_2] [class_1]	count=6
function	useless [function_2] ||| [function_1] [function_2]	count=2
function	gradient updates ||| grad	count=1
function	work for gpuincsubtensor ||| setsubtensor	count=1
function	to expm1 ||| expm1	count=1
arg	the end variables ||| wrt end	count=1
function	> ||| gt	count=2
module	a that would be ||| gof	count=1
function	return a hash from ||| hash from	count=1
function	to a gist ||| gist	count=1
function	wrt, computes gradients ||| subgraph	count=1
function	isclose ||| isclose	count=1
function	g++ ||| gcc	count=1
function	be removed ||| compress outs	count=1
function	depending how [function] is implemented ||| [function]	count=1
function	gradient the ||| grad	count=1
arg	encode [arg] ||| [arg]	count=1
arg	[arg_1] args ||| [arg_1] [arg_2]	count=1
function	python litterals ||| make constant	count=1
function	the version ||| cache version apply	count=1
function	slice [start ||| slice	count=1
function	hash of [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] leaf of ||| [function_1] [function_2]	count=2
arg	nesting ||| loop_orders dtypes loop_tasks	count=1
class	type's :attr ||| array type	count=1
class	wants to ||| optimizer	count=1
function	from the [function_2] ||| [function_2] can [function_1]	count=1
function	to make an inplace ||| inplace	count=1
arg	that x [arg_2] ||| [arg_2] [arg_1]	count=3
function	an alloc and ||| local alloc	count=2
arg	by b [arg_2] ||| [arg_2] m1 [arg_1]	count=2
function_arg	clip [arg_2] ||| [arg_2] [function_1]	count=7
arg	[arg_1] of node ||| [arg_2] [arg_1]	count=2
function	the same [function_2] ||| [function_1] [function_2]	count=1
class	the dimensions ||| py operators	count=1
function	output ||| get out	count=1
arg	initializes py_name ||| r name	count=1
function	create a comparator ||| cmp	count=1
arg	estimate [arg] ||| [arg]	count=1
function	a nested loop ||| loop	count=1
function	[function_1] bug ||| [function_1] macos sdot [function_2]	count=3
arg	that x [arg_2] ||| [arg_1] [arg_2]	count=3
arg	root ||| root	count=1
arg	a leftdims [arg_2] ||| [arg_1] [arg_2]	count=1
class	of ||| tensor py	count=1
arg	the value after the ||| default	count=1
function	merge 2 profiles returned ||| merge	count=1
arg	is the first functiongraph ||| no_recycling	count=1
function	exception object [function_2] ||| gof [function_1] [function_2]	count=3
function	a legal value for ||| is valid value	count=1
function	[function] them from ||| [function] func	count=1
function	names to an iterable ||| names	count=1
arg	its idx_list reorders the ||| idx_list get_count	count=1
function	the inner [function_2] ||| [function_2] [function_1]	count=4
class	this ||| py operators	count=2
function_arg	[function_1] triangle ||| [function_1] [arg_2]	count=2
function	[function_1] on ||| [function_2] [function_1]	count=4
arg	computes the ||| ishape kshape	count=1
arg	function ||| random_state a	count=1
function	defining the gradient ||| grad	count=1
arg	start ||| start	count=1
function_arg	the shape [arg_2] ||| [function_1] padleft [arg_2]	count=1
module	utilization [module] numpy ||| [module]	count=1
function	the following [function_2] ||| [function_2] [function_1]	count=1
function	detect if the g++ ||| gcc	count=1
arg	denum removes it ||| denum	count=1
function_arg	[function_1] function for ||| [arg_2] [function_1]	count=3
class	of this ||| operators	count=1
arg	the list remove are ||| remove reason	count=1
arg	given axis es ||| axis dtype op	count=2
function	of libraries ||| libraries	count=1
arg	mini-batch of a ||| input_shape filter_shape	count=3
function	the output ||| get output	count=1
class	inserting broadcasted dimensions ||| tensor py	count=1
function_arg	== [arg_2] ||| [function_1] a [arg_2]	count=1
arg	between min [arg_2] ||| [arg_2] [arg_1]	count=1
arg	tries ||| image_shape top_shape border_mode subsample	count=2
function	return the constant scalar ||| get scalar constant	count=1
function_arg	[function_1] to target ||| [function_1] var [arg_2]	count=1
arg	the ||| node	count=4
module	this ||| gof	count=19
arg	original graph to ||| inputs outputs copy_inputs_and_orphans memo	count=1
arg	while annotating ||| thunk exc_info storage_map	count=1
class	same kinds ||| type	count=1
arg	true if a and ||| a	count=1
function	and only adds dimension ||| local	count=1
function	the minimum ||| minimum	count=1
arg	encoding ||| nb_class dtype	count=1
arg	conventions imposed ||| theslice length	count=1
function	default reverse them ||| transpose	count=1
arg	function for ||| fn	count=1
class	graph and get ||| function graph	count=1
arg	original ||| outputs copy_inputs_and_orphans memo	count=1
arg	[arg_1] is the ||| vm linker accept [arg_1] [arg_2]	count=1
module	that would be a ||| gof	count=1
function	removes all asserts from ||| local remove all assert	count=1
function	modified bessel function ||| i1 inplace	count=1
function	all sigmoid to ultra_fast_sigmoid ||| ultra fast sigmoid	count=1
class	for same ||| tensor type	count=1
function_arg	[function_1] [arg_2] both inclusive ||| [function_1] [arg_2]	count=2
arg	a [arg_2] ||| eq [arg_1] [arg_2]	count=1
function	in a new ||| with new inputs	count=1
function	scale or inverse the ||| scale	count=1
arg	set of 2d filters ||| filters	count=2
function	dependence of ||| make dependence	count=1
arg	[arg_1] b ||| eq [arg_1] [arg_2]	count=3
arg	old_r ||| old_r	count=1
function	triangular [function_2] ||| [function_2] [function_1]	count=2
arg	[arg_1] + rightdims ||| [arg_1] [arg_2]	count=6
arg	leftdims [arg_2] ||| [arg_1] [arg_2]	count=1
arg	to reps ||| reps	count=1
function	a compiled module ||| module	count=1
function	validations on the inner ||| inner	count=1
module	nodes that ||| gof	count=1
function_arg	transfer function ||| transfer fn	count=1
function	* ||| sqr	count=1
function	scale each ||| scale	count=2
arg	not run [arg] gpu! ||| [arg] b	count=1
function	clone in a new ||| clone	count=1
function	the sum along ||| sum	count=1
arg	and ||| node name sub	count=1
function	det x and there ||| local det	count=1
module	confusion ||| tensor nnet	count=1
function	[function_1] package ||| [function_2] [function_1]	count=2
function	of arguments [function_2] ||| [function_2] [function_1]	count=2
class	for same ||| type	count=1
function	[function_1] extract ||| [function_1] [function_2]	count=1
function	orv ||| unify walk	count=1
function_arg	diagonal [arg_2] ||| [function_1] offset [arg_2]	count=2
arg	dtype as ||| dtype	count=1
module	that has ||| gof	count=1
function	the one ||| to one	count=1
class	theano ||| tensor py	count=11
function_arg	[function_1] [arg_2] ||| [function_1] integers [arg_2]	count=2
class	the navigator ||| navigator	count=1
arg	the outputs from the ||| outputs mode	count=1
function	[function_1] division inverse ||| [function_1] [function_2]	count=2
arg	min and ||| min	count=1
function	path ||| path	count=1
function	of header search paths ||| header dirs	count=1
function	[function_1] [function_2] ||| [function_2] constants [function_1] node	count=2
arg	a with b ||| a	count=1
arg	types of x y ||| x y	count=2
function	[function_1] alloc of ||| [function_2] [function_1]	count=2
function	function is a thunk ||| thunk	count=1
arg	u ||| u	count=3
arg	r operation on f ||| f	count=1
function_arg	> [arg_2] ||| [function_1] a [arg_2]	count=1
function_arg	[function_1] cost and/or ||| [arg_2] [function_1]	count=1
function_arg	gist and [arg_2] ||| [arg_2] [function_1]	count=1
arg	test a ||| pt n_tests rng	count=1
arg	v raises ||| v	count=1
function	sigmoid [function_2] ||| [function_2] [function_1]	count=2
arg	still in ||| fgraph replacements	count=1
arg	replaced by ||| allow_partial only_process_constants elemwise	count=1
arg	elementwise ||| b	count=7
function_arg	fill [arg_2] ||| [function_1] [arg_2]	count=3
arg	g_pt g_pt ||| g_pt	count=1
function	conv2d ||| conv2d	count=1
class	convolution with the specified ||| dnn conv	count=1
module	by this ||| gof	count=1
arg	f ||| f	count=3
module	the ||| tensor	count=1
function	of shape tuple or ||| infer shape	count=1
function	triangular ||| triangular	count=1
arg	scan the contents ||| dirname err files	count=1
function	the lock is ||| lock	count=1
function_arg	standard deviation [arg_2] ||| [arg_2] [function_1]	count=6
class	navigator deal with ||| navigator optimizer	count=1
class	local optimization wants to ||| local optimizer	count=1
arg	[arg_1] n-d tensor ||| [arg_1] [arg_2]	count=2
class	context_name ||| gpu	count=1
function	batch normalization of the ||| dnn batch normalization	count=1
function	unroll [function_2] ||| [function_1] [function_2]	count=3
arg	an apply_node recursively search ||| apply_node check reason	count=1
function	used is ||| gcc	count=1
function	<= ||| le	count=2
function	parse a ||| parse mul	count=1
function	thunk that is a ||| thunk	count=1
function	or [function] in one ||| local add [function]	count=1
arg	to type2 from type1 ||| type1 type2	count=1
function	a variable with a ||| variable	count=1
arg	return a string ||| name x z	count=1
class	kinds ||| type	count=1
arg	and outputs ||| outputs	count=1
function	multinomial ||| multinomial	count=3
function	alloc ||| alloc	count=2
function	use within the op ||| get op	count=1
arg	raise ||| node	count=1
function	[function_1] inverse ||| [function_2] [function_1]	count=4
function	[function_1] dot a ||| [function_1] [function_2]	count=1
function	config [function_2] ||| [function_1] [function_2]	count=1
function	loop executes ||| make reordered loop	count=1
arg	given axis es ||| axis dtype	count=1
function	default that removes ||| remove	count=1
function	name the object ||| name	count=1
rep	[module_class_1] [function_arg_2] ||| [module_class_1] [function_arg_2]	count=12
function	a new ||| clone	count=2
class	optionally inserting broadcasted dimensions ||| tensor py operators	count=1
function	whose ||| local useless	count=1
function	total time icluding the ||| compute total times	count=1
function	use within the op ||| op params	count=1
arg	input to a leftdims ||| input leftdims	count=1
function	the indices ||| indices	count=1
function	[function_1] [function_2] ||| [function_1] constant [function_2]	count=1
function	the op ||| op params	count=1
function	tan ||| tan	count=1
function	generate c ||| register specify shape c	count=1
function	suitable dummy values ||| provide	count=1
function	tensorvariable ||| as	count=1
arg	value has a ||| value	count=1
function_arg	warn about bugs fixed [function_1] [arg_2] ||| [function_1] [arg_2]	count=3
function	the abs ||| abs	count=2
arg	cost and/or from existing ||| cost	count=1
function	the version ||| code cache version apply	count=1
function	new graph ||| with new inputs	count=1
arg	from a with or ||| size a replace p	count=1
function	the argmax ||| argmax	count=1
function	canonical form that ||| get canonical form	count=2
function	[function] b ||| local subtensor of [function]	count=1
class	kinds of tensortype ||| tensor type	count=1
arg	triangle of an array ||| m k	count=2
function	value underlying variable v ||| value	count=1
arg	named module ||| fullname	count=1
class	for corrmm (direction="forward"), corrmm_gradweights ||| corr mm	count=1
arg	set of arrays to ||| choices out mode	count=1
module	as other scalar op ||| scalar	count=2
arg	clients list of r ||| r	count=1
function	[function_1] c ||| [function_1] [function_2]	count=2
arg	an exception while annotating ||| node thunk exc_info storage_map	count=1
function	polar ||| polar	count=1
module	copied ||| compile	count=1
function	to replace [function_2] ||| [function_1] [function_2]	count=3
function	schedule ||| sort schedule	count=1
function	supplied function as ||| as	count=1
arg	and b are ||| b	count=1
arg	check [arg_1] [arg_2] ||| vm linker accept [arg_1] [arg_2]	count=4
function	new variable ||| variable	count=1
function_arg	new [arg_2] ||| [arg_2] [function_1]	count=9
function	according to the idx ||| idx	count=1
function	return the constant ||| constant	count=2
function	the same ||| same	count=1
arg	the specified [arg] ||| random_state size avg [arg]	count=1
function	[function_1] inner graph ||| [function_2] [function_1]	count=1
arg	if allow_override is false ||| allow_override	count=1
function	legal [function_2] ||| [function_2] [function_1]	count=1
function	not [function] ||| [function]	count=1
function_arg	[function_1] match out_shape ||| [function_1] indices [arg_2]	count=2
class	the dimensions of ||| operators	count=1
class	feature should remove ||| feature	count=1
function	llvm one or not ||| gcc llvm	count=1
function	list of outputs ||| outputs	count=1
function	op ||| l op	count=1
arg	conventions imposed by python ||| theslice length	count=1
arg	encoding of [arg_2] ||| [arg_2] [arg_1]	count=2
function	det x and ||| local det	count=1
function	of cutils_ext ||| compile cutils	count=1
arg	[arg] tensor this ||| input leftdims [arg]	count=1
module	if the ||| gof	count=1
arg	second half by b ||| b	count=1
class	of a shared ||| shared	count=1
module	function that uses ||| scan_module	count=1
function	trace from ||| trace	count=1
module	convert python ||| tensor	count=1
function	this variable optionally inserting ||| dimshuffle	count=1
module	attach_feature the method that ||| gof	count=1
arg	if converting to type2 ||| type2	count=1
function_arg	of variables [arg_2] ||| [function_1] orphans [arg_2]	count=1
function	full ||| module	count=1
arg	convolving a mini-batch of ||| input_shape filter_shape	count=3
function	counter ||| counter	count=1
function_arg	lower [arg_2] ||| [arg_2] [function_1]	count=4
arg	u and uses ||| o u	count=2
function	kernel that can ||| kernel	count=2
arg	run [arg] gpu! ||| [arg] b	count=1
function_arg	with constant [arg_2] ||| [arg_2] [function_1]	count=5
function	[function_1] normalization ||| [function_1] [function_2]	count=3
class	[class_1] variable ||| [class_2] [class_1]	count=4
arg	match a variable ||| var	count=1
class	cache and none ||| cache	count=1
function	[function] distribution ||| [function]	count=1
arg	along the specified axis ||| axis sparse_grad	count=1
function	from variable and ||| get	count=1
arg	es of a ||| ddof keepdims	count=1
arg	if ||| storage_map	count=1
function	batch [function_2] ||| [function_1] [function_2]	count=4
function	matrix of ||| matrix	count=1
function	gpu_from_host abstractconv ||| conv gpu conv	count=1
arg	that was used to ||| inputs g_outputs	count=1
arg	input [arg_2] ||| [arg_1] [arg_2]	count=9
function	toposort ||| toposort	count=1
arg	to the fgraph outputs ||| fgraph expanded_inputs	count=1
function	a comparator ||| cmp	count=1
function_arg	a scan [arg_2] ||| [function_1] inplace fgraph [arg_2]	count=4
class	the cache and ||| cache	count=1
arg	[arg] both ||| size [arg]	count=1
function	remove ||| subtensor remove	count=1
arg	fgraph outputs ||| fgraph expanded_inputs	count=1
arg	by [arg] in mode ||| [arg]	count=1
function	of lib ||| lib	count=1
function	updates ordereddict [function_2] ||| [function_1] and [function_2]	count=1
function	the stack ||| copy stack	count=1
function	by default that removes ||| remove	count=1
arg	integer [arg] ||| size [arg]	count=1
module	in self ||| core	count=1
function	[function_1] [function_2] the same dtype and ||| sparse [function_2] [function_1]	count=8
function	randomstate ||| randomstate	count=1
arg	order v ||| v	count=2
class	and ||| pool grad	count=1
class	this mode ||| monitor mode	count=1
function	shape ||| set shape	count=1
function	revert the replacement if ||| replace all	count=1
class	optional ||| clinker op	count=2
arg	[arg_1] rightdims ||| [arg_2] [arg_1]	count=6
function	[function_1] all ||| [function_2] [function_1]	count=4
function_arg	of a [function_1] [arg_2] ||| sparse [function_1] sum [arg_2]	count=2
class	to the type's ||| gpu array type	count=1
function	variable ||| dimshuffle	count=1
function	complex-valued tensor from polar ||| from polar	count=1
function	version ||| code cache version apply	count=2
function	the matrix ||| matrix	count=1
class	scan return true iff ||| scan	count=1
function	x -> x ||| local	count=1
function	within the op code ||| get op params	count=1
module	if those nodes ||| gof	count=1
function	toposort return an ||| toposort	count=1
arg	by b ||| b	count=1
function	and ||| and	count=1
class	variable optionally ||| operators	count=1
function	dependence of nodes in ||| make dependence	count=1
arg	[arg] zview ||| name x [arg]	count=1
arg	similar behaviour as ||| fn sequences	count=2
arg	return [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
arg	iff other is the ||| other	count=1
arg	2d filters ||| input filters	count=2
function	function for diagonalsubtensor ||| diagonal subtensor	count=1
function	a inner ||| inner sitsot	count=1
arg	return a string ||| name x	count=1
arg	the outputs ||| outputs mode	count=1
function	that removes all asserts ||| remove all assert	count=1
function	a view ||| view tree	count=1
function_arg	[function_1] function ||| [function_1] [arg_2]	count=7
function	[function_1] dependence ||| [function_2] [function_1]	count=2
class	module file ||| key data	count=1
class	of this variable optionally ||| tensor py operators	count=1
arg	replace replace in ||| replace	count=1
function	the confusion [function_2] ||| [function_2] [function_1]	count=2
function_arg	[function_1] we ||| [arg_2] [function_1]	count=4
function	the shape ||| shape	count=4
function	sum along ||| sum	count=1
function	converts this to expm1 ||| expm1	count=1
function	variable on the ||| as gpuarray variable	count=2
function	[function_1] [function_2] ||| [function_2] zero [function_1]	count=1
function	[function_1] [function_2] sparse matrix by the ||| sparse [function_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] exc [arg_2]	count=1
function	"code_cleanup" ||| cleanup	count=1
arg	and t is ||| node input_storage output_storage	count=1
function	schedule function from comparators ||| schedule fn	count=1
arg	order v real ||| v	count=2
function	a gemm ||| gemm	count=1
arg	clients list of r ||| r client_to_remove	count=1
module	inserting ||| tensor	count=1
arg	attempt ||| arg leaves new_leaves op	count=1
class	list ||| list type	count=1
class	:attr ||| array type	count=1
function	for diagonalsubtensor ||| get diagonal subtensor view	count=1
class	optionally inserting broadcasted ||| tensor py operators	count=1
function	debug [function_2] ||| [function_1] [function_2]	count=2
function_arg	[function_1] a 4-d ||| [function_1] input [arg_2]	count=1
arg	/ b ||| b	count=1
arg	out for occurrences of ||| out	count=1
arg	is associated to it ||| failure_code	count=1
class	stream ||| random streams	count=5
function	[function] required ||| c header [function]	count=1
function	attempting to use dnn ||| dnn	count=2
arg	[arg_1] leftdims + ||| [arg_1] [arg_2]	count=2
function	inner-most loop executes code ||| reordered loop	count=1
function_arg	[function_1] b ||| [function_1] inplace a [arg_2]	count=16
function	the inner [function_2] ||| [function_1] [function_2]	count=4
arg	es of ||| ddof keepdims	count=1
function	[function] representation ||| as [function]	count=2
class	variable ||| tensor	count=1
function	gradient updates for matrix ||| grad	count=1
function	task ||| task	count=1
function	a schedule [function_2] ||| [function_2] [function_1]	count=1
function	the inner-most loop executes ||| loop	count=1
arg	zview [arg] zview ||| name x [arg]	count=1
function	the dot product ||| true dot	count=1
function	the context associated with ||| get context	count=1
function_arg	[function_1] name ||| [arg_2] [function_1]	count=1
arg	neighbours images2neibs> ||| ten4 neib_shape neib_step mode	count=1
class	for debugmode ||| base abstract	count=1
module	litterals ||| tensor	count=1
arg	pyobject * instance ||| sub check_input	count=1
function	det [function_2] ||| [function_2] [function_1]	count=3
module	object a that ||| gof	count=1
function	graph of apply nodes ||| sort apply nodes	count=1
class	solve operation ||| solve	count=1
function_arg	[function_1] according ||| [arg_2] [function_1]	count=5
function	the stack ||| stack	count=1
function_arg	[function_1] function drawing ||| [function_1] [arg_2]	count=1
module	around c_cleanup that ||| gof	count=1
function	the maximum ||| maximum	count=1
function	time on thunks ||| time	count=2
function	the inner graph ||| inner graph	count=1
function	op ||| op	count=7
class	scan return true ||| scan	count=1
arg	test ||| pt n_tests	count=1
function	// 1 ||| intdiv by one	count=1
class	implementation of mod ||| mod	count=1
arg	filters with [arg_2] ||| [arg_2] [arg_1]	count=1
function	access of a ||| access time	count=1
function	register ||| register	count=1
class	inserting broadcasted ||| tensor py	count=1
arg	fgraph to break aliasing ||| fgraph wrapped_inputs wrapped_outputs	count=1
arg	can be a 1-d ||| random_state size a replace	count=1
function	find broken ||| find bad	count=1
class	the navigator deal with ||| navigator optimizer	count=1
function	the g++ version ||| gcc	count=1
function_arg	of [function_1] [arg_2] ||| sparse [function_1] sum x axis [arg_2]	count=2
function	updates ordereddict [function_2] ||| [function_2] [function_1]	count=3
function	gradient w ||| grad	count=3
arg	es [arg_2] ||| [arg_2] [arg_1]	count=3
function_arg	polar [arg_2] ||| [arg_2] [function_1]	count=1
arg	[arg_1] n-d ||| [arg_1] [arg_2]	count=2
function	[true] ||| true	count=1
module	detect if the g++ ||| gof	count=1
function	grad ||| grad dict	count=2
class	tensor ||| operators	count=1
function_arg	inverse on ||| inverse a	count=1
function	if its [function] ||| undefined [function]	count=2
arg	inputs and outputs ||| inputs outputs	count=3
function	op code ||| get op	count=1
function	simplify ||| simplify	count=1
arg	original graph to a ||| inputs outputs copy_inputs_and_orphans memo	count=1
function	header [function_2] ||| object c [function_1] [function_2]	count=1
