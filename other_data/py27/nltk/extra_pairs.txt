nonbreaking prefixes corpus reader	this is a class to read the nonbreaking prefixes textfiles from the moses machine translation toolkit
french stemmer	the french snowball stemmer
reference	a set of reference values
show	if true, display the model that has been found
corpus	name of the corpus to take as input possible values are
test	a list of values to compare against the corresponding
dot	the position of the new edge's dot. this position
token	the token that should be stemmed
prob dist i	a probability distribution for the outcomes of an experiment a
reentrances	a dictionary from reentrance ids to values
classifier based tagger	a sequential tagger that uses a classifier to choose the tag for each token in a sentence
n_instances	the number of total sentences that have to be used for
canvas	canvas the canvas on which to draw the drs. if none is given create a new canvas
factory_kw_args	extra keyword arguments for probdist_factory
path_to_tree	a list of indices i1 i2 ..., in where
unigrams	a list of bigrams whose presence/absence has to be
grammar	the grammar used to parse texts
combinations	given n featurelists if combinations=k all generated templates will have
knbcorpus reader	this class implements - __init__, which specifies the location of the corpus
documents	a list or iterable of tokens
title	the title for the graph
abstract lazy sequence	an abstract base class for read-only sequences whose values are computed as needed
closures	closure properties for the extension of the concept
undirected type raise	undirected combinator for type raising
mod	a mod word to test as a modifier of 'head'
train	the fraction of the the corpus to be used for training (1=all)
chunk_types	the chunk types to be converted
rename_vars	if true then rename any variables in
words	the list of words to be put into the grid
entry dialog	a dialog box for entering
key	name of key marker at the start of each record. if set to
button	which button the user should use to click on
arity	the arity of the concept
moses tokenizer	this is a python port of the moses tokenizer from https //github
parser_model	path to parser model directory
anchor	the corner or side of the canvas widget that
utterance	the utterance id of the sample to play
sequence	the sequence of symbols which must contain the text
frel	the frame relation to be printed
regexp chunk parser	a regular expression based chunk parser regexpchunkparser uses a
found	the output of model_found()
norwegian stemmer	the norwegian snowball stemmer
categorized plaintext corpus reader	a reader for plaintext corpora whose documents are divided into categories based on their file identifiers
r	the amount of frequency
C	capitalization flag
fileids	the list of fileids that make up this corpus
parameters	the context target display tuples for the item
key	the name abbreviation or id number of the semantic type
gzip_compress	if true, ouput files are compressed with gzip
standard format	class for reading and processing standard format marker files and strings
spanish stemmer	the spanish snowball stemmer
ibmmodel2	lexical translation model that considers word order >>> bitext = []
word	a spanish word with or without accents
epsilon	adjusts threshold similarity score for near-optimal alignments
lhs	only return productions with the given left-hand side
tree widget	a canvas widget that displays a single tree
whitespace tokenizer	tokenize a string on whitespace space tab newline
fileids	a list or regexp specifying the ids of the files whose
unsorted chart parser	a bottom-up parser for pcfg grammars that tries edges in whatever order
whence	if 0 then the offset is from the start of the file
ibmmodel3	translation model that considers how a word can be aligned to multiple words in another language
badscore	the score to give to words which do not appear in each other's sets of synonyms
ibmmodel1	lexical translation model that ignores word order >>> bitext = []
feature_func	the function that will be applied to each
alpha	the relative weighting of precision and recall
order	one of preorder, postorder, bothorder,
correctTag	the correct tag for the *i*th token
file	the file identifier of the file to read
deterministic	if true adjudicate ties deterministically
k	the skip distance
sep	the separator string used to separate word strings
longest chart parser	a bottom-up parser for pcfg grammars that tries longer edges before shorter ones
direction	class representing the direction of a function application
cache	if true add this resource to a cache. if load()
unk	instance of a pos tagger conforms to taggeri
strings	list of strings to insert into the trie
other	feature with which to compare
german stemmer	the german snowball stemmer
sentiment intensity analyzer	give a sentiment intensity score to sentences
prover9parent	a common class extended by both prover9 and mace <mace mace>
simulate_root	the various verb taxonomies do not
heldout_fdist	the heldout frequency distribution
synset_relations	information about which synset relations
nomfile	the name of the file containing the predicate-
child	the child widget to remove. child must be a
variable	variable the variable to replace
pred holder	this class will be used by a dictionary that will store information about predicates to be used by the closedworldprover
cat	the parent of the leftcorners
bnccorpus reader	corpus reader for the xml version of the british national corpus
zero_based	nodes in the input file are numbered starting from 0
nodesep	a string that is used to separate the node
feature top down predict rule	a specialized version of the cached top down predict rule that operates on nonterminals whose symbols are featstructnonterminals
pretty list	displays an abbreviated repr of only the first several elements not the whole list
future	wraps and acts as a proxy for a value to be loaded lazily on demand
generic stanford parser	interface to the stanford parser
gold	the gold standard
train_sents	the correct tagging of the corpus
custom feature value	an abstract base class for base values that define a custom unification method
combinator	function<list<t>,r> to combine the results of the
english stemmer	the english snowball stemmer
b	expression
input	list of str input sentences to parse as a single discourse
morefeatures	additional features for the new feature
lhs	the left-hand side of the new probabilisticproduction
test	a list of values to compare against the
filetype	if specified then filetype indicates that
perceptron tagger	greedy averaged perceptron tagger as implemented by matthew honnibal
russian stemmer	the russian snowball stemmer
fileids	a list or regexp specifying the fileids in this corpus. default is oana-en.xml
confusion matrix	the confusion matrix between a list of reference values and a corresponding list of test values
tweet handler i	interface class whose subclasses should implement a handle method that twitter clients can delegate to
st	the semantic type to be printed
sentence	the sentence to be parsed
fail_on_unknown	if true then raise a value error if
lists	the underlying lists
list_of_references	a list of reference sentences w.r.t. hypotheses
delimiter	field delimiter
size	the maximum number of bytes to read. if no
crubadan corpus reader	a corpus reader used to access language an crubadan n-gram files
default tagger	a tagger that assigns the same tag to every token
production	a grammar production each production maps a single symbol
size	buffer at least size bytes before writing to file
labels	a list of the "known labels" for this
word net iccorpus reader	a corpus reader for the wordnet information content corpus
encoding	the encoding of the grammar if it is a binary string
start unzip message	data server has started unzipping a package
retracted	assumptions to be retracted
prob	the probability associated with the object
compresslevel	the compresslevel argument is an integer from 1
gisencoding	a binary feature encoding which adds one new joint-feature to the joint-features defined by binarymaxentfeatureencoding: a
combinator	function with the same signature as the
tokens	the sequence of tokens
elimeq	when set to true boxer removes all equalities from the
theorem tool command decorator	a base decorator for the provercommanddecorator and modelbuildercommanddecorator classes from which decorators can extend
semcor corpus reader	corpus reader for the semcor corpus
max_phrase_length	maximal phrase length if 0 or not specified
ex	expression
nfarray	an array that can be used to uncompress nf
pattern	a regular expression for filtering the fillers of
regexp tagger	regular expression tagger the regexptagger assigns tags to tokens by comparing their
toolbox settings	this class is the base class for settings files
size	number of bytes to buffer during calls to read() and write()
minimal set	find contexts where more than one possible target value can appear
tokens	the list of classified tokens from which to extract
lhs	only generate edges e where e.lhs()==lhs
marker	a character that is printed to the left of the
words	the words used to seed the similarity search
kwargs	keyword arguments passed to standardformat.fields()
assignment	a dictionary which represents an assignment of values to variables
test_sequence	a sequence of labeled test instances
hungarian stemmer	the hungarian snowball stemmer
agressive_dash_splits	option to trigger dash split rules
rhs	only generate edges e where e.rhs()==rhs
reflections	a mapping between first and second person expressions
s	the string to read
target	the item of interest
unit	one of 'token', 'word', or 'chunk'
model	a first order model is a domain *d* of discourse and a valuation *v*
discount	the new value to discount counts by
documents	a list of words label tuples
sep	the token separator
indices	list of int
t	the tree to be converted
fields	a list of fields that will be extracted from the json file and
word net corpus reader	a corpus reader used to access wordnet or its variants
fstruct_reader	a feature structure parser
synset1	first input synset
freq dist	a frequency distribution for the outcomes of an experiment a
other	other input synset
ngram1	first ngram to compare
visited	a set containing the ids of all feature
y	this cell's y coordinate
cutoffs	arguments specifying various conditions under
file_names	a list of alternative file names to check
function backed maxent feature encoding	a feature encoding that calls a user-supplied function to map a given featureset/label pair to a sparse joint-feature vector
seg1	a segmentation
downloader gui	graphical interface for downloading packages from the nltk data server
labelled_sequences	the training data a set of
name	a regular expression pattern used to search the
lemmas	a dictionary where keys are lemmas and values are sets
data	list of words
substitute bindings sequence	a mixin class for sequence clases that distributes variables() and substitute_bindings() over the object's elements
open on demand zip file	a subclass of zipfile zipfile that closes its file pointer
trigram collocation finder	a tool for the finding and ranking of trigram collocations or other association measures
bindings	a dictionary mapping from variables to values
grammar	the initial grammar to display
kneser ney prob dist	kneser-ney estimate of a probability distribution this is a version of
nechunk parser tagger	the iob tagger used by the chunk parser
pad_right	whether the ngrams should be right-padded
stanford tokenizer	interface to the stanford tokenizer >>> from nltk
data	tweet object returned by twitter api
hypothesis	a hypothesis sentence
tokenizer i	a processing interface for tokenizing a string
rules	an ordered list of transformation rules that
excludezero	do not output any feature with 0 in any of its positions
f_start	starting index of the possible foreign language phrases
conditional freq dist	a collection of frequency distributions for a single experiment run under different conditions
bindings	bindingdict a starting set of bindings with which
prover	a prover. if not set one will be created
trigram assoc measures	a collection of trigram association measures each association measure
event variable expression	this class represents variables that take the form of a single lowercase 'e' character followed by zero or more digits
sequence widget	a canvas widget that keeps a list of canvas widgets in a horizontal line
viterbi parser	a bottom-up pcfg parser that uses dynamic programming to find the single most likely parse for a text
rels	bundle of metadata needed for constructing a concept
depparser	the dependency parser
fmt	format specification
end	only generate edges e where e.end()==end
aligned corpus reader	reader for corpora of word-aligned sentences tokens are assumed
references	reference sentences
featuresets	an iterable over featuresets each a dict mapping
regexp tokenizer	a tokenizer that splits a string using a regular expression which matches either the tokens or the separators between tokens
input	str input sentence to parse
printunused	if true print a list of all unused templates
trees	a sequence of nltk trees usually parentedtrees
elt_handler	a function used to transform each element
estimator	a function taking
freqdist	the frequency distribution that the
bllip parser	interface for parsing with bllip parser bllipparser objects can be
pcfg	a probabilistic context-free grammar a pcfg consists of a
left	the suggested leftcorner
comparison	a comparison represents a comparative sentence and its constituents
fileid	thesaurus fileid to search in. if none search all fileids
modelfile	the model file
j_pegged	if specified neighbors that have a different
iff expression	this class represents biconditionals
args	items and lists to be combined into a single list
nombank pointer	a pointer used by nombank to identify one or more constituents in a parse tree
categories	a list specifying the categories whose files have to
index	the index where the child widget should be
x	the initial x coordinate for the upper left hand
chunk string	a string-based encoding of a particular chunking of a text
comment_chars	str of possible comment characters
pickle corpus view	a stream backed corpus view for corpus files that consist of sequences of serialized python objects (serialized using
used	tuple of two lists of atoms. the first lists the
fileids	a list of the files that make up this corpus
frame	the frame to be printed
cat	the parent of the leftcorner
options	extra parameters for the constructor such as
brill tagger	brill's transformational rule-based tagger brill taggers use an
rowvalues	a list of row values used to initialze the
tagged_corpus	a tagged corpus. each item should be
name	a regular expression pattern used to search the lu
gold	the chunk structures to score the chunker on
right_pad_symbol	the symbol to use for right padding default is none
smoothing function	this is an implementation of the smoothing techniques for segment-level bleu scores that was presented in
input_str	a string whose contents are used as stdin
graphs	a list of dependency graphs to train the scorer
visited_other	a set containing the ids of all other
alpino corpus reader	reader for the alpino dutch treebank
records	a list of records
language	the model name in the punkt corpus
arff formatter	converts featuresets and labeled featuresets to arff-formatted strings appropriate for input into weka
local timezone offset with utc	this is not intended to be a general purpose class for dealing with the local timezone
variable	variableexpression the variable bind
data	str for the input to be parsed
tag_pattern	this rule's tag pattern. when
regexp	regular expression that matches token separators must not be empty
f2e	the backward word alignment outputs from target-to-source
memo	a dictionary used to record the trees that we've
outputfilename	path to the output file
classifier i	a processing interface for labeling tokens with a single category label (or "class")
gaussian_prior_sigma	the sigma value for a gaussian
word	the hungarian word whose region r1 is determined
boxer drs parser	reparse the str form of subclasses of abstractboxerdrs
items	names of the chat-80 relations to extract
backward combinator	the backward equivalent of the forwardcombinator class
punkt token	stores a token of text with annotations produced during sentence boundary detection
node_index	the address of the 'destination' node
joinChar	a string used to connect collapsed node values (default = "+")
ngram	ngram to lookup
fileids	specifies the set of fileids for which paths should
text	a sentence whose subjectivity has to be classified
numoutcomes	the total number of outcomes for each
words	a list of words/tokens
k	window size if none set to half of the average reference segment length
naive bayes classifier	a naive bayes classifier naive bayes classifiers are
expression	expression
replace	if true then use the replaced intended word instead
child_pointer_lists	a sequence of lists of the edges that
word_tokenizer	tokenizer for breaking sentences or
word	the actual word to be replace "<word>"
propfile	the name of the file containing the predicate-
lazy map	a lazy sequence whose elements are formed by applying a given function to each element in one or more underlying lists
box widget	a canvas widget that places a box around a child widget
data	list of tokens (words or word tag tuples)
labelled_sequences	the supervised training data a set of
svd_dimensions	number of dimensions to use in reducing vector
lang	the iso 639 code of the language e.g. 'eng' for english 'rus' for russian
parallel prover builder command	this command stores both a prover and a model builder and when either prove() or build_model() is called then both theorem tools are run in
consistchk	if true, check that the result of adding the sentence is thread-consistent. updates self._readings
is_complete	only generate edges e where
mwe	the multi-word expression we're adding into the word trie
cutlength	words are stemmed by cutting them at this length
drs	a discourse representation structure
paice	class for storing lemmas stems and evaluation metrics
verbose	output the debugging messages during training
assoc_measure	bigram association measure to use as score function
dependency grammar	a dependency grammar a dependencygrammar consists of a set of
position	the position in the string to start parsing
context index	a bidirectional index between words and their 'contexts' in a text
candc_out	str output from c&c parser
cutlength	optional parameter to start counting from ui oi
stream	an input stream
tagged_sent	a list of tuples of word and bio chunk tag
attribs	the new canvas widget's attributes
s	the string to be converted
decisions	a dictionary mapping from feature values
index	the index whose neighborhood should be returned
s	the positional alignments in giza format
labels	the set of possible labels. if none is given then
unicodelines	whether to use unicode line drawing characters
weights	the feature weight vector for this classifier
string tokenizer	a tokenizer that divides a string into substrings by splitting on the specified string defined in subclasses
skip_ambiguous_tweets	if true remove tweets containing both happy
starts	where to start looking for feature
bottom up predict combine rule	a rule licensing any edge corresponding to a production whose right-hand side begins with a complete edge's left-hand side
tweet writer	handle data by writing it to a file
frontier	a list of the locations within tree of
rhs	the list specifying what kinds of children need to
averaged perceptron	an averaged perceptron as implemented by matthew honnibal
grammar	the new grammar
feature value tuple	a base feature value that is a tuple of other base feature values
test grammar	unit tests for cfg
parse_corpus	the corpus containing the parse trees
freltyp	the frame relation type to be printed
beam_size	the maximum length for the parser's edge queue
bottom up probabilistic chart parser	an abstract bottom-up parser for pcfg grammars that uses a chart to record partial results
concept	a concept class loosely based on skos (http //www
path	the feature path that led us to this unification
srctext	the sentence string from the source language
user	the username to authenticate with. use none to disable
alpha_convert	bool alpha convert automatically to avoid name clashes?
n	the number of things
lin thesaurus corpus reader	wrapper for the lisp-formatted thesauruses distributed by dekang lin
dictionary conditional prob dist	an alternative conditionalprobdist that simply wraps a dictionary of probdists rather than creating these from freqdists
dy	the number of pixels to move this canvas widget
chasen corpus view	a specialized corpus view for chasenreader similar to taggedcorpusview,
aset	the pos annotation set of the sentence to be printed
sklearn classifier	wrapper for scikit-learn classifiers
target_sents_lens	a list of target sentences' lengths
new_weights	the new feature weight vector
doc	input document
tags	an msd tag that is used to filter all parts of the used corpus
term	a set of variable objects that should not be returned from
child	the container's child widget. child must not
document	the document that will be passed as argument to the
chart parser	a generic chart parser a "strategy", or list of
readings	an additional list of readings
translation_option	information about the proposed expansion
height	the height of the new space widget
probabilistic nonprojective parser	a probabilistic non-projective dependency parser
defstr	the string to be printed
space widget	a canvas widget that takes up space but does not display anything
rel_name	name of the relation
space tokenizer	tokenize a string using the space character as a delimiter which is the same as s
bncword view	a stream backed corpus view specialized for use with the bnc corpus
random chart parser	a bottom-up parser for pcfg grammars that tries edges in random order
word	the word whose regions r1 and r2 are determined
shift_cost_coeff	constant used to compute the cost of a shift
conditional prob dist	a conditional probability distribution modeling the experiments that were used to generate a conditional frequency distribution
offset	a byte count offset
span	only generate edges e where e.span()==span
assumptions	input expressions to use as assumptions in the proof
timit tagged corpus reader	a corpus reader for tagged sentences that are included in the timit corpus
ngram tagger	a tagger that chooses a token's tag based on its word string and on the preceding n word's tags
n	the number of instances to consider (in case we want to use only a
inside chart parser	a bottom-up parser for pcfg grammars that tries edges in descending order of the inside probabilities of their trees
sentence	input sentence to parse as word tag pairs
parentChar	a string used to separate the node representation from its vertical annotation
tokens	the sentence that this chart will be used to parse
multi parented tree	a tree that automatically maintains parent pointers for multi-parented trees
sent	an annotation set or exemplar sentence to be printed
epsilon	the epsilon value use in method 1
porter stemmer	a word stemmer based on the original porter stemming algorithm
bottom up chart parser	a chartparser using a bottom-up parsing strategy
sequence	the source data to be converted into ngrams
chart comparer	:ivar _root the root window :ivar _charts a dictionary mapping names to charts
use_agenda	use an optimized agenda-based algorithm
is_regex	whether name is a regular expression
parser i	a processing class for deriving trees that represent possible structures for a sequence of tokens
dutch stemmer	the dutch snowball stemmer
stack	a list of strings and trees encoding
encoding	the encoding of the string if it is binary
algorithm	a case-insensitive string specifying which
semkey	the feature label to use for the root semantics in the tree
kwargs	additional arguments to pass to the training methods
features	a tuple of features default slash type
relation	if true then return tuples of (str pos relation_list)
symbols	the symbol name string. this string can be
top_n	number of best words/tokens to use sorted by association
pros cons corpus reader	reader for the pros and cons sentence dataset
graph	the graph represented as a dictionary of sets
rowvalue	a tuple of cell values one for each column
un chunk rule	a rule specifying how to remove chunks to a chunkstring, using a matching tag pattern
data	the response from twitter api
alignment	a storage class for representing alignment between two sequences s1 s2
history	a list of the tags for all words before *index*
punkt base class	includes common components of punkttrainer and punktsentencetokenizer
documents	a list of documents. if labeled=true, the method expects
Nr	the list *nr*, where *nr[r]* is the number of
hunpos tagger	a class for pos tagging with hunpos the input is the paths to
gold	the list of tagged sentences to score the tagger on
drt expression	this is the base abstract drt expression from which every drt expression extends
linear logic parser	a linear logic expression parser
stepping shift reduce parser	a shiftreduceparser that allows you to setp through the parsing process performing a single operation at a time
word	the word that is stemmed
unigrams	a list of words/tokens whose presence/absence has to be
incremental chart parser	an *incremental* chart parser implementing jay earley's parsing algorithm
file	the file to be searched through
features	the initial feature values for this feature
new_assumptions	new assumptions
future_score	approximate score for translating the
pairs	the patterns and responses
child	the child widget that changed
strategy	a list of rules that should be used to decide
kwargs	keyword arguments passed to toolbox.standardformat.fields()
top down chart parser	a chartparser using a top-down parsing strategy
samples	the samples to plot default is all samples
expression	this is the base abstract object for all logical expressions
cat	the suggested leftcorner
probabilistic	are the grammar rules probabilistic?
context tagger	an abstract base class for sequential backoff taggers that choose a tag for a token based on the value of its "context"
canvaswidget	the new canvas widget
bins	the number of sample values that can be generated
stop	if true, stopwords are thrown away
lancaster stemmer	lancaster stemmer >>> from nltk
text	a text whose polarity has to be evaluated
pretty dict	displays an abbreviated repr of values where possible
grammar	contains the chunking rules used to parse the
tagged_data	maximum number of rule instances to create
expandUnary	flag to expand unary or not (default = true)
cfg	a context-free grammar a grammar consists of a start state and
fileid_or_classid	an identifier specifying which class
argument	expression, for the argument
errors	error handling scheme for codec. same as decode() builtin method
regexp	the regular expression
sequence	the source data to be padded
sentence	an input sentence
new_indexes	a list of node addresses to check for
estimator	an optional function or class that maps a
scroll watcher widget	a special canvas widget that adjusts its canvas's scrollregion to always include the bounding boxes of all of its children
additional_java_args	this is the additional java arguments that
sentence_pair	a sentence in the source language and its
path_to_bin	the user-supplied binary location deprecated
p	the probability of the tree produced by the production
sequential backoff tagger	an abstract base class for taggers that tags words sequentially left to right
rightmost_stack	the rightmost elements of the parser's
regexp	the regular expression for this regexpchunkrule
variable	variable the variable to bind
cumulative	a flag to specify whether the freqs are cumulative (default = false)
var	a variable acting as a key for the assignment
feature fundamental rule	a specialized version of the fundamental rule that operates on nonterminals whose symbols are featstructnonterminals
stream	the stream to which the megam input file should be
filename	the name of the file to print the tree to
vnclass	a verbnet class identifier or an elementtree
smoothing	how much do we smooth synset counts default is 1.0
format	str indicating the format for displaying
annotation task	represents an annotation task i e people assign labels to items
featurelists	lists of features whose cartesian product will return a set of templates
leaf edge	an edge that records the fact that a leaf value is consistent with a word in the sentence
tree edge	an edge that records the fact that a tree is partially consistent with the sentence
item	the item to draw
right_tag_pattern	this rule's right tag
cutlength	words are stemmed by cutting at this length
cached top down predict rule	a cached version of topdownpredictrule after the first time
tree	a chunk tree
tag	'pos' part of speech 'sem' semantic or 'both'
text	the chunked tagged text that should be used for
click_to_sort	if true then create bindings that will
tokens	the list of input tokens
tag rule	an interface for tag transformations on a tagged corpus as performed by tbl taggers
canvaswidget	the canvas widget to remove
alwayson_features	if true then include always-on
height	the new height
sent_tokenizer	a tokenizer for breaking paragraphs into sentences
references	reference sentence
ignore_case	flag to set if case should be ignored when searching text
multi classifier i	a processing interface for labeling tokens with zero or more category labels (or "labels")
ref	the reference segmentation
classpath	a ':' separated list of directories jar
model builder command	this class holds a modelbuilder, a goal and a list of assumptions
c5	if true then the tags used will be the more detailed
tags	a list of tags corresponding by index to the words in the tokens list
rtext	the portion of the text that is not yet
binary	the location of the binary to call
srctext	the source language tokens a list of string
debug	if true give warning when retracted is not present on
reference	a gold standard alignment sure alignments
trace	the trace level. a trace level of 0 will
lhs	the new edge's left-hand side specifying the
review_line	a reviewline instance that belongs to the review
replace_bound	bool should bound variables be replaced?
doc	a parsed xml document
trace	if true generate trace output
left_pad_symbol	the symbol to use for left padding default is none
forward combinator	class representing combinators where the primary functor is on the left
alignment	alignment to be checked
column_index	a index representing the column of incoming arcs
shift reduce app	a graphical tool for exploring the shift-reduce parser the tool
opinion lexicon corpus reader	reader for liu and hu opinion lexicon blank lines and readme are ignored
syntax corpus reader	an abstract base class for reading corpora consisting of syntactically parsed text
width	the display width
repl	the replacement expression for this regexpchunkrule
collapsePOS	'false' default will not collapse the parent of leaf nodes (ie
horzMarkov	markov order for sibling smoothing in artificial nodes (none default = include all siblings)
variable binder expression	this an abstract class for any expression that binds a variable in an expression
tree	the tree that should be converted
string	the string being matched
positive_prob_prior	a prior estimate of the probability of the label
stem	if true then use word stems instead of word strings
blank_before	elements and subelements to add blank lines before
canvas	this canvas widget's canvas
configuration	class for holding configuration which is the partial analysis of the input sentence
width	the width of each line in characters (default=80)
end	end of range (note inclusive!) where this feature should apply
top down predict rule	a rule licensing edges corresponding to the grammar productions for the nonterminal following an incomplete edge's dot
stanford parser	>>> parser=stanfordparser(
reentrance_ids	a dictionary mapping from each id
chunked corpus reader	reader for chunked and optionally tagged corpora paragraphs
strip_space	if true strip spaces from word tokens
meaning	represents a single panlex meaning a meaning is a translation set derived
labeled	if true, assume that each document is represented by a
model builder	interface for trying to build a model of set of formulas
span	a tuple s e , where tokens[s e] is the
nechunk parser	expected input list of pos-tagged words
cache_size	determines the size of the cache used
root_label	the node label to use for the root
canvas frame	a tkinter frame containing a canvas and scrollbars
trainer	train method of a classifier
and expression	this class represents conjunctions
s	a string that will be checked to see if within which a
expand right rule	a rule specifying how to expand chunks in a chunkstring to the right using two matching tag patterns a left pattern and a
feature single edge fundamental rule	a specialized version of the completer / single edge fundamental rule that operates on nonterminals whose symbols are featstructnonterminals
callback	the callback function that will be called
factor	right or left factoring method (default = "right")
symbol	the node value corresponding to this
coordinates	a coordinate pair
simplify	bool simplify the proof?
max_len	the maximum order of n-gram this function should extract
gold	the list of chunked sentences to score the chunker on
sentence	a single sentence string
encoding	the encoding of the input string if it is binary
chart_class	the class that should be used to create
nombank corpus reader	corpus reader for the nombank corpus which augments the penn treebank with information about the predicate argument structure
parent	the tk widget that contains the colorized list
counts	data object to store counts of various parameters during training
stemmer i	a processing interface for removing morphological affixes from words
sequence	the source data to be converted into bigrams
rhs	the right-hand side of the new production
plot	if true plot a visual representation of the sentence polarity
g	an assignment to individual variables
aset_level	if true 'sent' is actually an annotation set within a sentence
context	the context in which the item of interest appears
rows	the number of rows in the grid
window_len	the dimension of the smoothing window should be an odd integer
root	the root directory for this corpus. default points to location in multext config file
test	a set of values to compare against the reference set
n	the degree of the ngrams
subjclass	the class of the subject named entity
encoding	the encoding of the files
normalize	flag to indicate normalization
fileobj	a bytesio stream to read from instead of a file
keepends	if false then strip newlines
format	output format for displaying models
search_leaves	whether ot return matching leaf nodes
filter	if true, only print out consistent thread ids and threads
edge i	a hypothesis about the structure of part of a sentence
cutoff checker	a helper class that implements cutoff checks based on number of iterations and log likelihood
canvas widget	a collection of graphical elements and bindings used to display a complex object on a tkinter canvas
streamer	retrieve data from the twitter streaming api
word	the word that is transliterated
reprfunc	if specified then use this function to
calculate_leftcorners	false if we don't want to calculate the
bindings	bindings for the new edge
hypothesis	a hypothesis translation
s	the contents of the file
constituents	the most likely constituents table. this
hyp	the hypothesis component of the pair
s	the string representation of a tagged token
nkjpcorpus text view	a stream backed corpus view specialized for use with text
bindings	bindingdict a dictionary of bindings used to simplify
bindings	bindingdict a starting set of bindings with which the
include_encoding	if true then return a list of
Tr	the list *tr*, where *tr[r]* is the total count in
schema	the schema used in a set of relational tuples
key	the identifier we are searching for
primitive category	class representing primitive categories
lazy concatenation	a lazy sequence formed by concatenating a list of lists this
chunk rule with context	a rule specifying how to add chunks to a chunkstring, using three matching tag patterns one for the left context one for the
maxlen	the maximum number of items to print
inputs	list of list of str input discourses to parse
graph	the initial graph represented as a dictionary of sets
featureset tagger i	a tagger that requires tokens to be featuresets a featureset
parsed	an expression of logic
child	the new child widget. child must not have a
sent	the sentence to be printed
pretty lazy map	displays an abbreviated repr of only the first several elements not the whole list
use_min_depth	this setting mimics older v2 behavior of nltk
line tokenizer	tokenize a string into its lines optionally discarding blank lines
trglen	the number of tokens in the target language
ngram	the ngram that needs to be searched
hidden markov model tagger	hidden markov model class a generative model for labelling sequence data
ruleformat	rule output format one of "str", "repr", "verbose"
sentence	input sentence to parse
abbreviate	if true abbreviate labels longer than 5 characters
alph	the alphabet to be used for filling blank cells
bncsentence	a list of words augmented by an attribute num used to record the sentence identifier (the n attribute from the xml)
mutable prob dist	an mutable probdist where the probabilities may be easily modified this
timeout	number of seconds before timeout set to 0 for
stem	if true then substitute stems for words
word	feature which examines the text word of nearby tokens
json_file	the original json file containing tweets
rhs	the right hand side of a cfg production
skip_header	if true skip the first line of the csv file (which usually
toktok tokenizer	this is a python port of the tok-tok pl from
remove_duplicates	should duplicates be removed?
synset	a synset
parser_options	optional dictionary of parser options see
child	the child widget. child must not have a
enconding	the encoding of the given files default is utf8
count_cutoff	a cutoff value that is used to discard
tree	the tree to be collapsed
labeled_sequence	a sequence of labeled training instances
closed domain prover	this is a prover decorator that adds domain closure assumptions before proving
rhs	the nonterminal used to form the right hand side
encoding	encoding used by settings file
prob_dist	the distribution from which to garner the
discourse tester	check properties of an ongoing discourse
ycoeparse corpus reader	specialized version of the standard bracket parse corpus reader that strips out (code
prover command decorator	a base decorator for the provercommand class from which other prover command decorators can extend
edges	a set of existing edges. the number of edges
words	the target words
plaintext corpus reader	reader for corpora that consist of plaintext documents paragraphs
downloader message	a status message object used by incr_download to communicate its progress
other	the synset that this synset is being compared to
ruleformat	format of reported rules
serialize_output	the file where the learned tbl tagger will be saved
label	the node label typically a string
speaker	if specified select specific speaker s defined
cooper store	a container for handling quantifier ambiguity via cooper storage
encoding	the encoding used by the model. unicode tokens
finish collection message	data server has finished working on a collection of packages
func	a function that takes two arguments a featureset
backlinks	a dictionary where the key is the alignment points and value is the cost referencing the languageindependent.priors
root_label	the label to use for the root of the tree
alignment_info	alignment under consideration
stream	the stream to which the tadm input file should be
dot	only generate edges e where e.dot()==dot
new_vars	a dictionary that is used to hold the mapping
word net object	a common base class for lemmas and synsets
width	the new width
trace	the level of diagnostic tracing output to produce 0-4
abstract collocation finder	an abstract base class for collocation finders whose purpose is to collect collocation candidate frequencies filter and rank them
trgtext	the sentence string from the target language
features	a list of feature specifications where
cycle_path	a list of node addresses each of which is in the cycle
informchk	if true, check that the result of adding the sentence is thread-informative. updates self._readings
reference	a reference sentence
hypothesis	the length of the hypothesis
max_rules	maximum number of rule instances to create
tokens	a list of strings i.e. tokenized text
categories	a list specifying the categories whose words have to
f_measure	if true, evaluate classifier f_measure
mwappdbcorpus reader	this class is used to read the list of word pairs from the subset of lexical pairs of the paraphrase database ppdb xxxl used in the monolingual word
double_neg_flip	if true double negation is considered affirmation
affix tagger	a tagger that chooses a token's tag based on a leading or trailing substring of its word string
occur_index	bool should predicates be occurrence indexed?
key	a function that maps each token to a normalized
a	expression
password	the password to authenticate with
probabilistic production	a probabilistic context free grammar production
boxer	this class is an interface to johan bos's program boxer a wide-coverage semantic parser that produces discourse representation structures drss
tokens	the list of word tag tokens to be chunked
special list	a list subclass which adds a '_type' attribute for special printing similar to an attrdict though this is not an attrdict subclass
save_classifier	the filename of the file where the classifier
samples	the samples whose frequencies should be returned
visited_self	a set containing the ids of all self
index	the index of the word whose tag should be
colorized list	an abstract base class for displaying a colorized list of items
style	the style to use for the format 3 4 10 columns
verify_tags	whether the individual tags should be
feature value concat	a base feature value that represents the concatenation of two or more featurevaluetuple or variable
split rule	a rule specifying how to split chunks in a chunkstring, using two matching tag patterns a left pattern and a right pattern
framenet corpus reader	a corpus reader for the framenet corpus
untag	if true, omit the tag from tagged input strings
reranker_options	optional dictionary of reranker options see
max_models	the maximum number of models that mace will try before
master	the widget that should contain the new
path_to_bin	the hunpos-tag binary
text	the string to be tokenized
kwargs	additional parameters passed to categorizedcorpusreader
binding	expression the atomic to which 'variable' should be bound
conll_file	str for the filename of the training input data
oval widget	a canvas widget that places a oval around a child widget
r	the number of times a thing is taken
vector space clusterer	abstract clusterer which takes tokens and maps them into a vector space
input	the discourse sentences
column_names	a list of names for the columns these
probdist_factory	the function or class that maps
prover command	this class holds a prover, a goal and a list of assumptions when
db	name of file to which data is written
trg_classes	target word classes
top down init rule	a rule licensing edges corresponding to the grammar productions for the grammar's start symbol
stanford postagger	a class for pos tagging with stanford tagger the input is the paths to
truncate	if specified then only show the specified
test_set	a list of tokens label tuples to use as gold set
delete_on_gc	if true then fileid will be deleted
gzip file system path pointer	a subclass of filesystempathpointer that identifies a gzip-compressed file located at a given absolute path
cross validation prob dist	the cross-validation estimate for the probability distribution of the experiment used to generate a set of frequency distribution
frame2	(optional 'frame' must be a different frame) only show relations
semcor word view	a stream backed corpus view specialized for use with the bnc corpus
unlabeled_featuresets	a list of featuresets whose label is unknown
s	a set containing tuples of str elements
encoding	the encoding of the input only used for text formats
unseen_features	if true then include unseen value
parser_dirname	the path to the maltparser directory that
dependency_scorer	a scorer which implements the
window	filters out fillers which exceed this threshold
deprecated	a base class used to mark deprecated classes a typical usage is to
start	the nonterminal from which to start generate sentences
word_tokenizer	the tokenizer instance that will be used to tokenize
start download message	data server has started downloading a package
assumptions	input expressions to use as assumptions in
function	function to call on each subexpression
boundary	boundary value
indent	the indentation level at which printing
templates	templates to be used in training
chunk_label	the node value that should be used for
fileids	a list or regexp specifying the fileids in the corpus
stepping recursive descent parser	a recursivedescentparser that allows you to step through the parsing process performing a single operation at a time
swedish stemmer	the swedish snowball stemmer
guessed	the chunked sentence to be scored
n_instances	the number of total tweets that have to be used for
stack	collection of _hypothesis objects
data	list of lists of word tag tuples
pattern	variable that is being replaced. the new variable must
fe	the frame element to be printed
conll srlinstance	an srl instance from a conll corpus which identifies and providing labels for the arguments of a single verb
sentences	a list of sentence strings
model3counts	data object to store counts of various parameters during training
forward	a dictionary mapping feature structures ids
sentence	the list of tokens to search from
escape	prepended string that signals lines to be ignored
num_mots	the number of target language words
verbose	if true, report on the updated list of sentences
xmlcorpus view	a corpus view that selects out specified elements from an xml file and provides a flat list-like interface for accessing them
words	words used for the analysis
single edge fundamental rule	a rule that joins a given edge with adjacent edges in the chart to form combined edges
ansi	whether to produce colors with ansi escape sequences
task	attribute for the particular nlp task that the data was drawn from
variable	variable
chunkparser	the chunkparser to be tested
searchpath	list of directories to search
blankline tokenizer	tokenize a string treating any sequence of blank lines as a delimiter
relsym	a label for the relation
alpha	the alpha value use in method 6
kmeans clusterer	the k-means clusterer starts with k arbitrary chosen means then allocates each vector to the cluster with the closest mean
conll corpus reader	a corpus reader for conll-style files these files consist of a
concepts	concepts
pretty lazy iterator list	displays an abbreviated repr of only the first several elements not the whole list
regexp	a regular expression matching the substring
seg2	a segmentation
argument	expression for the argument
other	clause
samples	the samples to plot
function	function<expression t> to call on each subexpression
cycle_indexes	only arcs from cycle nodes are considered. this
element wrapper	a wrapper around elementtree element objects whose main purpose is to provide nicer __repr__ and __str__ methods
cache_baseline_tagger	cache baseline tagger to this file (only interesting as a temporary workaround to get
handle_negation	if handle_negation == true apply mark_negation
backoff	the backoff tagger that should be used for this tagger
other	clause with which to unify
width	the width of the new space widget
prob	probability parameters of the new probabilisticproduction
fn_fname	the name of the frame
tweets_file	the file-like object containing full tweets
tagged_sent	the chunk tag that users want to extract e.g. 'np' or 'vp'
undirected substitution	substitution permutation combinator
y	the left side of the current drawing area
sentence_pair	source and target language sentence pair
dendrogram node	tree node of a dendrogram
dependency evaluator	class for measuring labelled and unlabelled attachment score for dependency parsing
error_output	the file where errors will be saved
hypothesis	hypothesis being expanded
index	the current index
t	the amount of time that the eval demon took
character	the character that needs to be checked
s	string to parse as a standard format marker input file
prover9command	a provercommand specific to the prover9 prover it contains
bins	the number of possible sample outcomes. bins
bigram tagger	a tagger that chooses a token's tag based its word string and on the preceding words' tag
semcor sentence	a list of words augmented by an attribute num used to record the sentence identifier (the n attribute from the xml)
stems	a dictionary where keys are stems and values are sets
skip_retweets	if true remove retweets
string	string to insert into the trie
index	the index of child in self
vowels	the vowels of the respective language that are
nfmap	a map that can be used to compress nf to a dense
prover	interface for trying to prove a goal from assumptions both the goal and
token table field	a field in the token table holding parameters for each token
src_phrase_span	word position span of the source phrase
maxent feature encoding i	a mapping that converts a set of input-feature values to a vector of joint-feature values given a label
functional category	class that represents a function application category
iterations	number of iterations to run training algorithm
trie	a trie implementation for strings
tokens	the text we are parsing. this is only used for
num	the number of words to generate (default=20)
brackets	the bracket characters used to mark the
fn_fid	the framenet id number of the frame
background	formulas which contain background information
new_node	a node dictionary to collapse the cycle nodes into
feature grammar	a feature-based grammar this is equivalent to a
stanford neural dependency parser	>>> from nltk parse stanford import stanfordneuraldependencyparser
learning_curve_take	how many rules plotted
function	the extractor function to add to the list of feature extractors
alignment	the word alignment outputs as list of tuples where
tokens	a list of words or punctuation to be parsed
tab tokenizer	tokenize a string use the tab character as a delimiter the same as s
synset	create a synset from a "<lemma> <pos> <number>" string where
sentiment analyzer	a sentiment analysis tool based on machine learning approaches
abstract chart rule	an abstract base class for chart rules abstractchartrule
ppattachment corpus reader	sentence_id verb noun1 preposition noun2 attachment
randomize	whether the training data should be a random subset of the corpus
transition	this class defines a set of transition which is applied to a configuration to get another configuration note that for different parsing algorithm the transition is different
abstract ccgcategory	interface for categories in combinatory grammars
sent	the list of exemplar sentences to be printed
cond_samples	the samples to initialize the conditional
tree	a tree represents a hierarchical grouping of leaves and subtrees
objclass	the class of the object named entity
dbname	filename of persistent store
sentence	a sentence whose polarity has to be classified
b	another list of independently generated test values
keyword	the word or phrase which is used for that comparative relation
lidstone prob dist	the lidstone estimate for the probability distribution of the experiment used to generate a frequency distribution
event	the event that will trigger the callback
type	optional frame relation type name or object ; show only relations
abstract container widget	an abstract class for canvas widgets that contain a single child such as boxwidget and ovalwidget
log	is the probability already logged
prob	the new probability
logprob	the log of the probability associated with
dictionary prob dist	a probability distribution whose probabilities are directly specified by a given dictionary
switchboard turn	a specialized list object used to encode switchboard utterances
strip	strip trailing whitespace from the last line of each field
all_phrases_from	phrases represented by their spans in
tree pretty printer	pretty-print a tree in text format either as ascii or unicode
fn_fid_or_fname	the framenet name or id number of the frame
select download dir message	indicates what download directory the data server is using
nombank tree pointer	wordnum height*wordnum height*
d	a dictionary in which to store the attributes
sparse	whether to use sparse matrices internally
nextsym	only generate edges e where
path_to_jar	the user-supplied jar location or none
propbank tree pointer	wordnum height*wordnum height*
other	an drtexpression to check equality against
seekable unicode stream reader	a stream reader that automatically encodes the source byte stream into unicode (like codecs
unaryChar	a string joining two non-terminals in a unary production (default = "+")
empty	only return productions with an empty right-hand side
lines	the number of lines to display (default=25)
lhs	the left-hand side of the new production
finish unzip message	data server has finished unzipping a package
attr dict	a class that wraps a dict and allows accessing the keys of the dict as if they were attributes
left_context_tag_pattern	a tag pattern that must match
stack decoder	phrase-based stack decoder for machine translation >>> from nltk
y	the initial y coordinate for the upper left hand
comment_char	the character which can appear at the start of
resolve	when set to true boxer will resolve all anaphoric drss and perform merge-reduction
extractor	a function that given a tuple of cells returns a
maxwidth	maximum number of characters before a label starts to
html	whether to wrap output in html code default plain text
expr_uid	the expression's language variety as a seven-character
brill template i	an interface for generating lists of transformational rules that apply at given sentence positions
logic_parser	the parser to be used to parse the logical expression
make_leaf	a canvaswidget constructor or a function that
fn_luid	the id number of the desired lu
num_entities	the number of entities in the model determines the row length in the table
cfgeditor	a dialog window for creating and editing context free grammars
model_filename	the name of the pre-trained model with .mco file
quadgram collocation finder	a tool for the finding and ranking of quadgram collocations or other association measures
left	the left delimiter printed before the matched substring
read	if true, symbol set pairs are read into a valuation
buffered gzip file	a gzipfile subclass that buffers calls to read() and write()
domain	set of {variable}s
j_pegged	if specified the search will be constrained to
tagger i	a processing interface for assigning a tag to each token in a list
childescorpus reader	corpus reader for the xml version of the childes corpus
reranker_options	optional
unicode_fields	set of marker names whose values are utf-8 encoded
num	the maximum number of collocations to print
trgtext	the target language tokens a list of string
ccgleaf edge	class representing leaf edges in a ccg derivation
dependency graph	a container for the nodes and labelled edges of a dependency structure
depth	the maximal depth of the generated tree
strip_space	if true then strip trailing spaces from word
freqdist	the frequency counts upon which to base the
bin	the full path to the megam binary. if not specified
childChar	a string separating the head node from its children in an artificial node (default = "|")
relation	if true then return tuples of (stem index
shallow	if true the method will modify the original document in place
parent	this canvas widget's hierarchical parent
word_tokenizer	tokenizer for breaking sentences or paragraphs
label	the base part of the preferred label for the concept
lu	the lu to be printed
type	list int
train_toks	the set of training tokens
nr_iter	number of training iterations
crftagger	a module for pos tagging using crfsuite https //pypi python org/pypi/python-crfsuite
parsed	an open formula
discourse	the current list of readings
dtype	data type used when building feature array
merge rule	a rule specifying how to merge chunks in a chunkstring, using two matching tag patterns a left pattern and a right pattern
error message	data server encountered an error
l1	tuple of two coordinate pairs defining the first line segment
application expression	this class is used to represent two related types of logical expressions
kwargs	additional parameters that will be passed as arguments to
ffreq_empirical	an array containing the empirical
file system path pointer	a path pointer that identifies a file which can be accessed directly via a given absolute path
senti text	identify sentiment-relevant string-level properties of input text
s	the conll string to be converted
background	formulas which express background assumptions
default_fields	fields to add to each type of element and subelement
sinica treebank corpus reader	reader for the sinica treebank
productions	the list of productions that defines the grammar
start	the start symbol
mode	a file mode which can be any of 'r', 'rb', 'a', 'ab',
rule	a rule checks the current corpus position for a certain set of conditions if they are all fulfilled the rule is triggered meaning that it
block_size	the default block size for reading. if an
expression	an expression
base prover command	this class holds a prover, a goal and a list of assumptions when
comparative sentences corpus reader	reader for the comparative sentence dataset by jindal and liu 2006
previous	previous hypothesis before expansion to this one
i_pegged	alignment point to j_pegged
text widget	a canvas widget that displays a single string of text
attribs	attributes for the canvas widgets that make up the
sexpr tokenizer	a tokenizer that divides strings into s-expressions
conditional prob dist i	a collection of probability distributions for a single experiment run under different conditions
dg	a dependency graph to score
numsamples	the number of samples to use in each demo
loop	the number of times to run through the patterns
categorized sentences corpus reader	a reader for corpora in which each row represents a single instance mainly a sentence
chart	a blackboard for hypotheses about the syntactic constituents of a sentence
regexp chunk app	a graphical tool for exploring the regular expression based chunk parser nltk
cycle_path	a list of node addresses that belong to the cycle
window	a threshold for the number of items to include in the left and right context
or expression	this class represents disjunctions
expecting	what we expected to see instead
children	the canvas widgets watched by the
romanian stemmer	the romanian snowball stemmer
ignorekeys	the keys to ignore. these keys will not be
id	identifier for the pair
startpos	the file position at which the view will
store_logs	whether to store the probabilities as logarithms
hyp	the hypothetical segmentation
slots	represents positions in a target sentence used to keep track of
rng	random number generator
syntree	a parse tree
column_index	specifies which column to sort using
ferel	the fe relation to be printed
sort_by_count	if true then sort by the count of each
test_sents	the tagged corpus
ic	an information content object (as returned by
morefeatures	if features is a mapping or none
expr	str
filename	filename containing the relations
other	an expression to check equality against
undirected binary combinator	abstract class for representing a binary combinator
text	the string of text to display
worder	the worder list output from word_rank_alignment
level	level of indentation for this element
start	start of range where this feature should apply
nonterm_parser	a function for parsing nonterminals
length	the size of the fixed-length joint-feature
random prob dist	generates a random probability distribution whereby each sample will be between 0 and 1 with equal probability (uniform random distribution
skip_tongue_tweets	if true remove tweets containing ":p" and ":-p"
n_instances	the number of total reviews that have to be used for
dependency_grammar	a word-to-word relation dependencygrammar
context	a string composed of element tags separated by
encoding	name of an encoding to use
k	window width
g	a variable assignment
witten bell prob dist	the witten-bell estimate of a probability distribution this distribution
progress message	indicates how much progress the data server has made
sentences	a list of list of word tag tuples
bindings	bindingdict containing bindings that should be used
margin	the right margin at which to do line-wrapping
initial_tagger	the baseline tagger
pattern	a tgrep search pattern
beta	hyperparameter used as a prior for the brevity penalty
table	a display widget for a table of values based on a multilistbox widget
value	where to index into the list of characters
deep	if true create a deep copy if false create
mleprob dist	the maximum likelihood estimate for the probability distribution of the experiment used to generate a frequency distribution
feature	the feature considered in the comparison relation
unlabeled_sequence	a sequence of unlabeled training instances
sample	sample of the event
fn_luid	the id number of the lexical unit
sent	the sentence to be parsed
srclen	the number of tokens in the source language tokens
length	attribute for the length of the text of the pair
reranker_features	path the reranker model's features file
load_args	keyword parameters used when loading the grammar
reranker_weights	path the reranker model's weights file
binding	expression the expression to which 'variable' should be bound
min_acc	the minimum score for a rule in order for it to be considered
mac morpho corpus reader	a corpus reader for the mac_morpho corpus each line contains a
positions	the positions where the transformation is to
ccgvar	class representing a variable ccg category
reflexive	if set also make the closure reflexive
filename	the name or path of the file
argument_indices	set for the indices of the glue formula from which the argument came
other	the synset to which the shortest path will be found
references	a list of reference translations
start_position	the specified beginning position of the string s
data	the data stream to print
expr	an expression of logic
recursive descent parser	a simple top-down cfg parser that parses texts by recursively expanding the fringe of a tree and matching it against a
word	the word whose region rv is determined
correct	the known-correct ("gold standard") chunked
reldict	a relation dictionary
downloader	a class used to access the nltk data server which can be used to download corpora and other data packages
template	a tbl template that generates a list of l{rule}s that apply at a given sentence position
text	the text component of the pair
strip_space	if true then strip trailing spaces from
graphs	a list of dependency graphs to train from
ccgchart parser	chart parser for ccgs
mwes	a sequence of multi-word expressions to be merged where
name	the name or path of the file
chunk_struct	the chunk structure to be further chunked
word	the currently active word
label	the preferred label for the concept
binary combinator rule	class implementing application of a binary combinator to a chart
grammar_url	a url specifying where the grammar is located
undirected function application	class representing function application
expand left rule	a rule specifying how to expand chunks in a chunkstring to the left using two matching tag patterns a left pattern and a right pattern
prover9command parent	a common base class used by both prover9command and macecommand, which is responsible for maintaining a goal and a set of assumptions
gzip_compress	if true create a compressed gzip file
unwrap	convert newlines in a field to spaces
chunk_tag_pattern	a tag pattern that must match for this
gaaclusterer	the group average agglomerative starts with each of the n vectors as singleton clusters
separator	string that should be inserted between words in a multi-word
name	a regular expression pattern used to match against
remaining_text	the portion of the text that is not yet
constant expression	this class represents variables that do not take the form of a single character followed by zero or more digits
unlabeled_sequence	the sequence of unlabeled symbols
rules	the sequence of rules that should be used to
text	text to split into sentences
phrase table	in-memory store of translations for a given phrase and the log
ngram2	second ngram to compare
porter stemmer	a word stemmer based on the porter stemming algorithm
consequent	expression for the consequent
samples	the complete set of samples
bindings	a set of variable bindings to be used and
up to date message	the package download file is already up-to-date
package	a directory entry for a downloadable package these entries are
statistic	name of statistic
tweet tokenizer	tokenizer for tweets
regexp chunk rule	a rule specifying how to modify the chunking in a chunkstring, using a transformational regular expression
inputs	a list of sentences
train_sents	training data
sizehint	ignored
labeled	indicates whether the given tokens are labeled
start collection message	data server has started working on a collection of packages
l2	tuple of two coordinate pairs defining the second line segment
bernoulli	if true then use the 'bernoulli' format. i.e.,
entity_2	the second entity considered in the comparison relation
reference	an ordered list of reference values
char tokenizer	tokenize a string into individual characters if this functionality
url	url presented to user for download help
s	a valuation string
encoding	name of an encoding to use. if it is specified then
logic_parser	a parser for lambda-expressions
expressions	a collection of expressions
srclen	the number of tokens in the source language
function variable expression	this class represents variables that take the form of a single uppercase character followed by zero or more digits
tagset	dictionary from tags to string descriptions used
logprob	the new log probability
recall	if true, evaluate classifier recall
errors	error handling scheme for codec. same as the encode()
runBrowser	true to start a web browser and point it at the web
categories	a list specifying the categories whose sentences
sent	if true include sentence bracketing
test_stats	dictionary of statistics collected during testing
text	the text that needs to be escaped
proxy	the http proxy server to use. for example
individual variable expression	this class represents variables that take the form of a single lowercase character (other than 'e') followed by zero or more digits
words	set of words used for analysis
errors	error handling scheme for codec. same as the decode()
tab_file	tab file as a file or file-like object
chunk parser i	a processing interface for identifying non-overlapping groups in unrestricted text
make_node	a canvaswidget constructor or a function that
rhs	only return productions with the given first item
options	a list of options that should be passed to the
brill tagger trainer	a trainer for tbl taggers
hypothesis	a hypothesis alignment aka. candidate alignments
chunk score	a utility class for scoring chunk parsers chunkscore can
root	root directory containing thesaurus lisp files
dependency graph error	dependency graph exception
start	the start position
blocking	if false, then return immediately after
cluster i	interface covering basic clustering functionality
valuation	a dictionary which represents a model-theoretic valuation of non-logical constants
discourse_id	str an identifier to be inserted to each occurrence-indexed predicate
tagset	the tagset that should be used in the returned object
recursive descent app	a graphical tool for exploring the recursive descent parser the tool
dependency span	a contiguous span over some part of the input string representing dependency (head -> modifier) relationships amongst words
framefiles	a list or regexp specifying the frameset
feature	an abstract base class for features a feature is a combination of
bottom up predict rule	a rule licensing any edge corresponding to a production whose right-hand side begins with a complete edge's left-hand side
feat struct nonterminal	a feature structure that's also a nonterminal it acts as its
obj	position in the record of the object of the predicate
valuation_str	str with the model builder's output
symbol widget	a canvas widget that displays special symbols such as the negation sign and the exists operator
trace	verbosity level
toks	the list of tokens to which feature_func should be
expression	the item to visit
reference	a reference to a page that may be generated by page_word
filter	the function to filter all local trees
instantiate vars chart	a specialized chart that 'instantiates' variables whose names start with '@', by replacing them with unique new variables
positions	the positions at which this features should apply
filename	str a filename for the output file
regexp stemmer	a stemmer that uses regular expressions to identify morphological affixes
feat list	a list of feature values where each feature value is either a basic value such as a string or an integer or a nested feature
items	the initial contents of the colorized list
emulate_multibleu	bool
slots	vacancy states of the slots in the target sentence
chunkstr	the chunkstring to which this rule is applied
head	a head word
leaf	the new edge's leaf value specifying the word
varex	the relevant free individual variable in parsed
remove_empty_top_bracketing	if the resulting tree has
model4counts	data object to store counts of various parameters during training
index	the index to check
bindings	a list of tuples mapping variable expressions to the
weighted	use the weighted variant of windowdiff
dx	the number of pixels to move this canvas widget
lazy subsequence	a subsequence produced by slicing a lazy sequence this slice
pairs	a pair of list str and tree, as generated by
span	the section of the text for which we are
value_string	the label used to classify a text/hypothesis pair
language specific stemmer	this helper subclass offers the possibility to invoke a specific stemmer directly
abstract variable expression	this class represents a variable to be used as a predicate or entity
mace command	a macecommand specific to the mace model builder it contains
model2counts	data object to store counts of various parameters during training
root_label	the top node of the tree being created
elt	the element that should be converted
sent_tokenizer	tokenizer for breaking paragraphs into sentences
shift reduce parser	a simple bottom-up cfg parser that uses two operations "shift" and "reduce", to find a single parse for a text
gamma	a real number used to parameterize the
check_reentrance	if true then also return false if
end	the end position
rhs	the right-hand side of the new probabilisticproduction
encoding	the encoding that should be used to read the corpus
trace	the level of tracing that should be used when
italian stemmer	the italian snowball stemmer
labels	a list of labels that should be used by the
visited_pairs	a set containing selfid otherid pairs
classifier based postagger	a classifier based part of speech tagger
conll srlinstance list	set of instances for a single sentence
pos	feature which examines the tags of nearby tokens
other	impexpression
strip_off_emoticons	if true strip off emoticons from all tweets
newchild	the canvas widget that should replace
lazy module	lazy module class
factory_args	extra arguments for probdist_factory
read error	exception raised by read_* functions when they fail
vertMarkov	markov order for parent smoothing (0 default = no vertical annotation)
new_node	the node which cycle nodes are collapsed into
tokens	the sentence to be parsed
month	if true return months instead of year-month-date
malt parser	a class for dependency parsing with maltparser the input is the paths to
sem_tag	whether to include semantic tags namely wordnet lemma
parented tree	a tree that automatically maintains parent pointers for single-parented trees
discount	the discount applied when retrieving counts of
isristemmer	isri arabic stemmer based on algorithm arabic stemming without a root dictionary
encoding	the default unicode encoding for the files
graph	a dependency graph to score
dependency_grammar	a grammar of word-to-word relations
directed binary combinator	wrapper for the undirected binary combinator
start	only generate edges e where e.start()==start
href	the hypertext reference to be solved
document	a list of words/tokens or a tuple words label
query	sql query
master	the widget that should contain the new table
s	input line
start package message	data server has started working on a package
training_stats	a dictionary of statistics collected
substitute bindings i	an interface for classes that can perform substitutions for variables
symbol	the name of the symbol to display
transform	an optional function for transforming training
sample	the sample whose probability
from_uid	the source expression's language variety as a
punkt parameters	stores data used to perform sentence boundary detection with punkt
tokens	the source text
cols	the number of columns in the grid
finish download message	data server has finished downloading a package
cumulative	a flag to specify whether the plot is cumulative (default = false)
verbnet corpus reader	an nltk interface to the verbnet verb lexicon
production	the cfg production that licenses the tree
moses detokenizer	this is a python port of the moses detokenizer from https //github
word punct tokenizer	tokenize a text into a sequence of alphabetic and non-alphabetic characters using the regexp \w+|[^\w\s]+
model5counts	data object to store counts of various parameters during training
is_incomplete	only generate edges e where
width	the display width (default=70)
sfm_file	name of the standard format marker input file
child	the child that changed
unification failure error	an exception that is used by _destructively_unify to abort unification when a failure is encountered
signature	dict that maps variable names to types (or string
limit	an integer to set the number of tweets to convert. after the
save_analyzer	if true, store the sentimentanalyzer in a pickle file
training_opt	python-crfsuite training options
grammar	featuregrammar or name of feature-based grammar
e2f	the forward word alignment outputs from source-to-target
simple good turing prob dist	simplegoodturing probdist approximates from frequency to frequency of frequency into a linear line under log space by linear regression
indian corpus reader	list of words one per line blank lines are ignored
lazy zip	a lazy sequence whose elements are tuples each containing the i-th element from each of the argument sequences
args	a list of command-line arguments
tagset	the tagset to be used e.g. universal wsj brown
body	the html body corresponding to the word
feature chart	a chart for feature grammars
trace_chart_width	the default total width reserved for
max_iterations	the maximum number of em iterations
production	the production that has been applied
s	the string we're parsing
categorized corpus reader	a mixin class used to aid in the implementation of corpus readers for categorized corpora
typed maxent feature encoding	a feature encoding that generates vectors containing integer float and binary joint-features of the form
references	a list of reference sentences
para_block_reader	the block reader used to divide the
ycoecorpus reader	corpus reader for the york-toronto-helsinki parsed corpus of old english prose ycoe a 1
e_start	starting index of the possible source language phrases
debug_level	the level of debugging which should be
categories	a list specifying the categories whose sentences have
feature tree edge	a specialized tree edge that allows shared variable bindings between nonterminals on the left-hand side and right-hand side
src_phrase_span	span of word positions covered by the
debug	bool indicating whether debug statements should print
feature value set	a base feature value that is a set of other base feature values
a	a list of test values
signature	dict<str str> that maps variable names to type
kwargs	additional parameters required by the function function
synset_relations	synset keys and relation types for which to display relations
text	text to split into words
order	specifies whether to sort the values in
vowels	the hungarian vowels that are used to determine
word list corpus reader	list of words one per line blank lines are ignored
descr	a short description of the purpose and/or effect
child	the new child widget. child must not already
maxlen	the maximum number of items to display
logic_parser	the parser that will be used to parse logical
reentrances	a dictionary that maps from the id of
fraction	this is a simplified backwards compatible version of fractions fraction
multi listbox	a multi-column listbox where the current selection applies to an entire row
operation	a character identifying the operation that
language_model	target language model. must define a
tn t	tnt - statistical pos tagger important notes
size	the maximum number of bytes to read. if not
tagged_token	the tuple representation of a tagged token
allow_step	if true then the slice object may have a
output	the output file where results have to be reported
synset	the synset for which we're building the relations
conll chunk corpus reader	a conllcorpusreader whose data file contains three columns words pos and chunk
twitter corpus reader	reader for corpora that consist of tweets represented as a list of line-delimited json
tokens	sequence of tokens to be tagged
parallel prover builder	this class stores both a prover and a model builder and when either prove() or build_model() is called then both theorem tools are run in
bigram assoc measures	a collection of bigram association measures each association measure
index_counter	counter for unique indices
model builder command decorator	a base decorator for the modelbuildercommand class from which other prover command decorators can extend
columns	specifies what columns should be included in
span	the span to add
rtefeature extractor	this builds a bag of words for both the text and the hypothesis after throwing away some stopwords then calculates overlap and difference
thread_id	thread id
N	beam search degree see above
edge rule	to create an edge rule make an empty base class that uses edgerule as the first base class and the basic rule as the
regexp	a regular expression
graph	a dependency graph to assign scores to
projective dependency parser	a projective rule-based dependency parser a projectivedependencyparser
i	source word position under consideration
abstract parented tree	an abstract base class for a tree that automatically maintains pointers to parent nodes
ibmmodel4	translation model that reorders output words based on their type and their distance from other related words in the output sentence
avoid_empty_clusters	include current centroid in computation
Trained	indication that the pos tagger is trained or not
feature value type	a helper class for featuregrammars, designed to be different from ordinary strings
n	the maximum number of sentences to return
expr_tt	the expression's text
stepping chart parser	a chartparser that allows you to step through the parsing process adding a single edge at a time
mapping	a dictionary mapping from fname fval label
timit corpus reader	reader for the timit corpus or any other corpus with the same file layout and use of file formats
ccglexicon	class representing a lexicon for ccg grammars
alpha	hyperparameter used as a prior for the unigram precision
stale message	the package download file is out-of-date or corrupt
n	the ngram order
filename	the input csv filename
weights	weights for unigrams bigrams trigrams and so on
baseline_backoff_tagger	the file where rules will be saved
tokens	the list of words that are being tagged
save_loc	if not none, saves a pickled model in this location
ic	an information content object (as returned by load_ic())
probabilistic mix in	a mix-in class to associate probabilities with other classes (trees rules etc
features	the features to build this template on
env_vars	a list of environment variable names to check
framenet error	an exception class for framenet-related errors
fstruct_reader	the parser that will be used to parse the
resource_name	the name of the resource to search for
propbank pointer	a pointer used by propbank to identify one or more constituents in a parse tree
unique names prover	this is a prover decorator that adds unique names assumptions before proving
name_pattern	the name of the jar file
chunker	the chunker being evaluated
default	the child that will be used if the value of
stream backed corpus view	a 'view' of a corpus file which acts like a sequence of tokens it can be accessed by index iterated over etc
trigram tagger	a tagger that chooses a token's tag based its word string and on the preceding two words' tags
word	the russian word whose regions rv and r2 are determined
imp expression	this class represents implications
mtecorpus view	class for lazy viewing the mte corpus
references	a corpus of lists of reference sentences w.r.t. hypotheses
threaded	if true, print out each thread id and the corresponding thread
eleprob dist	the expected likelihood estimate for the probability distribution of the experiment used to generate a frequency distribution
cjkchars	an object that enumerates the code points of the cjk characters as listed on http //en
precision	if true, evaluate classifier precision
beta	the parameter to assign more importance to recall over precision
stanford segmenter	interface to the stanford segmenter >>> from nltk
obj	the obj to be printed
cfdist	the conditionalfreqdist specifying the
quadgram assoc measures	a collection of quadgram association measures each association measure
feat dict	a feature structure that acts like a python dictionary i e a
reviews corpus reader	reader for the customer review data dataset by hu liu 2004
references	a corpus of list of reference sentences w.r.t. hypotheses
bigram collocation finder	a tool for the finding and ranking of bigram collocations or other association measures
stanford dependency parser	>>> dep_parser=stanforddependencyparser(
learning_curve_output	filename of plot of learning curve s train and also test if available
tokens	the tagged sentence
see	if true then call self.see() with the newly
fileid	the file identifier for the file whose path
hidden markov model trainer	algorithms for learning hmm parameters from training data these include
bin	the full path to the java binary. if not specified
unlabeled_sequences	the unsupervised training data a set of
forward type raise rule	class for applying forward type raising
word net lemmatizer	wordnet lemmatizer lemmatize using wordnet's built-in morphy function
treebank word tokenizer	the treebank tokenizer uses regular expressions to tokenize text as in penn treebank
ibmmodel	abstract base class for all ibm models
rows	a list of row values used to initialze the table
top_n	number of best words/tokens to use sorted by frequency
pos_tag	whether to include part-of-speech tags
elem	element to be indented. will be modified
scandinavian stemmer	this subclass encapsulates a method for defining the string region r1
tokens	list of sentences to be tagged
probabilistic projective dependency parser	a probabilistic projective dependency parser
text	the source text
sentence	test just this sentence
window	the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'
queue	the queue of edge objects to sort. each edge in
sentence_aligned_corpus	sentence-aligned parallel corpus
nonterminal	a non-terminal symbol for a context free grammar nonterminal
model_dir	path to the unified model directory
edge	the new edge
N	the total number of outcomes recorded by the heldout
rhs	the new edge's right-hand side specifying the
min_score	the minimum score for a rule in order for it to be considered
toktype	distinguish named entities from ordinary words
stanford tagger	an interface to stanford taggers subclasses must define
nftranspose	the transpose of nfarray
classifier	a classifier instance previously trained
unlabeled_sequences	the training data a set of
authenticate	methods for authenticating with twitter
tagset	the name of the tagset used by this corpus to be used
binary maxent feature encoding	a feature encoding that generates vectors containing a binary joint-features of the form
hyp_len	the length of the hypothesis for a single sentence or the
child	the child canvas widget to remove
token sequence	a token list with its original length and its index
dependencies	list of int for the indices on which this atom is dependent
tag_pattern	the tag pattern to convert to a regular
distance	the distance number of edges from this hypernym to
transition parser	class for transition based parser implement 2 algorithms which are "arc-standard" and "arc-eager"
word net error	an exception class for wordnet-related errors
ipipancorpus reader	corpus reader designed to work with corpus created by ipi pan
equality expression	this class represents equality expressions like "(x = y)"
collection	a directory entry for a collection of downloadable packages
tree	flat representation of toolbox data whole database or single record
display	the information to be reported for each item
configuration	is the current configuration
tweet viewer	handle data by sending it to the terminal
tree	a partial structure for the text that is
review	a review is the main block of a reviewscorpusreader
comp_type	an integer defining the type of comparison expressed
tokens	the document list of tokens that this
drt parser	a lambda calculus expression parser
x	the top of the current drawing area
unattested	an array that is 1 for features that are
filename	a filesystem path
punkt language vars	stores variables mostly regular expressions which may be language-dependent for correct application of the algorithm
min_score	stop training when no rules better than min_score can be found
lc	iso 639 alpha-3 code. if specified filters returned varieties
resource_url	a url specifying where the resource should be
right_context_tag_pattern	a tag pattern that must match
tree segment widget	a canvas widget that displays a single segment of a hierarchical tree
prover	a nltk.inference.api.prover
bottom up left corner chart parser	a chartparser using a bottom-up left-corner parsing strategy
log_prob	log probability that given src_phrase,
chart view	a component for viewing charts this is used by chartparserapp to
comment_char	a character that marks comments. any lines
fileid	the path to the file that is read by this
word	the word used to seed the similarity search
minimum	the minimum number of distinct target forms
lazy iterator list	wraps an iterator loading its elements on demand and making them subscriptable
template_stats	if true will print per-template statistics collected in training and optionally testing
aligned sent	return an aligned sentence object which encapsulates two sentences along with an alignment between them
corpus reader	a base class for "corpus reader" classes each of which can be used to read a specific corpus format
hypothesis	partial solution to a translation
sent_tokenizer	the tokenizer that will be used to split each tweet into
tokens	a single string i.e. sentence text
winlens	window lengths where to look for feature
error	behaviour for encoding errors see https //docs.python.org/3/library/codecs.html#codec-base-classes
children	the widgets that should be aligned
nkjpcorpus morph view	a stream backed corpus view specialized for use with ann_morphosyntax
pretty lazy concatenation	displays an abbreviated repr of only the first several elements not the whole list
to_uid	the target language variety as a seven-character
stack widget	a canvas widget that keeps a list of canvas widgets in a vertical line
tokens	a tagged sentence
uniform prob dist	a probability distribution that assigns equal probability to each sample in a given set and a zero probability to all other
min_len	the minimum order of n-gram this function should extract
stream	the stream to print to. stdout by default
discourse_ids	list of str identifiers to be inserted to each occurrence-indexed predicate
bins	the number of possible event types. this must be at least
mtecorpus reader	reader for corpora following the tei-p5 xml scheme such as multext-east
token	the tokens being tagged
model	a hiddenmarkovmodeltagger instance used to begin
path pointer	an abstract base class for 'path pointers ' used by nltk's data package to identify specific paths
base model builder command	this class holds a modelbuilder, a goal and a list of assumptions when
data	a new semantic value
other	expression
lemma	the lexical entry for a single morphological form of a sense-disambiguated word
fileid	the name of the underlying file
inputfilename	path to the input file
portuguese stemmer	the portuguese snowball stemmer
backward type raise rule	class for applying backward type raising
bindings	bindingdict a dictionary of all current bindings
canvaswidget	the new canvas widget. canvaswidget
size_canvas	bool true if the canvas size should be the exact size of the drs
tgrep exception	tgrep exception type
src_phrase	source language phrase of interest
parse_fileid_xform	a transform that should be applied
inputs	list of str input sentences to parse as individual discourses
grammar	the grammar or a list of regexpchunkparser objects
other_type	type
labeled_featuresets	a list of featureset label
sentence_length	length of source sentence being
logarithmic	if false then use non-logarithmic weights
str	the string to be mapped
xml tool	helper class creating xml file to one without references to nkjp namespace
bindings	a dictionary mapping variables to values
length	only generate edges e where e.length()==length
errors	the error handling strategy for the output writer
outfile	the output csv filename
source_word_classes	lookup table that maps a source word
text collection	a collection of texts which can be loaded with list of texts or with a corpus consisting of one or more texts and which supports
templates	how many sentences of training and testing data to use
regexp parser	a grammar based chunk parser chunk regexpparser uses a set of
trg_phrase	translation of the source phrase in this
depgraphs	list of dependencygraph objects for training input data
conds	list of expression for the conditions
categories	a list specifying the categories whose words have
input	a grammar either in the form of a string or as a list of strings
token searcher	a class that makes it easier to use regular expressions to search over tokenized strings
text	a wrapper around a sequence of simple string tokens which is intended to support initial exploration of texts (via the
mtefile reader	class for loading the content of the multext-east corpus it
samples	the samples that should be given uniform
glueFormulaFactory	glueformula for creating new glue formulas
query	retrieve data from the twitter rest api
word	the target word
parentChar	a sting separating the node label from its parent annotation (default = "^")
sample	the sample whose frequency
transpositions	whether to allow transposition edits
chart	the chart being used to parse the text. this
standard stemmer	this subclass encapsulates two methods for defining the standard versions of the string regions r1 r2 and rv
aligned sent corpus view	a specialized corpus view for aligned sentences
expression	expression the expression with which to replace it
classifier	the current classifier
word	the word that the body corresponds to
europarl corpus reader	reader for europarl corpora that consist of plaintext documents
elem	toolbox data in an elementtree structure
dependency production	a dependency grammar production each production maps a single
unichars corpus reader	this class is used to read lists of characters from the perl unicode properties (see http //perldoc
labeled	if true then toks contains labeled tokens --
chunk_label	the label to use for chunk nodes
vars	the set of variables that should be renamed
constraint	this class represents a constraint of the form (l =< n), where l is a label and n is a node a label or a hole
input	a grammar either in the form of a string or else
newvar	variable, for the new variable
hole semantics	this class holds the broken-down components of a hole semantics i e it
chink rule	a rule specifying how to remove chinks to a chunkstring, using a matching tag pattern
word_tokenizer	a tokenizer for breaking sentences or paragraphs
min_acc	discard any rule with lower accuracy than min_acc
fileids	a list or regexp specifying the fileids in this corpus
del_cost	deletion cost
min_len	minimum length of the ngrams aka. n-gram order/degree of ngram
values	a list of 1's and 0's that represent whether a relation holds in a mace4 model
n_instances	the number of total tweets that have to be classified
entity_1	the first entity considered in the comparison relation
chart rule i	a rule that specifies what new edges are licensed by any given set of existing edges
num_sents	how many sentences of training and testing data to use
ibmmodel5	translation model that keeps track of vacant positions in the target sentence to decide where to place translated words
devset	a list of chunked sentences
dendrogram	represents a dendrogram a tree with a specified branching order this
separator	the string to use to separate tokens
possible	a gold standard reference of possible alignments
port	the port number for the server to listen on defaults to
counter	a counter that auto-increments each time its value is read
bins	included for compatibility with nltk.tag.hmm
match	regexp match of the problem token
label	the label to be appended to each tweet contained in the csv file
trace	trace = 1 or trace = 2 for more verbose tracing
review line	a reviewline represents a sentence of the review together with optional annotations of its features and notes about the reviewed item
j_pegged	if specified the alignment point of j_pegged
encoding	the unicode encoding that should be used to
attempts	the number of times to attempt placing a word
finish package message	data server has finished working on a package
trglen	the number of tokens in the target language tokens
paren widget	a canvas widget that places a pair of parenthases around a child widget
features	the initial value for this feature
hypotheses	a list of hypothesis sentences
bins	the number of possible event types. this must be
collapseRoot	'false' default will not modify the root production
stanford nertagger	a class for named-entity tagging with stanford tagger the input is the paths to
verbose	whether or not to print path when a file is found
tagger	the tagger used to pos tag the raw string before
sequence	the source data to be converted into trigrams
punkt trainer	learns parameters used in punkt sentence boundary detection
concatenated corpus view	a 'view' of a corpus file that joins together one or more streambackedcorpusviews<streambackedcorpusview>
proof_string	str the proof to decorate
width	the number of characters allotted to each
graph	a dependency graph whose set of edges need to be
lemmawords	set or list of words corresponding to certain lemma
prim_only	a boolean that determines whether the variable is restricted to primitives
detect_blocks	the method that is used to find blocks
bracket parse corpus reader	reader for corpora that consist of parenthesis-delineated parse trees like those found in the "combined" section of the penn treebank
encoding	an encoding that is used to convert the
conditions	the conditions to plot default is all
est_bytes	a hint giving an estimate of the number of
threads	a mapping from thread ids to lists of reading ids
heldout prob dist	the heldout estimate for the probability distribution of the experiment used to generate two frequency distributions
categorized bracket parse corpus reader	a reader for parsed corpora whose documents are divided into categories based on their file identifiers
zip file path pointer	a path pointer that identifies a file contained within a zipfile which can be accessed by reading that zipfile
fundamental rule	a rule that joins two adjacent edges to form a single combined edge
oldchild	the child canvas widget to remove
bracket widget	a canvas widget that places a pair of brackets around a child widget
left_tag_pattern	this rule's left tag
review_lines	the list of the reviewlines that belong to the review
synset2	second input synset. must be the same part of
ngram assoc measures	an abstract class defining a collection of generic association measures
feature_name	the name of the feature that this
alignment info	helper data object for training ibm models 3 and up read-only
feat struct	a mapping from feature identifiers to feature values where each feature value is either a basic value (such as a string or an
chart cell	a cell from the parse chart formed when performing the cyk algorithm
e_end	starting index of the possible source language phrases
document	a list of words/tokens
emclusterer	the gaussian em clusterer models the vectors as being produced by a mixture of k gaussian sources
nonprojective dependency parser	a non-projective rule-based dependency parser this parser
training_set	the training set to be passed as argument to the
k	the k value use in method 4
words	the words to be plotted
explicit	if true then use the 'explicit' format. i.e.,
max_rules	output at most max_rules rules
token	class representing a token
child	the canvas widget that should be inserted
word	the current word
item	the item to visit
freqdists	a list of the frequency distributions
dry_run	if true the don't actually set the child's
finnish stemmer	the finnish snowball stemmer
fileids	a list of rte corpus fileids
vnframe	an elementtree containing the xml contents of
text tiling tokenizer	tokenize a document into topical sections using the texttiling algorithm
f_end	starting index of the possible foreign language phrases
kw	keyword arguments for the new canvas. see the
ins_cost	insertion cost
verbose	if true print a message when loading a resource
separate_baseline_data	use a fraction of the training data exclusively for training baseline
bracket_sent	if true include sentence bracketing
weight_senses_equally	if this is true gives all
symbols	a list of individual constants in the semantic representation
base_fdist	the base frequency distribution
skipintersecting	if true do not output intersecting templates non-disjoint positions for some feature
recursive	bool also find discourse referents in subterms?
contingency measures	wraps ngramassocmeasures classes such that the arguments of association measures are contingency table values rather than marginals
tagspec	a tag specification indicating what xml
word_tokenizer	tokenizer for breaking the text of tweets into
train_toks	training data represented as a list of
rtecorpus reader	corpus reader for corpora in rte challenges
subj	position in the record of the subject of the predicate
probability_tables	optional. use this to pass in custom
icfile	the name of the wordnet_ic file (e.g. "ic-brown.dat")
skipped	tuple of two clause objects. the first is a list of all
delete_on_gc	if true then the temporary file will be
span	the span of the production
i	the index of the token whose tag should be corrected
rslpstemmer	a stemmer for portuguese
unigram tagger	unigram tagger the unigramtagger finds the most likely tag for each word in a training
feature_func	the function that extracts features for each token of a sentence. this function should take
sentences	a list or iterator of sentences where each sentence
lazy corpus loader	to see the api documentation for this lazily loaded corpus first run corpus
chart_class	the class used for storing the chart
snowball stemmer	snowball stemmer the following languages are supported
from_tt	the source expression's text
repp tokenizer	a class for word tokenization using the repp parser described in rebecca dridan and stephan oepen 2012 tokenization returning to a
features	the initial list of features for this feature
field_orders	order of fields for each type of element and subelement
danish stemmer	the danish snowball stemmer
target_word_classes	lookup table that maps a target word
spans	a sequence of start end offsets of the tokens
feature value union	a base feature value that represents the union of two or more featurevalueset or variable
closest_ref_len	the length of the closest reference for a single
punkt sentence tokenizer	a sentence tokenizer which uses an unsupervised algorithm to build a model for abbreviation words collocations and words that start
feature	a feature identifier that's specialized to put additional constraints default values etc
text	a unicode string or a byte string encoded in the given
parser	the class used for parsing should be chartparser
leaf_labels	an optional list of strings to use for labeling the leaves
base theorem tool command	this class holds a goal and a list of assumptions to be used in proving or model building
max_len	maximum length of the ngrams set to length of sequence by default
naive bayes dependency scorer	a dependency scorer built around a maxent classifier in this
maxent classifier	a maximum entropy classifier (also known as a "conditional exponential classifier")
chart matrix view	a view of a chart that displays the contents of the corresponding matrix
tag	the name of the tagset to use or none for no tags
scrollbar	if true then create a scrollbar for the
parent	the parent tkinter widget. if no parent is
value	classification label for the pair
cmd	the java command that should be called formatted as
trace	the level of diagnostic tracing output to produce
root	the root directory for this corpus
chunkstr	the chunk string to which each rule should be
accuracy	if true, evaluate classifier accuracy
raw	boolean flag marking the input data
all_instances	a list of instances e.g. documents that will be split
basic tweet handler	minimal implementation of tweethandler
window_size	the number of tokens spanned by a collocation (default=2)
sentence_readings	readings to process
concordance index	an index that can be used to look up the offset locations at which a given word occurs in a document
num_words	the number of source language words
nkjpcorpus segmentation view	a stream backed corpus view specialized for use with ann_segmentation
min_freq	the minimum number of occurrencies of bigrams to take
dependency scorer i	a scorer for calculated the weights on the edges of a weighted dependency graph
logic parser	a lambda calculus expression parser
source_sents_lens	a list of target sentences' lengths
empty predict rule	a rule that inserts all empty productions as passive edges in every position in the chart
corpus	the corpus from which we create an information
remove_duplicates	if true remove tweets appearing more than once
command	the function to apply either _draw_command or _visit_command
test	a list of probability distributions over values to
laplace prob dist	the laplace estimate for the probability distribution of the experiment used to generate a frequency distribution
set holder	a list of sets of variables
closed world prover	this is a prover decorator that completes predicates before proving
hyp	the segmentation to evaluate
db	name of file from which data is read
new_end	the new end index
sentence	a single input sentence to parse
assumptions	a list of expressions
repl	an expression specifying what should replace the
lazy enumerate	a lazy sequence whose elements are tuples each ontaining a count from zero and a value yielded by underlying sequence
fn_docid	the framenet id number of the document
verbose	boolean flag indicating whether training should be
undirected composition	functional composition harmonic combinator
propbank corpus reader	corpus reader for the propbank corpus which augments the penn treebank with information about the predicate argument structure
sequences	lists of token sequences sentences in some applications to be tagged
ignore readme corpus view	this corpusview is used to skip the initial readme block of the corpus
grammar	the grammar used to generate sentences
max_iterations	number of baum-welch interations to perform
tagged corpus view	a specialized corpus view for tagged documents it can be
elt	an elementtree element
drt concatenation	drs of the form ' drs + drs '
length	desired output length
xmlcorpus reader	corpus reader for corpora whose documents are xml files
samples	the samples to initialize the frequency
tokens	a list of featuresets dicts or labelled featuresets
encoding	a feature encoding used to convert featuresets
s	the string to print consisting of words and spaces
x	the input signal
reference	a list of reference values
index	the new edge's index specifying the position of
mwetokenizer	a tokenizer that processes tokenized text and merges multi-word expressions into single tokens
feature_probdist	p(fname=fval|label), the probability
verbose	whether output should be verbose
chunk rule	a rule specifying how to add chunks to a chunkstring, using a matching tag pattern
pad_left	whether the ngrams should be left-padded
convergence_logprob	the maximum change in log probability to
theorem tool command	this class holds a goal and a list of assumptions to be used in proving or model building
rtepair	container for rte text-hypothesis pairs
mtetag converter	class for converting msd tags to universal tags more conversion options are currently not implemented
term	expression, for the term
tokens	the tokens to print
childChar	a string used in construction of the artificial nodes separating the head of the
sent_tokenizer	tokenizer for breaking paragraphs
right	the right delimiter printed after the matched substring
word	the french word whose region rv is determined
tokens	the tagged tokens being tagged
root_label	the node value that should be used for the
inputs	sentences to be parsed
show text	a tkinter window used to display a text showtext is
root	a path pointer identifying the root directory for
tagged corpus reader	reader for simple part-of-speech tagged corpora paragraphs are
instance	a list or iterable of tokens
sentences	input sentences to parse
gzip_compress	if true, output files are compressed with gzip
digraphs	the digraphs that are used to determine the
sample	the sample for which to update the probability
cutoff	if the most likely tag for a context occurs
func	the function that should be called when
word	the word whose region r1 is determined
ids_f	input file object consisting of tweet ids one to a line
twitter	wrapper class with restricted functionality and fewer options
sent	the list of sentences to be printed
s	the string to be tokenized
input	the input string
used_vars	a set of variables whose names should not be
vowels	the french vowels that are used to determine
incremental_stats	if true will tag incrementally and collect stats for each rule rather slow
signature	dict(str -> list abstractvariableexpression
path_to_model	the model file
categorized tagged corpus reader	a reader for part-of-speech tagged corpora whose documents are divided into categories based on their file identifiers
