function	fulltextindex ||| handle fulltextindex elt	count=2
arg	callback that ||| callback	count=1
class	function must be ||| regexp	count=1
class	a dependency ||| probabilistic projective dependency parser	count=1
class	all productions ||| cfg	count=1
function	bigram features reflecting the ||| extract bigram feats	count=1
module_class	[module_1] production ||| [module_1] [class_2]	count=2
class	the ||| shift	count=4
class	dict if its variable ||| binding dict	count=1
class	[class_1] as ||| [class_1] [class_2]	count=3
class	this corpus or ||| categorized corpus	count=1
function	return the hole that ||| hole	count=1
module	count error-rate relative ||| metrics	count=1
arg	of word tag tuples ||| stem relation	count=1
function	[function] of ||| tag [function]	count=3
function	newvar ||| alpha convert	count=2
arg	int limit ||| limit	count=1
class	sentence ||| view	count=1
class	corpus file underlying ||| lazy sequence	count=1
class	[class_1] sentences ||| [class_2] [class_1]	count=1
arg	to implement the ||| unit bracket_sent	count=1
function	adjust [function_2] ||| [function_2] [function_1]	count=1
class	given trigram ||| trigram collocation finder	count=1
class	supported languages as ||| crubadan	count=1
class	number of samples ||| simple good turing prob dist	count=1
module	list of supported ||| corpus reader	count=1
function	info from the fulltextindex ||| fulltextindex	count=1
class	buffered [class_2] ||| [class_2] [class_1]	count=2
class	as ||| crubadan corpus reader	count=1
function	chunks represented in ||| chunks	count=1
class	neural ||| stanford neural	count=1
class	corpus [class_2] ||| [class_1] [class_2]	count=20
function	a subcorpus of ||| lusubcorpus	count=1
arg	node return a ||| node	count=1
class	text contents ||| senseval corpus	count=1
class	remaining text ||| stepping shift reduce	count=1
function	belonging to ||| vectorspace	count=1
function	mapping dictionary ||| mapping	count=1
arg	word tokens ||| tokens	count=1
arg	arrange [arg] into ||| [arg] rows cols	count=1
class	be ||| chart parser	count=1
class	return a ||| crubadan	count=1
module	needs to be how ||| app	count=1
class	the frontier in particular ||| stepping	count=1
module	feature [module] to ||| [module]	count=1
function	of all frames that ||| frames	count=1
module	in this semantic representation ||| sem	count=1
arg	[arg] tree2semi_rel into ||| [arg]	count=2
class	build the internal indexes ||| framenet corpus	count=1
class	childes ||| childescorpus reader	count=2
function	about the ||| info	count=1
class	underlying this ||| lazy sequence	count=1
function	extract the unique counter ||| get unique counter	count=1
function	which returns the type ||| type	count=2
class	the remaining text to ||| stepping	count=1
function	a sequence ||| sequence	count=1
function_arg	[function_1] chart parsers ||| [function_1] [arg_2]	count=2
function	return the hole ||| hole	count=1
function	returns a subtype ||| expression	count=1
arg	a given resource ||| resource_url	count=1
class	known as positive ||| positive	count=1
module	the cached ||| core	count=1
arg	status_code the ||| status_code	count=1
class	corpus or for ||| categorized corpus reader	count=1
module	in particular ||| parse	count=1
class	that is licensed by ||| recursive descent parser	count=1
class	[class] that ||| [class] encoding	count=1
arg	the distance of ||| distance simulate_root	count=1
class	of [class_2] ||| [class_1] [class_2]	count=1
arg	of the word ||| word	count=1
module	use the rest api ||| twitter	count=2
class	encoded as tuples ||| chunked	count=1
function	pretty-printing an ||| pretty	count=1
class	single sentence ||| tn t	count=2
module	be called after this ||| draw	count=1
function	on a given training ||| train	count=2
class	the given element ||| corpus reader	count=1
function	likelihood a ||| likelihood	count=1
class	a russian ||| russian stemmer	count=1
function	factory ||| factory	count=1
arg	trained ||| trained n c	count=1
function	list ||| list	count=3
arg	the [arg] ||| words [arg]	count=1
class	[class_1] this pointer ||| [class_1] [class_2]	count=2
class	[class_1] set ||| [class_1] [class_2] add	count=4
function_arg	[function_1] pretty-printed ||| [arg_2] [function_1]	count=2
class	the cmudict lexicon as ||| cmudict corpus	count=1
function	construct ||| construct	count=2
class	function ||| drt	count=1
function	projective dependency ||| projective	count=1
function	score for a ||| score	count=2
class	pointer ||| propbank tree pointer	count=1
class	associated menu ||| mutable option menu	count=1
function	of citation bib ||| citation	count=1
arg	of child to not ||| child index	count=1
function	construct a value ||| construct	count=2
function	a graph represented as ||| transclose	count=1
class	is ||| i	count=1
arg	the list of items ||| items	count=1
function	[function_1] to parse ||| [function_2] [function_1]	count=3
class	convert ||| query	count=1
class	if ||| drt glue demo	count=1
arg	return ||| other	count=5
arg	target ||| target	count=1
class	of the frontier ||| descent parser	count=1
function	[function_1] alignment ||| [function_2] [function_1]	count=3
class	freqdist to ||| freq	count=1
module	from nltk corpus ||| corpus reader	count=1
arg	the *worder* list i ||| character_based	count=1
function	lists for ||| lists	count=1
class	corpus ||| chunked corpus reader	count=1
arg	and punctuation symbols encoded ||| c5 strip_space stem	count=1
class	of all parses that ||| recursive descent parser	count=2
module	an alignment ||| translate	count=1
function	rv ||| rv	count=1
class	[class_1] that ||| [class_2] [class_1]	count=11
class	:return a corpus ||| nombank corpus reader	count=1
class	log ||| probabilistic mix in	count=1
function	indices ||| indices	count=1
arg	p [arg_2] ||| [arg_1] [arg_2]	count=4
function	in the ||| draw	count=1
function	to be overridden ||| all symbols	count=1
class	the graph ||| dependency graph	count=1
class	hypothesized structure is consistent ||| edge i	count=1
class	gzip [class_2] ||| [class_1] [class_2]	count=1
arg	[arg] and return ||| [arg]	count=1
arg	be trained ||| unk trained	count=1
class	generated when ||| up probabilistic	count=1
function	right [function_2] ||| [function_2] [function_1]	count=1
class	parser state ||| descent parser	count=1
function	true if ||| contains	count=1
function	list ||| from id	count=1
module_class	[module_1] [class_2] ||| [module_1] text [class_2]	count=3
function	of sentences ||| sentences	count=1
module	return true if ||| core	count=7
arg	a simple manner ||| follow to_screen stream	count=1
arg	highest information content ||| ic	count=1
function	[function_1] category ||| [function_1] [function_2]	count=2
class	of the remaining ||| stepping shift reduce	count=1
arg	trained ||| trained n	count=1
arg	constructor should only be ||| parent	count=1
function	of pairs ||| pairs	count=1
module	is consistent with ||| parse	count=1
class	the crfsuite ||| crftagger	count=1
function	synset relations [function_2] ||| [function_1] [function_2]	count=3
class	to invalidate the ||| dist	count=1
function_arg	the given [arg_2] ||| [function_1] [arg_2]	count=5
function	of chomsky ||| chomsky	count=1
class	confusion matrix from a ||| confusion matrix	count=1
function	size ||| size	count=1
arg	a synset note that ||| word synset	count=1
class	similar to a list's ||| pretty lazy iterator list	count=1
function	a local ||| retrieve	count=1
function	[function_1] binding operators ||| [function_2] [function_1]	count=1
function	section for ||| section	count=1
function_arg	[function_1] n-gram f-score ||| [function_1] [arg_2]	count=2
class	the remaining text to ||| parser	count=1
class	first element of the ||| descent parser	count=1
class	conditional frequency distribution in ||| conditional freq dist	count=1
arg	[arg_1] ranks2 ||| [arg_2] [arg_1]	count=1
class	of the remaining text ||| shift reduce	count=1
module	for this canvaswidget the ||| draw	count=1
class	compute ||| net corpus reader	count=1
class	are ||| corpus reader	count=1
function	fulltextindex xml file ||| fulltextindex elt	count=1
class	if the rule ||| rule	count=1
function	cyrillic ||| cyrillic	count=1
function	patterns and extract ||| pro	count=2
arg	for the given variable ||| variable	count=1
arg	given root directory ||| root fileids	count=1
class	a quadgram ||| quadgram	count=1
class	rule given the ||| rule	count=1
arg	[arg_1] if ||| [arg_2] [arg_1]	count=4
class	of this rule ||| chunk rule with	count=1
arg	string for the ||| string	count=1
class	edges ||| chart	count=1
function	the top ||| top	count=1
class	end ||| reduce parser	count=1
class	remaining text to the ||| stepping shift reduce	count=1
function	encoded as a list ||| tagged	count=3
function	update _tag_positions to reflect ||| update tag positions	count=1
function	bleu ||| bleu	count=1
arg	return the proof string ||| format	count=1
module	the internal indexes ||| reader	count=1
function	fraction ||| recall	count=1
arg	word using the ||| word	count=1
arg	trees which [arg_2] ||| [arg_1] [arg_2]	count=3
function_arg	[function_1] the terminal ||| [function_1] [arg_2]	count=4
function	to parse a ||| tagged parse	count=1
function_arg	[function_1] quadgramcollocationfinder ||| [arg_2] [function_1]	count=1
function	the tree ||| tree	count=1
arg	q for ||| q	count=1
class	function ||| drt glue	count=1
class	called if ||| regexp chunk app	count=1
function	fileids that ||| fileids	count=2
arg	of rows ||| rows	count=1
class	stream ||| seekable unicode stream	count=1
function	state ||| tag	count=1
arg	language as ||| lang	count=1
class	cmudict lexicon as ||| cmudict corpus	count=1
class	with eval(), [class] lists all ||| [class]	count=1
arg	tree :return an ||| tree	count=2
function_arg	[function_1] tokens ||| [function_1] to parse [arg_2]	count=4
function	subtype ||| variable	count=1
function	similarity ||| similarity	count=4
class	the sequence with ||| tagger	count=1
class	a bigram collocation finder ||| trigram collocation	count=1
class	this rule it ||| chunk rule with	count=1
module	and whose root node ||| parse	count=1
function	*rule* applies at the ||| rule applies	count=1
function	[function_1] the columns ||| [function_2] [function_1]	count=6
arg	[arg_1] and fstruct2 ||| [arg_1] [arg_2]	count=1
module	the tree should be ||| app	count=1
module	this scroll-watcher's ||| draw	count=1
module_class	by this container ||| draw abstract container	count=1
class	must ||| parser	count=1
class	this function must ||| regexp chunk	count=1
function	_tag_positions to ||| positions	count=1
function	rule to ||| rule	count=2
function	edge in the ||| edge scores	count=1
function	true if a ||| contains	count=1
function	appropriate ||| variable	count=1
class	text to the end ||| shift	count=1
class	as iso ||| corpus reader	count=1
arg	each rule of ||| chunkstr	count=1
module	[module] productions ||| [module]	count=1
function	rule to the word ||| rule	count=1
arg	location is ||| location	count=1
function_arg	[function_1] limit the ||| [function_1] [arg_2]	count=1
arg	to the window_size ||| window_size pad_left	count=1
class	sample outcomes that have ||| freq dist	count=1
function	calculates the average ||| average	count=1
function	pretty-printing a ||| pretty	count=4
class	path identified [class_2] ||| [class_2] [class_1]	count=1
module	the end ||| parse	count=1
arg	iff self and other ||| other check_reentrance visited_self	count=1
class	invalidate the ||| freq dist	count=1
function	relation table into a ||| relation	count=1
class	languages as iso 639-3 ||| reader	count=1
class	the sequence ||| hidden markov	count=1
class	that have been ||| parser	count=1
class	edge if the edge ||| tree edge	count=1
class	punkt word segmentation regular ||| punkt	count=1
arg	that encodes the ||| chunk_struct debug_level	count=1
class	corpus ||| sentences corpus	count=1
function	values ||| values	count=1
class	integers ||| hidden markov model tagger	count=1
function	form i e ||| form	count=1
function	on its relation ||| tgrep relation	count=1
function	from the [function_2] ||| [function_1] [function_2]	count=1
arg	of a valuation ||| valuation lexicon	count=1
arg	version of this ||| prefix depth	count=1
class	[class] corpus each ||| [class] corpus	count=2
class	performs a projective dependency ||| projective dependency parser	count=1
class	of the ||| descent parser	count=1
class	the [class_1] [class_2] ||| core [class_1] [class_2] reader	count=1
class	parser uses ||| parser	count=1
module	languages as ||| corpus	count=1
class	return this ||| edge i	count=1
function	length six patterns ||| pro w64	count=2
function	top of the ||| top	count=1
function	blank ||| default	count=1
class	by this rule given ||| chart rule i	count=1
arg	file specified by save_classifier ||| save_classifier	count=1
class	called ||| app	count=2
function	error message when ||| error	count=1
module	canvas widgets ||| draw	count=1
class	[class_1] probability ||| [class_1] [class_2]	count=4
function_arg	the tag [arg_2] ||| [function_1] [arg_2]	count=4
arg	q for [arg_2] ||| [arg_1] [arg_2]	count=1
function	lambda function representing a ||| tgrep	count=2
class	[class_1] hack=true ||| [class_2] [class_1]	count=6
class	frontier in particular if ||| stepping recursive descent	count=1
function	that instantiates and returns ||| expression	count=1
arg	a defaultdict if strings ||| strings	count=1
class	ensure a proper ||| simple good turing	count=1
class	[class] of ||| [class] corpus	count=3
function_arg	add [arg_2] ||| [arg_2] [function_1]	count=1
function	the [function] to this ||| [function]	count=1
function_arg	of words [arg_2] ||| [arg_2] [function_1]	count=3
function	representing a ||| aug	count=1
function	a block from ||| block	count=1
class	change ||| reduce parser	count=1
arg	from alignment_infos ||| alignment_infos	count=1
arg	no filename ||| filename verbose	count=1
class	of tweets as as ||| twitter corpus reader	count=1
class	probability ||| model	count=1
function	bound node ||| node	count=1
function_arg	skolemize [arg_2] ||| [arg_2] [function_1]	count=3
module	the name of ||| corpus reader	count=1
function	applicable suffix-removal rule ||| rule	count=1
class	element of ||| recursive	count=1
class	that each line in ||| corpus reader	count=1
arg	match the [arg_2] ||| [arg_2] [arg_1]	count=2
module_class	[module_1] for the ||| [module_1] swadesh [class_2]	count=1
arg	the vector ||| vector	count=2
function	string value ||| value	count=1
module	sentence string ||| app	count=1
class	consistent with the ||| edge i	count=1
class	move a token ||| shift reduce parser	count=1
arg	the input string s ||| input encoding	count=1
class	to the end of ||| shift reduce	count=1
function	all [function_2] ||| [function_1] [function_2]	count=2
class	[class_1] this rule ||| [class_2] [class_1]	count=2
class	[class_1] based on ||| [class_1] [class_2]	count=4
class	sentences ||| corpus reader	count=1
function	a projective dependency ||| projective rule parse	count=1
module_class	[module_1] currently ||| [module_1] [class_2]	count=1
arg	a word with their ||| word	count=1
module	[module] that map ||| [module]	count=1
class	the ||| parser	count=7
function_arg	[function_1] posted by ||| [arg_2] [function_1]	count=4
arg	split disjunction ||| first second	count=1
function	rules that would correct ||| rules	count=1
module	much ||| parse	count=1
function	pointer to preserve reentrancy ||| apply forwards to bindings	count=1
class	underlying ||| lazy sequence	count=1
function	chart's leaves ||| leaves	count=1
module	end of the ||| parse	count=1
function	measure ||| measure	count=1
class	unicode encoding [class] file ||| [class]	count=1
class	that ||| probabilistic nonprojective parser	count=2
class	the transition dictionary ||| transition	count=1
class	canvaswidget is ||| canvas widget	count=1
function	use of [function_2] ||| [function_2] [function_1]	count=1
class	a ||| corpus reader	count=1
module	rest api ||| twitter	count=2
class	move a ||| reduce parser	count=1
arg	of documents each of ||| cls documents	count=1
function	conll ||| conll	count=1
arg	given item at ||| item x y	count=1
class	expression for the ||| imp expression	count=1
class	of this tree ||| multi parented tree	count=1
function	syntax ||| syntax	count=1
function_arg	euclidean distance [arg_2] ||| [function_1] [arg_2]	count=5
function	tweets by a given ||| tweets by user	count=1
function	recommended [function] ||| [function] chunk	count=3
function	given ||| from	count=1
function	edge in the dependencygraph ||| edge	count=1
function	function ||| function	count=1
class	list of supported languages ||| crubadan	count=1
function_arg	[function_1] [arg_2] ||| [function_1] resource_url [arg_2]	count=9
module	this is a factory ||| sem	count=1
function	various methods of ||| drt discourse demo	count=1
class	that is licensed ||| parser	count=1
function	[function_1] qtree ||| [function_1] [function_2]	count=3
arg	text and the list ||| text	count=1
class	a probability [class_2] ||| [class_1] [class_2]	count=12
module	enter the ||| sem	count=1
module	if ||| app	count=2
arg	string of bracketted tagged ||| s chunk_label	count=1
function	a variety of information ||| user info	count=1
class	model ||| builder command decorator	count=1
arg	the list of samples ||| samples	count=1
class	frequency distribution in ||| turing prob dist	count=1
class	called ||| chunk app	count=1
arg	words through ||| words	count=1
function_arg	[function_1] [arg_2] stream's file position at ||| [function_1] [arg_2]	count=7
class	tree should be etc ||| chart view	count=1
function_arg	[function_1] of child ||| [arg_2] [function_1]	count=1
function	about ||| user info	count=1
function	the primitive [function_2] ||| [function_2] [function_1]	count=1
arg	return a string representation ||| format	count=3
class	probability state ||| markov model tagger	count=1
class	:return the text contents ||| senseval	count=1
function	s-expressions from the ||| sexpr	count=1
arg	to c{replacement_tag} if all ||| templateid original_tag replacement_tag conditions	count=1
arg	fval1 ||| fval1 fval2	count=1
function_arg	pointer of child ||| delparent child index	count=2
function	userid to ||| lookup by userid demo	count=1
class	the first element ||| stepping recursive	count=1
class	the remaining text ||| stepping shift reduce parser	count=1
function	to register it's json ||| register	count=1
arg	compute the [arg_1] [arg_2] any sequence over a ||| [arg_2] [arg_1]	count=1
function	userid to a ||| by userid demo	count=1
function	named ||| ne	count=2
module	the internal ||| reader	count=1
function	source id ||| source	count=1
arg	given item ||| item x	count=1
arg	used to implement the ||| bracket_sent	count=1
class	:rtype str :return ||| laplace prob dist	count=1
module	up this corpus or ||| corpus	count=1
arg	build ||| synset_relations	count=1
class	return a list ||| corpus reader	count=1
function	returns the score for ||| score ngram	count=2
function	of ||| variable	count=1
module_class	the synset ||| corpus reader synset	count=1
function	representation but if it ||| repr	count=5
arg	s of specified fileids ||| fileids	count=1
class	new maxent [class_2] ||| [class_2] [class_1]	count=1
function	list ||| info from id	count=1
function	of all possible word ||| all	count=2
function	most recent edge ||| current chartrule	count=1
class	featuresets for its classifier ||| classifier	count=1
arg	defaultdict if strings is ||| strings	count=1
function	score for ||| score ngram	count=2
function	prove a theorem ||| prove	count=1
arg	the reference that is ||| references	count=1
arg	override counter __setitem__() to ||| key val	count=1
class	of the feature ||| feat	count=1
class	list of supported languages ||| crubadan corpus	count=1
class	state sequence ||| model tagger	count=1
class	calculates values of ||| assoc measures	count=2
class	verbnet ||| verbnet	count=6
function_arg	beginning of [arg_2] ||| [function_1] [arg_2]	count=1
class	of samples ||| simple good turing prob dist	count=1
class	file underlying this corpus ||| lazy	count=2
function	[function_1] latex ||| [function_1] [function_2]	count=1
function	plug the [function_2] ||| [function_1] [function_2]	count=1
arg	n-gram f-score described ||| min_len max_len	count=1
function	the standard [function_2] ||| [function_2] [function_1]	count=6
module	to ||| app	count=2
module	a collection of ||| sem	count=1
class	translation model and an ||| ibmmodel2	count=1
arg	:param positive_featuresets ||| positive_featuresets	count=1
class	sequence with ||| hidden markov model tagger	count=1
class	this corpus ||| corpus	count=10
function	induce [function_2] ||| [function_1] [function_2]	count=1
function	exemplar sentence and a ||| exemplar of fes	count=1
class	the graph ||| graph	count=1
function_arg	:param labels a ||| init labels	count=2
function	plausible semtypes in order ||| semtypes	count=1
function	unique counter ||| get unique counter	count=2
function	return the static web ||| get static web	count=1
module_class	[module_1] wrapper ||| [module_1] element [class_2]	count=2
class	[class_1] widget ||| [class_1] [class_2]	count=9
class	[class_1] parsing a ||| [class_2] [class_1]	count=4
function	[function_1] similarity ||| [function_1] [function_2]	count=4
class	a probabilisticdependencygrammar based ||| dependency parser	count=1
class	find ||| canvas frame	count=1
arg	data package the following ||| format cache verbose	count=1
function	a single [function] character followed ||| [function]	count=2
function	redirects arcs to ||| arcs	count=1
function_arg	apply each rule ||| apply chunkstr	count=1
class	which indicates how much ||| edge	count=1
function	a userid to a ||| userid demo	count=1
class	if ||| parser app	count=1
arg	text this sets the ||| tokens	count=1
class	given a [class_2] ||| [class_2] [class_1]	count=2
class	the end of ||| shift reduce	count=1
function	is ||| parse	count=1
function_arg	given [arg_2] ||| [arg_2] [function_1]	count=5
arg	s as ||| fileids tagset	count=2
function	alignment [function] rate ||| alignment [function]	count=1
arg	the actual [arg_2] ||| [arg_2] [arg_1]	count=2
function	produce a plot showing ||| dispersion plot	count=1
arg	probabilistic parsers the ||| choice draw_parses print_parses	count=1
class	synset to the ||| synset	count=2
function_arg	[function_1] labels ||| [arg_2] [function_1]	count=2
module	in alphabetical ||| corpus reader	count=1
function	an exemplar sentence ||| exemplar of fes	count=2
arg	its id luname ||| fn_luid ignorekeys luname	count=1
arg	replace [arg_1] [arg_2] across every atom ||| inference clause replace [arg_1] [arg_2]	count=1
function	upper frame page if ||| static upper page	count=1
class	a token from the ||| stepping	count=1
function	normalize ||| normalize boundaries	count=2
class	to ||| stepping shift reduce	count=1
function	which [function] not ||| [function] most	count=1
function	two sentences c{source_sents[i]}, ||| align	count=1
function	static [function_2] ||| [function_2] [function_1]	count=5
function	[function] human-readable ||| error [function]	count=3
module	a factory method that ||| sem	count=1
arg	on 10000 ||| trainer n_instances output	count=1
arg	reading ids in ||| threads	count=1
function	root counting the ||| hypernym distances	count=1
arg	set of tagged data ||| data	count=1
function_arg	trace output [arg_2] ||| [function_1] [arg_2]	count=1
arg	the matched substrings ||| string	count=1
function	sentences each encoded as ||| tagged sents	count=2
class	move a ||| shift	count=1
function	log probability ||| logprob	count=1
module	tag for the ||| tag	count=1
function	of ||| id	count=2
arg	documents ||| documents	count=2
class	the neural [class_2] ||| [class_2] [class_1]	count=5
module	this scroll-watcher's canvas to ||| draw	count=1
function	strategy used ||| strategy	count=1
function	probabilities uniformly ||| uniform probabilities	count=1
class	enter the ||| parser	count=1
class	over sets ||| i	count=1
class	probability state sequence this ||| hidden markov	count=1
function	save ||| save	count=2
arg	p and q for ||| p q	count=1
function	the scrollregion ||| scrollregion	count=1
module	of the frontier ||| parse	count=1
function	step 5a from "an ||| step5b	count=1
class	perform a single parsing ||| parser	count=1
function	node into the ||| node	count=1
module	function ||| app	count=2
module	the name ||| corpus	count=1
module	move a token from ||| parse	count=1
arg	node return ||| node	count=1
arg	the actual ||| intact_word	count=1
module	be how big the ||| app	count=1
function	is ||| calculate	count=1
module	internal indexes to ||| reader	count=1
function_arg	[function_1] under the ||| [arg_2] [function_1]	count=5
function	each element ||| tokenize sents	count=1
function	two [function_2] ||| [function_2] [function_1]	count=1
class	corpus ||| string category corpus reader	count=1
arg	the given scoring function ||| score_fn w1 w2 w3	count=1
class	text to the ||| reduce	count=1
arg	that encodes ||| chunk_struct debug_level	count=1
function	prove ||| prove	count=2
class	must be ||| chart	count=1
function	productions ||| productions	count=5
class	big ||| view	count=2
function	this is ||| variable expression	count=1
function_arg	[function_1] of remaining_text ||| [arg_2] [function_1]	count=3
class	the corpus ||| reviews corpus reader	count=2
function	helper ||| annotation ascii fe	count=1
function_arg	[function_1] [arg_2] of the variable ||| sem variable [function_1] [arg_2]	count=1
arg	[arg_1] version ||| [arg_2] [arg_1]	count=3
arg	tuple (val end_position) ||| s start_position	count=1
class	and scores [class] ngram ||| [class]	count=1
function	the ||| expression	count=1
class	the dict with ||| dict	count=1
class	to prevent unnecessary ||| resolution	count=1
arg	and ||| line	count=1
class	listbox ||| listbox	count=4
arg	between vectors u and ||| u	count=1
function	relations data ||| relations data	count=2
class	token's ||| punkt token	count=1
class	a substitution corresponding to ||| ccgvar	count=1
function	to convert ||| to	count=1
arg	and ||| line primitives families var	count=1
class	in ||| stepping recursive descent	count=1
class	underlying [class_2] ||| [class_2] [class_1]	count=3
class	token ||| reduce parser	count=1
arg	a list of ||| category fileids	count=1
class	:see ||| individual variable	count=2
class	this function must be ||| glue demo	count=1
class	this function must be ||| regexp	count=1
class	figure out ||| chart view	count=1
function	[function_1] lists for ||| [function_2] [function_1]	count=5
arg	the matched substrings ||| string left	count=1
class	corpus ||| reviews corpus	count=1
class	canvas [class_2] ||| [class_1] [class_2] tags	count=2
function	values return the f-measure ||| f measure	count=1
function	inverts a directed ||| invert	count=1
class	training ||| transition parser	count=1
class	languages ||| crubadan corpus reader	count=1
arg	hunpos-tag ||| path_to_bin encoding	count=1
function	the sentences in that ||| sentences from	count=1
class	rule it has ||| chunk rule	count=1
class	logic [class_2] ||| [class_2] [class_1]	count=2
class	words in alphabetical ||| lexicon	count=1
function	a [function] ||| handle [function]	count=1
arg	package the following ||| format cache verbose	count=1
class	[class_1] distribution ||| [class_1] [class_2]	count=13
module	unit needs to ||| app	count=1
class	return all ||| comparative sentences	count=1
arg	the probabilistic parsers the ||| choice draw_parses print_parses	count=1
function_arg	[function_1] symbol ||| [function_1] state [arg_2]	count=1
function	binary concept out of ||| binary concept	count=1
class	set ||| set	count=2
class	supported languages ||| corpus reader	count=1
function	[function_1] measure ||| [function_2] [function_1]	count=1
arg	add ||| add	count=3
function	tagger to tag ||| tag	count=1
arg	distance of each node ||| distance	count=1
arg	file if no filename ||| filename verbose	count=1
function	object ||| init	count=1
class	bigrams in the given ||| bigram	count=1
arg	given directory ||| root encoding	count=1
class	frequency distribution in ||| freq dist	count=2
arg	words by stems defined ||| words cutlength	count=1
class	to figure ||| chart view	count=1
arg	and punctuation symbols encoded ||| speaker stem	count=1
module_class	to this [class_2] ||| [module_1] [class_2]	count=8
module	structure ||| parse	count=1
function	maps the tag ||| map tag	count=1
class	boxer ||| boxer	count=2
module	up this corpus or ||| corpus reader	count=1
class	of words [class_2] ||| [class_1] [class_2]	count=3
function	freqdist ||| freq	count=2
function	returns the likelihood of ||| likelihood	count=1
arg	can all ||| fail_on_unknown	count=1
arg	matches tagspec, ||| tagspec elt_handler	count=1
function	will be downloaded ||| get download dir	count=1
function_arg	[function_1] a word ||| [arg_2] [function_1]	count=2
function	file and update the ||| file	count=1
arg	with [arg] ||| [arg]	count=2
arg	if strings is provided ||| strings	count=1
module	supported languages as ||| corpus reader	count=1
function	error message when ||| parse error	count=1
arg	for etree ||| etree	count=1
class	function must be called ||| chart	count=1
arg	the regular expression ||| regexp	count=2
module	the various ||| inference	count=2
arg	[arg_1] finalize is ||| [arg_1] [arg_2]	count=5
arg	optional frame object name ||| frame frame2 type	count=1
arg	given fileids ||| fileids	count=2
class	the frontier in ||| recursive descent	count=1
module_class	this [class_2] ||| [module_1] lazy iterator [class_2]	count=1
class	:rtype str :return a ||| laplace prob	count=1
function	string containing ||| format	count=1
arg	the expression ||| expression command x	count=1
arg	augmented tokens ||| tokens	count=1
arg	of the words through ||| words	count=1
class	dependency graph based ||| probabilistic projective dependency	count=1
class	in particular if ||| recursive descent parser	count=1
function	probability of the given ||| probability	count=1
function	set the [function_2] ||| [function_1] [function_2]	count=1
arg	rule data tables to ||| rule	count=1
class	frontier in ||| stepping recursive	count=1
arg	used to implement ||| fileid unit bracket_sent	count=1
arg	trained ||| unk trained n c	count=1
function	root ||| root	count=1
function	[function_1] an integer ||| [function_2] [function_1]	count=1
function	targets and frame names ||| frames	count=1
function	tweets tokenized using tweettokenizer ||| demo tweets	count=1
class	encoded as ||| tagged corpus	count=2
arg	segmentations [arg_2] ||| metrics pk [arg_2] [arg_1]	count=1
module_class	this table's ||| draw table	count=3
arg	a given sample ||| sample	count=1
class	reads the pickle ||| pickle	count=1
arg	of all nonterminals for ||| cat	count=1
class	in particular ||| stepping recursive descent parser	count=1
arg	a list of tokens ||| tokens	count=2
arg	list of lists ||| fileids tagset	count=1
class	this tree occurs as ||| multi parented tree	count=1
function	if [function_2] ||| [function_2] [function_1]	count=4
class	a probabilisticdependencygrammar based ||| probabilistic projective dependency parser	count=1
arg	luname frameid ||| ignorekeys luname frameid	count=1
arg	produce the *worder* ||| reference hypothesis character_based	count=1
arg	:param expression the expression ||| expression	count=1
function_arg	string containing [arg_2] ||| [arg_2] [function_1]	count=4
class	sequence with ||| hidden markov model	count=1
class	joint-feature vectors [class_2] ||| [class_2] [class_1]	count=1
module_class	[module_1] widget ||| [module_1] [class_2]	count=3
arg	correction ||| labels mapping unseen_features alwayson_features	count=1
class	version on the childes ||| childescorpus	count=1
arg	of the probabilistic parsers ||| choice draw_parses print_parses	count=1
class	construct ||| bigram collocation finder	count=1
class	which indicates how much ||| i	count=1
class	to the end ||| shift reduce parser	count=1
class	of information about ||| query	count=1
function	[function_1] lists ||| [function_1] [function_2]	count=5
function	windowdiff score ||| windowdiff	count=1
arg	text and the ||| text	count=1
function	encoded as ||| tagged	count=3
function	instantiates ||| expression	count=1
class	map from contexts to ||| context	count=1
class	contains ||| porter stemmer	count=1
function_arg	tokenize a [arg_2] ||| [function_1] [arg_2]	count=2
class	the first element ||| stepping	count=1
class	token from the ||| stepping shift	count=1
arg	are associated with edge ||| edge	count=1
module	descent ||| parse	count=1
class	the first element of ||| stepping recursive	count=1
function	tagged [function] ||| ne chunk [function]	count=1
function	the cache is a ||| cache	count=1
function	of two ||| align	count=2
class	generated when ||| probabilistic	count=1
class	include the bounding boxes ||| scroll watcher widget	count=1
function	construct a value for ||| construct	count=2
arg	from ||| start	count=1
function	[function_1] help page ||| [function_2] [function_1]	count=4
arg	an alignment ||| alignment_info	count=2
arg	domain of a valuation ||| valuation	count=1
arg	and returns a tuple ||| line primitives families var	count=1
class	a list ||| crubadan corpus reader	count=1
function_arg	[function_1] event ||| [function_1] [arg_2]	count=3
class	to the ||| shift reduce	count=1
class	be generated when ||| bottom up probabilistic	count=1
function	identifier of ||| predid	count=1
arg	level chrf character [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=4
class	file or ||| gzip file	count=1
function_arg	to indent an ||| indent elem level	count=1
function	compatible with [function_2] ||| [function_1] [function_2]	count=3
class	called if ||| chart	count=1
class	function ||| regexp chunk	count=1
class	underlying ||| lazy	count=5
class	[class_1] verbnet class ||| [class_2] [class_1]	count=2
function	initialize this object's probability ||| init	count=1
function_arg	rule [arg_2] ||| [arg_2] [function_1]	count=1
function	that are after ||| after	count=1
class	must be ||| drt glue demo	count=1
function	of ||| expression	count=1
class	must be ||| regexp chunk	count=1
class	stemmer ||| lancaster stemmer	count=1
class	true ||| feat	count=1
function_arg	move the [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	belonging [arg_2] ||| [function_1] vector [arg_2]	count=1
arg	[arg_1] frameid and ||| [arg_1] [arg_2]	count=4
class	collocation ||| trigram collocation	count=1
class	639-3 ||| crubadan	count=2
class	view for that ||| view	count=1
function_arg	[function_1] of strings ||| [arg_2] [function_1]	count=3
class	edge ||| edge i	count=2
function	to parse a sentence ||| parse	count=1
class	0 75 ||| kneser ney prob dist	count=1
class	be ||| parser app	count=1
function	the fulltextindex xml file ||| fulltextindex elt	count=1
function	by ||| by user	count=1
class	as iso 639-3 ||| corpus	count=1
function	convert a ||| info	count=1
function	wu-palmer [function_2] ||| [function_2] [function_1]	count=1
function	of target sentence and ||| t a	count=2
class	enter the ||| regexp chunk app	count=1
arg	its forward pointer to ||| forward fs_class visited	count=1
arg	q for feature ||| q	count=1
function	[function_1] arc ||| [function_2] [function_1]	count=5
class	the end of the ||| reduce parser	count=1
function	the java binary ||| config java	count=1
class	frontier ||| descent parser	count=1
arg	the multi-word ||| mwes separator	count=1
function	to realign punctuation that ||| realign	count=1
class	module ||| lazy module	count=1
function_arg	the fringe [arg_2] ||| [arg_2] [function_1]	count=2
function	a variety ||| user info from id	count=1
arg	of the utterance identifiers ||| sex spkrid sent_type	count=1
class	new maxent ||| maxent	count=1
function	labels ||| labels	count=1
arg	given [arg] parser's ||| [arg]	count=1
arg	information content value ||| synset1 synset2 ic	count=1
class	the first ||| recursive descent	count=1
class	files ||| reviews corpus reader	count=1
arg	lists frame element objects ||| frame	count=1
module	read ||| corpus reader	count=1
function	stream ||| token stream	count=1
function	pointer lists ||| pointer lists	count=2
arg	documents located at the ||| fileids sep word_tokenizer	count=2
class	lidstone estimate to ||| lidstone	count=1
class	the end ||| reduce parser	count=1
module	of the [module] on a ||| [module]	count=1
class	for a given trigram ||| trigram	count=1
function	by [function] ||| [function]	count=3
function	variety of ||| info from id	count=1
class	frequency distribution in ||| prob dist	count=1
arg	single instance applying ||| instance	count=1
function	read ||| read	count=6
arg	of 'self' ||| other	count=1
function	from the fulltextindex ||| handle fulltextindex	count=1
function_arg	tokenize [arg_2] ||| [arg_2] [function_1]	count=2
arg	the given tree ||| tree	count=1
function	to a uniform ||| set uniform	count=1
function	latex ||| latex	count=1
function	variables used ||| find variables	count=2
function	length to the hypothesis ||| ref length	count=1
module	first element of ||| parse	count=1
class	encoded as a list ||| tagged corpus reader	count=2
module	the hypothesized structure is ||| parse	count=1
class	iterator of all parses ||| descent	count=2
class	move a token ||| stepping shift	count=1
function_arg	index [arg_2] ||| [arg_2] [function_1]	count=2
module_class	tweets [class_2] ||| [module_1] [class_2]	count=3
function	this ||| tag	count=1
class	position' [class] given that ||| [class]	count=2
function	a number ||| number	count=1
function	the height of a ||| height	count=1
function	the static web ||| get static web	count=2
function	return all positive words ||| positive	count=1
arg	punktparameters object ||| lang_vars token_cls	count=1
function	into conll format ||| conll	count=1
arg	helper used to implement ||| unit bracket_sent	count=1
module	639-3 ||| corpus	count=1
module	languages ||| corpus	count=1
class	corpus or in ||| corpus	count=2
function	probability [function_2] ||| [function_2] [function_1]	count=16
class	in the same sentence ||| punkt sentence tokenizer	count=1
class	maxent ||| maxent	count=1
class	expression for ||| application expression	count=1
arg	of function results for ||| function	count=1
function_arg	[function_1] between tagsets ||| [arg_2] [function_1]	count=3
class	all leaves [class] have not ||| [class]	count=1
class	[class_1] reader with ||| [class_1] [class_2]	count=2
class	positive examples (i ||| positive naive bayes classifier	count=1
arg	index ||| index depth	count=1
function	friendly error message ||| error	count=1
class	which ||| edge i	count=1
class	which indicates how ||| edge i	count=1
class	the [class] ||| [class]	count=3
function	suffix-removal rule to ||| rule	count=1
arg	nonterminals for ||| cat	count=1
class	in this object ||| substitute bindings i	count=1
function	log probability of ||| output logprob	count=1
function	string containing a ||| pretty format	count=1
class	the ||| descent	count=2
class	a single parsing ||| descent parser	count=1
module	and returns a ||| sem	count=1
arg	the node ||| node	count=1
function	the left sibling ||| left sibling	count=1
function	abstractvariableexpression ||| variable expression	count=1
function	krippendorff's interval distance ||| interval distance	count=2
function	restore selection & ||| restore	count=1
function	returns an iterator over ||| select	count=1
arg	baseline ||| initial_tagger templates trace	count=1
module	and an alignment model ||| translate	count=1
module	path exists return ||| core	count=1
class	to prevent unnecessary ||| resolution prover command	count=1
function	demonstration showing the ||| parse demo	count=1
arg	binary ||| binary args verbose	count=1
class	state ||| hidden markov model tagger	count=2
arg	synset and relation type ||| synset relation	count=1
class	end of the stack ||| reduce	count=1
function	resource cache ||| cache	count=1
class	specifying ||| mtecorpus	count=1
class	file where grammar can ||| cfg	count=1
class	the parser uses to ||| parser	count=1
arg	[arg_1] feature f ||| [arg_2] [arg_1]	count=3
module	how much ||| parse	count=1
function	whether the word ||| head word	count=1
class	a token ||| parser	count=1
class	parser state ||| parser	count=1
class	must be ||| regexp	count=1
function	probability of all ||| prob all	count=6
module_class	return an iterator ||| core abstract	count=1
class	token in a sentence ||| sentence tokenizer	count=1
module	values as its ||| metrics	count=1
function	[function_1] page if ||| [function_2] [function_1]	count=3
class	that ||| shift reduce parser	count=1
class	a ||| probabilistic projective dependency parser	count=1
class	string to figure out ||| chart view	count=1
arg	source-to-target and [arg_2] ||| [arg_2] [arg_1]	count=1
arg	load load ||| load	count=1
arg	of rows and ||| rows	count=1
class	move a token ||| shift	count=1
function	and returns ||| variable	count=1
function	a factory ||| variable expression	count=1
function	[function] of ||| cluster [function]	count=2
module	enter the ||| app	count=2
class	[class_1] uses to ||| [class_2] [class_1]	count=8
module	tweets are ||| twitter	count=1
class	this corpus ||| chunked corpus	count=1
arg	under the ||| node_index	count=1
class	of ||| corpus reader	count=2
module	of the recursive descent ||| parse	count=1
function_arg	[function_1] p ||| [function_1] [arg_2]	count=3
class	tagged ||| childescorpus reader	count=1
function	parse on the ||| parse	count=1
class	element of the frontier ||| stepping recursive	count=1
class	a token from ||| stepping shift reduce	count=1
arg	callback ||| callback	count=1
class	[class_1] parsers that ||| [class_1] [class_2]	count=3
arg	synset and [arg_2] ||| [arg_1] [arg_2]	count=2
function	two [function_2] ||| [function_1] [function_2]	count=1
class	the sequence with ||| markov	count=1
class	the feature with the ||| feat dict	count=1
arg	:param positive_featuresets a ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
function	pointer for the data ||| data	count=1
function	counter from [function_2] ||| [function_1] [function_2]	count=1
function	conjunction of ||| conjunction	count=1
module	factory ||| sem	count=1
class	string ||| chart view	count=1
function	two texts ||| align texts	count=2
module	and using ||| core	count=1
function	hide_column() ||| hide column	count=1
class	known as positive examples ||| positive naive bayes classifier	count=1
class	the corpus ||| corpus	count=9
class	state sequence ||| hidden markov	count=1
function	helper for ||| annotation ascii fe	count=1
function	python [function_2] ||| [function_1] [function_2] unicode compatible klass	count=1
function	word type ||| type	count=1
function	the string value ||| value	count=1
function	top ||| top	count=1
class	candidate periods as sentence ||| punkt sentence	count=1
function	add [function_2] ||| [function_2] [function_1]	count=5
function	model ||| model var	count=2
arg	word [arg_2] ||| [arg_2] [arg_1]	count=1
function	tweets by a given ||| tweets by user demo	count=1
class	of the corpus ||| comparative sentences corpus reader	count=1
arg	word ||| stem	count=2
arg	words [arg_2] ||| [arg_2] [arg_1]	count=8
function_arg	nodes in [arg_2] ||| [function_1] pattern [arg_2]	count=1
arg	[arg_1] list of ||| [arg_2] [arg_1]	count=1
class	the chart rule ||| stepping chart	count=1
arg	expression in ||| expression	count=1
class	parsing a text ||| chart parser	count=1
function	by a given ||| by user demo	count=1
arg	items the items ||| items	count=1
arg	synset note that ||| word synset	count=1
class	stream ||| unicode stream reader	count=1
function	have equal ||| equal	count=1
arg	*worder* ||| character_based	count=1
function_arg	[function_1] the vector ||| [function_1] vectorspace [arg_2]	count=3
class	classifier ||| maxent classifier	count=1
arg	words by ||| words cutlength	count=2
class	:param ||| prover command	count=2
function	evaluate and print ||| evaluate	count=1
function_arg	[function_1] load load ||| [function_1] [arg_2]	count=1
class	frequency distribution in two ||| simple good turing prob dist	count=1
arg	python port of the ||| return_str	count=1
function	step 3 from ||| step3	count=1
class	by this classifier ||| bayes classifier	count=1
arg	target [arg_2] ||| [arg_2] [arg_1]	count=1
class	underlying [class_2] ||| core [class_1] [class_2]	count=1
module	tag position ||| tag	count=1
arg	[arg_1] the item ||| [arg_2] [arg_1]	count=2
arg	of word ||| c5 strip_space stem	count=1
function	euclidean distance ||| euclidean distance	count=2
function	search for past ||| search demo	count=1
class	in alphabetical ||| opinion lexicon	count=1
function	with its [function] ||| annotation ascii [function]	count=3
function_arg	[function_1] model_found() ||| [arg_2] [function_1]	count=1
class	zip file ||| zip file	count=1
function	a friendly error ||| error	count=1
function	a new ||| add	count=1
function_arg	[function_1] of documents ||| [function_1] [arg_2]	count=1
class	this corpus or ||| corpus reader	count=2
function	[function_1] abbreviation if ||| [function_2] [function_1]	count=2
class	be ||| chart parser app	count=1
class	this ||| nombank instance	count=1
class	the fixed-length [class] that ||| [class] encoding	count=1
class	count error-rate relative ||| paice	count=1
class	colorized [class_2] ||| [class_1] [class_2]	count=1
function	rule to the ||| apply rule	count=1
function	stemming ||| stemming	count=1
class	must be ||| parser	count=1
arg	the list ||| fileids sent tag strip_space	count=1
class	tokenized sentences ||| perceptron	count=1
arg	the given start ||| start	count=2
class	as iso 639-3 ||| crubadan	count=1
class	of [class_2] ||| [class_2] [class_1]	count=1
function	sentences ||| sents	count=5
function	the users ||| info from	count=1
function	corpus of classified ||| write	count=2
function	[function_1] chart to ||| [function_2] [function_1]	count=1
class	this confusion [class_2] ||| [class_2] [class_1]	count=1
module	category ||| ccg	count=2
function	past tweets by ||| tweets by user	count=1
function	chomsky [function_2] ||| [function_2] [function_1]	count=3
function	[function] falls ||| [function]	count=2
function	[function_1] [function_2] ||| core [function_1] [function_2]	count=1
class	[class_1] expression to ||| [class_2] [class_1]	count=5
module	that instantiates ||| sem	count=1
class	:see ||| function variable	count=1
arg	if its variable ||| variable	count=1
arg	vector to unit length ||| vector	count=1
function	a [function] values ||| [function]	count=1
function	expressions as ||| expressions	count=1
function_arg	tree positions [arg_2] ||| [arg_2] [function_1]	count=6
function_arg	[function_1] with_shutdown is ||| [function_1] [arg_2]	count=4
class	a single [class_2] ||| [class_2] [class_1]	count=1
class	the first element ||| parser	count=1
class	parent ||| parented tree	count=2
class	cached ||| freq dist	count=2
class	corpus or ||| categorized corpus	count=1
module	this corpus view ||| corpus	count=4
class	the minimal set ||| minimal set add	count=1
arg	and other ||| other check_reentrance	count=1
arg	title the title of ||| title review_lines	count=1
arg	vectors to clusters learning ||| vectors	count=1
class	of supported ||| reader	count=1
arg	data [arg_2] ||| [arg_2] [arg_1]	count=2
function	a ||| info from id	count=2
class	swedish ||| swedish	count=1
class	return lemmas of ||| word net	count=1
module	languages as iso ||| corpus	count=1
function	the type ||| get type	count=2
function	containing [function] of ||| [function]	count=2
arg	stream is a ||| stream	count=1
class	feature of ||| feature chart	count=1
class	[class_1] parser and ||| [class_1] [class_2]	count=5
class	returns words in specified ||| nkjpcorpus reader	count=1
class	candidate ngrams which ||| abstract collocation finder	count=1
class	the ||| reduce parser	count=4
function	exists to be overridden ||| all symbols	count=1
class	encoded as a ||| tagged corpus reader	count=2
function	label ||| label	count=2
arg	ranks1 and [arg_2] ||| [arg_2] [arg_1]	count=4
arg	list of ||| category fileids	count=1
function	the unique counter ||| unique counter	count=1
function	a userid to a ||| by userid	count=1
class	the ||| chart parser app	count=1
arg	of the words ||| words	count=1
function_arg	the given featureset ||| classify featureset	count=1
arg	add ||| sequence func add	count=1
class	a pickle corpus and ||| pickle corpus	count=1
class	[class_1] sentences ||| [class_1] [class_2]	count=1
arg	[arg_1] grammar ||| [arg_2] [arg_1]	count=2
class	of the frontier in ||| parser	count=1
class	of predicates from ||| closed world prover	count=1
class	when parsing a text ||| bottom up probabilistic chart parser	count=1
module	this constructor should only ||| draw	count=1
arg	tagger must be trained ||| unk trained	count=1
function	variety ||| user info	count=1
module	which indicates ||| parse	count=1
arg	frame element objects ||| frame	count=1
module	by this ||| draw	count=7
class	inside probabilities of the ||| inside chart	count=1
class	the cached ||| dist	count=1
function	a freqdist containing only ||| freq	count=1
class	[class_1] corpus and ||| [class_1] [class_2]	count=2
arg	frame object name or ||| frame	count=1
function	immediately ||| immediately	count=2
module	box for this ||| draw	count=1
class	the ||| stepping shift reduce	count=4
function_arg	local file [arg_2] ||| [function_1] resource_url [arg_2]	count=1
arg	consideration given the ||| rule train_sents test_sents	count=1
function	in a valuation ||| valuation	count=1
function	first pass ||| annotate first pass	count=2
class	a unicode string ||| unicode	count=1
module	of supported ||| reader	count=1
arg	initialize the multi-word ||| mwes separator	count=1
class	text to the ||| shift reduce	count=1
class	conditional frequency distribution ||| conditional freq dist	count=4
class	all parses ||| descent	count=2
function	of the indices ||| parent indices	count=1
class	much ||| edge	count=1
class	text as a list ||| text	count=1
function	the best incoming ||| best incoming	count=2
class	languages as ||| corpus reader	count=1
function_arg	[function_1] [arg_2] ||| [function_1] rule word [arg_2]	count=1
arg	[arg] executable and ||| path_to_model [arg]	count=2
arg	search for a ||| searchpath	count=1
module	encoded ||| corpus reader	count=1
function	points to ||| entry	count=1
class	particular if ||| stepping recursive descent	count=1
arg	:param [arg] value to ||| [arg]	count=1
function	[function_1] of target ||| [function_1] t [function_2]	count=2
module	words in alphabetical ||| corpus	count=1
class	neural dependency ||| neural dependency	count=1
arg	a segmentation [arg_2] ||| metrics pk [arg_2] [arg_1]	count=1
arg	its id luname frameid ||| luname frameid	count=1
class	the remaining ||| shift reduce parser	count=1
class	of ||| stepping recursive descent parser	count=1
class	should be etc ||| chart view	count=1
class	text returns a list ||| punkt sentence tokenizer	count=1
arg	lines at exactly ||| lines wrap_at	count=1
function	top-lebel node in ||| exprs	count=1
arg	produce the *worder* ||| character_based	count=1
function	from a subcorpus of ||| handle lusentence	count=1
class	text to the end ||| shift reduce	count=1
function_arg	each successive [arg_2] ||| [function_1] s [arg_2]	count=1
arg	pk metric for a [arg_1] [arg_2] ||| [arg_2] [arg_1]	count=4
class	be how big ||| chart view	count=1
arg	to implement ||| fileid bracket_sent tag strip_space	count=1
function	tweets by a given ||| tweets by	count=1
arg	of word ||| fileids speaker stem	count=1
module	make up this corpus ||| corpus reader	count=1
class	first element of ||| stepping recursive	count=1
function_arg	[function_1] no filename ||| [function_1] resource_url [arg_2]	count=2
function	[function_1] columns ||| [function_2] [function_1]	count=4
function	all existing indexes ||| indexes	count=2
function	is ||| variable expression	count=1
class	return the unicode encoding [class_1] [class_2] known ||| [class_2] [class_1]	count=2
class	file or buffer ||| file	count=1
arg	node ||| node	count=1
function	sentence to be translated ||| translate	count=1
function	self _readings to construct ||| construct threads	count=1
function	best incoming [function_2] ||| [function_2] [function_1]	count=4
arg	the cluster ||| cluster	count=1
class	[class] corpus ||| [class] corpus	count=2
function	[function_1] sets ||| tag describe [function_1] [function_2]	count=1
class	file identifiers ||| ycoecorpus	count=1
arg	[arg_1] and fstruct2 ||| [arg_2] [arg_1]	count=1
function	indices where this ||| indices	count=1
function	generates ||| from	count=1
arg	a baseline ||| initial_tagger templates trace	count=1
function	[function_1] for tadm ||| [function_2] [function_1]	count=8
arg	[arg] values ||| [arg] test	count=3
function	update _tag_positions ||| update tag positions	count=1
class	order ||| lexicon corpus reader	count=1
class	state sequence ||| hidden markov model	count=1
class	a unit needs to ||| chart	count=1
function	:return the tree ||| production to tree	count=1
arg	parent ||| parent	count=1
class	frequency distribution in ||| simple good turing prob dist	count=1
class	of this tree ||| tree	count=1
class	for this corpus ||| categorized corpus	count=1
function	[function_1] distance similarity ||| [function_2] [function_1]	count=1
function	sequence with the ||| tag	count=1
arg	consequent of 'self' ||| other	count=1
function	register ||| add child	count=1
class	the cached ||| freq dist	count=1
class	the ||| model	count=2
function_arg	first-order logic expression ||| fol expression	count=1
arg	successive match of *regexp* ||| regexp	count=1
arg	in a line ||| line	count=1
class	token ||| parser	count=1
class	this decision [class_2] ||| [class_2] [class_1]	count=1
class	for this corpus ||| chunked corpus reader	count=1
module	its value otherwise return ||| core	count=1
module_class	[module_1] canvasframe the ||| [module_1] canvas [class_2]	count=1
arg	probabilistic parsers ||| choice draw_parses print_parses	count=1
class	each context to ||| context index	count=1
arg	[arg_1] tuples ||| [arg_2] [arg_1]	count=3
class	plaintext corpus ||| plaintext corpus	count=1
function	citation bib ||| citation	count=1
class	a bigram collocation ||| collocation finder	count=1
class	a finnish ||| finnish stemmer	count=1
arg	to implement ||| bracket_sent tag strip_space	count=1
class	list of supported languages ||| corpus	count=1
arg	a list of characters ||| category fileids	count=1
function	rule (see also str ||| demo str	count=1
function	return [function] ||| [function]	count=1
class	return new feature encoding ||| binary maxent feature encoding	count=1
arg	of 'variable' with 'expression' ||| expression replace_bound alpha_convert	count=1
function_arg	and other ||| values other	count=1
class	list of supported ||| crubadan corpus	count=1
class	object ||| substitute bindings	count=1
arg	all_phrases_from that ||| all_phrases_from hypothesis	count=1
class	counts ||| freq dist	count=3
class	move ||| stepping shift	count=1
arg	documents each of ||| cls documents	count=1
class	uses ||| tn t	count=1
function	been recorded by this ||| n	count=1
class	chunkstring ||| chunk string	count=1
function	convert a list ||| from id	count=1
arg	to arrange [arg] into a ||| [arg] rows cols	count=1
arg	optional frame object name ||| frame frame2	count=1
arg	id luname ||| luname	count=1
module	return an iterable of ||| core	count=1
function	tabulate the ||| tabulate	count=1
function	fileids that make ||| fileids	count=1
module	in alphabetical order ||| corpus reader	count=1
function	child [function_2] ||| [function_1] [function_2]	count=5
class	the end of the ||| parser	count=1
function_arg	[function_1] metric ||| metrics masi [function_1] [arg_2]	count=1
module	how big ||| app	count=2
arg	pos tagged sentence into ||| sentence	count=1
function	an [function] node ||| [function]	count=1
function	first expression ||| first	count=1
arg	bncwordviews or the list ||| fileids sent tag	count=1
module	it is ||| chunk	count=1
class	particular if ||| stepping	count=1
module	information about the users ||| twitter	count=1
function	of all words ||| words	count=1
function	combine ||| combine	count=1
class	the ||| model tagger	count=4
function	the cosine of the ||| cosine	count=1
class	a ngramassocmeasures ||| contingency measures	count=1
module	conjunctive normal ||| sem	count=1
function	guess ||| guess	count=1
arg	word tokens construct and ||| tokens	count=1
function	node with the given ||| by	count=1
class	called ||| glue	count=1
function	each successive match of ||| tokenize	count=1
function_arg	[function_1] classifier performance ||| [arg_2] [function_1]	count=1
module_class	[module_1] frequency distribution ||| [module_1] [class_2]	count=2
function	score for ||| score	count=3
arg	the sentence ||| sentence	count=1
arg	speaker dialect ||| dialect	count=1
class	word ||| punkt language vars	count=1
class	list ||| list	count=8
arg	the multi-word tokenizer ||| mwes separator	count=1
class	context to ||| context index	count=1
function	iso 639-3 code ||| iso	count=1
arg	the given variable ||| variable	count=1
class	text contents of the ||| senseval	count=1
arg	containing a pretty-printed version ||| width prefix depth	count=1
class	if ||| chart parser	count=1
class	move a token from ||| reduce	count=1
function	to write ||| write	count=1
module_class	[module_1] bounding ||| [module_1] [class_2]	count=4
class	words in alphabetical ||| opinion lexicon corpus	count=1
arg	empty ||| cond_samples	count=1
arg	words ||| words	count=4
function	to convert a single ||| to	count=1
function	depth of each ||| depth	count=1
function	have frequency [function_2] ||| [function_1] [function_2]	count=1
class	intended to be overridden ||| drt	count=1
class	collocation ||| trigram collocation finder	count=1
module	and return ||| core	count=5
module	in ||| corpus	count=1
class	the underlying stream ||| seekable unicode stream	count=1
function	log [function_2] ||| [function_2] [function_1]	count=1
class	the pl196x ||| pl196x	count=1
arg	feature structure ||| fstruct fs_class	count=1
function	dictionary ||| make	count=1
function	training ||| finalize training	count=1
class	called if ||| parser app	count=1
class	[class_1] structure is ||| [class_1] [class_2]	count=1
module_class	[module_1] [class_2] ||| [module_1] zip file [class_2]	count=4
function	to find a space ||| find	count=1
class	list of all verb ||| verbnet corpus reader	count=1
class	the end ||| parser	count=1
function	make ||| make	count=1
arg	v with expression ||| expression	count=3
module	big the ||| app	count=1
class	the ||| markov model tagger	count=4
class	tweets as as ||| twitter corpus reader	count=1
class	invalidate the ||| freq	count=1
class	a swedish ||| swedish	count=1
class	must be ||| regexp chunk app	count=1
class	[class_1] within zipfile ||| [class_2] [class_1]	count=8
class	a ||| stepping	count=1
function	from a frame ||| frame	count=1
class	the inside probabilities of ||| inside	count=1
class	if ||| recursive descent	count=1
function	repr ||| repr	count=1
class	dependency graph based on ||| probabilistic projective dependency	count=1
function	value of a given ||| value	count=1
class	the ||| framenet corpus reader	count=1
module	and ||| sem	count=1
class	be how ||| chart view	count=1
class	tagged corpus ||| tagged corpus	count=1
arg	constant describing the ||| info_or_id download_dir	count=1
arg	a list of word ||| c5 strip_space stem	count=1
arg	split the [arg] in ||| [arg]	count=1
function	[function_1] words ||| [function_2] [function_1]	count=6
class	return new feature ||| feature	count=2
class	iso ||| crubadan	count=1
class	sentence boundary ||| punkt sentence tokenizer	count=2
class	the remaining text ||| shift reduce	count=1
module_class	for [module_1] [class_2] ||| [module_1] [class_2]	count=2
function	instantiates and ||| variable	count=1
function	return the fraction ||| recall	count=1
class	element of the ||| recursive descent	count=1
module	the [module] ||| [module]	count=9
arg	[arg_1] and relation ||| [arg_2] [arg_1]	count=3
class	probability of a dependency ||| projective dependency parser	count=1
function	[function_1] arc ||| [function_1] [function_2]	count=5
function	a module to find ||| find	count=1
arg	[arg_1] label tuples ||| [arg_2] [arg_1]	count=8
arg	a sequence of data ||| data start end	count=1
class	to the end ||| stepping shift reduce	count=1
module	appears in the ||| inference	count=1
arg	word of length five ||| word	count=1
arg	should be used to ||| tokens index	count=1
function	a previously bound node ||| node	count=1
function	[function_1] to chunk ||| [function_2] [function_1]	count=2
class	dictionary containing the probdists ||| dictionary conditional prob	count=1
function_arg	[function_1] an alignment ||| [function_1] a given s [arg_2]	count=2
function	mode ||| mode	count=1
function	replacing each feature structure ||| retract	count=1
function	rid of all tags ||| tags	count=1
module	this canvaswidget the ||| draw	count=1
function	chart to a pickle ||| chart	count=1
arg	featureset [arg_2] ||| [arg_1] [arg_2]	count=4
class	words ||| opinion	count=1
class	structure is consistent ||| edge	count=1
class	as a ||| tagged corpus	count=1
function	the input string ||| input	count=1
function	of plausible semtypes ||| semtypes	count=1
function	depending on its relation ||| tgrep relation	count=1
class	of ||| recursive	count=1
function	[function_1] file for ||| [function_1] [function_2]	count=3
function	the probability ||| probability	count=1
arg	invalidate the cached n ||| key	count=1
arg	fileids ||| fileids	count=9
class	underlying ||| seekable unicode	count=3
class	line in ||| twitter corpus reader	count=1
arg	by repeatedly taking ||| train_sents test_sents min_score min_acc	count=1
class	this function must ||| glue	count=1
function	[function_1] nodes ||| [function_2] [function_1]	count=1
class	text ||| shift	count=1
class	enter the ||| glue	count=1
arg	tagged sentence ||| sentence	count=1
class	parsing a text ||| reduce parser	count=1
function_arg	phonetic segments p ||| diff p	count=1
function_arg	the average [arg_2] ||| [arg_2] [function_1]	count=3
class	a proper [class_2] ||| [class_1] [class_2]	count=2
class	an xml element in ||| reader	count=1
arg	given [arg] ||| [arg]	count=6
function	userid to ||| by userid	count=1
module	n ||| core	count=1
function_arg	result of model_found() ||| result found	count=2
function	of the longest ||| max	count=1
class	which indicates how much ||| edge i	count=1
class	inside probabilities of the ||| inside	count=1
function	[function_1] counter ||| [function_2] [function_1]	count=3
class	identifiers ||| ycoecorpus reader	count=2
function	epytext @field to ||| epytext	count=1
class	given trigram using ||| trigram collocation finder	count=1
function	to each ||| to	count=1
module	this set ||| core	count=1
class	[class_1] sentence ||| [class_1] [class_2]	count=2
function	normal form i e ||| normal form	count=1
function	child pointer lists for ||| child pointer lists	count=1
function_arg	first-order logic [arg_2] ||| [function_1] [arg_2]	count=1
function	position [function] by ||| char seek [function]	count=1
class	in the expression to ||| expression	count=2
class	over sets ||| classifier i	count=1
class	space widget ||| space widget	count=2
class	buffered ||| buffered	count=1
function	users ||| user info from	count=1
class	given trigram using ||| trigram	count=1
function_arg	:param refs list ||| init refs conds	count=1
arg	return a list ||| fileids	count=1
class	corpus ||| sentences corpus reader	count=3
module	out how ||| app	count=1
arg	label pair return ||| label	count=1
function	abbreviation ||| reclassify abbrev	count=1
function	fringe ||| fringe	count=1
class	returns ||| punkt sentence tokenizer	count=2
function_arg	checksum for [arg_2] ||| [function_1] [arg_2]	count=1
class	feature encoding based on ||| binary maxent feature encoding	count=1
arg	:return a list of ||| fileids tagset	count=1
arg	[arg_1] finalize ||| [arg_1] [arg_2]	count=5
function	lists of word/tag/iob tuples ||| iob sents	count=1
arg	stack ||| stack	count=2
arg	the *worder* ||| hypothesis character_based	count=1
class	supported languages as iso ||| corpus	count=1
class	method serves as a ||| drt	count=1
module_class	this [class_2] ||| [module_1] [class_2]	count=156
arg	modelbuilder ||| modelbuilder	count=1
function	an error ||| error	count=1
class	fixed-length [class] that are ||| [class] encoding	count=1
function	contingency table from marginal ||| contingency	count=1
function	file ||| file	count=7
function_arg	[function_1] boundaries ||| [arg_2] [function_1]	count=1
function	of unigram ||| unigram	count=1
arg	the rest ||| keywords	count=1
class	make up this corpus ||| timit corpus reader	count=1
module	return ||| corpus reader	count=4
function_arg	phonetic segments [arg_2] ||| [function_1] [arg_2]	count=6
class	of the frontier ||| stepping recursive	count=1
arg	from a [arg_2] ||| [arg_1] [arg_2]	count=1
function	to resize ||| resize	count=1
arg	of rows and ||| rows cols attempts	count=1
class	the end ||| stepping shift	count=1
function	table's _rows variable match ||| table	count=1
class	must be called ||| chart parser app	count=1
function	stemming ||| do stemming	count=1
class	frontier in ||| recursive descent parser	count=1
arg	of tagged data ||| data	count=1
class	the sentence ||| view	count=1
class	collocation ||| abstract collocation	count=1
function	train the tagger ||| train	count=1
arg	a set of reference ||| reference	count=1
function	induce a ||| induce	count=1
arg	the window_size ||| window_size	count=1
arg	a collection of documents ||| cls documents	count=1
function	subcorpus of an lu ||| lusentence	count=1
class	variable [class_2] ||| [class_1] [class_2]	count=5
class	same sentence ||| punkt sentence	count=1
class	corpus ||| corpus	count=28
arg	matches tagspec, and return ||| tagspec elt_handler	count=1
class	because the neural ||| stanford neural	count=1
class	given bigram using the ||| bigram	count=1
arg	[arg_1] [arg_2] output ||| [arg_1] [arg_2]	count=4
function	in ||| from	count=1
function_arg	experiment _create_rand_fdist [arg_2] ||| [arg_2] [function_1]	count=2
function	sents ||| parse sents	count=1
module_class	this tree as ||| core tree	count=1
arg	q for [arg_2] ||| [arg_2] [arg_1]	count=1
class	is a tuple made ||| reviews	count=1
class	reader using ||| reader	count=1
function	a set of pairs ||| pairs	count=1
function	[function_1] from the ||| [function_2] [function_1]	count=4
class	file identifiers ||| ycoecorpus reader	count=1
function	this is ||| variable	count=1
function	length six patterns and ||| pro w64	count=1
class	contents of the corpus ||| framenet corpus reader	count=1
function	[function_1] [function_2] ||| [function_1] model2 [function_2]	count=2
arg	of word tag tuples ||| speaker stem relation	count=1
function	[function_1] measure ||| [function_1] [function_2]	count=1
class	:param ||| model builder command	count=1
class	aligned corpus reader for ||| aligned corpus reader	count=1
function	rule (see also str ||| str	count=1
function	check to ||| check grammar	count=1
class	over ||| multi classifier i	count=1
arg	given ||| node	count=1
arg	the *worder* list ||| reference hypothesis character_based	count=1
class	words for ||| swadesh corpus	count=1
class	if ||| drt glue	count=1
class	fileids in this corpus ||| corpus	count=1
module	text ||| parse	count=1
arg	sentence as ||| sentence	count=1
module	this instance's predicate ||| corpus	count=1
class	the file [class_2] ||| [class_2] [class_1]	count=4
class	return ||| crubadan	count=1
class	rule given ||| rule	count=1
arg	the distance ||| distance simulate_root	count=1
arg	in ||| tr nr n	count=1
function	a meaning ||| get meaning	count=1
module	variety ||| twitter	count=1
function_arg	synset [arg_2] ||| [arg_2] [function_1]	count=2
function	the jaccard index ||| jaccard	count=1
class	rule it has the ||| chunk rule with	count=1
class	in alphabetical ||| opinion	count=1
class	of ||| instance	count=1
function	state sequence this ||| tag	count=1
arg	binary with ||| binary args verbose	count=1
class	as a list ||| tagged	count=1
module	and an alignment ||| translate	count=1
class	the ||| hidden markov model	count=2
function	[function] lexical translation ||| [function]	count=1
class	this function must ||| chunk app	count=1
class	first element ||| recursive descent parser	count=1
module_class	[module_1] as as ||| [module_1] [class_2]	count=1
function	of information about ||| from	count=1
arg	and punctuation symbols ||| strip_space stem	count=2
arg	status_code the status code ||| status_code data	count=1
arg	appearances ||| word_fd	count=1
arg	the given file s ||| fileids tagset	count=2
module	for ||| reader	count=1
function	license file ||| license	count=1
function_arg	belonging to [arg_2] ||| [arg_2] [function_1]	count=1
function	list of fileids ||| fileids	count=1
module	return a list ||| reader	count=1
class	if the feature with ||| feat dict	count=1
class	build the internal ||| framenet	count=1
class	remove ||| dependency evaluator	count=1
arg	grammar ||| grammar root_label	count=1
function_arg	[function_1] words ||| [arg_2] [function_1]	count=2
class	which indicates how ||| edge	count=1
class	affixes from the ||| stemmer i	count=1
arg	from a ||| srctext trgtext alignment max_phrase_length	count=1
class	a list ||| corpus reader	count=1
class	new classifier [class_2] ||| [class_2] [class_1]	count=3
arg	a featureset ||| featureset	count=1
arg	all ||| callback	count=3
class	in alphabetical order ||| opinion lexicon corpus reader	count=1
class	in the text ||| text	count=1
function	cosine of the ||| cosine	count=1
module	returns ||| corpus reader	count=3
arg	modelbuildercommand modelbuildercommand ||| modelbuildercommand	count=1
class	be etc ||| chart	count=1
function	a variety of ||| user info from id	count=1
module	this canvaswidget has ||| draw	count=2
class	function must ||| drt	count=1
function_arg	[function_1] tree ||| [function_1] [arg_2]	count=2
arg	remaining_text ||| remaining_text	count=1
module	box for this canvaswidget ||| draw	count=1
class	a corpus view that ||| nombank corpus	count=1
class	chart rule used to ||| stepping chart parser	count=1
function	its relation ||| tgrep relation	count=1
function	corresponding start stop bounds ||| bounds	count=1
function	recorded by this ||| n	count=1
function	a list of productions ||| productions	count=1
module_class	[module_1] for editing ||| [module_1] [class_2]	count=6
class	build the internal ||| corpus reader	count=1
function	[function_1] web help ||| [function_1] [function_2]	count=3
arg	in the reference ||| reference	count=1
function	a list of ||| id	count=1
function	speech tagger to tag ||| pos tag	count=1
function_arg	local [arg_2] ||| [function_1] resource_url [arg_2]	count=1
function	single [function] ||| [function]	count=1
function	realign punctuation that ||| realign	count=1
function	belonging ||| vectorspace	count=1
class	file or buffer ||| buffered gzip file	count=1
arg	text [arg_2] ||| [arg_1] [arg_2]	count=5
function	the url ||| url	count=2
arg	the reference ||| references hyp_len	count=1
class	is ||| edge	count=1
class	the internal indexes to ||| corpus	count=1
function_arg	approximate score [arg_2] ||| [arg_2] [function_1]	count=2
class	sentences in [class_2] ||| [class_2] [class_1]	count=1
function	log ||| log	count=2
class	a dependency graph based ||| dependency parser	count=1
class	[class_1] dependency ||| [class_1] [class_2]	count=7
function_arg	stem a [arg_2] ||| [arg_2] [function_1]	count=3
arg	given ||| node ancestors	count=1
module	to be how ||| app	count=1
class	of samples with frequency ||| freq dist	count=1
function	list of ||| from	count=1
class	of words for ||| swadesh corpus	count=1
arg	a string of bracketted ||| s chunk_label root_label	count=1
class	token from ||| reduce parser	count=1
class	variable binder [class_2] ||| [class_1] [class_2]	count=2
arg	labels a list ||| labels	count=2
module	consistent ||| parse	count=1
class	[class_1] examples (i ||| [class_2] [class_1]	count=4
arg	the fileids of ||| fileids	count=1
class	which ||| punkt	count=1
arg	*worder* list ||| character_based	count=1
function	the status of ||| status	count=1
function	of bigram features reflecting ||| extract bigram feats	count=1
function	leaves of ||| leaves	count=1
module_class	this widget [class_2] ||| [module_1] [class_2]	count=2
function	the ||| drt discourse	count=1
arg	replace every instance [arg_1] [arg_2] across every atom ||| inference clause replace [arg_1] [arg_2]	count=1
class	[class_1] probability ||| [class_2] [class_1]	count=4
class	which 'variable' is bound ||| binding dict	count=1
function_arg	[function_1] [arg_2] of the variable ||| [function_1] [arg_2]	count=1
arg	be ||| text	count=1
class	needs to be how ||| view	count=1
class	of the ||| stepping shift	count=2
function	the log probability ||| output logprob	count=1
arg	[arg_1] [arg_2] ||| [arg_1] [arg_2]	count=480
function	subcorpus of ||| lusentence	count=1
class	conditional frequency [class_2] ||| [class_1] [class_2]	count=2
arg	return ||| other ic	count=1
arg	from ||| srctext	count=1
class	element of the frontier ||| recursive descent parser	count=1
function	[function_1] similarity ||| [function_2] [function_1]	count=4
arg	creates the sentence ||| source_blocks target_blocks params	count=1
module	this set is ||| core	count=1
function	block comparison method ||| block comparison	count=1
function	already been [function] this is ||| ensure [function]	count=1
function	frames ||| frames	count=1
class	words in ||| lexicon corpus	count=1
function	the indices ||| parent indices	count=1
module	defines the [module] macro ||| [module]	count=1
arg	multiple ||| top_relation_label	count=1
function	new ||| add	count=1
class	contents of the corpus ||| corpus reader	count=4
class	[class_1] for the ||| [class_2] [class_1]	count=1
module_class	[module_1] widget ||| [module_1] text [class_2]	count=3
function	the depth of each ||| depth	count=1
function	3 ||| step3	count=1
function_arg	[function_1] no filename ||| [arg_2] [function_1]	count=2
arg	training text ||| verbose	count=1
function	first ||| first	count=2
arg	symbol ||| symbol	count=3
class	predicate ||| instance	count=2
arg	produce the *worder* list ||| character_based	count=1
class	if the feature ||| feat dict	count=1
class	[class] structure ||| [class]	count=3
class	all ||| opinion lexicon corpus	count=1
class	of this rule ||| rule	count=1
class	to ||| paice	count=1
class	probabilistic ||| probabilistic	count=1
function	pop the first expression ||| pop first	count=1
function	sentence_aligned_corpus and [function] lexical translation ||| [function]	count=1
class	wordnet [class_2] ||| [class_1] [class_2]	count=5
function	a new ||| new	count=1
function	words or a ||| words	count=1
function	construct a new ||| new	count=1
class	[class_1] distribution ||| core [class_1] [class_2]	count=3
module	how big a ||| app	count=1
arg	returns a list ||| category fileids	count=1
arg	'expression' ||| expression replace_bound alpha_convert	count=1
function	[function_1] used by ||| [function_2] [function_1]	count=8
class	trigram ||| trigram	count=1
module	>>> from nltk corpus ||| corpus reader	count=1
module	from ||| parse	count=1
module	of a ||| sem	count=1
class	as positive [class_2] ||| [class_2] [class_1]	count=2
class	as ||| reader	count=1
class	tagger to ||| tagger	count=1
function	parse a sentence takes ||| tagged parse	count=1
arg	[arg_1] [arg_2] ||| [arg_2] trees [arg_1]	count=9
arg	and ||| cls	count=1
function	a binding [function_2] ||| [function_1] [function_2]	count=5
arg	database table ||| dbname verbose	count=1
function	[function_1] [function_2] ||| [function_1] [function_2]	count=1228
function	the conjunction of ||| conjunction	count=1
function	5a from "an ||| step5b	count=1
function	under [function] ||| [function] unicode	count=1
arg	for a given widget ||| widget	count=1
function	initialize the ||| init	count=1
module	for the ||| sem	count=1
class	for this sentence boundary ||| punkt sentence	count=1
function_arg	checksum for [arg_2] ||| [arg_2] [function_1]	count=1
class	in this [class_1] [class_2] ||| [class_1] [class_2]	count=1
class	as a list of ||| tagged corpus	count=1
class	when parsing a ||| shift reduce parser	count=1
function	probability ||| prob alignment	count=1
arg	ranks2 for keys ||| ranks2	count=1
class	*estimate[r]* is the probability ||| heldout prob	count=1
class	feature encoding ||| binary maxent feature encoding	count=1
function	first character is lowercase ||| first lower	count=1
class	a [class_1] [class_2] ||| [class_1] [class_2]	count=6
module	tag ||| tag	count=4
class	how big the tree ||| view	count=1
arg	helper used to implement ||| fileid bracket_sent tag strip_space	count=1
class	state sequence this ||| model	count=1
class	the text contents of ||| senseval	count=1
function	information ||| user info from	count=1
class	iso 639-3 ||| corpus reader	count=1
class	to invalidate the ||| freq	count=1
class	of ||| crubadan corpus	count=1
function	true if the ||| is	count=2
class	to ||| freq dist	count=2
arg	expression, for ||| argument	count=1
class	brill tagger on ||| brill tagger trainer	count=2
class	of the ||| nombank	count=1
function_arg	demonstration of [arg_2] ||| [arg_2] [function_1]	count=4
arg	and ||| line primitives	count=1
function	step 3 ||| step3	count=1
function	each ||| regexp span tokenize	count=1
arg	given sequence ||| sequence	count=1
arg	luname ||| luname	count=1
class	best ||| nonprojective parser	count=1
module_class	by this [class_2] ||| [module_1] [class_2] tags	count=4
function	text generates [function_2] ||| [function_2] [function_1]	count=6
arg	a new edge ||| edge	count=1
class	a token from ||| stepping shift	count=1
class	as ||| tagged	count=1
class	the moses detokenizer ||| moses detokenizer	count=2
arg	p and [arg_2] ||| [arg_2] [arg_1]	count=4
class	path pointer ||| file path pointer	count=1
arg	ranks2 ||| ranks2	count=1
function	incoming arc to the ||| incoming arc	count=1
class	of the frontier ||| stepping recursive descent	count=1
arg	-- ie ||| fileid	count=1
function	are lexicalised ||| lexical	count=1
class	this probability ||| heldout prob	count=1
class	:param ||| tableau prover command	count=1
function	log p , ||| logprob	count=1
function	userid to a ||| userid	count=1
class	new feature encoding based ||| binary maxent feature encoding	count=1
arg	self and other ||| other check_reentrance	count=1
function	return the number of ||| num	count=2
arg	goal sem ||| goal	count=1
class	a new iterator ||| iterator	count=1
function	the likelihood of the ||| likelihood	count=1
function	use of a previously ||| pred use	count=1
arg	to look up ||| history	count=1
class	out how big a ||| chart	count=1
module	remaining text ||| parse	count=1
class	:param ||| base model builder command	count=1
class	identifiers for the files ||| ycoecorpus reader	count=1
class	first element of the ||| stepping recursive	count=1
arg	word tag [arg_2] ||| [arg_1] [arg_2]	count=1
arg	a specified xml file ||| fileid tagspec	count=1
module	canvas that this ||| draw	count=1
class	words in alphabetical order ||| lexicon corpus reader	count=1
function	use ||| use	count=1
function	static ||| get static	count=1
function	[function_1] probability ||| [function_1] [function_2]	count=3
function	entries containing word transcriptions ||| entries	count=1
class	russian ||| russian stemmer	count=1
class	encoded as a ||| tagged corpus	count=2
arg	returns a list of ||| category fileids	count=1
class	a token from ||| shift reduce parser	count=1
function_arg	[function_1] quadgramcollocationfinder given ||| [function_1] word_fd [arg_2]	count=1
function	the top of ||| find top	count=1
function	[function_1] sentence ||| [function_1] [function_2]	count=3
arg	tree [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	tagged words [arg_2] ||| [function_1] fileids [arg_2]	count=4
function	the users ||| info from id	count=1
arg	drawing the ||| x y	count=2
function	alignments ||| alignments	count=2
class	where grammar can ||| cfg	count=1
class	from ||| shift reduce	count=1
class	end ||| stepping shift	count=1
module	labels and feature ||| classify	count=1
function	alignment of two texts ||| align texts	count=1
function_arg	[function_1] of variable ||| [function_1] [arg_2]	count=3
module	supported languages ||| reader	count=1
function	counter from [function_2] ||| [function_2] [function_1]	count=1
module	[module] regexpparser ||| [module]	count=2
module	the list of the ||| inference	count=1
function	the depth of ||| depth	count=1
arg	under the node ||| node_index	count=1
arg	filename ||| filename	count=2
function_arg	root counting [arg_2] ||| [arg_2] [function_1]	count=3
arg	label tuples ||| label	count=1
class	read ||| stream backed corpus view	count=1
function	the word ||| word	count=1
class	iso 639-3 ||| reader	count=1
function	subcorpus of ||| lusubcorpus	count=1
class	corpus view [class_2] ||| [class_2] [class_1]	count=1
function	log probability ||| output logprob	count=1
class	a corpus view that ||| nombank corpus reader	count=1
arg	a tree [arg_2] ||| [arg_2] [arg_1]	count=1
arg	string representation of ||| format	count=1
arg	[arg_1] ranks2 for ||| [arg_2] [arg_1]	count=1
class	plaintext ||| plaintext	count=1
arg	return true if x ||| x	count=1
class	list of supported languages ||| reader	count=1
class	expression to ||| lambda expression	count=1
module	a ||| core	count=1
function_arg	[function_1] return ||| [arg_2] [function_1]	count=9
module_class	[module_1] [class_2] ||| [module_1] tagged [class_2]	count=5
function	of ||| info from id	count=2
function	string value of a ||| value	count=1
class	a list of ||| crubadan corpus reader	count=1
function	[function_1] target sentence ||| [function_2] [function_1]	count=2
function	identifies [function] at ||| identify [function]	count=1
arg	the given item at ||| item x	count=1
class	:param ||| builder command decorator	count=1
function	[function_1] sentences in ||| [function_2] [function_1]	count=6
arg	[arg_1] segmentation ||| [arg_2] [arg_1]	count=6
arg	input expression ||| assumptions max_models	count=1
arg	optional frame ||| frame frame2	count=1
class	stream ||| stream	count=5
function	size of the ||| size	count=1
arg	and other ||| other	count=2
class	rtepairs from a rte ||| rtecorpus	count=1
function	contents of the table's ||| table	count=1
class	the files that ||| reviews corpus	count=1
function	write ||| write	count=1
class	chunkstring that ||| string	count=1
class	when ||| bottom up probabilistic	count=1
class	words in alphabetical order ||| opinion lexicon corpus	count=1
function	sequence yields ||| sequence	count=1
class	be etc ||| chart view	count=1
arg	[arg_1] productions ||| [arg_2] [arg_1]	count=1
arg	pk metric for a [arg_1] [arg_2] any sequence over a ||| metrics pk [arg_2] [arg_1]	count=2
class	particular if ||| recursive descent	count=1
function	users ||| user info	count=1
arg	[arg_1] and ||| [arg_2] [arg_1]	count=10
arg	matched substrings ||| string	count=1
function_arg	[function_1] string ||| [arg_2] [function_1]	count=1
class	[class_1] given ||| [class_2] [class_1]	count=1
class	of file identifiers for ||| ycoecorpus reader	count=1
class	the inside probabilities of ||| inside chart parser	count=1
class	end of the ||| reduce	count=1
module_class	[module_1] editing ||| [module_1] [class_2]	count=4
class	remaining text ||| stepping shift	count=1
arg	character [arg] ||| list_of_references hypotheses [arg]	count=3
module	this object ||| draw	count=1
function	[function_1] help page ||| [function_1] [function_2]	count=4
module	and using the ||| core	count=1
class	construct ||| discourse tester	count=2
class	given trigram using the ||| trigram collocation finder	count=1
module	up this corpus ||| corpus	count=1
function_arg	adds [function_1] [arg_2] ||| [function_1] [arg_2] mod_address	count=6
class	the neural dependency ||| neural dependency	count=1
arg	if finalize is true ||| verbose finalize	count=1
class	[class] frame's xml ||| [class]	count=3
module	for the best one ||| translate	count=1
function	return a tokenized list ||| list	count=1
class	of words for the ||| swadesh corpus reader	count=1
class	press ||| canvas widget	count=1
function_arg	pointer [arg_2] ||| [function_1] [arg_2]	count=3
class	end of ||| shift	count=1
arg	fileids as a single ||| fileids	count=1
module	called ||| app	count=2
arg	of tokens segmented ||| pos_tag	count=1
class	build the internal indexes ||| framenet	count=1
arg	tree :return an iterator ||| tree	count=2
function	tuple of ||| entries	count=1
function	the unique [function_2] ||| [function_2] [function_1]	count=4
class	in particular ||| recursive descent parser	count=1
function	return the f-measure ||| f measure	count=1
arg	location is within the ||| location	count=1
class	file identifiers for the ||| ycoecorpus	count=1
function	helper for ||| ascii fe	count=1
module	languages ||| corpus reader	count=2
class	consistent with the ||| i	count=1
function	the log probability of ||| output logprob	count=1
arg	assigns the [arg_2] ||| [arg_2] [arg_1]	count=8
module	return ||| core	count=110
module	return true if a ||| core	count=1
function	compiles and returns a ||| re	count=2
function	tokenization ||| tokenizer	count=1
arg	the assumptions ||| goal assumptions	count=1
class	the ||| chart	count=3
module_class	this canvasframe the ||| draw canvas frame	count=1
module	in this drs ||| sem	count=1
function	of information about the ||| user info	count=1
class	token from ||| shift reduce	count=1
function	logged values returning ||| log	count=1
function	height of [function_2] ||| [function_2] [function_1]	count=2
arg	count ||| count alignment_info	count=1
class	invalidate ||| freq	count=1
class	that the parser uses ||| parser	count=1
function	as list of words ||| words	count=1
class	[class] be ||| [class] reading	count=3
class	in particular if ||| stepping recursive descent	count=1
class	of the frontier in ||| descent	count=1
class	all ||| lexicon corpus	count=1
function	that instantiates and returns ||| variable expression	count=1
function	special category ||| category	count=1
arg	can be retrived via ||| synset_key	count=1
function	[function_1] [function_2] for an app and ||| [function_1] [function_2] creds_file	count=1
class	to figure out ||| chart	count=1
module	much of ||| parse	count=1
function	[function_1] pcfg grammar ||| [function_2] [function_1]	count=1
arg	of the "known labels" ||| mapping unseen_features alwayson_features	count=2
module	of file [module] for the ||| [module]	count=1
function	match the first ||| match	count=1
arg	the hunpos-tag ||| path_to_bin encoding verbose	count=1
class	a proper ||| simple good turing	count=1
arg	all_phrases_from that contains ||| all_phrases_from hypothesis	count=1
class	are generated [class] ||| maxent feature encoding [class]	count=1
function	previously bound node ||| node	count=1
arg	show all ||| show	count=1
class	update ||| brill tagger trainer	count=2
arg	word ||| fileids speaker stem	count=1
function	:return the grammar used ||| grammar	count=1
arg	and print classifier ||| classifier	count=1
class	parser and the ||| parser	count=1
class	in ||| stepping	count=1
function_arg	[function_1] size bytes ||| [function_1] [arg_2]	count=1
function	readings ||| readings	count=1
arg	a list of ||| fileids tagset	count=1
function	binding to each tkinter ||| bind to	count=1
function	speech ||| pos	count=1
class	return the unicode encoding [class_1] [class_2] file if known ||| [class_2] [class_1]	count=2
class	returns a list of ||| punkt sentence tokenizer	count=1
function	known abbreviation or ||| reclassify abbrev	count=1
class	by [class_2] ||| [class_2] [class_1] length	count=1
function	the top of the ||| top	count=1
class	:param ||| vector space clusterer	count=1
function	indices where ||| parent indices	count=1
class	this function must ||| drt	count=1
class	the ||| chunk app	count=1
function	read up ||| read	count=2
arg	to invalidate ||| key	count=1
class	move ||| stepping	count=1
function_arg	edge [arg_2] ||| [arg_2] [function_1]	count=1
arg	drtindividualvariableexpression for ||| consequent	count=1
class	the scroll-watcher ||| scroll watcher	count=1
function	for ||| corpus	count=1
arg	featureset [arg_2] ||| [arg_2] [arg_1]	count=4
class	particular ||| recursive descent parser	count=1
arg	each token should be ||| tokens	count=1
function	to build ||| build	count=1
function	likelihood ||| likelihood	count=3
function_arg	the likelihood [arg_2] ||| [function_1] vectorspace [arg_2]	count=1
function	assumes that ||| tweets	count=1
class	compute ||| word net corpus reader	count=1
arg	the token into ||| token	count=1
module	needs ||| app	count=1
arg	file s as a ||| fileids c5	count=2
function	a subtype of ||| variable expression	count=1
arg	given list of tokens ||| tokens	count=2
function	[function_1] [function_2] ||| [function_2] label [function_1]	count=6
function	pos-tagged words extracted from ||| pos	count=1
arg	stream is ||| stream	count=1
class	a unicode string ||| unicode stream	count=1
class	the corpus ||| pros cons corpus	count=1
arg	be used [arg_2] ||| [arg_2] [arg_1]	count=1
class	data ||| word net corpus reader	count=1
function	of the table's _rows ||| check table	count=1
arg	tag tuples ||| relation	count=1
function	information about ||| user info from id	count=1
class	a dutch ||| dutch	count=1
function_arg	tag [arg_2] ||| [function_1] [arg_2]	count=4
function	to parse multiple ||| parse	count=1
arg	specified by save_classifier ||| training_set save_classifier	count=1
class	sentences ||| sentence tokenizer	count=1
function	lookup 'key' [function_2] ||| [function_1] [function_2]	count=1
module_class	[module_1] [class_2] ||| [module_1] twitter [class_2]	count=3
arg	[arg_1] f-score it ||| chrf list_of_references hypotheses [arg_1] [arg_2]	count=1
module_class	[module_1] log ||| [module_1] [class_2]	count=2
module	frontier ||| parse	count=1
function	[function] annotated ||| [function] fulltext	count=1
class	probability ||| markov model	count=1
arg	or if its variable ||| variable	count=1
class	the files that ||| reviews corpus reader	count=1
class	of the review ||| review	count=1
function	return the grammar used ||| grammar	count=1
class	class ||| sklearn	count=1
class	must be called if ||| chunk app	count=1
arg	specified number of rows ||| rows cols	count=1
class	[class_1] corpus ||| [class_2] [class_1]	count=7
class	a corpus view ||| propbank corpus reader	count=1
class	trigram using the ||| trigram collocation	count=1
class	to the ||| shift	count=1
class	sentence ||| sentence tokenizer	count=3
function	its relation to other ||| relation	count=1
class	return a list ||| list	count=1
module	identifiers ||| corpus reader	count=1
class	is consistent with the ||| edge i	count=1
class	generated [class] ||| maxent feature encoding [class]	count=1
arg	valuation ||| valuation	count=1
function	the eval ||| eval	count=1
function	macro name [function_2] ||| [function_1] [function_2]	count=1
function	roleset ||| roleset	count=2
arg	for a synset note ||| synset	count=1
function	of information about ||| user info from id	count=1
function_arg	tree [arg_2] ||| [function_1] tree [arg_2]	count=1
arg	new edge ||| edge	count=3
function_arg	[function_1] [arg_2] ||| [function_1] pattern [arg_2]	count=34
function	returns the likelihood ||| likelihood	count=2
function_arg	[function_1] variable v ||| [function_1] [arg_2]	count=3
class	from ||| reduce parser	count=1
arg	list of file identifiers ||| filetype	count=1
arg	subtypes of tree cls ||| cls tree	count=1
arg	words and possibly non-contiguous ||| bigram_fd window_size	count=1
function	:param c the ||| init	count=1
class	the brill [class_2] ||| [class_2] [class_1]	count=3
arg	divide a string of ||| s chunk_label root_label	count=1
function	method that ||| variable expression	count=1
arg	on larger ||| g_graph b_graph	count=1
class	count error-rate relative to ||| paice	count=1
class	contents of ||| category	count=1
function	counter ||| counter	count=1
function_arg	[function_1] item ||| [function_1] [arg_2]	count=1
module_class	[module_1] corpus reader ||| [module_1] plaintext [class_2]	count=1
function	height of the ||| height	count=1
arg	in graphs list ||| graphs	count=1
function	interpretations ||| r1r2	count=1
function	convert ||| user info	count=1
function	userid to a screen ||| by userid	count=1
function	list of chunks ||| chunk	count=1
class	stack ||| reduce parser	count=1
function	to realign punctuation ||| realign boundaries	count=1
arg	assigns ||| assign_clusters	count=1
function	leaves of the ||| leaves	count=1
function	edge's right-hand side which ||| rhs	count=1
class	performs a projective ||| projective	count=1
arg	of rows ||| rows cols attempts	count=1
function	a subcorpus of ||| lusentence	count=1
function	given corpus of classified ||| write	count=2
class	corpus ||| category corpus	count=1
function	loaded ||| loaded	count=1
function_arg	[function_1] trees ||| [arg_2] [function_1]	count=6
function	word tokenizer ||| word	count=1
function	[function_1] there ||| [function_1] [function_2]	count=1
function	of s-expressions from the ||| sexpr	count=1
function	the probability [function_2] ||| [function_2] [function_1]	count=8
function	a uniform ||| uniform	count=1
function_arg	[function_1] estimator ||| [arg_2] [function_1]	count=1
function	number of entries ||| size	count=1
class	encoded as a list ||| tagged corpus	count=2
arg	string ||| string	count=3
class	how big the tree ||| chart	count=1
arg	tagger must be trained ||| trained n	count=1
function	arrange ||| manage	count=1
arg	given speaker dialect ||| dialect	count=1
function	nonterminal ||| nonterminal	count=1
class	of supported ||| crubadan corpus	count=1
class	to file or buffer ||| file	count=1
arg	return a score ||| other ic	count=1
module	the hypothesized ||| parse	count=1
arg	which are ||| stream	count=1
arg	information content ||| synset2 ic verbose	count=1
function	list of fileids that ||| fileids	count=1
module	corpus or ||| corpus reader	count=1
class	synset to the root ||| synset	count=1
class	add all edges licensed [class_1] [class_2] are currently in the ||| [class_2] [class_1]	count=2
function	the probability of the ||| probability	count=1
arg	expressed as ||| src_sentence trg_sentence	count=2
function	the number ||| num	count=3
function	find a space for ||| find room	count=1
module	function must ||| app	count=2
arg	[arg_1] xml ||| [arg_2] [arg_1]	count=2
class	as as a list ||| corpus reader	count=1
class	the end of ||| parser	count=1
class	bigram using the ||| bigram collocation finder	count=1
arg	its forward pointer ||| forward fs_class visited	count=1
function	section ||| section	count=1
function	information about the users ||| info from id	count=1
arg	document of ||| document	count=2
function	identifier ||| predid	count=1
function	file for [function_2] ||| [function_2] [function_1]	count=20
arg	finalize is ||| finalize	count=1
function	attempts to realign ||| realign	count=1
arg	[arg_1] frameid ||| [arg_2] [arg_1]	count=4
function	a ||| expression	count=2
function_arg	s-expressions from [arg_2] ||| [arg_2] [function_1]	count=3
arg	[arg_1] pattern ||| [arg_2] trees [arg_1]	count=3
class	in a ||| reader	count=1
function	[function_1] distance metric ||| [function_2] [function_1]	count=1
class	how big the tree ||| chart view	count=1
arg	models a fertility model ||| source_word_classes target_word_classes	count=2
arg	tokens construct ||| tokens	count=1
function	[function] consisting ||| ne chunk [function]	count=1
class	positive ||| opinion lexicon corpus reader	count=1
class	this semantics ||| hole semantics	count=1
function	the upper frame ||| upper	count=1
module	alphabetical ||| reader	count=1
class	joint-feature values ||| maxent feature encoding	count=1
class	a feature with the ||| feat dict	count=1
arg	[arg] in ||| [arg]	count=3
class	discourse or of ||| discourse tester	count=1
module	should ||| app	count=1
module	of the frontier in ||| parse	count=1
module	nltk corpus ||| corpus reader	count=1
class	the frontier ||| stepping recursive descent	count=1
function	the [function] ||| [function]	count=24
function	the left [function_2] ||| [function_1] [function_2]	count=1
class	invalidate the cached n ||| freq	count=1
class	to the minimal set ||| minimal set	count=1
function	of entries ||| entries	count=1
function	add an epytext ||| add epytext	count=3
class	of the stack ||| stepping	count=1
arg	[arg] the twitter ||| [arg]	count=1
arg	tagged data to ||| data	count=1
class	is a substitution ||| ccgvar	count=1
class	words in ||| reader	count=1
function	of entries ||| size	count=1
function	convert a list ||| info	count=1
class	dependency graph based ||| projective dependency	count=1
function	variety of information about ||| from	count=1
module	list ||| twitter	count=1
class	characters ||| stream reader	count=2
class	the first element of ||| stepping recursive descent	count=1
arg	index of ||| index	count=1
arg	originals ||| originals	count=1
function	data for a ||| data	count=1
class	from the frequency distribution ||| freq dist	count=1
function	features reflecting the presence/absence ||| feats	count=2
class	for ||| corpus	count=1
function	sentences in ||| sents	count=1
module_class	of [module_1] [class_2] structure suitable for embedding ||| [module_1] [class_2] struct	count=1
class	this function must ||| parser	count=1
class	and return that ||| backoff	count=1
module	return all ||| corpus	count=1
function_arg	wu-palmer similarity [arg_2] ||| [arg_2] [function_1]	count=4
class	token in a sentence ||| punkt sentence tokenizer	count=1
arg	list of characters ||| category fileids	count=1
class	iso 639-3 ||| crubadan corpus reader	count=1
class	xml element in a ||| reader	count=1
function	the sentences ||| sentences	count=2
class	out ||| chart	count=1
class	projective ||| projective	count=1
function	and ||| demo	count=1
function	the users ||| user info from	count=1
function_arg	[function_1] remaining_text to ||| [function_1] stack [arg_2]	count=3
module	all ||| corpus reader	count=3
function	to ||| parse	count=1
class	header_mode a ||| nkjpcorpus header	count=1
function	clustering parameters ||| cluster	count=1
function	the likelihood ||| likelihood	count=2
class	content of tweets ||| twitter	count=1
function	attempts to realign punctuation ||| realign	count=1
arg	located at the given ||| fileids word_tokenizer sent_tokenizer	count=1
function	various ||| discourse	count=2
class	this rule and ||| chart rule	count=1
arg	specified number of rows ||| rows	count=1
function	a variety ||| info from	count=1
function	module to convert a ||| taggedsent to	count=1
arg	and q for ||| q	count=1
arg	use a grammar ||| grammar trace	count=1
class	list [class_2] ||| [class_2] [class_1]	count=2
arg	:rtype bool :return ||| rightmost_stack	count=1
function	:return whether the word ||| word	count=1
function	header ||| header	count=1
class	creates a distribution ||| dist	count=1
class	must ||| glue demo	count=1
arg	of child to ||| child index dry_run	count=1
class	encoded as tuples ||| chunked corpus	count=1
arg	function the function that ||| function	count=1
class	proper [class_2] ||| [class_1] [class_2]	count=2
class	structure ||| i	count=2
class	rule it has ||| rule with	count=1
function	subcorpus of a lexical ||| lusubcorpus	count=1
module	value otherwise return ||| core	count=1
class	a russian ||| russian	count=2
function	remove entities ||| html entities	count=1
function	probability of ||| prob	count=4
class	generator ||| stepping chart	count=1
class	update the transition ||| transition	count=1
arg	the item ||| item	count=4
class	list ||| corpus reader	count=1
function	rule to ||| apply rule	count=1
class	of this rule ||| rule with	count=1
class	a buffered gzip ||| buffered gzip	count=1
module_class	twitter [class_2] ||| [module_1] [class_2]	count=4
class	first ||| recursive	count=1
module	chart [module] return true ||| [module]	count=1
function	create an ||| init	count=1
arg	return a ||| other verbose	count=3
arg	concept objects [arg] ||| concepts [arg]	count=3
class	frequency ||| dist	count=1
function	factory method that instantiates ||| expression	count=1
arg	sentence as a list ||| sentence	count=1
module	name ||| corpus reader	count=2
class	the end of ||| reduce parser	count=1
function	the beginning of the ||| shift	count=1
module	information about ||| twitter	count=1
module_class	[module_1] as as ||| [module_1] twitter [class_2]	count=1
class	a dependency ||| projective dependency parser	count=1
arg	[arg_1] match ||| [arg_2] [arg_1]	count=3
function	of an ellipsis ||| ellipsis	count=1
function	the edge ||| edge	count=1
arg	base_fdist ||| base_fdist heldout_fdist	count=1
class	corpus view that ||| corpus reader	count=2
class	a list of tweets ||| twitter corpus reader	count=1
module	single corpus using an ||| corpus reader	count=1
class	a corpus view that ||| corpus reader	count=2
function	convert a list of ||| info	count=1
class	as ||| tagged corpus reader	count=1
class	of tweets ||| twitter corpus reader	count=1
class	language phrase ||| phrase	count=1
class	element of the ||| stepping recursive descent parser	count=1
function	[function] is the ||| calculate [function]	count=1
module	sentence ||| app	count=1
class	the inside probabilities ||| inside chart parser	count=1
class	called if ||| app	count=2
module_class	any [class_2] ||| [module_1] [class_2]	count=2
class	text ||| viterbi	count=1
class	dependency parser ||| dependency parser	count=2
class	ngrams using the ||| ngram	count=2
arg	root the root directory ||| root propfile framefiles verbsfile	count=1
class	feature list ||| feat list	count=2
class	maxent classifier ||| maxent classifier	count=2
class	colorized ||| colorized	count=2
class	over ||| i	count=2
class	uses to choose ||| based	count=1
arg	luname frameid and framename ||| fn_luid ignorekeys luname frameid	count=1
function_arg	[function_1] [arg_2] of ||| [function_1] [arg_2]	count=2
arg	given file s as ||| fileids speaker stem relation	count=1
arg	the multi-word tokenizer with ||| mwes separator	count=1
class	as a ||| tagged corpus reader	count=1
class	is in the thesaurus ||| lin thesaurus	count=1
arg	word between them ||| wildcard_fd trigram_fd	count=1
function	an initial ||| initial	count=1
function_arg	apply the [arg_2] ||| [function_1] rule word [arg_2]	count=1
module_class	[module_1] path ||| [module_1] [class_2]	count=2
class	included [class] ||| [class]	count=1
class	joint-feature ||| maxent feature encoding i	count=2
class	path identified by this ||| path	count=1
class	must be called ||| chart	count=1
function	tuple containing the names ||| names	count=1
arg	:param data bytes ||| data size	count=2
function	[function_1] model ||| [function_2] [function_1]	count=1
arg	replace any [arg] ||| [arg] forward fs_class	count=1
function_arg	:param refs ||| init refs	count=1
class	of the inside probabilities ||| inside chart parser	count=1
class	returns words ||| nkjpcorpus	count=1
class	is consistent with ||| edge	count=2
function	is closed ||| closed	count=1
function	rv that is ||| rv	count=1
class	be called ||| glue demo	count=1
arg	[arg] leave ||| [arg] block_size	count=2
function	a variety of information ||| info from id	count=1
arg	to implement the view ||| fileid bracket_sent tag strip_space	count=1
class	state sequence ||| markov	count=1
class	element in ||| corpus reader	count=1
class	the expression to ||| lambda expression	count=1
function	euclidean ||| euclidean	count=1
module	as iso 639-3 ||| corpus reader	count=1
arg	must be trained ||| trained n	count=1
module	a list of supported ||| reader	count=1
arg	provercommand provercommand to ||| provercommand	count=1
class	creating defaultdict of ||| lin thesaurus	count=1
class	logic parsers [class_2] ||| [class_2] [class_1]	count=2
class	widget [class] a ||| [class]	count=2
function	comparison (from listofkeywords ||| keywords readme	count=1
module	this object's probability this ||| core	count=1
function_arg	rules [arg_2] ||| [function_1] [arg_2]	count=2
arg	implement the view methods ||| bracket_sent	count=1
class	stemmer ||| stemmer	count=4
arg	for appearances ||| word_fd bigram_fd	count=1
arg	a [arg] ||| ref hyp [arg]	count=2
class	to ||| shift reduce	count=1
class	update the transition dictionary ||| transition	count=1
class	tree ||| chart view	count=1
arg	python port ||| return_str	count=1
class	given bigram ||| bigram collocation	count=1
class	of the corpus ||| reviews corpus reader	count=1
function	transitive ||| transitive	count=1
class	same sentence ||| sentence	count=1
class	collects ||| punkt trainer	count=1
function_arg	[function_1] with_shutdown ||| [arg_2] [function_1]	count=4
function	the score of the ||| score	count=1
arg	*worder* list i ||| character_based	count=1
class	this function must be ||| drt glue	count=1
function	the score for ||| score ngram	count=2
function	the probability [function_2] ||| [function_1] [function_2]	count=8
function	a category ||| category	count=1
arg	strings ||| strings	count=2
function	substitute ||| substitute	count=1
function_arg	self [arg_2] ||| [arg_2] [function_1]	count=1
function	chi-square ||| chi sq	count=1
arg	line ||| line	count=1
class	tagger to map from ||| tagger	count=1
function	the regions ||| regions	count=1
function	list ||| info from	count=1
function	recent tweets ||| tweets	count=1
class	parsing a tree ||| tree	count=1
arg	to implement the ||| bracket_sent	count=1
class	a token ||| reduce parser	count=1
class	elements of ||| lazy map	count=1
class	add all edges licensed [class_1] [class_2] that are currently in ||| [class_2] [class_1]	count=2
class	the pickled model ||| perceptron	count=2
arg	consequent of 'self' ||| other bindings	count=1
class	production ||| production	count=5
module	internal indexes to ||| corpus reader	count=1
function	trains the ||| train	count=1
class	move ||| reduce	count=1
arg	list ||| fileids sent tag	count=1
class	discourse or ||| discourse tester	count=1
class	edges in this chart ||| feature chart	count=1
class	text to ||| reduce parser	count=1
class	:see expression ||| individual variable expression	count=4
arg	of word tag ||| fileids speaker stem	count=1
function	frame ||| frame	count=4
function	find a space for ||| find	count=1
function	a new [function_2] ||| [function_2] [function_1]	count=4
function	information about the users ||| from	count=1
class	binder in the expression ||| expression	count=1
function	lambda function representing ||| tgrep	count=2
function	the log probability ||| log prob	count=1
arg	positive_featuresets ||| positive_featuresets	count=1
class	much of the hypothesized ||| edge	count=1
class	function must be ||| app	count=2
class	called ||| drt	count=1
class	xml element in ||| corpus reader	count=1
function_arg	in [arg_2] ||| [function_1] [arg_2]	count=6
function	*rule* applies ||| applies	count=1
function	strings ||| build	count=1
arg	highest information content value ||| synset2 ic	count=1
arg	to produce the *worder* ||| character_based	count=1
class	collocation finder with the ||| collocation finder	count=1
class	:param ||| regexp chunk app	count=1
class	as ||| corpus	count=2
arg	devset_name the name of ||| devset_name devset grammar	count=1
function	creates a table ||| token table	count=1
function	edge in ||| edge	count=1
function_arg	[function_1] file ||| [arg_2] [function_1]	count=2
function	various methods ||| demo	count=2
function	into a first-order logic ||| fol	count=1
function	frames that contain ||| frames	count=1
function	file and update ||| file	count=1
function	the score for a ||| score ngram	count=2
function_arg	[function_1] function ||| [function_1] [arg_2]	count=3
function	[function_1] from the ||| [function_1] [function_2]	count=4
arg	word of length ||| word	count=1
class	text to the ||| reduce parser	count=1
module	labels and ||| classify	count=1
module	identified by this ||| core	count=1
class	a text ||| text	count=1
arg	:param src_sentence ||| src_sentence	count=1
class	a projective [class_2] ||| [class_1] [class_2]	count=1
function	relations [function_2] ||| [function_2] [function_1]	count=3
arg	text if [arg_2] ||| [arg_2] [arg_1]	count=4
class	bigram collocation finder ||| collocation finder	count=1
function	euclidean [function_2] ||| [function_1] [function_2]	count=1
module	error-rate relative to ||| metrics	count=1
function	of entries containing ||| entries	count=1
module	nltk corpus import wordnet ||| corpus reader	count=1
class	the end ||| shift reduce parser	count=1
arg	splitting the string at ||| s	count=1
class	length ||| isristemmer	count=2
class	that this probability ||| prob	count=2
class	when parsing a text ||| parser	count=2
arg	left-hand side or ||| lhs	count=2
class	be called if ||| chunk app	count=1
function	information about the users ||| from id	count=1
class	rule given the ||| chart rule	count=1
arg	lines at ||| lines	count=1
class	bigram using ||| bigram collocation	count=1
class	cfg ||| cfg	count=1
class	the frontier ||| stepping recursive descent parser	count=1
class	is the ||| transition	count=1
function	chunker to chunk ||| chunk	count=2
arg	a specified xml ||| tagspec	count=1
function	persistent database ||| val	count=1
arg	the other ||| other	count=1
arg	the given sequence ||| sequence	count=1
arg	word ||| speaker stem	count=1
function	bigram ||| extract bigram	count=1
function	register it's json ||| register	count=1
function_arg	[function_1] [arg_2] ||| [function_1] state [arg_2]	count=6
class	of the files ||| reviews corpus reader	count=1
arg	of the chart parsers ||| choice print_times print_grammar print_trees	count=1
function	3 from "an algorithm ||| step3	count=1
class	move ||| reduce parser	count=1
class	of all parses that ||| descent parser	count=2
class	sequence with ||| markov model	count=1
function	of ||| user info from	count=2
class	new iterator over ||| lazy iterator	count=1
function	convert a list ||| user info from	count=1
module	return ||| corpus	count=2
function	the fileids that make ||| fileids	count=1
class	element wrapper ||| element wrapper	count=2
class	element in a ||| corpus reader	count=1
class	to the ||| reduce parser	count=1
arg	with other a ||| other	count=1
function	[function_1] token ||| [function_2] [function_1]	count=1
function	timer decorator to ||| timer	count=1
module	this widget ||| draw	count=3
class	of ||| stepping shift reduce	count=2
function	this is a factory ||| variable expression	count=1
function	the kendall's [function] correlation coefficient ||| kendall [function]	count=1
module	snowball stemmers ||| stem	count=1
function	sentences in the ||| sents	count=1
function	named entity chunker to ||| ne	count=2
function	a subtype ||| expression	count=1
class	internal indexes to ||| reader	count=1
class	as a list ||| tagged corpus reader	count=1
arg	a string ||| s	count=3
function	[function] of the ||| cluster [function]	count=2
class	called if ||| chart parser	count=1
class	minimal ||| minimal	count=1
class	the tweet ||| tweet	count=1
class	structure ||| edge i	count=1
function_arg	each element [arg_2] ||| [arg_2] [function_1]	count=1
class	an xml element in ||| framenet corpus reader	count=1
class	for the ||| corpus reader	count=3
class	construct ||| quadgram collocation finder	count=1
module_class	after this [class_2] ||| [module_1] [class_2]	count=4
function	remove the given ||| remove	count=2
class	to ||| dist	count=1
function	[function] of ||| [function] to	count=1
function	cnf ||| cnf	count=1
arg	s ||| fileids tag	count=1
class	the absolute path ||| file system	count=1
class	scroll-watcher ||| scroll watcher	count=2
class	be called ||| chunk app	count=1
function	template sets in this ||| template sets	count=1
class	this ||| regexp chunk app	count=1
class	contents of ||| category corpus	count=1
function	node label ||| node label	count=2
class	string ||| view	count=1
function	error message when parsing ||| error	count=1
class	brill [class_2] ||| [class_1] [class_2]	count=3
arg	token into ||| token	count=1
function	template [function_2] ||| tag describe [function_1] [function_2]	count=4
function	main frame ||| pack	count=1
function	computes the probability of ||| prob	count=2
function	boundaries ||| boundaries	count=1
arg	pos tagged sentence ||| sentence	count=1
arg	tokens construct and return ||| tokens	count=1
arg	sequence of items ||| sequence n k	count=1
function	the various methods of ||| drt discourse demo	count=1
function	of information about ||| user info from	count=1
class	fileids in this corpus ||| corpus reader	count=1
function	chart to ||| chart	count=1
class	of processing ||| tweet handler i	count=1
function	standard ||| standard	count=1
class	this [class_1] [class_2] ||| [class_1] [class_2]	count=4
arg	tab file ||| tab_file lang	count=1
class	sequence with the ||| hidden markov	count=1
function	verbose string representation ||| str	count=2
function	tagger to tag the ||| tag	count=1
arg	frame object name ||| frame frame2 type	count=1
arg	of tokens using a ||| tokens	count=1
arg	the distance of each ||| distance	count=1
arg	be a punktparameters object ||| lang_vars token_cls	count=1
arg	[arg_1] relation ||| [arg_1] [arg_2]	count=3
class	the fixed-length [class] ||| [class] encoding	count=1
arg	add more [arg] to the ||| [arg]	count=1
function	unigram features reflecting the ||| unigram feats	count=1
function	the sentences in that ||| sentences	count=1
arg	input ||| assumptions max_models	count=1
arg	all possible ways of ||| ancestors0 queue potential_labels0	count=1
class	of (corpus_property_key value) ||| childescorpus reader	count=1
module	this function returns the ||| core	count=1
arg	the "known labels" ||| mapping unseen_features alwayson_features	count=2
function	are ||| top	count=1
arg	encodes the ||| chunk_struct debug_level	count=1
arg	word tag tuples ||| fileids speaker stem relation	count=1
arg	drawing the item ||| x y	count=1
class	[class_1] the given ||| [class_2] [class_1]	count=1
function	binding to each ||| bind to columns	count=2
class	change ||| stepping shift reduce parser	count=1
function	an integer ||| int	count=1
function	tweets tokenized using ||| tweets	count=1
arg	all ||| cnf	count=1
arg	return a score denoting ||| other verbose simulate_root	count=3
function	returns the similarity score ||| similarity	count=1
class	this rule it ||| rule	count=1
class	total mass of probability ||| prob dist	count=1
class	in the expression to ||| lambda expression	count=1
function	of the best incoming ||| best incoming	count=1
arg	n-gram f-score described in ||| hypothesis min_len max_len	count=1
class	displaying the ||| descent parser	count=1
class	if the graph ||| dependency graph	count=1
class	expression ||| expression	count=22
class	in the thesaurus ||| lin thesaurus	count=1
class	corpus file underlying this ||| lazy	count=2
function	methods of ||| discourse	count=2
arg	the list ||| fileids sent	count=1
function	trace output ||| trace shift	count=1
arg	children that cover ||| constituents	count=1
arg	position ||| position	count=1
class	periods as sentence ||| punkt sentence	count=1
function_arg	fringe of tree ||| fringe tree treeloc	count=2
function	module [function_2] ||| [function_2] [function_1]	count=3
class	in alphabetical order ||| reader	count=1
function	patterns and ||| pro	count=2
class	this rule given ||| chart rule	count=1
function	and returns a ||| variable expression	count=1
class	a text returns a ||| punkt sentence	count=1
class	must be called if ||| app	count=2
class	of the ||| reduce parser	count=2
arg	raw_score likelihood ||| raw_score src_phrase_span	count=1
function	greatest number ||| max	count=1
module_class	[module_1] [class_2] ||| [module_1] lazy iterator [class_2]	count=2
class	as as a ||| corpus	count=1
arg	[arg_1] extracted ||| [arg_2] [arg_1]	count=3
function	the static index ||| static index	count=2
class	move a token ||| parser	count=1
function	save a ||| save	count=1
function	for past tweets by ||| tweets by user	count=1
function	this ||| variable	count=1
arg	rows and ||| rows	count=1
class	of supported languages as ||| crubadan corpus reader	count=1
class	a long verbnet class ||| verbnet	count=1
function	output of ||| output	count=1
function	concise string ||| repr	count=1
arg	list of tokens ||| tokens	count=5
class	the file within zipfile ||| zip file	count=1
arg	order for cls ||| cls	count=1
function	[function_1] web ||| [function_2] [function_1]	count=3
arg	generate freqdist ||| freqdist gamma bins	count=1
class	tag of ||| tag	count=1
class	probability state sequence this ||| hidden markov model	count=1
function	returns the score ||| score	count=2
function	main frame widget in ||| pack	count=1
function	words chunks ||| words	count=1
function	incoming [function_2] ||| [function_1] [function_2]	count=4
function_arg	:rtype [arg_2] ||| [function_1] [arg_2]	count=3
class	all ||| opinion lexicon corpus reader	count=1
class	0 75 ||| kneser ney	count=1
class	files that ||| reviews	count=1
class	639-3 language code ||| crubadan	count=1
arg	given user ||| user count	count=1
module	initialize the [module] ||| [module]	count=3
arg	given freqdists for appearances ||| word_fd	count=1
arg	given the tuple representation ||| tagged_token	count=1
class	collocation finder with ||| collocation finder	count=1
function_arg	[function_1] trees ||| [function_1] pattern [arg_2]	count=6
class	this confusion matrix ||| confusion matrix	count=2
function	its [function] ||| annotation ascii [function]	count=3
function	rare [function_2] ||| [function_2] [function_1]	count=2
class	must be called ||| drt glue	count=1
arg	the fileids of the ||| fileids	count=1
class	list of file identifiers ||| ycoecorpus	count=1
function	named entity ||| ne	count=2
class	matrix ||| matrix	count=2
class	probability state sequence ||| model	count=1
class	of the ||| recursive descent	count=1
function	[function_1] comparison ||| [function_1] [function_2]	count=1
class	sentence string to figure ||| chart view	count=1
class	construct a new maxent ||| maxent	count=1
function	input file [function_2] ||| [function_2] [function_1]	count=12
function	plot the ||| plot	count=1
arg	a list of word ||| fileids speaker stem	count=1
function	given an exemplar sentence ||| exemplar of fes	count=1
function	the probability ||| prob	count=2
function_arg	edge in [arg_2] ||| [arg_2] [function_1]	count=1
arg	replace any [arg] has a ||| [arg] forward fs_class	count=1
module	given ||| corpus reader	count=1
class	big ||| chart view	count=2
function	descended from ||| descendants	count=1
class	expression ||| application expression	count=2
arg	in positions where ||| tokens positions	count=1
class	corpus view that acts ||| propbank corpus reader	count=1
class	return the chart rule ||| chart	count=1
arg	for appearances of words ||| word_fd bigram_fd	count=1
function	return a string containing ||| format	count=1
function	to resize a ||| resize	count=1
class	by this classifier ||| naive bayes classifier	count=1
class	text ||| reduce	count=1
module	whether tweets are coming ||| twitter	count=1
function	the upper frame page ||| get static upper page	count=1
arg	list of word tag ||| c5 strip_space stem	count=1
function	of the names of ||| names	count=1
arg	list of text ||| word_tokenizer sent_tokenizer	count=1
class	enter ||| chunk app	count=1
class	canvas widget's ||| canvas	count=2
arg	vectors to ||| vectors	count=1
function	right-hand side which specifies ||| rhs	count=1
class	big ||| chart	count=2
arg	n-gram [arg_2] ||| [arg_2] [arg_1]	count=8
module	abstractvariableexpression appropriate for ||| sem	count=1
arg	a symbol ||| symbol	count=1
module	this widget and the ||| draw	count=1
function_arg	mapping dictionary [arg_2] ||| [arg_2] [function_1]	count=1
class	lancaster [class_2] ||| [class_2] [class_1]	count=1
class	hypothesized ||| edge i	count=1
function	rv that ||| rv	count=1
arg	whether a feature ||| feat	count=1
class	chunkstring that ||| chunk string	count=1
function	the greatest number of ||| max	count=1
arg	a sequence ||| sequence	count=3
arg	fileids that have to ||| fileids	count=1
arg	returns the top n ||| n	count=1
class	called if ||| drt	count=1
class	list of the synset ||| synset	count=1
class	corpus view that acts ||| corpus	count=2
function	demonstration showing the creation ||| rule parse demo	count=1
function_arg	local [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	:param [arg_2] ||| sem variable [function_1] [arg_2]	count=3
function	and returns a subtype ||| expression	count=1
class	the sequence ||| hidden markov model tagger	count=1
class	the class ||| sklearn	count=1
class	iso ||| corpus reader	count=1
arg	returns a list ||| fileids	count=1
class	indicates ||| i	count=1
function	[function_1] format("verbose") ||| [function_2] [function_1]	count=2
class	the scroll-watcher the ||| scroll watcher	count=1
class	supported ||| corpus reader	count=1
module	must be ||| sem	count=1
arg	alignment in alignment_info, ||| alignment_info	count=1
class	words for the specified ||| swadesh corpus	count=1
class	as positive ||| positive	count=1
arg	:param expression the expression ||| expression command x	count=1
class	split the frequency distribution ||| prob dist	count=1
function	of tagged [function_2] ||| [function_1] [function_2]	count=6
module_class	of this space ||| draw space	count=1
module_class	of [module_1] [class_2] ||| [module_1] [class_2]	count=66
class	a given trigram using ||| trigram	count=1
arg	n-gram [arg_2] ||| chrf list_of_references hypotheses [arg_1] [arg_2]	count=4
class	iso 639-3 ||| corpus	count=1
class	:rtype str :return a ||| laplace	count=1
function	index for a ||| index	count=1
function	return the upper frame ||| upper	count=1
class	the end of the ||| shift reduce parser	count=1
function	make sure that a ||| sanity check	count=1
function	are "preterminals", [function] ||| [function]	count=1
function	the number of entries ||| size	count=1
function_arg	[function_1] a sentence ||| [arg_2] [function_1]	count=1
function	readers of http //stackoverflow ||| synset from pos and offset	count=1
function	entity chunker to chunk ||| chunk	count=2
function	return a matrix of ||| matrix	count=1
function	left ||| left	count=2
class	particular ||| descent	count=1
arg	c{replacement_tag} if all ||| templateid original_tag replacement_tag conditions	count=1
arg	of remaining_text to the ||| remaining_text	count=1
function	of ||| info	count=2
function	named [function_2] ||| [function_1] [function_2]	count=2
class	be ||| demo	count=1
function_arg	[function_1] pretty-printed version ||| [function_1] [arg_2]	count=2
class	a ||| stepping shift	count=1
function	variety ||| from id	count=1
class	instance's ||| nombank	count=1
class	frequency distribution ||| freq dist	count=10
function	stem ||| stem	count=1
class	words in alphabetical order ||| corpus	count=1
function	all sentences in ||| sents	count=1
function	a subcorpus ||| lusubcorpus	count=1
class	thesaurus ||| lin thesaurus	count=2
function	the greatest number ||| max	count=1
function	a freqdist ||| freq	count=1
class	corpus if ||| verbnet corpus reader	count=1
function	given chart into ||| set	count=1
arg	a string ||| s chunk_label root_label	count=1
class	end of the stack ||| shift reduce parser	count=1
class	sentence string to ||| chart	count=1
arg	a given widget ||| widget	count=1
arg	limit ||| limit	count=1
function	likelihood of ||| likelihood	count=1
class	an hungarian ||| hungarian stemmer	count=1
function	method ||| variable expression	count=1
class	the initial tagger ||| brill tagger	count=1
function	information about ||| user info	count=1
function	names ||| names	count=3
arg	containing ||| vnframe	count=1
class	with ||| edge	count=1
class	standard format ||| standard format	count=2
function	[function_1] lists ||| [function_2] [function_1]	count=5
function	return a string ||| pretty format	count=1
class	this tagger uses to ||| based tagger	count=1
function_arg	tagged words [arg_2] ||| [arg_2] [function_1]	count=9
module	the various methods of ||| inference	count=2
class	is consistent ||| i	count=1
arg	segmentations [arg_2] ||| [arg_1] [arg_2]	count=1
class	text ||| text	count=7
class	languages as iso 639-3 ||| crubadan corpus reader	count=1
function	is [function_2] ||| [function_2] [function_1]	count=5
function	factory ||| variable expression	count=1
class	the first element ||| stepping recursive descent parser	count=1
class	brill tagger ||| brill tagger	count=1
class	move a ||| stepping shift reduce	count=1
function	a freqdist containing ||| freq	count=1
class	maxent [class_2] ||| [class_1] [class_2]	count=1
class	this function must be ||| regexp chunk	count=1
function	generates the sentences ||| sentences	count=1
arg	a [arg] ||| [arg]	count=5
class	must be called if ||| glue	count=1
function	pop the first ||| pop first	count=3
function	logged values returning the ||| log	count=1
class	canvas widget's bounding box ||| canvas widget	count=2
module	token from ||| parse	count=1
class	context to ||| context	count=1
module	for the ||| reader	count=1
function	cfgs can be created ||| cfg	count=1
arg	remaining lines at exactly ||| lines	count=1
function	the names [function_2] ||| [function_2] [function_1]	count=4
class	rule ||| chunk rule with context	count=1
class	function ||| chunk	count=1
class	move a ||| shift reduce	count=1
class	alphabetical order ||| opinion	count=1
function	best incoming arc to ||| best incoming arc	count=1
class	positive ||| positive	count=1
function	suffix-removal rule to ||| apply rule	count=1
class	the sequence with ||| markov model tagger	count=1
function	update the graphical display ||| update	count=1
function	parse a ||| tagged parse	count=1
function	tgrep search string into ||| tgrep tokenize	count=1
arg	positive_featuresets a ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
function	:param c the correction ||| init	count=1
class	each context to the ||| context	count=1
function_arg	[function_1] match the ||| [function_1] nodes pattern trees [arg_2]	count=1
module	exists return ||| core	count=1
class	structure is consistent ||| i	count=1
function	roleset used by ||| roleset	count=1
class	corpus view that reads ||| view	count=1
class	consistent with ||| edge i	count=1
class	to invalidate ||| freq	count=1
class	tweets ||| twitter	count=2
function	[function_1] for ||| [function_2] [function_1]	count=6
function_arg	[function_1] and returns ||| [arg_2] [function_1]	count=6
class	may cause the object ||| mutable	count=1
module_class	all the subtrees of [module_1] [class_2] optionally restricted ||| [module_1] [class_2]	count=1
function	[function_1] ratios ||| [function_2] [function_1]	count=1
class	of words ||| swadesh	count=1
class	of supported ||| corpus reader	count=1
function	mapping dictionary ||| tagset mapping	count=1
module	and values ||| metrics	count=1
arg	sentence as ||| sentence verbose	count=1
module	is ||| core	count=1
function	print a list ||| print	count=1
function	a variety of information ||| user info from	count=1
class	element of the ||| recursive descent parser	count=1
function	[function] feature whose ||| [function]	count=1
function	closest length ||| closest ref length	count=1
module	configure this widget use ||| draw	count=1
function	sentence strings ||| build sentence	count=1
arg	x ||| x	count=1
function	node [function_2] ||| [function_2] [function_1]	count=2
arg	with_shutdown is true ||| with_shutdown	count=1
arg	ranks2 for ||| ranks2	count=1
module	labels ||| classify	count=1
function_arg	[function_1] all ||| [arg_2] [function_1]	count=3
function	indices where this ||| parent indices	count=1
class	positive [class_2] ||| [class_1] [class_2]	count=2
arg	alignment in alignment_info, ||| alignment_info j_pegged	count=1
function_arg	[function_1] context_to_tag a ||| [arg_2] [function_1]	count=1
arg	and punctuation ||| c5 strip_space stem	count=1
function	dictionary ||| predicate dict	count=1
module	the hypothesized structure ||| parse	count=1
class	the corpus ||| cons corpus	count=1
class	must ||| drt	count=1
function	demonstration ||| demo	count=9
function	sentence and ||| of	count=1
arg	s as a list ||| fileids c5	count=2
function	[function_1] less ||| [function_2] [function_1]	count=2
class	encoding [class] ||| [class]	count=1
arg	child to not point ||| child	count=1
class	in ||| lexicon	count=1
arg	if index ||| index	count=1
function_arg	distance [arg_2] ||| metrics masi [function_1] [arg_2]	count=4
class	parsing a ||| stepping recursive descent parser	count=1
function	[function_1] incoming ||| [function_2] [function_1]	count=3
arg	assigns the ||| assign_clusters	count=1
function_arg	table of [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg_1] can ||| [arg_2] [arg_1]	count=1
class	print ||| brill tagger	count=1
class	[class_1] binder ||| [class_2] [class_1]	count=4
arg	return a ||| other ic	count=1
arg	the distance of ||| distance	count=1
function	use of a ||| use	count=1
function	the various methods ||| discourse	count=2
function	uppercase ||| is funcvar	count=1
arg	sequence ||| sequence	count=7
function	root counting ||| hypernym distances	count=1
function	chunkstr, in turn ||| notrace	count=1
function	returns a subtype ||| variable expression	count=1
function	and [function_2] ||| [function_1] [function_2]	count=1
function	induce a pcfg grammar ||| induce pcfg	count=1
function	fulltextindex xml file ||| handle fulltextindex	count=1
module_class	in the stack ||| translate stack	count=1
class	when ||| up probabilistic	count=1
class	a marker ||| standard format	count=1
arg	the file s ||| fileids	count=1
function	log probability of ||| log prob	count=1
class	particular if ||| descent	count=1
class	concatenating ||| lazy iterator	count=1
class	be how big ||| view	count=1
function	string containing [function] ||| [function]	count=2
class	out how big ||| view	count=1
function	with [function_2] ||| [function_1] [function_2]	count=4
function	on the underlying byte ||| tell	count=1
module	previously opened ||| core	count=1
module	descent parser ||| parse	count=1
module	to invalidate ||| core	count=1
class	context ||| context index	count=1
class	rule it has the ||| chunk rule with context	count=1
function	count for this ||| count	count=1
class	of ||| reader	count=2
class	in a sentence ||| punkt sentence tokenizer	count=2
function	returning ||| classification probdist	count=1
class	this function must be ||| chunk app	count=1
function	to each tkinter ||| to	count=1
module_class	return true [class_2] ||| [module_1] [class_2]	count=8
class	representatino of the dependencyspan ||| dependency span	count=1
function_arg	[function_1] synset note ||| [arg_2] [function_1]	count=4
class	this sentence boundary detector ||| punkt sentence tokenizer	count=1
arg	alignments from alignment_infos ||| alignment_infos	count=1
class	parses that ||| recursive descent parser	count=4
class	a token ||| shift reduce parser	count=1
function	construct ||| construct readings	count=1
class	the first element ||| recursive	count=1
class	should be ||| view	count=1
function	construct ||| construct threads	count=1
arg	tagged data ||| data	count=1
class	remaining text ||| stepping shift reduce parser	count=1
function	by ||| by	count=1
class	first element ||| recursive	count=1
arg	word tag ||| fileids speaker stem	count=1
class	a new canvas widget ||| widget	count=1
function	the various methods of ||| demo	count=2
module	as ||| reader	count=1
module	this corpus view that ||| corpus reader	count=4
class	edge if the edge ||| feature tree edge	count=1
class	must be called if ||| chart parser app	count=1
module	a [module] ||| [module]	count=8
arg	bracketed tree [arg_2] ||| [arg_2] [arg_1]	count=4
arg	and q ||| q	count=1
function	all sentences ||| sents	count=2
arg	initial_tagger ||| initial_tagger rules training_stats	count=1
class	an hungarian ||| hungarian	count=1
function	a variety ||| info	count=1
arg	item is a ||| item	count=1
class	name of the ||| nombank	count=1
arg	a given user ||| user count	count=1
class	move a token from ||| stepping shift reduce parser	count=1
function	size of the file ||| file size	count=1
module	text widget used for ||| draw	count=1
arg	be used [arg_2] ||| [arg_1] index [arg_2]	count=1
class	remaining text to ||| stepping	count=1
function	topmost hypernyms of ||| root hypernyms	count=1
arg	and punctuation ||| strip_space stem	count=2
function	an ellipsis ||| ellipsis	count=1
class	element of the ||| descent	count=1
arg	the selected ||| delta see	count=1
class	or not the given ||| corpus reader	count=1
arg	devset_name the ||| devset_name devset	count=1
class	union ||| freq dist	count=2
arg	probdist_dict ||| probdist_dict	count=1
arg	fileids as ||| fileids	count=2
function	all tags ||| tags	count=1
class	childes format ||| childescorpus	count=1
function_arg	to [arg_2] ||| cache [function_1] tempfile cls sequence [arg_2]	count=2
module_class	[module_1] [class_2] including graphical ||| [module_1] [class_2]	count=4
function	of information ||| id	count=1
module	chunk parser using a ||| chunk	count=1
function	list of ||| user	count=1
arg	draw the given item ||| item x	count=1
class	handling ||| streamer	count=1
function_arg	children [arg_2] ||| [arg_2] [function_1]	count=4
class	this variable binder ||| variable binder	count=2
arg	trees which ||| trees	count=1
module	internal ||| reader	count=1
arg	string of ||| s chunk_label	count=1
arg	the input string ||| input encoding	count=1
class	the end of ||| shift	count=1
arg	from a [arg_2] ||| [arg_2] [arg_1]	count=1
class	:param ||| stack decoder	count=1
arg	[arg] beginning ||| [arg]	count=1
function	the text ||| text	count=2
arg	train and test a ||| trainer save_analyzer n_instances output	count=1
module	this instance's ||| corpus	count=1
function	remove all [function_2] ||| [function_2] [function_1]	count=1
class	end of ||| reduce parser	count=1
arg	rule data ||| rule	count=1
function	the previous ||| previous	count=1
module	the name ||| reader	count=1
module	return a list ||| corpus	count=1
function	errors ||| error	count=1
arg	segmentations a ||| k boundary	count=1
module	relative to ||| metrics	count=1
class	processing ||| i	count=1
class	supported languages as iso ||| crubadan	count=1
class	graph ||| dependency graph	count=1
arg	samples is ||| samples	count=1
module	convert a list ||| twitter	count=1
function_arg	button press [arg_2] ||| [arg_2] [function_1]	count=3
function	and expected agreements for ||| multi kappa	count=1
arg	given text [arg_2] ||| [arg_1] [arg_2]	count=5
module	this corpus view that ||| corpus	count=4
module	full [module] in ||| [module]	count=1
function	synset relations data for ||| relations data	count=1
class	[class_1] stemmer ||| [class_1] [class_2]	count=3
function	returns a padded ||| pad	count=1
class	occurs as a child ||| multi parented	count=1
arg	[arg_1] q ||| [arg_1] [arg_2]	count=1
arg	the *worder* list ||| character_based	count=1
class	lu ||| framenet	count=1
class	the dict if its ||| dict	count=1
class	frames ||| corpus reader	count=1
function	construct a value ||| construct threads	count=1
class	a variety of information ||| query	count=1
function	all words ||| words	count=1
class	a unit needs ||| chart view	count=1
class	i ||| i	count=7
function	immutable ||| frozen	count=1
class	sentence ||| punkt sentence	count=3
class	from ||| stepping shift	count=1
arg	[arg_1] root directory ||| [arg_2] [arg_1]	count=2
function	first pass ||| first pass	count=1
class	build ||| framenet	count=1
class	candidate periods as sentence ||| sentence	count=1
class	marker value ||| standard format	count=1
function	the indices where this ||| parent indices	count=1
function_arg	[function_1] the word ||| [arg_2] [function_1]	count=1
function	a matrix ||| matrix	count=1
function	the url [function_2] ||| [function_2] [function_1]	count=8
class	as in manning and ||| assoc measures	count=1
function	[function_1] pass ||| [function_1] [function_2]	count=3
function	the alignment [function] rate ||| alignment [function]	count=1
function	to ||| parse to	count=1
class	a ||| stepping shift reduce	count=1
arg	return a score ||| other verbose	count=3
class	text ||| reduce parser	count=1
module	about ||| twitter	count=1
function	[function_1] file ||| [function_1] [function_2]	count=3
function	tables to a uniform ||| uniform	count=1
class	the same sentence ||| sentence	count=1
module	the sentence ||| app	count=1
function	tree nodes in ||| nodes	count=1
function	for ||| sample	count=1
class	the moses ||| moses	count=3
function	updating scores the score ||| score	count=1
function	1a from "an ||| step1a	count=1
class	that ||| parser	count=10
function_arg	sort the [arg_2] ||| [arg_2] [function_1]	count=1
class	conditional frequency ||| conditional freq	count=3
class	in particular ||| stepping recursive	count=1
arg	s as a ||| fileids speaker stem relation	count=1
class	this function must ||| app	count=2
class	file identifiers for ||| ycoecorpus reader	count=1
function	past tweets [function_2] ||| [function_2] [function_1]	count=3
class	the ||| freq dist	count=2
arg	sequence of ||| sequence n k	count=1
module_class	text widget [class_2] ||| [module_1] [class_2]	count=4
function	that instantiates ||| variable expression	count=1
function	[function_1] scrollregion ||| [function_1] [function_2]	count=1
arg	frame element ||| frame	count=1
arg	and ||| line primitives families	count=1
class	return ||| lexicon corpus	count=1
class	of the given ||| corpus reader	count=2
class	[class_1] for ||| [class_1] [class_2]	count=1
function	this chart's leaves ||| leaves	count=1
function	list of sentence ||| sentence list	count=3
class	move a token ||| stepping shift reduce parser	count=1
function	temporarily hide ||| hide	count=1
function	given a collection ||| from	count=1
class	tags ||| tagger	count=2
class	return ||| corpus	count=2
class	scores ngrams using ||| ngram assoc	count=3
class	of the remaining text ||| shift	count=1
arg	an exemplar sentence ||| sent aset_level	count=1
function	the [function] ||| calculate [function]	count=1
class	return the chart rule ||| stepping chart	count=1
module	enter ||| app	count=2
arg	list of [arg_2] ||| [arg_1] [arg_2]	count=2
class	frontier in particular ||| recursive descent parser	count=1
class	probability ||| prob dist	count=2
class	if ||| app	count=2
function	lexicographic exemplar sentences ||| exemplars	count=1
arg	the document of ||| document	count=2
class	princeton wordnet ||| word net	count=1
function	the fulltextindex ||| fulltextindex elt	count=1
class	expression to ||| drt lambda expression	count=1
module	appropriate for the ||| sem	count=1
module	for the given speaker ||| corpus reader	count=1
function	tkinter mainloop ||| mainloop	count=6
function	template ||| template	count=1
function	tokenized list ||| list	count=1
class	[class_1] given ||| [class_1] [class_2]	count=1
arg	classifier on 10000 ||| trainer n_instances output	count=1
class	the hypothesized structure ||| edge i	count=1
class	remaining text to ||| shift reduce parser	count=1
class	[class_1] finder ||| [class_1] [class_2]	count=3
class	from contexts to tags ||| context	count=1
class	a corpus ||| corpus reader	count=2
function_arg	[function_1] featureset ||| [function_1] [arg_2]	count=6
function	the corresponding string ||| tuple2str	count=1
class	frontier ||| stepping recursive descent	count=1
function	variety ||| info from	count=1
function_arg	given location is ||| in range location	count=1
class	end of the stack ||| parser	count=1
function	implements step 1c ||| step1c	count=1
arg	be extracted ||| tokens trace	count=2
arg	that cover [arg_2] ||| [arg_2] [arg_1]	count=2
arg	true if x ||| x	count=1
function	given ||| from documents	count=2
class	conditional [class_2] ||| core [class_1] [class_2]	count=2
arg	from consideration given ||| train_sents test_sents	count=1
module	corpus using an appropriate ||| corpus reader	count=1
function_arg	[function_1] given ||| [function_1] plugging plugging [arg_2]	count=1
function	one entity ||| descape entity	count=1
class	dependency ||| probabilistic projective dependency	count=1
class	path ||| path	count=5
function	[function_1] index ||| [function_2] [function_1]	count=6
module	of ||| corpus	count=2
function	index [function_2] ||| [function_1] [function_2]	count=1
class	return ||| corpus reader	count=2
arg	a new edge to ||| edge	count=1
class	of the hypothesized ||| edge i	count=1
function_arg	encoded as [arg_2] ||| [function_1] sents fileids [arg_2]	count=1
function	[function_1] distance ||| [function_2] [function_1]	count=4
class	consistent ||| edge i	count=1
function	binding to ||| bind to	count=3
function	convert a list ||| info from	count=1
function	this chart's sentence ||| leaves	count=1
function	parse multiple ||| tagged parse	count=1
arg	items ||| items	count=1
arg	positive_featuresets a ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
module	alignment model ||| translate	count=1
class	dutch ||| dutch	count=1
function	with the given ||| remove by	count=1
arg	the document ||| document	count=2
function	construct a bigramcollocationfinder ||| init	count=1
function	this is a ||| expression	count=1
arg	of data ||| data start	count=1
class	of this decision tree ||| decision tree	count=1
arg	a new callback that ||| callback	count=1
function	expressions ||| expressions	count=1
function	where the feature ||| feature	count=1
class	return ||| opinion lexicon corpus	count=1
function	to each element of ||| sents	count=1
arg	frame ||| frame frame2	count=1
function_arg	[function_1] tree ||| [arg_2] [function_1]	count=2
arg	string [arg_2] ||| [arg_2] [arg_1]	count=2
function	variety ||| info	count=1
class	[class_1] finder ||| [class_2] [class_1]	count=3
class	given trigram using the ||| trigram	count=1
function	the string representation ||| repr	count=1
class	move ||| shift reduce parser	count=1
function	list of ||| user info from	count=1
function	run [function] within the ||| import [function]	count=1
arg	given subcorpus ||| subcorpus	count=1
function	[function_1] qtree ||| [function_2] [function_1]	count=3
arg	generic a ||| generic word	count=1
module	this canvaswidget ||| draw	count=3
class	sentences in [class_2] ||| [class_1] [class_2]	count=1
arg	expression and ||| expression	count=1
class	ngrams using ||| ngram	count=5
class	generated when parsing a ||| descent parser	count=1
function	a binding to each ||| bind to columns	count=1
module	this set is formed ||| core	count=1
class	to 0 75 ||| kneser ney	count=1
arg	tokens ||| tokens	count=9
class	text [class] ||| string [class]	count=3
class	called ||| parser app	count=1
class	marker value tuple ||| standard format	count=1
arg	highest information content value ||| synset2 ic verbose	count=1
arg	be used to ||| tokens	count=1
function	convert ||| to	count=1
arg	at the given index ||| index	count=1
class	finder ||| finder	count=1
class	from two counters ||| freq	count=1
class	element ||| stepping recursive descent parser	count=1
function	a demonstration of the ||| malt demo	count=1
class	corpus file underlying ||| abstract lazy	count=1
class	tree should ||| chart	count=1
function	parse multiple ||| parse	count=1
function	[function_1] label ||| [function_2] [function_1]	count=7
class	add all edges licensed [class_1] [class_2] edges that are currently ||| [class_2] [class_1]	count=2
arg	file by combining ||| root base_url	count=1
module	the various methods ||| inference	count=2
class	candidate ngrams w1 ||| abstract collocation finder	count=1
arg	frame ||| frame frame2 type	count=1
arg	the symbol ||| symbol	count=1
class	in an ||| corpus reader	count=1
module_class	[module_1] freqdist to ||| [module_1] [class_2]	count=2
function	path [function_2] ||| [function_2] [function_1]	count=1
module	for this canvaswidget ||| draw	count=1
class	lancaster [class_2] ||| [class_1] [class_2]	count=1
function	header as a string ||| header section	count=1
class	frontier in particular if ||| recursive descent parser	count=1
class	in ||| descent	count=1
function	contains a [function_2] ||| [function_2] [function_1]	count=1
function	save a chart ||| save chart	count=2
function_arg	positions in [arg_2] ||| [function_1] [arg_2]	count=1
class	[class_1] based ||| [class_1] [class_2]	count=4
class	remaining text to ||| shift	count=1
class	unicode string ||| unicode stream	count=1
class	this corpus ||| twitter corpus reader	count=1
arg	data bytes to ||| data size	count=2
class	bigram collocation finder ||| trigram collocation finder	count=1
function	synsets ||| synsets	count=1
function	of information about ||| user info	count=1
class	particular if ||| recursive	count=1
class	of the inside probabilities ||| inside chart	count=1
arg	stream and ||| stream	count=1
function	dict ||| dict	count=1
class	the mutable probdist ||| mutable prob dist	count=1
class	the sequence with the ||| model tagger	count=1
arg	which match the given ||| search_leaves	count=1
class	[class_1] weights ||| [class_2] [class_1]	count=8
function	poisson-stirling ||| poisson stirling	count=1
function	node [function] ||| tgrep node [function]	count=1
arg	at the terminal ||| inputfilename outputfilename mode	count=1
module_class	return true ||| core feat	count=1
module	name ||| corpus	count=1
arg	a symbol when ||| symbol	count=1
function	group ||| group	count=1
function	be the top ||| find top	count=1
module	this ||| sem	count=2
class	which indicates ||| edge	count=1
function	left-hand side which ||| lhs	count=1
function	this edge's left-hand side ||| lhs	count=1
arg	a sequence of items ||| sequence n k	count=1
function	the [function] node ||| [function] node literal	count=1
function	arcs ||| redirect arcs	count=1
arg	boxer_drs_interpreter a ||| boxer_drs_interpreter	count=1
function	six patterns and ||| pro w6	count=2
class	iso 639-3 ||| crubadan	count=2
function	score of the highest-weighted ||| score	count=1
function_arg	lists for [arg_2] ||| [arg_2] [function_1]	count=1
function	flatten a list ||| flatten	count=1
class	xml element in ||| framenet corpus reader	count=1
function	upper frame ||| static upper	count=1
class	with ||| hidden markov model	count=1
function	identifiers for the fileids ||| fileids	count=1
class	:see [class_2] ||| [class_1] [class_2]	count=3
class	enter the ||| chunk app	count=1
function	entries ||| size	count=1
class	positive ||| corpus reader	count=1
arg	copy the given resource ||| resource_url	count=1
module	this corpus ||| corpus	count=5
arg	defaultdict if strings ||| strings	count=1
function	entries ||| entries	count=1
function	f-measure ||| f measure	count=1
arg	or ||| fileids categories	count=1
class	words in alphabetical ||| reader	count=1
class	text to the ||| stepping	count=1
module	a valuation from a ||| sem	count=1
arg	frame optional frame ||| frame	count=1
function	out the string representation ||| repr	count=1
class	reader with the ||| reader	count=1
class	is ||| punkt trainer	count=2
arg	patterns ||| grammar root_label loop	count=1
function_arg	ending step [arg_2] ||| [arg_2] [function_1]	count=4
function	check whether ||| check	count=1
arg	is the maximum of ||| other	count=2
function	to construct a value ||| construct threads	count=1
function	tree positions in the ||| positions	count=1
module	then [module] a tuple ||| [module]	count=2
function	of words/sentences ||| views	count=1
class	probdist ||| lidstone prob dist	count=1
function	not absolute [function] that it ||| [function]	count=1
arg	be ||| tokens	count=3
class	file ||| abstract	count=1
function	assumes that each line ||| read tweets	count=1
function	step 5a from ||| step5b	count=1
function	most frequent [function] contexts first ||| [function]	count=1
function	is beginning a sentence ||| is	count=1
class	in the same sentence ||| punkt sentence	count=1
class	corpus view that acts ||| nombank corpus	count=1
function	tagger to a file ||| tagger	count=1
class	function must be ||| chunk app	count=1
function	the various methods ||| drt discourse demo	count=1
class	this rule it has ||| chunk rule with context	count=1
class	the dict if its ||| binding dict	count=1
arg	word ||| word	count=23
class	chart rule used ||| chart parser	count=1
class	underlying this corpus view ||| lazy sequence	count=1
class	distribution in ||| dist	count=1
class	the tree ||| chart	count=1
function	:return the log probability ||| logprob	count=1
function	the logged values returning ||| log	count=1
function	bleu [function_2] ||| [function_2] [function_1]	count=4
module	of abstractvariableexpression appropriate ||| sem	count=1
arg	that s ||| s	count=1
function_arg	[function_1] [arg_2] ||| [function_1] lemmas [arg_2]	count=9
arg	[arg_1] string and ||| [arg_2] [arg_1]	count=6
class	return ||| i	count=1
function	_tag_positions to reflect the ||| positions	count=1
class	child's parent will ||| stack	count=1
class	[class_1] that can ||| [class_2] [class_1]	count=8
function	a timer decorator ||| timer	count=1
module	name of ||| reader	count=1
class	collocation finder ||| collocation finder	count=2
function_arg	[function_1] grammar ||| [function_1] [arg_2]	count=3
class	remaining ||| stepping shift reduce parser	count=1
function	the left ||| left	count=1
function	a sequence yields each ||| sequence	count=1
class	function ||| chart parser app	count=1
class	corpus ||| nombank corpus	count=3
function	of two texts ||| align texts	count=2
class	the brill ||| brill	count=1
module	a ||| parse	count=2
class	returns ||| nkjpcorpus	count=3
function	a vowel else false ||| vowel	count=1
class	in alphabetical order ||| lexicon	count=1
arg	a sentence as ||| sentence	count=1
function	target sentence and ||| t a	count=4
class	for the ||| nombank corpus reader	count=1
function	a [function] for the ||| [function]	count=1
function	pop [function_2] ||| [function_2] [function_1]	count=3
arg	frame element objects if ||| frame	count=1
class	big the ||| chart	count=1
class	a feature ||| feat	count=3
function	returns a decorator ||| decorator	count=1
function	[function_1] tag ||| [function_1] [function_2]	count=2
class	a pickle ||| pickle	count=1
arg	synset and ||| synset	count=1
function	features each ||| features	count=1
arg	the given synset and ||| synset	count=1
function	process length six patterns ||| pro w6	count=1
class	underlying stream ||| seekable unicode stream reader	count=1
class	for this sentence boundary ||| punkt sentence tokenizer	count=1
module	by this ||| parse	count=2
function_arg	stem [arg_2] ||| [function_1] [arg_2]	count=3
function	java binary and ||| config java	count=1
function	[function_1] to each ||| [function_1] [function_2]	count=2
class	match ||| descent parser	count=1
function	method ||| expression	count=1
class	words in alphabetical ||| corpus reader	count=1
class	the first element ||| stepping recursive descent	count=1
class	a projective [class_2] ||| [class_2] [class_1]	count=1
class	function must ||| chunk	count=1
class	canvas [class] and ||| canvas [class]	count=1
function	[function_1] in ||| [function_2] [function_1]	count=3
class	initializer should ||| probabilistic mix in	count=1
function	relation table into ||| relation	count=1
function_arg	[function_1] probabilistic parsers ||| [function_1] [arg_2]	count=2
class	the first element of ||| descent parser	count=1
class	of the hypothesized structure ||| edge i	count=1
class	feature structures ||| feat struct	count=1
class	file ||| gzip file	count=1
class	structure that ||| struct	count=1
class	this rule it ||| rule with	count=1
class	import the module ||| lazy module	count=1
function	a text generates the ||| from	count=1
class	dictionary containing the ||| dictionary	count=1
arg	string ||| s	count=10
arg	model_found() ||| found	count=1
function_arg	a category [arg_2] ||| [arg_2] [function_1]	count=4
arg	and punctuation [arg_2] ||| [arg_2] [arg_1]	count=1
class	counts [class_2] ||| [class_2] [class_1]	count=4
function	rules ||| rules	count=3
class	corpus ||| corpus reader	count=28
class	frequency distribution ||| good turing prob dist	count=1
function	pearson's chi-square ||| chi sq	count=1
function	illustrate the various ||| drt	count=1
class	of all ||| comparative	count=1
function	set of rules ||| rules	count=1
arg	domain of a valuation ||| valuation lexicon	count=1
module	consistent with the ||| parse	count=1
class	the neural [class_2] ||| [class_1] [class_2]	count=5
class	and return that ||| sequential backoff	count=1
function	sets ||| sets	count=1
arg	and punctuation symbols encoded ||| fileids speaker stem	count=1
function	a variety of information ||| from	count=1
class	single ||| corpus reader	count=1
function	[function_1] there ||| [function_2] [function_1]	count=1
arg	corpus train_toks ||| cls train_toks count_cutoff labels	count=1
function	a userid to ||| by userid	count=1
class	this tagger to map ||| tagger	count=1
function	the use of ||| use	count=1
class	russian ||| russian	count=2
arg	given text if finalize ||| text verbose finalize	count=1
module	return this ||| parse	count=1
class	by this rule ||| rule i	count=2
class	in the given language ||| corpus reader	count=1
function_arg	[function_1] [arg_2] ||| [function_1] word_fd [arg_2]	count=4
arg	sequence of data ||| data	count=1
class	files that have to ||| reviews	count=1
function	write out a ||| show	count=1
arg	text this ||| tokens	count=1
function	convert a list ||| user info	count=1
module_class	[module_1] canvasframe ||| [module_1] [class_2]	count=14
class	table's ||| table	count=3
class	information about the ||| query	count=1
class	opinion lexicon note that ||| opinion lexicon	count=1
function	citation bib file for ||| citation	count=1
function	elementtree _elementinterface ||| elementtree	count=1
function	new ||| init	count=41
function	the model ||| model	count=2
class	this function must be ||| parser app	count=1
arg	input expression to ||| assumptions timeout	count=1
class	chart rule used to ||| chart	count=1
class	'tree position' [class] given that ||| [class]	count=2
class	this function ||| chunk	count=1
class	set to 0 75 ||| kneser ney prob	count=1
function	given a collection of ||| from documents	count=1
module	in ||| tbl	count=1
function_arg	recent tweets [arg_2] ||| [arg_2] [function_1]	count=2
function_arg	alignments [arg_2] ||| [function_1] [arg_2]	count=6
arg	reference that is ||| references hyp_len	count=1
function	top of the formula ||| find top	count=1
function_arg	the beginning [arg_2] ||| [function_1] stack [arg_2]	count=3
class	a probabilisticdependencygrammar ||| parser	count=1
class	mapping each context to ||| context index	count=1
class	dictionary ||| mace command	count=1
class	parsing a ||| reduce parser	count=1
function	name ||| name	count=1
class	finnish ||| finnish stemmer	count=1
function	token from the beginning ||| shift	count=2
class	internal ||| framenet corpus	count=1
arg	text ||| tokens	count=1
class	tags the ||| markov model tagger	count=1
class	pickle ||| app	count=1
function	string representation ||| str	count=1
function_arg	read up [arg_2] ||| [function_1] [arg_2]	count=4
function	a raw string ||| raw	count=1
arg	for a text ||| text	count=1
function	to the chunk ||| chunk	count=1
function	:return beta-converted version ||| simplify	count=1
function	[function_1] chart's leaves ||| [function_2] [function_1]	count=1
module	information ||| twitter	count=1
class	that is licensed ||| descent parser	count=1
function	determine an ||| one	count=1
class	figure ||| chart view	count=1
module	out ||| app	count=1
class	in this chart ||| feature chart	count=1
class	bigram ||| bigram collocation	count=1
function_arg	[function_1] given user ||| [arg_2] [function_1]	count=5
class	if a feature ||| feat	count=1
function_arg	[function_1] of documents ||| [arg_2] [function_1]	count=1
module	build the ||| reader	count=1
function	for word ||| word	count=1
arg	return a list of ||| fileids	count=1
class	this expression ||| expression	count=1
arg	file from the wordnet_ic ||| icfile	count=1
arg	word of ||| word	count=1
arg	for the sentence ||| sentence	count=1
function	conjunction ||| conjunction	count=1
arg	uses ||| strategy trace trace_chart_width	count=1
arg	and ||| fileids speaker stem	count=1
function	main frame ||| grid	count=1
function	next best [function_2] ||| [function_1] [function_2]	count=4
module	return a ||| corpus	count=1
function	[function_1] tokenization ||| [function_2] [function_1]	count=3
module_class	by this [class_2] ||| [module_1] canvas [class_2]	count=1
class	this ||| glue	count=1
arg	given list of fileids ||| fileids	count=1
function	remove all objects from ||| clear	count=1
class	set to 0 75 ||| kneser ney	count=1
class	a dictionary containing ||| dictionary conditional prob	count=1
function_arg	[function_1] alignment ||| [function_1] a given s [arg_2]	count=2
class	appears [class] ||| [class]	count=1
arg	input expression ||| assumptions prover	count=2
class	indexes ||| framenet	count=1
arg	tagged sentence into ||| sentence	count=1
arg	specified entry ||| entry	count=1
class	to be overridden ||| drt	count=1
function	positions ||| tgrep positions	count=1
class	from ||| shift reduce parser	count=1
arg	s [arg_2] ||| [arg_2] [arg_1]	count=1
function	cache ||| cache	count=1
function	top-lebel node in ||| exprs action	count=1
class	heldout estimate to ||| heldout	count=1
arg	of rows ||| rows cols	count=1
function	a list ||| user info from id	count=1
arg	binary with the ||| binary	count=1
function	of chunks each of ||| chunks	count=1
class	depth ||| text tiling tokenizer	count=1
module	the sequence ||| tag	count=1
arg	given part of speech ||| pos simulate_root	count=1
class	there is a substitution ||| ccgvar	count=1
class	this ||| regexp	count=1
function	standard interpretations ||| r1r2 standard	count=1
class	a token from the ||| stepping shift reduce	count=1
arg	set of productions ||| productions	count=1
arg	[arg_1] by ||| [arg_2] [arg_1]	count=1
arg	of the penn treebank ||| nx	count=1
module	indicates how much ||| parse	count=1
class	bigram collocation finder ||| trigram collocation	count=1
function	cache is ||| cache	count=1
function	up the macro name ||| macro	count=1
class	distribution ||| prob dist	count=1
arg	[arg] preserve ||| fstruct [arg]	count=2
arg	graph ||| graph	count=3
module	alphabetical order ||| corpus reader	count=1
class	in ||| lexicon corpus reader	count=1
function	assumes that ||| read tweets	count=1
arg	demon ||| t	count=1
arg	of remaining_text ||| remaining_text	count=1
arg	[arg_1] index ||| [arg_1] [arg_2]	count=1
arg	by only testing candidate ||| realign_boundaries	count=1
class	configure ||| chart view	count=1
class	:param ||| binding dict	count=1
class	samples ||| turing prob dist	count=1
function	perform the first pass ||| first pass	count=1
arg	s as a list ||| fileids tag	count=1
arg	temporary file as a ||| delete_on_gc	count=1
class	[class_1] corpus or ||| [class_2] [class_1]	count=2
arg	drawing the [arg_2] ||| [arg_2] [arg_1]	count=2
arg	from a ||| srctext trgtext	count=1
class	dictionary ||| dict	count=1
class	tag ||| tag	count=1
arg	[arg_1] and relation ||| [arg_1] [arg_2]	count=3
class	displaying ||| recursive descent parser	count=1
class	update the parent ||| parented tree	count=2
class	enter the ||| drt glue	count=1
class	vector of joint-feature ||| maxent feature	count=1
module	instance's predicate ||| corpus	count=1
class	scores [class_2] ||| [class_2] [class_1]	count=6
function	count ||| count	count=1
function_arg	[function_1] and relation ||| [arg_2] [function_1]	count=1
class	function must ||| regexp chunk app	count=1
arg	of stack ||| stack	count=1
arg	luname frameid and ||| ignorekeys luname frameid	count=1
class	classifier [class_2] ||| [class_2] [class_1]	count=3
class	other logic parsers ||| logic	count=1
function	convert a list ||| from	count=1
function_arg	[function_1] translating the ||| [function_1] [arg_2]	count=3
class	based on the ||| based	count=1
function	the ||| from id	count=1
class	as iso 639-3 ||| corpus reader	count=1
arg	matches tagspec, and ||| tagspec elt_handler	count=1
module	end of the stack ||| parse	count=1
function_arg	[function_1] offset ||| [arg_2] [function_1]	count=2
class	of the ||| nombank instance	count=1
function	is [function_2] ||| [function_1] [function_2]	count=5
arg	the binary ||| binary	count=1
class	the lancaster stemmer ||| lancaster stemmer	count=2
class	base frequency ||| dist	count=1
class	of this rule it ||| rule with	count=1
class	values of a quadgram ||| quadgram	count=1
arg	specified by save_classifier ||| save_classifier	count=1
function	implements step 1a from ||| step1a	count=1
class	in a ||| corpus reader	count=1
module	be how big ||| app	count=1
arg	of tokens ||| tokens tags	count=1
function	from a subcorpus ||| handle lusentence	count=1
module	for ||| corpus reader	count=10
class	counts from two conditionalfreqdists ||| conditional freq dist	count=1
function	the [function] of ||| [function]	count=2
module_class	opened [class_2] ||| [module_1] [class_2]	count=4
module_class	pickle [class_2] ||| [module_1] pickle [class_2]	count=4
arg	modelbuilder the theorem tool ||| modelbuilder	count=1
arg	possible ways of plugging ||| ancestors0 queue potential_labels0	count=1
arg	of data ||| data start end	count=1
class	for this sentence ||| sentence tokenizer	count=1
function	subcorpus of an lu ||| handle lusentence	count=1
module	words in ||| corpus	count=1
function	log ||| logprob	count=1
function	[function_1] the shortest ||| [function_2] [function_1]	count=2
function	for ||| repr	count=1
module	string value [module] an ||| corpus [module]	count=1
class	to a list's ||| pretty lazy	count=1
class	first element of ||| stepping	count=1
class	if hack=true ||| cooper	count=1
function	left sibling ||| left sibling	count=1
class	a list ||| query	count=1
function	a userid to ||| userid	count=1
function	:param c ||| init	count=1
function_arg	[function_1] a sequence ||| [arg_2] [function_1]	count=4
class	the remaining text ||| parser	count=1
function	a dictionary of unigram ||| unigram	count=1
class	this ||| demo	count=1
function_arg	[function_1] quadgramcollocationfinder ||| [function_1] word_fd [arg_2]	count=1
class	the end ||| stepping shift reduce	count=1
class	bounding ||| canvas widget	count=1
function	applies ||| rule applies	count=1
class	end ||| stepping	count=1
class	of the remaining ||| stepping	count=1
class	corpus ||| nombank corpus reader	count=2
module_class	this canvas ||| draw canvas	count=6
function	leacock chodorow similarity ||| lch similarity	count=2
function_arg	the beginning [arg_2] ||| [arg_2] [function_1]	count=4
function	s-expressions from the ||| sexpr block	count=1
class	from a sentence in ||| corpus reader	count=1
arg	of documents each ||| documents	count=1
function	binding operators [function_2] ||| [function_2] with [function_1]	count=1
class	in this corpus or ||| timit corpus reader	count=1
class	[class_1] rule given ||| [class_2] [class_1] apply everywhere chart grammar	count=1
function	words and punctuation symbols ||| words	count=8
class	this corpus ||| category corpus reader	count=1
arg	configure the table cell ||| cnf	count=1
class	build ||| corpus	count=1
function	userid ||| lookup by userid	count=1
module	various methods of ||| inference	count=2
arg	configure the table ||| cnf	count=1
arg	in alignment_info, ||| alignment_info	count=1
function	sentence ||| sentence	count=2
function	to each element of ||| tokenize sents	count=1
function_arg	[function_1] labels a ||| [function_1] [arg_2]	count=2
class	of the given ||| framenet corpus reader	count=1
function	about the users ||| user	count=1
class	this probability distribution ||| core prob dist	count=1
function	probability of target sentence ||| prob t a	count=2
class	that can ||| parser	count=2
class	pointer pointing at ||| pointer	count=1
function	is a left corner ||| leftcorner parents	count=1
class	parsing a text ||| viterbi parser	count=2
function	search for ||| search demo	count=1
arg	input expression ||| assumptions	count=5
class	neural dependency ||| stanford neural dependency	count=2
function	that instantiates and returns ||| variable	count=1
function	a dictionary of ||| dict	count=1
arg	a given text ||| text	count=1
function	base ||| base fdist	count=1
class	the hypothesized ||| i	count=1
class	calculates ||| assoc measures	count=2
class	of all verb ||| verbnet corpus reader	count=1
module	languages as ||| reader	count=1
arg	[arg_1] look up ||| [arg_1] [arg_2]	count=1
arg	to csv ||| outfile	count=1
function	[function_1] concept out ||| [function_1] [function_2]	count=1
class	the sequence with ||| hidden markov model	count=1
class	resulting list ||| base class	count=1
function_arg	annotated sentences [arg_2] ||| [function_1] [arg_2]	count=1
arg	creates the ||| source_blocks target_blocks	count=1
function	exemplar sentences optionally filtered ||| exemplars	count=1
function	bounding box for ||| bbox	count=1
module_class	of [class_2] ||| [module_1] [class_2]	count=2
class	text contents of ||| senseval corpus	count=1
arg	a quadgramcollocationfinder given freqdists ||| quadgram_fd ii iii	count=1
arg	of the correction ||| labels mapping unseen_features alwayson_features	count=1
function_arg	indent [arg_2] ||| [function_1] [arg_2]	count=1
function	megam based ||| megam	count=1
class	of the ||| edge	count=1
function	:return the dendrogram ||| dendrogram	count=1
function	top-lebel node in a ||| tgrep exprs action	count=1
class	tree ||| tree	count=22
function	the euclidean distance ||| euclidean distance	count=2
class	big the tree should ||| chart view	count=1
module	methods of ||| inference	count=2
function	methods of ||| drt	count=1
function	words or a list ||| words	count=1
class	move a ||| shift reduce parser	count=1
class	function ||| app	count=2
module	corpus that [module] model ||| [module]	count=2
function	probability state sequence ||| tag	count=1
class	tree in ||| tree	count=1
module_class	[module_1] non-terminal ||| [module_1] [class_2]	count=2
class	file ||| buffered gzip file	count=1
function	display a friendly error ||| error	count=1
class	return lemmas [class_2] ||| [class_2] [class_1]	count=1
function	the java binary and ||| java	count=1
class	element of the ||| stepping recursive	count=1
function	returns a view ||| view	count=1
class	parsing a text ||| shift reduce parser	count=1
class	trie ||| trie	count=1
class	french ||| french	count=1
class	in alphabetical order ||| lexicon corpus reader	count=1
function	from the beginning ||| shift	count=2
class	be ||| chart view	count=2
function	rare [function_2] ||| [function_1] [function_2]	count=2
class	the mutable probdist based ||| mutable prob dist	count=1
class	this ||| edge	count=1
module	illustrate the ||| inference	count=2
arg	limit the number of ||| limit	count=1
function	tags the ||| tag	count=1
module_class	[module_1] synset ||| [module_1] [class_2]	count=2
class	in the chart ||| chart	count=1
class	tags the sequence with ||| markov	count=1
class	the overall ||| chunk score	count=2
function	[function] string ||| [function]	count=2
arg	make sure that s ||| s verify_tags	count=1
class	combine ||| reading command	count=1
function	[function_1] rule ||| [function_1] [function_2]	count=3
class	[class_1] [class_2] a ||| [class_2] [class_1]	count=2
function	helper ||| fe	count=1
class	classify ||| sentiment analyzer	count=1
class	corpus ||| pros cons corpus	count=1
function	[function_1] to ||| [function_2] [function_1]	count=4
class	a dictionary containing ||| dictionary	count=1
arg	tuple representation of ||| tagged_token sep	count=1
arg	specified entry [arg_2] ||| [arg_2] [arg_1]	count=2
arg	similarity matrix s ||| s s	count=1
function	as a single ||| raw	count=1
function	six ||| w6	count=1
class	would be more ||| map	count=1
arg	for ||| winlens excludezero	count=1
function	features each feature ||| features	count=1
function	of ||| user	count=2
function	lists for the ||| lists	count=1
function	interpretations of the ||| r1r2	count=1
function	primitive is [function_2] ||| [function_2] [function_1]	count=1
function	md5 checksum for a ||| md5 hexdigest	count=1
arg	every instance [arg] with ||| [arg]	count=1
function_arg	[function_1] numsamples x ||| [arg_2] [function_1]	count=3
class	[class_1] this pointer ||| [class_2] [class_1]	count=2
function	epytext @field ||| epytext	count=1
arg	to ||| key	count=1
class	in particular ||| recursive	count=1
arg	any [arg] has ||| [arg] forward fs_class	count=1
class	error-rate relative ||| paice	count=1
arg	of suffix-removal rules represented ||| rules	count=1
function	adjust the [function_2] ||| [function_2] [function_1]	count=1
arg	cover [arg_2] ||| [arg_2] [arg_1]	count=2
function	the upper frame page ||| static upper page	count=1
function	the cached ||| setitem	count=1
class	detokenizer ||| detokenizer	count=1
arg	drawing [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	target sentence [arg_2] ||| [arg_2] [function_1]	count=2
arg	consideration given ||| rule train_sents test_sents	count=1
arg	distance of each node ||| distance simulate_root	count=1
function	sequence with ||| tag	count=1
arg	assigns the vectors ||| vectors assign_clusters	count=3
function	into a dictionary ||| make	count=1
function	variety of information ||| user info	count=1
arg	positions ||| positions	count=1
arg	association measure ||| measures	count=1
function	[function_1] tadm based ||| [function_2] [function_1]	count=6
function_arg	tweets [arg_2] ||| [arg_2] [function_1]	count=2
function	an [function] node specified ||| [function]	count=1
function	the cache ||| cache	count=1
module	as ||| corpus	count=2
function	is a ||| expression	count=1
function	feature ||| feature	count=2
function	appropriate ||| expression	count=1
arg	the original text and ||| text	count=1
function	this ||| variable expression	count=1
arg	[arg] beginning with ||| [arg]	count=1
class	romanian ||| romanian stemmer	count=1
class	a collocation [class_2] ||| [class_1] [class_2]	count=1
class	iso 639-3 ||| crubadan corpus	count=1
class	all ||| reader	count=1
arg	implement the view ||| fileid bracket_sent tag strip_space	count=1
function	target ||| a	count=2
arg	pre-trained ||| model_filename	count=1
class	element ||| stepping recursive descent	count=1
class	feature of the ||| feature chart	count=1
function_arg	a string [arg_2] ||| [arg_2] [function_1]	count=4
class	probability state sequence ||| model tagger	count=1
class	invalidate the cached n ||| dist	count=1
function	first expression that ||| first	count=1
class	moses tokenizer ||| moses tokenizer	count=2
class	figure out ||| chart	count=1
function	an integer begins ||| int	count=1
class	set ||| probabilistic mix in	count=1
arg	part of speech ||| pos simulate_root	count=1
arg	variable v with ||| variable	count=3
arg	expression ||| expression command x	count=1
arg	target of its forward ||| forward fs_class	count=1
function	of bigram [function_2] ||| [function_1] [function_2]	count=3
function	build a nltk sem ||| build	count=1
function	new index for a ||| add index	count=1
function	upper frame [function_2] ||| [function_1] [function_2]	count=2
arg	specified [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
function	representing a [function_2] ||| [function_2] [function_1]	count=1
class	a text returns ||| punkt	count=1
function	that ||| iter	count=1
function	plausible semtypes ||| get semtypes	count=1
module	build the internal ||| corpus reader	count=1
class	a single parsing ||| parser	count=1
module	the internal indexes to ||| corpus reader	count=1
class	into the table so ||| table	count=1
arg	dependencygraph graph ||| graph	count=1
class	to ||| logic parser	count=2
function	main frame widget ||| grid	count=1
class	into the table ||| table	count=1
class	unicode encoding [class] ||| corpus [class]	count=1
module	instantiates and returns a ||| sem	count=1
arg	phrase_table table of ||| phrase_table language_model	count=1
class	return lemmas [class_2] ||| [class_1] [class_2]	count=1
class	from ||| stepping shift reduce parser	count=1
class	tokenizer binary ||| tokenizer	count=1
class	element of the ||| stepping recursive descent	count=1
function	convert a ||| info from id	count=1
arg	input string ||| input encoding	count=1
function	use of ||| pred use	count=1
class	must be called ||| app	count=2
module_class	[module_1] frequency ||| [module_1] [class_2]	count=2
function	of speech ||| pos	count=1
arg	training ||| verbose	count=1
arg	of speech ||| pos simulate_root	count=1
arg	document ||| document	count=3
class	a unicode ||| unicode	count=1
function	tkinter mainloop this function ||| mainloop	count=3
function	load a subcorpus ||| lusubcorpus	count=1
class	with ||| markov model	count=1
arg	document of each ||| document	count=2
class	an iterator ||| abstract	count=1
arg	of segmentations a ||| seg1 seg2 k boundary	count=1
module	build the internal indexes ||| corpus reader	count=1
arg	given start ||| start	count=2
class	chart rule used ||| stepping chart parser	count=1
arg	drtindividualvariableexpression for the ||| consequent	count=1
function_arg	[function_1] [arg_2] ||| [function_1] file [arg_2]	count=1
function	create ||| create	count=1
function	returns a subtype of ||| variable expression	count=1
class	tags the sequence ||| model	count=1
arg	creates ||| weight_senses_equally smoothing	count=1
arg	[arg] the ||| tokens index [arg]	count=3
class	i e ||| i	count=6
class	of the stack ||| shift	count=1
arg	matrix s [arg_2] ||| [arg_2] [arg_1]	count=1
function	label ||| label pred	count=1
module	supported languages as iso ||| corpus reader	count=1
arg	can be ||| tokens	count=1
class	token from ||| stepping shift	count=1
function	checksum for a given ||| hexdigest	count=1
function	callback used to resize ||| resize	count=1
module_class	[module_1] tree that ||| [module_1] [class_2]	count=2
function	url for the ||| get url	count=2
class	element ||| element	count=1
arg	t in ||| s t	count=1
class	this function ||| chart parser	count=1
function	bigram [function_2] ||| [function_2] [function_1]	count=3
arg	file s ||| fileids strip_space	count=1
function	[function_1] chunk ||| [function_1] [function_2]	count=2
arg	augmented word tokens construct ||| tokens	count=1
function_arg	read from [arg_2] ||| [arg_2] [function_1]	count=4
module_class	[module_1] canvasframe the ||| [module_1] [class_2]	count=1
arg	various methods of discoursetester ||| reading_command	count=2
arg	of word ||| speaker stem	count=1
arg	[arg_1] list ||| [arg_1] [arg_2]	count=1
function	entity to ||| entity	count=1
class	set of all ||| comparative	count=1
arg	title the title ||| title review_lines	count=1
arg	neighbors ||| j_pegged	count=1
arg	be trained ||| trained n	count=1
function	[function] lexical ||| [function]	count=1
module_class	of this canvasframe ||| draw canvas frame	count=1
function_arg	[function_1] earley parsers ||| [arg_2] [function_1]	count=2
class	a corpus view ||| corpus	count=2
function	score of the ||| score	count=1
module	probability state sequence ||| tag	count=1
function	the various ||| drt discourse demo	count=1
arg	list of tokens using ||| tokens	count=1
function	from the conjunction of ||| conjunction	count=1
arg	s as ||| fileids tag	count=1
function	string representing ||| aug	count=1
function_arg	[function_1] vector ||| [arg_2] [function_1]	count=2
arg	located at the ||| fileids word_tokenizer sent_tokenizer	count=1
function	of sentences each ||| sents	count=4
arg	devset_name the ||| devset_name	count=1
function	find ||| find	count=2
function	md5 checksum for ||| md5 hexdigest	count=1
class	tree or none ||| tree	count=2
arg	a synset note ||| synset	count=1
function	run [function] within ||| import [function]	count=1
class	because the neural ||| neural	count=1
module	a single corpus ||| corpus reader	count=1
function	from a subcorpus of ||| lusentence	count=1
function_arg	:param boxer_drs_interpreter ||| init boxer_drs_interpreter	count=1
class	up the colorized ||| colorized	count=1
function	demonstration showing ||| rule parse demo	count=1
function_arg	given training [arg_2] ||| [arg_2] [function_1]	count=2
class	a new iterator ||| lazy iterator	count=1
class	from contexts ||| context	count=1
class	token from ||| shift	count=1
function	valuation file ||| valuation	count=1
arg	parses a string ||| string	count=1
function	add ||| push	count=1
arg	index the index ||| index depth	count=1
function	1a from "an algorithm ||| step1a	count=1
function	synset ||| synset	count=1
function	top-lebel node ||| exprs	count=1
arg	train and test ||| trainer save_analyzer n_instances output	count=1
class	by [class_2] ||| [class_2] [class_1] apply chart grammar	count=3
function	unique counter from ||| get unique counter from	count=1
class	must ||| chart parser app	count=1
class	[class_1] matrix ||| [class_2] [class_1]	count=4
function	list of nodes ||| collapse nodes	count=1
class	function must be ||| glue	count=1
class	be called if ||| parser app	count=1
function	left children ||| left children	count=1
class	the chart rule ||| stepping chart parser	count=1
function	section for the ||| section	count=1
arg	discoursetester ||| input reading_command background	count=1
class	this ||| drt glue demo	count=1
class	use simple ||| simple	count=1
module	nltk corpus import ||| corpus reader	count=1
class	be called if ||| demo	count=1
function_arg	[function_1] of *regexp* ||| [arg_2] [function_1]	count=1
function	[function_1] the longest ||| [function_2] [function_1]	count=2
function	of ||| user info	count=2
arg	string ||| s chunk_label root_label	count=1
class	token from ||| stepping	count=1
class	build the ||| framenet corpus reader	count=1
function	information about the users ||| user info from	count=1
function	convert a ||| user	count=1
class	encoding [class] ||| corpus [class]	count=1
class	[class_1] distribution ||| [class_2] [class_1]	count=23
class	function must be ||| drt glue	count=1
class	to invalidate the ||| freq dist	count=1
function	from the fulltextindex xml ||| fulltextindex	count=1
function	tree ||| to tree	count=1
class	the end of the ||| reduce	count=1
class	be ||| regexp chunk app	count=1
class	of the frontier in ||| stepping recursive descent parser	count=1
function	illustrate the various methods ||| drt	count=1
class	[class_1] file ||| [class_1] [class_2]	count=3
module_class	this tree ||| core tree	count=1
function	hierarchical parent ||| parent	count=1
arg	freqdist ||| freqdist gamma	count=1
class	[class_1] tagger on ||| [class_2] [class_1]	count=2
module	value [module] an rte ||| corpus [module]	count=1
class	[class] file if ||| [class]	count=3
function_arg	:param estimator ||| init estimator	count=1
function	data xml index ||| build index	count=1
arg	s as a ||| fileids tag	count=1
arg	the given directory ||| root encoding	count=1
function	[function_1] target sentence ||| [function_1] [function_2]	count=2
class	of supported languages ||| crubadan corpus reader	count=1
arg	pretty-printed [arg_2] ||| [arg_1] [arg_2]	count=3
arg	[arg_1] can all ||| [arg_2] [arg_1]	count=1
function	of two [function_2] ||| [function_1] [function_2]	count=1
function	variety of ||| info	count=1
function	build a nltk ||| build	count=1
function	multiple pos tagged ||| tagged	count=1
module	supported ||| corpus	count=1
function	rank alignment ||| rank alignment	count=2
class	color ||| chart view	count=1
function_arg	[function_1] given file ||| [function_1] [arg_2]	count=3
function	list of nodes ||| nodes	count=1
class	for this encoding ||| feature encoding	count=2
arg	the current round ||| upper_date_limit lower_date_limit	count=1
function	values return the fraction ||| precision	count=1
arg	tuple representation of a ||| tagged_token sep	count=1
arg	word tag ||| speaker stem	count=1
class	tagger to map ||| tagger	count=1
class	when [class_2] ||| [class_1] [class_2]	count=2
class	a list's ||| abstract lazy sequence	count=1
class	of supported languages as ||| crubadan corpus	count=1
function	past tweets by ||| tweets by user demo	count=1
class	this function ||| drt glue demo	count=1
function	a learning curve -- ||| learning curve	count=1
class	sentence breaks ||| punkt sentence	count=1
arg	[arg_1] [arg_2] the ||| [arg_1] index [arg_2]	count=3
module	this instance's predicate ||| corpus reader	count=1
function	method that instantiates and ||| variable	count=1
class	enter ||| glue	count=1
class	in this chart ||| chart	count=1
function	word ||| is head word	count=1
class	bounding boxes of all ||| scroll watcher widget	count=1
function	[function_1] parse ||| [function_2] with [function_1]	count=1
module	[module] between p ||| [module]	count=1
class	corpus file underlying this ||| lazy sequence	count=1
class	of this rule it ||| chunk rule with	count=1
arg	[arg] executable ||| path_to_model [arg]	count=2
function	top-lebel ||| tgrep exprs action	count=2
arg	be trained ||| unk trained n c	count=1
function_arg	[function_1] [arg_2] takes between _eval_demon_min and ||| [function_1] [arg_2]	count=8
function_arg	[function_1] fit ||| [arg_2] [function_1]	count=1
module	it ||| chunk	count=1
class	pointer in ||| pointer	count=1
function	six patterns and extract ||| pro w6	count=1
class	to a list's ||| pretty lazy iterator list	count=1
class	in ||| recursive	count=1
function	method that instantiates and ||| expression	count=1
function	http //stackoverflow ||| synset from pos and offset	count=1
class	of a quadgram ||| quadgram	count=1
function	license file if it ||| license	count=1
module	display ||| app	count=1
function	of all [function_2] ||| [function_1] [function_2]	count=2
class	text contents ||| senseval corpus reader	count=1
class	particular if ||| stepping recursive	count=1
class	the zip file ||| core zip file	count=1
arg	quadgramcollocationfinder given freqdists ||| quadgram_fd ii iii	count=1
class	cross-validation estimate to ||| cross validation	count=1
arg	input ||| input encoding	count=1
arg	positive_featuresets a ||| positive_featuresets unlabeled_featuresets	count=1
module_class	[module_1] feature with ||| [module_1] [class_2]	count=2
arg	s as a ||| fileids	count=18
module_class	the twitter api ||| twitter streamer	count=1
arg	otherwise [arg] included ||| [arg]	count=1
arg	name the name ||| name	count=1
function	abbreviation ||| abbrev	count=2
class	return the chart rule ||| chart parser	count=1
module_class	[module_1] an iterator ||| [module_1] [class_2]	count=2
class	because the neural dependency ||| neural dependency	count=1
class	enter the ||| glue demo	count=1
class	a list's ||| pretty lazy concatenation	count=1
arg	based on ||| elt_handler	count=1
arg	its forward ||| forward bindings	count=1
function	can be replaced ||| can unify	count=1
arg	in positions where it ||| tokens positions	count=1
function	belonging to the ||| vectorspace	count=1
arg	the highest probability ||| unlabeled_sequence	count=1
class	of the files ||| reviews	count=1
arg	words can ||| words fail_on_unknown	count=2
function	epytext @field to a ||| epytext	count=1
class	in this object ||| substitute	count=1
function	[function_1] encoded as ||| [function_2] [function_1]	count=24
class	the ||| edge	count=2
function	[function_1] is ||| [function_2] [function_1]	count=10
function	create a valuation ||| valuation	count=1
function	training data ||| train	count=1
arg	creates the sentence ||| source_blocks target_blocks	count=1
class	much of ||| edge i	count=1
function_arg	[function_1] expressed as ||| [arg_2] [function_1]	count=16
function	adds an [function] ||| [function]	count=2
function	information about the users ||| user	count=1
class	uses a ||| tn t	count=1
arg	the reference that ||| references hyp_len	count=1
function	greatest number of ||| max	count=1
arg	remaining_text to [arg_2] ||| [arg_2] [arg_1]	count=2
function	[function_1] all possible ||| [function_2] [function_1]	count=6
class	tree as ascii ||| tree	count=1
class	calculates [class_2] ||| [class_2] [class_1]	count=4
class	contents ||| category corpus	count=1
class	read ||| xmlcorpus view	count=1
arg	of all nonterminals ||| cat	count=1
class	the tree should ||| chart	count=1
function	with the greatest number ||| max	count=1
function	readme file ||| readme	count=1
class	this rule and the ||| chart rule	count=1
class	grammar production ||| cfg	count=2
class	indexes ||| corpus	count=1
function	collapse ||| collapse	count=2
function	redirects arcs to any ||| arcs	count=1
class	be called ||| demo	count=1
arg	sequence ||| sequence n	count=1
class	given language [class_2] ||| [class_2] [class_1]	count=4
function	save the ||| save	count=1
class	must ||| regexp chunk	count=1
class	the frontier in particular ||| descent parser	count=1
function_arg	check whether [arg_2] ||| [function_1] informative [arg_2]	count=2
arg	to csv ||| outfile fields	count=1
class	feature ||| feat dict	count=3
function	of the [function] ||| [function] in	count=1
function	a binding to each ||| bind to	count=1
function	named entity [function_2] ||| [function_1] [function_2]	count=4
arg	that cover span ||| span constituents	count=2
arg	[arg_1] bytes ||| [arg_2] [arg_1]	count=2
class	a ||| view	count=1
class	rule it has ||| rule	count=1
arg	to the target tagset ||| target source_tag	count=1
arg	'self' ||| other	count=1
class	dictionary containing ||| dictionary conditional	count=1
function	bigram features reflecting the ||| bigram feats	count=1
arg	file by combining the ||| root base_url	count=1
function	about the ||| from id	count=1
class	first element of ||| stepping recursive descent parser	count=1
function	load ||| luannotationset elt	count=1
function	[function_1] tags ||| [function_1] [function_2]	count=1
function	of all tags ||| tags	count=1
function	test [function_2] ||| [function_1] [function_2]	count=1
class	alphabetical ||| opinion	count=1
class	how ||| chart view	count=2
arg	of variable ||| variable	count=4
function	[function_1] of target ||| [function_2] [function_1]	count=2
arg	corpus train_toks ||| cls train_toks count_cutoff	count=1
class	:see expression ||| expression	count=2
arg	the similarity matrix s ||| s s	count=1
arg	a featureset [arg_2] ||| [arg_2] [arg_1]	count=4
class	remaining ||| shift reduce	count=1
class	a single parsing ||| stepping recursive descent parser	count=1
class	[class_1] pointer in ||| core [class_1] [class_2]	count=1
arg	text :type text ||| text	count=1
function	concepts indexed by ||| process bundle	count=1
function	use ||| pred use	count=1
class	to ||| corpus	count=1
class	in [class_2] ||| [class_2] [class_1]	count=6
arg	synset ||| synset	count=2
class	vector of joint-feature ||| maxent feature encoding i	count=1
class	:return a corpus view ||| propbank corpus reader	count=1
function	counter from ||| counter from	count=2
function	code ||| to	count=1
class	tags ||| hidden markov model	count=1
function_arg	:param boxer_drs_interpreter a ||| init boxer_drs_interpreter	count=1
class	start [class] given ||| [class]	count=1
arg	input ||| assumptions	count=5
arg	multi-word tokenizer ||| mwes separator	count=1
function	lin similarity ||| lin similarity	count=2
arg	synset and [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	an error [arg_2] ||| [function_1] [arg_2]	count=1
class	remaining text to the ||| stepping shift reduce parser	count=1
function	:return the height ||| height	count=1
function	[function_1] static ||| [function_2] [function_1]	count=1
class	unit needs ||| chart view	count=1
function	the cosine of ||| cosine	count=1
arg	if strings ||| strings	count=1
function	for word [function_2] ||| [function_1] [function_2]	count=1
module_class	[module_1] multi-column listbox ||| [module_1] [class_2]	count=2
class	remaining text ||| shift reduce	count=1
class	as a list of ||| corpus	count=1
function	the euclidean [function_2] ||| [function_2] [function_1]	count=1
arg	the probabilistic parsers ||| choice draw_parses print_parses	count=1
arg	[arg_1] tagset ||| [arg_2] [arg_1]	count=5
class	to the ||| stepping	count=1
class	given the iso ||| corpus reader	count=1
function_arg	distance [arg_2] ||| [function_1] [arg_2]	count=5
function	python ||| python	count=1
class	tags the sequence ||| hidden markov model	count=1
function	concept out ||| concept	count=1
class	this encoding ||| encoding	count=3
module	corpus view that is ||| corpus	count=4
function	of synsets for the ||| synsets	count=1
class	[class] the given ||| [class]	count=1
class	indexes to ||| reader	count=1
class	files that ||| reviews corpus reader	count=1
class	unit needs ||| view	count=1
arg	constructor should only ||| parent	count=1
arg	highest ||| unlabeled_sequence	count=1
class	must be called ||| glue demo	count=1
function	the output ||| output	count=1
module	the frontier ||| parse	count=1
arg	freqdist ||| freqdist	count=1
arg	edge ||| edge	count=3
function_arg	[function_1] refs ||| [function_1] [arg_2]	count=1
arg	id luname frameid and ||| ignorekeys luname frameid	count=1
class	must be ||| chunk	count=1
function	probability of [function_2] ||| [function_1] [function_2]	count=14
arg	*worder* list i ||| hypothesis character_based	count=1
function_arg	file [arg_2] ||| [function_1] file [arg_2]	count=1
function	applies at ||| applies	count=1
module	languages ||| reader	count=1
module_class	for this feature ||| core feature	count=1
arg	or ||| fileids	count=2
function	into pseudosentences ||| divide to tokensequences	count=1
class	move a token ||| stepping shift reduce	count=1
class	new feature encoding based ||| maxent feature encoding i	count=1
function_arg	chunk [arg_2] ||| [function_1] [arg_2]	count=1
class	neural dependency parser ||| stanford neural dependency parser	count=1
function_arg	[function_1] vector ||| [function_1] vectorspace [arg_2]	count=2
class	if this dependencygrammar ||| probabilistic dependency grammar	count=1
class	when parsing a ||| probabilistic chart parser	count=1
class	a given trigram ||| trigram	count=1
class	of the ||| stepping recursive descent parser	count=1
module	the ||| corpus reader	count=7
arg	use nltk's currently recommended ||| tagged_tokens binary	count=1
function	returns a freqdist containing ||| freq	count=1
function	:param int ||| init	count=1
class	corpus or for ||| categorized corpus	count=1
function	parse multiple sentences takes ||| tagged parse	count=1
class	first element of the ||| stepping	count=1
function_arg	[function_1] stream and ||| [function_1] [arg_2] block_size comment_char	count=3
function	the first [function_2] ||| [function_2] [function_1]	count=4
arg	segmentation [arg_2] ||| metrics pk [arg_2] [arg_1]	count=1
arg	and relation ||| relation	count=1
class	must be called ||| parser	count=1
class	return a list of ||| corpus reader	count=1
function_arg	which [arg_2] ||| [arg_2] [function_1]	count=4
function	also str ||| str	count=1
function	check to make sure ||| check	count=1
class	of ||| reduce parser	count=2
class	probability ||| hidden markov	count=1
function	"preterminals", [function] ||| [function]	count=1
arg	registers the new edge ||| edge	count=2
module	helper function for ||| corpus reader	count=2
class	a standard [class_2] ||| [class_1] [class_2]	count=1
arg	starting at [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
class	[class_1] format ||| [class_2] [class_1]	count=2
class	not point to self ||| abstract	count=1
arg	terminal ||| inputfilename outputfilename mode	count=1
class	space [class_2] ||| [class_1] [class_2]	count=1
function	demonstration of ||| demo	count=5
function	information about ||| user info from	count=1
class	the perl unicode properties ||| unichars corpus	count=1
function_arg	:param [arg_2] ||| [function_1] [arg_2]	count=46
function	the fulltextindex xml file ||| handle fulltextindex elt	count=1
class	positive examples the edges ||| naive bayes	count=1
arg	caller function as input ||| caller	count=1
class	romanian ||| romanian	count=1
module	is a ||| sem	count=1
function	the fulltextindex xml ||| fulltextindex	count=1
arg	token ||| token	count=2
class	list ||| query	count=1
class	frontier in particular ||| stepping recursive descent	count=1
function	s the grammar is ||| calculate grammar	count=1
function	parse multiple sentences takes ||| parse	count=1
class	alphabetical order ||| corpus reader	count=1
class	sentences in ||| sentences	count=1
function	readme txt file ||| readme	count=2
class	multi-column [class_2] ||| [class_2] [class_1]	count=1
arg	self and other ||| other	count=2
function	the various ||| drt	count=1
arg	index of ||| index depth	count=1
arg	the tokens in bigrams ||| bigrams	count=1
module	the users ||| twitter	count=1
class	[class_1] frequency distribution ||| core [class_1] [class_2]	count=1
arg	from a word-aligned sentence ||| srctext trgtext	count=1
module	plaintext ||| corpus reader	count=1
function_arg	left children [arg_2] ||| [arg_2] [function_1]	count=4
module	abstractvariableexpression appropriate ||| sem	count=1
function	this function generates the ||| generate	count=1
class	the ||| descent parser	count=2
arg	[arg_1] segmentation is ||| [arg_2] [arg_1]	count=3
arg	s as ||| fileids c5	count=2
function	columns ||| column	count=1
class	of a dependency ||| probabilistic projective dependency parser	count=1
function	_tag_positions to ||| tag positions	count=1
module	words ||| corpus reader	count=3
class	of ||| stepping shift	count=2
function	recommended part of speech ||| pos	count=1
arg	[arg_1] f ||| [arg_1] [arg_2]	count=3
arg	and ||| strip_space stem	count=2
function	close a previously ||| close	count=1
arg	the node return ||| node	count=1
arg	of productions ||| productions	count=2
class	[class_1] gzip ||| [class_1] [class_2]	count=1
module	for the given speaker ||| reader	count=1
function	the number [function_2] ||| [function_1] [function_2]	count=2
function	[function_1] to convert ||| [function_1] [function_2]	count=2
function	[function_1] measure for ||| [function_2] [function_1]	count=1
arg	trees [arg_2] ||| [arg_2] [arg_1]	count=3
class	to the end of ||| stepping shift	count=1
class	frontier ||| stepping	count=1
arg	segmentations [arg_2] ||| [arg_2] [arg_1]	count=4
arg	original text and the ||| text	count=1
function	construct a trigramcollocationfinder ||| init	count=1
class	rule ||| chunk rule	count=1
function_arg	:param int [arg_2] ||| [function_1] [arg_2]	count=4
class	use stanfordparser ||| generic stanford parser	count=2
class	supported languages ||| corpus	count=1
arg	try to ||| desired_x desired_y	count=1
function	set the log probability ||| set	count=1
class	brill ||| brill	count=2
arg	devset_name the name ||| devset_name	count=1
class	displaying ||| descent parser	count=1
function	contents of citation bib ||| citation	count=1
function	the truncation line ||| truncation	count=1
class	function must ||| parser	count=1
arg	[arg_1] list of ||| [arg_1] [arg_2]	count=1
module	as iso ||| reader	count=1
class	first element of the ||| stepping recursive descent parser	count=1
arg	method ||| method	count=1
class	with ||| hidden markov	count=1
function_arg	less [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	[function_1] tree the ||| [arg_2] [function_1]	count=2
function	distance metric >>> from ||| distance	count=1
module	how ||| app	count=2
module_class	tagged [class_2] ||| [module_1] [class_2]	count=5
function	number of left children ||| left children	count=1
class	generated when parsing a ||| probabilistic chart parser	count=1
function	subtype of ||| variable expression	count=1
class	binder [class_2] ||| [class_1] [class_2]	count=2
function	plot ||| plot	count=3
arg	appends the given span ||| span	count=1
arg	binary with the given ||| binary	count=1
function	most recent tweets ||| tweets	count=1
function	an application ||| application	count=1
arg	tagger must be trained ||| unk trained n c	count=1
function	features ||| features	count=2
function	number ||| num	count=3
function_arg	[function_1] feature ||| [function_1] informative [arg_2]	count=1
class	each feature ||| feat	count=1
class	the absolute ||| file system	count=1
arg	the reference ||| reference	count=1
module	displayed by this ||| draw	count=2
function	words and ||| words	count=2
function	fes ||| fes	count=1
class	element of ||| descent parser	count=1
class	construct ||| collocation finder	count=3
function	extract the unique ||| get unique	count=1
arg	structures that [arg_2] ||| [arg_2] [arg_1]	count=2
function	the present ||| extract features	count=1
function	id only relations involving ||| relations	count=1
class	to ||| parser	count=3
arg	of reference ||| reference	count=4
class	simple ||| simple	count=1
class	underlying [class_2] ||| core [class_1] [class_2] reader	count=1
class	text returns a ||| punkt sentence	count=1
function	convert a ||| user info from id	count=1
class	text contents of ||| senseval corpus reader	count=1
arg	[arg_1] version ||| [arg_1] [arg_2]	count=3
function	variables used by ||| find variables	count=2
class	initialize the crfsuite ||| crftagger	count=1
function_arg	[function_1] filtered by ||| [function_1] lhs [arg_2]	count=2
module	after this ||| draw	count=1
class	the frontier ||| stepping recursive	count=1
class	indicates ||| edge i	count=1
arg	the distance ||| distance	count=1
class	this corpus ||| timit corpus	count=1
module	with the ||| tag	count=1
class	called ||| chart parser	count=1
arg	one [arg] corpus that ||| [arg]	count=2
module	make a ||| sem	count=1
class	the frontier in particular ||| stepping recursive descent parser	count=1
module	for a primitive category ||| ccg	count=1
class	will add edges licensed [class_1] [class_2] ||| [class_2] [class_1] apply chart grammar	count=7
module	exemplify ||| tbl	count=1
arg	function results for each ||| function	count=1
function	apply self prob_classify() ||| prob classify many	count=2
class	new feature encoding ||| binary maxent feature encoding	count=1
arg	replace every [arg_1] [arg_2] across every atom ||| [arg_1] [arg_2]	count=1
class	[class] a ||| [class]	count=1
arg	source-to-target and ||| e2f	count=1
class	token from the ||| stepping shift reduce	count=1
module_class	[module_1] positive ||| [module_1] [class_2]	count=4
function	expression for word tokenization ||| word tokenizer	count=1
arg	use [arg] rightmost stack ||| [arg]	count=1
function	rule to the ||| rule	count=2
class	frontier in particular ||| stepping recursive descent parser	count=1
function_arg	[function_1] an alignment ||| [function_1] given s [arg_2]	count=6
function	compatible with ||| pformat	count=1
arg	the neighbors ||| j_pegged	count=1
function	rare abbreviation if ||| rare abbrev	count=2
class	all parses that can ||| recursive descent parser	count=2
module	hypothesized structure is consistent ||| parse	count=1
module	a string and return ||| core	count=1
arg	synset note ||| word synset	count=1
function	expression ||| expression	count=1
arg	by [arg] ||| [arg]	count=5
function	error ||| error	count=2
module	chart [module] return ||| [module]	count=1
module	which looks ||| core	count=1
arg	positive_featuresets ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
arg	a synset ||| word synset	count=1
class	end of ||| stepping shift	count=1
arg	a discoursetester ||| input reading_command background	count=1
function	return the [function] to ||| [function]	count=1
function	or disable warnings of ||| warnings	count=1
arg	valuation_str str with ||| valuation_str format	count=1
class	of predicates from the ||| closed world prover	count=1
function	[function] tag should ||| [function]	count=1
function	score for a given ||| score	count=2
class	princeton wordnet 3 ||| word net	count=1
class	beginning ||| reduce parser	count=2
arg	located at ||| fileids word_tokenizer sent_tokenizer	count=1
class	indexes to ||| corpus reader	count=1
class	are known as positive ||| positive	count=1
class	supported languages as ||| corpus reader	count=1
class	end of the stack ||| stepping shift reduce	count=1
arg	replace every instance [arg_1] [arg_2] across every atom ||| [arg_1] [arg_2]	count=1
class	dict with which ||| dict	count=1
function	parse a primitive category ||| parse	count=1
function	be the top ||| top	count=1
function	the first expression that ||| first	count=1
function	applicable suffix-removal rule ||| apply rule	count=1
function	returns only the text ||| strings	count=1
arg	[arg_1] feature f ||| [arg_1] [arg_2]	count=3
class	ngramassocmeasures class ||| contingency measures	count=1
function	disable warnings of ||| warnings	count=1
arg	positive_featuresets a list of ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
function	various methods of ||| discourse	count=2
class	in this corpus or ||| timit corpus	count=1
class	name of the file ||| file	count=1
function_arg	[function_1] demon ||| [arg_2] [function_1]	count=4
arg	synset note ||| synset	count=1
class	the expression ||| expression	count=2
class	sequence this ||| markov	count=1
function_arg	lists [arg_2] ||| [arg_2] [function_1]	count=1
arg	and fstruct2 ||| fstruct2 trace	count=1
function	redirects arcs ||| arcs	count=1
function_arg	[function_1] stream ||| [function_1] [arg_2]	count=2
arg	its iso latin value ||| m defs	count=1
module	of ||| parse	count=5
class	the sentence string to ||| chart view	count=1
arg	context_to_tag ||| context_to_tag backoff	count=1
module	find the ||| inference	count=1
arg	[arg_1] ranks2 ||| [arg_1] [arg_2]	count=1
function	string representation ||| repr	count=4
function_arg	[function_1] tokens ||| [arg_2] [function_1]	count=4
module	tweets are coming in ||| twitter	count=1
arg	ranks1 ||| ranks1	count=1
function	length to the hypothesis ||| length	count=1
function	various methods ||| discourse	count=2
class	the ||| tagger	count=2
function	path distance [function_2] ||| [function_1] [function_2]	count=1
class	lexical translation model and ||| ibmmodel2	count=1
function	the average ||| average	count=1
class	to ||| stepping shift	count=1
arg	train and test ||| trainer save_analyzer	count=1
arg	on the node return ||| node	count=1
function	determines the approximate score ||| score	count=1
function	complete ||| complete	count=1
class	rule it has ||| chunk rule with	count=1
function	[function] for ||| [function]	count=3
class	given a long ||| corpus reader	count=1
class	sentence boundary detector or ||| punkt sentence tokenizer	count=1
function	returns a freqdist containing ||| freq threshold	count=1
class	cached n ||| dist	count=1
function	corresponding string representation ||| tuple2str	count=1
function	replace all instances ||| replace	count=3
module	ipython ||| core	count=1
function	apply all ||| apply	count=1
function_arg	[function_1] [arg_2] ||| [function_1] vector [arg_2]	count=3
function	local file if ||| retrieve	count=1
class	a tree ||| tree	count=2
class	be called ||| drt	count=1
arg	left-hand side or the ||| lhs rhs	count=2
function	[function] info ||| handle [function]	count=2
function	of the indices where ||| indices	count=1
function_arg	[function_1] iter tree ||| [function_1] [arg_2]	count=1
arg	of word tag tuples ||| stem	count=1
class	return the chart ||| chart	count=1
arg	assumptions ||| assumptions	count=2
module	if this ||| draw	count=2
function	mappings of lemmas in ||| lemmas	count=1
function	information ||| from	count=1
class	this function ||| drt	count=1
class	[class_1] [class_2] not including graphical ||| [class_1] [class_2] tags	count=1
module	the ||| inference	count=8
class	[class_1] dictionary ||| [class_2] [class_1]	count=1
function	block from ||| block	count=1
class	sequence with the ||| tagger	count=1
function_arg	of words [arg_2] ||| [function_1] fileids [arg_2]	count=3
function	*rule* applies at ||| applies	count=1
arg	configure ||| cnf	count=1
function	[function_1] word alignments ||| [function_2] [function_1]	count=10
function	valuation ||| valuation	count=2
arg	an ||| elem level	count=1
function	likelihood a float of ||| likelihood	count=1
module_class	position this [class_2] ||| [module_1] [class_2]	count=4
arg	valuation_str str with ||| valuation_str	count=1
class	the text contents ||| senseval corpus reader	count=1
module_class	[module_1] path pointer ||| [module_1] [class_2]	count=2
function	_sentences to construct a ||| construct	count=1
class	get ||| drs drawer	count=1
class	end of the stack ||| stepping shift reduce parser	count=1
class	instance's predicate ||| instance	count=1
arg	chrf character [arg] ||| list_of_references hypotheses [arg]	count=3
function	a model ||| model	count=1
class	this ||| hidden markov	count=1
class	the text ||| text	count=2
module	instantiates and ||| sem	count=1
class	build the ||| framenet corpus	count=1
function	a copy ||| copy	count=1
class	should be generated when ||| probabilistic	count=1
class	particular ||| descent parser	count=1
class	rule ||| rule with context	count=1
arg	constant describing ||| info_or_id download_dir	count=1
arg	a given text if ||| text verbose	count=1
class	return the chart rule ||| stepping chart parser	count=1
function	entity to ||| descape entity	count=1
class	text to the ||| stepping shift reduce parser	count=1
class	to ||| stepping shift reduce parser	count=1
class	be called ||| drt glue demo	count=1
class	text content of tweets ||| twitter	count=1
class	should be etc ||| view	count=1
class	a token ||| shift reduce	count=1
class	string to figure ||| view	count=1
module	must be ||| app	count=2
arg	c{replacement_tag} if all of ||| templateid original_tag replacement_tag conditions	count=1
class	rule it has ||| rule with context	count=1
class	predicate ||| propbank instance	count=1
arg	[arg_1] item ||| [arg_2] [arg_1]	count=2
arg	:param status_code the status ||| status_code data	count=1
function_arg	of fileids [arg_2] ||| [arg_2] [function_1]	count=1
function	the number of clusters ||| num clusters	count=1
class	that can be ||| parser	count=2
class	variable binder ||| variable binder	count=2
function	[function_1] url ||| [function_2] [function_1]	count=5
function	returns the node label ||| tgrep node label	count=1
arg	rows ||| rows	count=1
function	pre-calculate of which form ||| forms	count=1
function	to train the tagger ||| train	count=1
function	compatible with the ||| pformat	count=1
class	given language to princeton ||| corpus reader	count=1
module	a list ||| sem	count=2
function	start ||| start	count=1
arg	reflexive ||| reflexive	count=1
arg	must be trained ||| unk trained	count=1
function	all frames that ||| frames	count=1
function	if the given ||| range	count=1
function	the given ||| remove by	count=1
class	plug ||| hole semantics	count=1
arg	file s as ||| fileids strip_space	count=1
class	the ||| chart parser	count=1
arg	pairs is a ||| pairs	count=1
function	beginning of the remaining ||| shift	count=1
class	e g tags=['subst', 'comp'] ||| nkjpcorpus reader	count=1
arg	ranks1 and ||| ranks1	count=1
function	a probability distribution ||| prob	count=2
class	contents ||| category	count=1
class	the table ||| table	count=3
function	of two [function_2] ||| [function_2] [function_1]	count=1
function	tweets by ||| tweets by	count=1
class	tweets ||| twitter corpus	count=1
function_arg	[function_1] stemming ||| [arg_2] [function_1]	count=1
class	words ||| lexicon corpus reader	count=1
function	document ||| doc	count=1
function	new index for ||| add index	count=1
function	that are immediately after ||| immediately after	count=1
class	assignment and ||| assignment	count=1
class	context-free grammar from the ||| cfg	count=1
function	updates the edge ||| edge	count=1
function	been [function] this is ||| ensure [function]	count=1
function	tabulate the given samples ||| tabulate	count=1
module_class	[module_1] its ||| [module_1] feat [class_2]	count=4
arg	of child ||| child	count=2
class	the meaning's ||| meaning	count=4
function	a tuple ||| entries	count=1
arg	the given string ||| s	count=2
function	[function] to this ||| [function]	count=1
function	register ||| add	count=1
class	that have been ||| nonprojective parser	count=1
function	and returns a subtype ||| variable	count=1
class	given a text returns ||| punkt sentence	count=1
function	used by ||| find	count=1
function	read pointer forward ||| forward	count=1
function	[function_1] the first ||| [function_2] [function_1]	count=1
arg	in a line ||| linenum line	count=1
arg	xml description ||| roleset_id	count=1
function	likelihood of the ||| likelihood	count=1
function	[function_1] synset relations ||| [function_1] [function_2]	count=1
class	as sentence breaks yielding ||| punkt sentence	count=1
class	true if the underlying ||| seekable unicode	count=1
class	normalises ||| space clusterer	count=1
class	contents of the corpus ||| sentences corpus reader	count=2
class	change ||| shift reduce parser	count=1
function	values return the fraction ||| recall	count=1
class	lemma ||| corpus reader	count=1
class	corpus view that ||| nombank corpus reader	count=1
arg	used to implement the ||| fileid bracket_sent tag strip_space	count=1
arg	tokens ||| tagged_tokens	count=1
class	of the corpus ||| sentences corpus reader	count=2
class	brill tagger on ||| brill tagger	count=1
class	in particular if ||| descent	count=1
arg	text if [arg_2] ||| [arg_1] [arg_2]	count=4
arg	language ||| lang	count=1
arg	process some ||| keywords	count=1
module	build the internal ||| corpus	count=1
module	frontier in particular ||| parse	count=1
module	the recursive descent parser ||| parse	count=1
function_arg	[function_1] int limit ||| [function_1] [arg_2]	count=1
function	for tadm based on ||| tadm	count=1
class	figure out how big ||| view	count=1
function	variety ||| user	count=1
function	sentence ||| t	count=2
arg	tokens index ||| tokens index	count=2
function	[function_1] of chomsky ||| [function_2] [function_1]	count=1
function	a demonstration showing the ||| rule parse demo	count=1
arg	a tree ||| tree	count=1
function_arg	special category [arg_2] ||| [function_1] [arg_2]	count=1
arg	token into a cluster ||| token	count=1
class	this function ||| demo	count=1
class	end of the ||| stepping shift reduce parser	count=1
function_arg	[function_1] initial_tagger the ||| [function_1] [arg_2]	count=1
function	demonstration showing the creation ||| demo	count=2
function	node from the conjunction ||| conjunction	count=1
arg	produce the *worder* list ||| hypothesis character_based	count=1
class	this ||| tagger	count=1
arg	[arg_1] of productions ||| [arg_1] [arg_2]	count=1
function	freqdist ||| freq threshold	count=2
class	from this synset ||| synset	count=1
function_arg	a string [arg_2] ||| [function_1] [arg_2]	count=4
function	tag() to each element ||| sents	count=1
function_arg	page [arg_2] ||| [function_1] [arg_2]	count=3
function	a lambda function representing ||| tgrep	count=2
arg	the document of each ||| document	count=2
module	build ||| corpus	count=1
class	the minimal set ||| minimal set	count=1
class	for right-arc [class] ||| [class]	count=3
function	describes the use ||| use	count=1
function	child pointer [function_2] ||| [function_2] [function_1]	count=4
class	distribution [class_2] ||| [class_2] [class_1]	count=2
function_arg	[function_1] earley parsers ||| [function_1] [arg_2]	count=2
class	rule that ||| rule	count=1
class	the frequency distribution in ||| good turing prob dist	count=1
class	for [class_2] ||| [class_2] [class_1] encoding file	count=3
class	feature [class_2] ||| [class_2] [class_1]	count=3
class	order ||| corpus reader	count=1
class	witten-bell probability estimates ||| witten bell prob	count=1
arg	and q for feature ||| q	count=1
arg	input expression to ||| assumptions max_models model_builder	count=1
function	[function_1] blank ||| [function_2] [function_1]	count=1
function	the latex qtree ||| latex qtree	count=2
class	absolute path identified by ||| file system	count=1
arg	of segmentations [arg_2] ||| metrics pk [arg_2] [arg_1]	count=1
module	is ||| sem	count=1
arg	of strings ||| strings	count=1
arg	[arg_1] as tuples ||| [arg_1] [arg_2]	count=1
class	the resulting list ||| base class	count=1
function	for past tweets by ||| tweets by user demo	count=1
class	assignment and update ||| assignment	count=1
arg	given item ||| item	count=2
function	use of a ||| pred use	count=1
class	to ||| reader	count=1
class	calculates values ||| assoc measures	count=2
arg	fileids of the ||| fileids	count=1
module	called if ||| app	count=2
arg	stream ||| stream	count=2
function	is hidden ||| hidden	count=1
function	a module ||| taggedsent	count=1
arg	list ||| fileids	count=5
arg	modelbuilder the theorem tool ||| modelbuilder goal	count=1
class	boundary detector ||| punkt	count=1
arg	the given synset ||| synset	count=1
class	be called if ||| drt glue demo	count=1
arg	from [arg_2] ||| [arg_2] [arg_1]	count=1
class	frontier in ||| stepping recursive descent	count=1
function_arg	[function_1] [arg_2] to ||| [function_1] [arg_2]	count=2
class	this decision tree ||| decision tree	count=1
arg	fstruct1 and fstruct2 ||| fstruct1 fstruct2 trace	count=2
class	corpus view ||| propbank corpus	count=1
arg	tab file containing mappings ||| tab_file	count=1
arg	for the file s ||| fileids	count=1
class	the chart rule used ||| chart	count=1
arg	of documents each ||| cls documents	count=1
class	function must be called ||| app	count=2
arg	classid if specified ||| classid	count=1
arg	the boundaries ||| boundaries	count=1
class	much of the hypothesized ||| i	count=1
function	a known abbreviation or ||| reclassify abbrev	count=1
function_arg	[function_1] the cluster ||| [arg_2] [function_1]	count=1
function	a networkx labeled directed ||| nx	count=1
arg	current round of ||| upper_date_limit lower_date_limit	count=1
function	arrange the child ||| manage	count=1
function	[function_1] patterns and ||| [function_2] [function_1]	count=12
class	in particular ||| stepping	count=1
class	the first element of ||| recursive descent	count=1
function	[function_1] arc to ||| [function_2] [function_1]	count=5
arg	based on a specified ||| elt_handler	count=1
function	[function_1] 2 ||| [function_1] [function_2] unicode compatible klass	count=1
class	must ||| chart	count=1
module_class	the lowest descendant of [module_1] [class_2] ||| [module_1] [class_2]	count=2
arg	perform the actual word ||| word intact_word	count=1
arg	to implement the ||| fileid unit bracket_sent	count=1
function	instantiates and returns a ||| variable expression	count=1
function	code based on iso ||| iso to	count=1
function	and ||| values	count=1
function	all variables in ||| variables	count=1
function	set the [function_2] ||| [function_2] [function_1]	count=1
class	is ||| edge i	count=1
class	the internal indexes to ||| framenet corpus	count=1
class	reader for a set ||| reader	count=3
module	up this corpus ||| corpus reader	count=1
arg	the text ||| text	count=1
module	how much of ||| parse	count=1
function	plausible semtypes in ||| get semtypes	count=1
class	string to figure out ||| view	count=1
function	java ||| java	count=1
arg	if stem ||| stem	count=1
class	check ||| reduce parser	count=1
class	must be called ||| drt	count=1
arg	string for ||| string	count=1
class	of samples ||| turing prob dist	count=1
function	5a ||| step5b	count=1
function	use nltk's currently recommended [function_1] [function_2] ||| [function_1] [function_2]	count=20
function	convert this expression ||| to	count=1
function	:return a probability distribution ||| prob	count=2
class	dependency graph ||| dependency	count=1
arg	location is within ||| location	count=1
class	that is ||| recursive descent parser	count=1
function_arg	[function_1] and ||| [arg_2] [function_1]	count=19
function	of concepts indexed by ||| process bundle	count=1
class	function must be called ||| drt	count=1
arg	reference that is ||| references	count=1
function	*rule* applies at ||| rule applies	count=1
class	may cause ||| mutable	count=1
function	load a valuation ||| load	count=1
module	elements managed by this ||| draw	count=2
function	relation to other nodes ||| tgrep relation	count=1
function	arc to ||| arc	count=1
class	pickle corpus and then ||| pickle corpus	count=1
class	mutable probdist based on ||| mutable prob dist	count=1
class	remaining ||| reduce parser	count=1
class	canvas [class_2] ||| [class_1] [class_2]	count=7
class	this tree ||| tree	count=2
arg	method ||| method indent	count=1
function	upper frame ||| upper	count=1
function	given a slice ||| slice	count=1
class	likelihood ||| vector space clusterer	count=1
class	when parsing a ||| up probabilistic chart parser	count=1
arg	:rtype bool :return true ||| rightmost_stack	count=1
class	returns a list ||| punkt	count=1
arg	*worder* ||| reference hypothesis character_based	count=1
function	from the fulltextindex ||| handle fulltextindex elt	count=1
class	much of the ||| i	count=1
function	which returns the type ||| get type	count=2
arg	a single sentence ||| sentence threaded verbose	count=1
class	generated when parsing a ||| recursive descent parser	count=1
class	of probability ||| prob dist	count=1
arg	[arg_1] with fstruct2, ||| [arg_1] [arg_2]	count=1
class	projective [class_2] ||| [class_1] [class_2]	count=1
class	the first element of ||| parser	count=1
function	relations data for a ||| relations data	count=1
arg	assigns the vectors to ||| vectors assign_clusters	count=1
function	by deleting ||| remove variables	count=1
class	dependency parser and the ||| dependency parser	count=1
function	s-expressions from ||| sexpr block	count=1
arg	stem ||| stem	count=1
arg	file identifiers ||| filetype	count=1
function_arg	[function_1] [arg_2] ||| cache [function_1] tempfile cls sequence [arg_2]	count=5
function	plug the [function_2] ||| [function_2] [function_1]	count=1
class	of processing ||| i	count=1
function	is of chomsky normal ||| is chomsky normal	count=1
arg	tuple representation of a ||| tagged_token	count=1
function_arg	[function_1] boxer_drs_interpreter a ||| [arg_2] [function_1]	count=1
function	[function] data ||| [function]	count=3
arg	if [arg_2] ||| [arg_2] [arg_1]	count=4
arg	to the cluster ||| cluster	count=1
function	[function_1] of all ||| [function_2] [function_1]	count=6
module_class	all [class_2] ||| [module_1] [class_2]	count=2
function	the first pass ||| first pass	count=1
arg	iter tree ||| rtext tree frontier	count=1
function	:return a [function] for ||| [function]	count=1
arg	for feature f ||| f	count=1
class	binder in the expression ||| drt lambda expression	count=1
arg	from a ||| start	count=1
function	add blank ||| add default	count=2
arg	invalidate the ||| key	count=1
class	element of the frontier ||| stepping recursive descent	count=1
function	users ||| from	count=1
class	cross-validation estimate ||| cross validation	count=1
class	in alphabetical order ||| opinion lexicon	count=1
class	this corpus or for ||| categorized corpus	count=1
class	list of ||| query	count=1
arg	implement the view methods ||| unit bracket_sent	count=1
class	a ||| parser	count=12
class	return a list ||| crubadan	count=1
class	in this corpus ||| corpus reader	count=2
function	form i e all ||| form	count=1
arg	tab file containing mappings ||| tab_file lang	count=1
class	[class_1] as as ||| [class_2] [class_1]	count=3
function	iso ||| iso	count=1
function	alignment algorithm ||| alignment	count=1
arg	the probability ||| prob	count=1
function	[function_1] most emoticons ||| [function_1] [function_2]	count=1
arg	given edge ||| edge	count=1
class	for [class_2] ||| [class_2] [class_1]	count=3
function	of features each ||| features	count=1
module	a list ||| twitter	count=1
class	of the hypothesized structure ||| i	count=1
module_class	[module_1] canvaswidget is ||| [module_1] [class_2]	count=8
function	available [function] ||| describe [function]	count=3
function	of information about the ||| info	count=1
class	classifier ||| classifier	count=8
class	to a list's ||| pretty list	count=1
function	make look-ups faster ||| buildindexes	count=1
function	list of chunks each ||| chunks	count=1
class	[class_1] tagger ||| [class_1] [class_2]	count=2
arg	the expression to ||| expression	count=1
module	indicates how ||| parse	count=1
function_arg	categories for [arg_2] ||| [function_1] [arg_2]	count=1
arg	of its forward pointer ||| forward fs_class visited	count=1
class	a probabilisticdependencygrammar based ||| parser	count=1
function	the unique [function_2] ||| [function_1] [function_2]	count=4
arg	list [arg_2] ||| [arg_1] [arg_2]	count=2
arg	pretty-printed version ||| width prefix depth	count=2
class	will only succeed the ||| immutable tree	count=1
module	should be etc ||| app	count=1
arg	its variable [arg_2] ||| [arg_1] [arg_2]	count=2
function	chunkstr, in ||| notrace	count=1
function	transform the ||| transform	count=1
module	indicates ||| parse	count=1
class	xml element in a ||| corpus reader	count=1
module_class	previously opened [class_2] ||| [module_1] [class_2]	count=4
function	the various ||| drt discourse	count=1
function	the name ||| name	count=1
class	tree as ascii or ||| tree	count=1
function	the static [function_2] ||| [function_2] [function_1]	count=5
arg	given tree ||| tree	count=1
class	to elements of lists ||| lazy map	count=1
function_arg	[function_1] from ||| [function_1] [arg_2]	count=3
class	the hypothesized structure is ||| edge i	count=1
class	at the path ||| path	count=1
function	subcorpus of ||| handle lusentence	count=1
arg	tuples ||| relation	count=2
class	linear regression ||| good turing prob dist	count=1
arg	the *worder* ||| reference hypothesis character_based	count=1
function	all conditions for ||| conditions	count=1
function	information about ||| info	count=1
class	for the given corpus ||| corpus reader	count=1
class	for editing the productions ||| cfgeditor	count=1
class	dict if its ||| dict	count=1
function	static [function_2] ||| [function_1] [function_2]	count=5
class	matrix from a list ||| matrix	count=1
arg	and other ||| other check_reentrance visited_self visited_other	count=1
class	to the end of ||| shift reduce parser	count=1
function_arg	[function_1] of model_found() ||| [arg_2] [function_1]	count=1
class	rule it ||| rule	count=1
class	sentence boundary detector ||| punkt sentence	count=1
module	information about the ||| twitter	count=1
arg	as a list ||| fileids	count=1
class	use maltparser to ||| malt	count=2
function	tgrep ||| tgrep	count=3
function	invalidate the ||| setitem	count=1
class	be called if ||| chart	count=1
arg	with 'expression' ||| variable expression replace_bound alpha_convert	count=1
arg	the given pattern ||| pattern	count=2
function	decode ||| decode	count=2
function	methods of ||| demo	count=2
arg	of its forward pointer ||| forward fs_class	count=1
class	necessary to ||| nkjpcorpus	count=1
arg	v this is ||| v	count=1
class	list of tweets ||| twitter	count=1
arg	collection of documents each ||| documents	count=1
function	the nodes ||| nodes	count=1
module	invalidate the cached ||| core	count=1
arg	data returned by ||| data	count=1
function	copy ||| copy	count=1
function_arg	s-expressions from [arg_2] ||| [function_1] [arg_2] comment_char	count=2
arg	the list of ||| fileids sent	count=1
function	button ||| cb	count=1
function	block comparison ||| block comparison	count=1
class	underlying list ||| lazy	count=1
function	modifiers is listed for ||| arity parse	count=1
arg	objects [arg] ||| concepts [arg]	count=3
class	information about ||| query	count=1
function	parse a string representing ||| aug parse	count=1
module	return all ||| corpus reader	count=1
function	word where the feature ||| feature	count=1
function	tweets tokenized using ||| demo tweets	count=1
arg	[arg_1] with expression ||| [arg_1] [arg_2]	count=9
arg	sentence ||| sentence	count=5
function	information about ||| id	count=1
class	lists the [class] lists ||| [class]	count=1
function	test [function_2] ||| [function_2] [function_1]	count=1
class	list concatenating ||| lazy iterator list	count=1
arg	true if [arg] terminal which ||| [arg]	count=1
module	all ||| corpus	count=1
module	be called ||| app	count=2
class	of supported languages ||| crubadan	count=1
arg	classifier on 10000 ||| n_instances output	count=1
module_class	[module_1] [class_2] ||| [module_1] [class_2]	count=401
function_arg	log probability [arg_2] ||| [function_1] [arg_2]	count=2
arg	execute with the assumptions ||| assumptions	count=1
function	probabilities uniformly to ||| uniform probabilities	count=1
function	return the feature ||| feature	count=1
function	get synset relations data ||| get relations data	count=1
arg	the given file s ||| fileids speaker stem relation	count=1
class	dictionary containing the probdists ||| dictionary conditional prob dist	count=1
arg	print classifier ||| classifier	count=1
function	relation ||| tgrep relation	count=1
class	as a list of ||| tagged corpus reader	count=1
function	modify ||| decorate	count=1
arg	the token into a ||| token	count=1
class	sequence with the ||| markov	count=1
class	:return a corpus ||| nombank corpus	count=1
function_arg	train on sentence_aligned_corpus [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
function	exemplar sentences optionally ||| exemplars	count=1
class	state ||| markov model	count=1
class	collocation [class_2] ||| [class_1] [class_2]	count=1
function	list [function_2] ||| [function_2] [function_1]	count=4
arg	[arg_1] by ||| [arg_1] [arg_2]	count=1
arg	on 10000 ||| n_instances output	count=1
class	must be called if ||| regexp chunk	count=1
module	function given ||| corpus reader	count=1
function	construct a value for ||| construct threads	count=1
function	to construct ||| construct threads	count=1
class	variable [class_2] ||| [class_2] [class_1]	count=5
class	[class_1] reader using ||| [class_1] [class_2]	count=1
class	move a token from ||| stepping shift	count=1
module_class	[module_1] for ||| [module_1] [class_2]	count=1
class	up this corpus ||| corpus	count=2
function_arg	[function_1] other ||| [function_1] [arg_2]	count=1
class	long verbnet class ||| verbnet	count=1
function	to construct a ||| construct readings	count=1
function	returns a ||| expression	count=1
arg	event in self ||| event	count=1
function	a module [function_2] ||| [function_1] [function_2]	count=3
function	height of ||| height	count=2
class	return a ||| corpus	count=2
function	the use ||| pred use	count=1
class	encoded as tuples ||| chunked corpus reader	count=1
class	[class_1] set having ||| [class_1] [class_2] add	count=4
arg	of function ||| function	count=1
class	order ||| lexicon	count=1
class	function must be called ||| chart parser	count=1
module	subtype ||| sem	count=1
class	in the test ||| test	count=1
arg	appearances of words ||| word_fd bigram_fd	count=1
class	from the ||| stepping shift reduce parser	count=1
class	build ||| framenet corpus reader	count=1
function	tabulate the given ||| tabulate	count=1
function_arg	[function_1] [arg_2] ||| [function_1] nodes pattern trees [arg_2]	count=3
function	[function_1] in that ||| [function_1] [function_2]	count=3
arg	frame object ||| frame frame2 type	count=1
arg	t in the target ||| t	count=1
class	save ||| chart parser app	count=1
class	as iso ||| crubadan	count=1
class	indicates how much of ||| edge	count=1
class	list of ||| reader	count=1
function	alignedsent objects ||| aligned sents	count=1
function	modify and return ||| decorate	count=1
class	confusion [class_2] ||| [class_1] [class_2]	count=5
class	return this ||| i	count=1
arg	handle a release callback ||| event	count=1
class	tagger ||| tagger	count=5
arg	list ||| conds	count=1
arg	the remaining lines ||| lines wrap_at	count=1
class	new iterator ||| iterator	count=1
class	list of ||| crubadan corpus	count=1
class	the ||| glue demo	count=1
class	words in alphabetical order ||| reader	count=1
arg	text if finalize is ||| text verbose finalize	count=1
arg	row ||| rowvalue	count=1
class	a single parsing ||| recursive descent parser	count=1
function	entity ||| descape entity	count=1
arg	positive_featuresets ||| positive_featuresets unlabeled_featuresets	count=1
module	tag position mapping & ||| tag	count=1
function_arg	sentence and [arg_2] ||| [function_1] a given s [arg_2]	count=2
function	of s-expressions from the ||| sexpr block	count=1
class	sentence ||| t	count=2
class	the first ||| descent	count=1
arg	string of bracketted ||| s	count=1
class	in the given ||| corpus reader	count=1
arg	module returns a list ||| category fileids	count=1
function	color ||| color	count=1
arg	source-to-target and [arg_2] ||| [arg_1] [arg_2]	count=1
function_arg	[function_1] rule ||| [arg_2] [function_1]	count=1
module	how ||| parse	count=1
class	contexts to tags ||| context	count=1
class	wordnet 3 ||| word net	count=1
arg	the words ||| words	count=1
arg	encoded as tuples ||| relation	count=1
function	return a vector ||| vector	count=1
module	text to the end ||| parse	count=1
function	enter the tkinter mainloop ||| mainloop	count=6
class	encoding ||| feature encoding	count=2
function	error message ||| error	count=1
function	tweets by a ||| tweets by user	count=1
function	is of [function_2] ||| [function_2] [function_1]	count=4
module	position this ||| draw	count=2
function	help [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] concept out ||| [function_2] [function_1]	count=1
class	that ||| recursive descent parser	count=4
class	index ||| index	count=2
class	version on the childes ||| childescorpus reader	count=1
function	sentence to be ||| translate	count=1
arg	window_size ||| window_size	count=1
class	[class_1] contexts ||| [class_2] [class_1]	count=2
class	the internal indexes to ||| reader	count=1
function	a matrix of ||| matrix	count=1
class	classifier based on ||| classifier based tagger	count=2
function	the fulltextindex xml ||| handle fulltextindex	count=1
class	return a list ||| corpus	count=1
arg	of the symbol ||| symbol	count=1
class	substitution ||| ccgvar	count=1
class	if the underlying ||| seekable unicode	count=1
function	cosine ||| cosine	count=1
class	to figure out how ||| chart	count=1
function	brevity ||| brevity	count=1
function	get [function_2] ||| [function_1] [function_2]	count=7
arg	binary with the ||| binary args verbose	count=1
arg	status_code ||| status_code data	count=1
arg	node is root ||| root	count=1
class	used by this tagger ||| tagger	count=1
arg	of text [arg_2] ||| [arg_2] [arg_1]	count=4
class	bigram collocation ||| trigram collocation finder	count=1
arg	matching the filter function ||| filter	count=1
module_class	the twitter api ||| twitter query	count=1
class	sequence ||| tagger	count=2
function_arg	[function_1] [arg_2] into account partial agreement ||| [function_1] [arg_2]	count=1
class	function ||| glue demo	count=1
class	proper probability distribution ||| simple good turing prob dist	count=1
function	convert ||| convert	count=1
class	joint-feature ||| maxent feature	count=1
function	frequent [function] contexts ||| [function]	count=1
class	for this encoding ||| binary maxent feature encoding	count=1
function	contexts ||| contexts	count=1
class	in particular if ||| stepping recursive descent parser	count=1
function	size of the file ||| size	count=1
module	of the ||| reader	count=1
class	the lancaster [class_2] ||| [class_2] [class_1]	count=1
class	logic [class_2] ||| [class_1] [class_2]	count=2
function	ratios as ||| ratio	count=1
class	[class_1] linear regression ||| [class_2] [class_1]	count=2
arg	divide a string ||| s chunk_label root_label	count=1
class	tree in three ||| tree	count=1
arg	encodes the chunking of ||| chunk_struct debug_level	count=1
function	indicating [function] ||| [function]	count=1
class	enter ||| glue demo	count=1
module	for this ||| draw	count=1
function	a string containing ||| pretty format	count=1
function_arg	list of [arg_2] ||| [arg_2] [function_1]	count=2
arg	file s as a ||| fileids tagset	count=2
module	a list of supported ||| corpus reader	count=1
function	with all existing indexes ||| register with indexes	count=2
function	the least common subsumer ||| lcs	count=1
class	[class_1] distribution ||| [class_1] [class_2] renormalize r nr	count=5
module	to be how big ||| app	count=1
function	leaves ||| leaves	count=2
class	for the specified ||| corpus	count=1
function_arg	each successive [arg_2] ||| [arg_2] [function_1]	count=1
function	this function "calculates ribes ||| ribes	count=1
arg	the originals ||| originals	count=1
function	greatest number of outcomes ||| max	count=1
class	the perl unicode properties ||| unichars corpus reader	count=1
arg	of segmentations ||| k boundary	count=1
arg	into ||| read	count=1
function	induce a [function_2] ||| [function_1] [function_2]	count=1
function	an [function] ||| [function]	count=2
function	normalize the ||| normalize boundaries	count=1
class	be called if ||| chart parser	count=1
class	frequency distribution ||| simple good turing prob dist	count=1
arg	to implement ||| unit bracket_sent	count=1
function	the status of the ||| status	count=1
arg	root directory ||| root omw_reader	count=1
class	function must ||| drt glue demo	count=1
class	remaining ||| stepping shift reduce	count=1
function	print a ||| print	count=1
function	[function_1] qtree package ||| [function_1] [function_2]	count=3
arg	trees ||| trees	count=2
class	to be how big ||| chart view	count=1
class	mapping contexts to tags ||| tagger	count=1
function	from the fulltextindex ||| fulltextindex elt	count=1
function	instantiates and ||| expression	count=1
function	[function_1] index page ||| [function_2] [function_1]	count=3
arg	rows and ||| rows cols	count=1
function	sentences each encoded as ||| sents	count=2
class	a token from the ||| shift	count=1
function	grammar used ||| grammar	count=2
arg	widget ||| widget	count=1
function	to construct a value ||| construct readings	count=1
function	get the [function_2] ||| [function_1] [function_2]	count=3
class	the corpus or in ||| corpus	count=2
class	rule it has ||| chunk rule with context	count=1
function	of alignedsent objects ||| aligned sents	count=1
class	this function must ||| drt glue	count=1
function_arg	entity to [arg_2] ||| [function_1] [arg_2]	count=1
function	find the next best ||| best	count=1
class	to the chart ||| chart	count=1
function	return the standard interpretations ||| r1r2 standard	count=1
function	bleu for ||| corpus bleu	count=2
function	to this input ||| parse	count=1
module	refers ||| tbl	count=1
class	supported languages ||| reader	count=1
arg	creates the ||| source_blocks target_blocks params	count=1
function	binding to each tkinter ||| bind to columns	count=1
module	exemplify repr ||| tbl	count=1
arg	search for ||| env_vars searchpath	count=1
class	header_mode ||| header	count=1
module	primitive category ||| ccg	count=1
arg	a feature ||| feat	count=1
class	element in ||| reader	count=1
function	print a list of ||| print	count=1
class	collocation finder ||| abstract collocation finder	count=2
function	train the ||| train	count=1
function	variety ||| user info from	count=1
function	create an instance of ||| init	count=1
class	this instance's predicate ||| nombank instance	count=1
arg	val ||| val	count=1
class	logic parsers [class_2] ||| [class_1] [class_2]	count=2
function	lin ||| lin	count=1
module	on whether tweets are ||| twitter	count=1
function	its relation to other ||| tgrep relation	count=1
arg	actual word ||| word intact_word	count=2
class	nonterminal ||| nonterminal	count=1
arg	the string at ||| s	count=1
module	indexes to ||| reader	count=1
class	tree should be ||| view	count=1
module	this instance's predicate ||| reader	count=1
class	corpus ||| verbnet corpus reader	count=1
arg	the expression ||| expression	count=2
class	ibm ||| ibmmodel	count=1
class	sentence in an subcorpus ||| corpus reader	count=1
module	from the ||| parse	count=1
class	the frontier ||| recursive descent	count=1
function_arg	lemma objects [arg_2] ||| [function_1] [arg_2]	count=1
function	the score for a ||| score	count=2
function	of plausible semtypes in ||| semtypes	count=1
arg	[arg_1] match the ||| [arg_2] [arg_1]	count=3
class	of the ||| instance	count=1
function	[function_1] 2 ||| [function_2] [function_1]	count=1
function_arg	[function_1] sequence of ||| [function_1] [arg_2]	count=4
class	can be generated ||| arff formatter	count=1
arg	frame ||| frame	count=2
class	return the unicode encoding [class_1] [class_2] file if known ||| [class_2] [class_1] encoding file	count=2
arg	takes a sentence as ||| sentence verbose	count=1
class	that a token has ||| reduce parser	count=1
function	chunks each of which ||| chunks	count=1
class	displaying ||| parser	count=1
class	enter ||| chart	count=1
function	modify and return the ||| decorate	count=1
function	contains ||| contains	count=4
class	a dependency graph ||| probabilistic projective dependency parser	count=1
function	the [function] of this ||| [function]	count=2
class	big the tree should ||| view	count=1
function	past tweets [function_2] ||| [function_1] [function_2]	count=3
arg	from a list of ||| start	count=1
arg	number of rows and ||| rows cols attempts	count=1
function	to find ||| find	count=2
class	a corpus ||| corpus	count=2
class	this classifier ||| bayes classifier	count=1
module	tag for ||| tag	count=2
arg	the target [arg_2] ||| [arg_1] [arg_2]	count=1
module_class	[module_1] for the ||| [module_1] [class_2]	count=1
arg	self and other ||| other check_reentrance visited_self visited_other	count=1
arg	of speech ||| pos	count=1
class	chart rule used ||| chart	count=1
class	view for ||| view	count=1
arg	event ||| event	count=1
function	a demonstration of the ||| demo	count=5
class	to figure out how ||| view	count=1
class	return all ||| opinion	count=1
class	[class_1] pointer in ||| [class_2] [class_1]	count=1
class	move ||| stepping shift reduce parser	count=1
function	build a ||| build	count=2
arg	tree :return ||| tree	count=2
module_class	a string representation of [module_1] [class_2] ||| [module_1] [class_2]	count=4
module	any ||| core	count=1
arg	strings is provided it ||| strings	count=1
class	a projective dependency ||| projective dependency parser	count=2
module	meaning's ||| corpus reader	count=4
arg	from a word-aligned sentence ||| srctext	count=1
arg	set of all nonterminals ||| cat	count=1
class	state ||| tagger	count=1
function	the cyrillic alphabet ||| cyrillic	count=1
class	as iso ||| corpus	count=1
module	needs to ||| app	count=1
function	be the top of ||| find top	count=1
module	how big the ||| app	count=1
class	for a given bigram ||| bigram	count=1
function	will be the top ||| find top	count=1
function	the mode ||| mode	count=1
module	childes corpus ||| corpus reader	count=1
function_arg	[function_1] refs list ||| [arg_2] [function_1]	count=1
arg	s ||| fileids strip_space	count=1
module	a collection of expression ||| sem	count=1
class	as in manning ||| assoc measures	count=1
class	sentence in an subcorpus ||| reader	count=1
class	moses ||| moses	count=3
class	and current weights and ||| averaged	count=1
arg	which match [arg_2] ||| [arg_2] trees [arg_1]	count=1
arg	of variable v with ||| variable	count=3
function	distance ||| distance	count=5
function	[function_1] the static ||| [function_2] [function_1]	count=1
function	six patterns and ||| pro w64	count=2
module	[module] the ||| [module]	count=3
class	a token ||| stepping shift	count=1
function	for a [function] ||| handle [function]	count=1
arg	[arg_1] if finalize ||| [arg_2] [arg_1]	count=4
arg	[arg_1] f-score described ||| [arg_1] [arg_2]	count=1
class	underlying [class_2] ||| [class_1] [class_2]	count=1
function	return the corresponding string ||| tuple2str	count=1
module_class	[module_1] initializer should ||| [module_1] [class_2]	count=8
arg	of *regexp* ||| regexp	count=1
function	returns a list of ||| list	count=1
arg	labels a list of ||| labels	count=2
function_arg	by [arg_2] ||| [function_1] [arg_2]	count=1
arg	with a specific c{alignment} ||| i j source_sents target_sents	count=1
arg	binary ||| binary args	count=1
class	generated when parsing a ||| shift reduce parser	count=1
arg	classifier performance ||| test_set classifier accuracy f_measure	count=1
class	api ||| streamer	count=1
arg	word and ||| word	count=2
class	:return the meaning's ||| meaning	count=4
arg	complete tree structures that ||| tree_class	count=1
class	of ||| nombank instance	count=1
class	this instance's ||| nombank instance	count=1
function	module ||| taggedsent	count=1
module	the [module] on ||| [module]	count=1
function_arg	corpus [arg_2] ||| [arg_2] [function_1]	count=4
function	file to ||| file	count=1
class	order ||| opinion lexicon corpus reader	count=1
function	model ||| model	count=4
function	the various ||| demo	count=2
module	string value [module] an rte ||| corpus [module]	count=1
function	the unique ||| get unique	count=1
class	this [class_2] ||| [class_1] [class_2]	count=2
function	to create a ||| init	count=3
module	full tweets if available ||| twitter	count=1
function	to parse multiple sentences ||| parse	count=1
function	a userid to ||| userid demo	count=1
class	the path identified by ||| path	count=1
function	crosses the truncation line ||| truncation	count=1
module	function must be called ||| sem	count=1
arg	its variable ||| variable	count=1
class	tagger uses to ||| based tagger	count=2
arg	child to ||| child index	count=2
function	information about the ||| user info	count=1
function	an error in a ||| error	count=1
class	for this alignedsent ||| aligned sent	count=1
function	returns ||| expression	count=1
function	userid to a ||| lookup by userid demo	count=1
function_arg	[function_1] n-gram ||| [arg_2] [function_1]	count=2
function	the table's _rows variable ||| table	count=1
module	a list of ||| corpus	count=1
arg	augmented word tokens ||| tokens	count=1
arg	pairs is ||| pairs	count=1
function_arg	from [arg_2] ||| [function_1] [arg_2]	count=4
function_arg	[function_1] under ||| [function_1] [arg_2]	count=5
function_arg	[function_1] [arg_2] the variable ||| [function_1] [arg_2]	count=1
arg	s ||| s verify_tags	count=1
arg	implement the view ||| bracket_sent tag strip_space	count=1
function	to each ||| to columns	count=1
function	factory method ||| variable	count=1
class	languages as iso ||| corpus reader	count=1
class	in particular ||| descent parser	count=1
class	this function must ||| chart parser app	count=1
class	the brill tagger on ||| brill tagger	count=1
class	use simple linear regression ||| simple good turing prob dist	count=1
arg	list of word ||| stem	count=2
class	the corpus ||| cons corpus reader	count=1
function	collocations derived from ||| collocations	count=1
function_arg	of tagged [arg_2] ||| [function_1] to parse [arg_2]	count=1
class	particular ||| recursive descent	count=1
arg	most ||| words	count=1
function	variety of information about ||| info from	count=1
class	(corpus_property_key value) ||| childescorpus	count=1
class	files that have ||| reviews	count=1
arg	a method ||| handler	count=2
function	in ||| draw	count=1
class	utterances in this corpus ||| corpus reader	count=1
function	a subtype ||| variable	count=1
class	needs ||| chart view	count=1
class	alphabetical order ||| opinion lexicon	count=1
class	how ||| edge i	count=1
arg	classifier performance on the ||| test_set classifier accuracy f_measure	count=1
class	be overridden ||| drt	count=1
module	a list of ||| reader	count=1
arg	divide a string of ||| s chunk_label	count=1
arg	a single instance applying ||| instance	count=1
class	encoded as a list ||| tagged	count=2
arg	file identifiers for the ||| filetype	count=1
arg	[arg] with ||| [arg]	count=1
function	convert a list of ||| info from id	count=1
arg	[arg] takes ||| [arg]	count=1
arg	list of tokens ||| tokens tags	count=1
arg	p ||| p	count=3
arg	text label ||| label word_tokenizer	count=1
module	how big the tree ||| app	count=1
arg	file if no filename ||| filename	count=1
class	featuresets [class] ||| multi classifier [class]	count=4
function	new data xml index ||| index	count=1
class	to be how ||| chart	count=1
class	the feature identifiers ||| feat	count=1
class	of the ||| recursive	count=1
class	decision tree ||| decision tree classifier	count=2
function_arg	word alignments [arg_2] ||| [arg_2] [function_1]	count=6
arg	the list of tokens ||| tokens	count=1
function	with [function_2] ||| [function_2] [function_1]	count=4
arg	its forward pointer to ||| forward fs_class	count=1
function	[function] should ||| demo multiposition [function]	count=3
arg	data bytes ||| data size	count=2
function	relation to other ||| relation	count=1
class	as as a ||| corpus reader	count=1
class	encoding [class] file ||| [class]	count=1
function	unigram features reflecting ||| extract unigram feats	count=2
module	the [module] macro ||| [module]	count=1
function_arg	construct a [arg_2] ||| [function_1] word_fd [arg_2]	count=4
class	the given ||| framenet corpus reader	count=2
function	training data from a ||| train	count=1
function	possible word alignments ||| alignments	count=2
class	probability state ||| hidden markov model tagger	count=1
function	representing [function_2] ||| [function_2] [function_1]	count=1
class	move a token ||| reduce	count=1
module	of the hypothesized ||| parse	count=1
function	sentences in ||| sentences	count=1
class	sentence string ||| view	count=1
function_arg	[function_1] the item ||| [arg_2] [function_1]	count=1
class	probability of a dependency ||| probabilistic projective dependency parser	count=1
class	in store if ||| store	count=1
function	an sql ||| sql	count=1
function	columns used ||| column	count=1
module	if ||| parse	count=1
function	relation to ||| relation	count=1
class	the remaining text to ||| stepping shift reduce parser	count=1
class	using the lancaster ||| lancaster	count=1
class	words in ||| opinion	count=1
function	[function_1] to convert ||| [function_2] [function_1]	count=2
class	this rule given the ||| chart rule	count=1
function	by pointwise mutual information ||| pmi	count=1
arg	sentence takes a sentence ||| sentence	count=1
class	stack ||| shift reduce parser	count=1
class	a dependency graph based ||| projective dependency parser	count=1
class	feature ||| feat	count=15
class	hypothesized structure is consistent ||| i	count=1
function	a list of ||| from id	count=1
class	text to the end ||| parser	count=1
class	[class] frame's ||| [class]	count=3
class	to be how big ||| chart	count=1
function	to each element ||| sents	count=2
function	[function_1] children ||| [function_1] [function_2]	count=3
class	for a given bigram ||| bigram collocation finder	count=1
class	parser uses to ||| parser	count=1
arg	valuation ||| valuation lexicon	count=1
class	languages as ||| crubadan	count=1
module	if ||| sem	count=1
arg	pair of segmentations ||| k boundary	count=1
arg	each rule ||| chunkstr	count=1
arg	rows ||| rows cols attempts	count=1
class	in particular if ||| recursive descent	count=1
arg	id luname [arg_2] ||| [arg_1] [arg_2]	count=4
arg	input stream ||| stream	count=1
class	a probability [class_2] ||| [class_2] [class_1]	count=12
arg	devset_name ||| devset_name devset	count=1
function	of ||| drt discourse demo	count=1
class	big the tree ||| chart	count=1
module	be called if ||| app	count=2
function	that instantiates ||| variable	count=1
function	update the ||| update rule	count=1
function	set of labels ||| labels	count=1
class	as ||| ngram assoc measures	count=1
function	most emoticons ||| emoticons	count=1
function	predicate-argument annotation ||| lines	count=2
function	information about the ||| from	count=1
class	all bigrams ||| bigram	count=1
function	list ||| from	count=1
class	that is licensed by ||| parser	count=1
function	the columns used ||| column	count=1
arg	based on [arg_2] ||| [arg_2] [arg_1]	count=4
function_arg	the present [arg_2] ||| [arg_2] [function_1]	count=1
class	that ||| descent parser	count=4
function	sentence to ||| translate	count=1
class	candidate ngrams ||| abstract collocation finder	count=2
module	return true iff ||| core	count=1
function	tagger to ||| tagger	count=1
arg	in the current round ||| upper_date_limit lower_date_limit	count=1
arg	prob_dist ||| prob_dist	count=1
class	for the current ||| thesaurus corpus reader	count=1
arg	probdist_dict a ||| probdist_dict	count=1
module	given ||| corpus	count=1
function	tweets tokenized ||| tweets	count=1
module	this is a ||| sem	count=1
class	of all parses ||| descent	count=2
function	tgrep ||| tgrep tokenize	count=1
arg	modelbuilder ||| modelbuilder goal	count=1
function	variety of information about ||| user info	count=1
function	the standard interpretations ||| r1r2 standard	count=1
module	return ||| parse	count=1
class	self ||| abstract	count=2
class	sentence in an ||| corpus reader	count=1
arg	the specified entry ||| entry	count=1
function	an exemplar [function_2] ||| [function_2] [function_1]	count=4
function	synsets for the ||| synsets	count=1
function	sample ||| sample	count=1
class	the [class_1] [class_2] ||| [class_1] [class_2]	count=6
class	and the associated menu ||| mutable option menu	count=1
function	[function_1] all possible ||| [function_1] [function_2]	count=6
class	words in alphabetical order ||| lexicon corpus	count=1
function	its relation to ||| relation	count=1
function	first-order logic ||| fol	count=1
arg	being observed in ||| state	count=1
module	text to the ||| parse	count=1
function_arg	[function_1] trees which ||| [function_1] pattern [arg_2]	count=3
function	describes the use of ||| use	count=1
class	which indicates ||| edge i	count=1
function	convert a userid to ||| lookup by userid demo	count=1
function	grammar is ||| calculate grammar	count=2
arg	from consideration given the ||| rule train_sents test_sents	count=1
class	needs ||| view	count=1
function	sentence level chrf character ||| sentence chrf	count=1
function	its relation ||| relation	count=1
module	and whose ||| parse	count=1
class	the frequency distribution ||| simple good turing prob dist	count=1
class	necessary to ||| nkjpcorpus reader	count=1
function_arg	[function_1] stack ||| [function_1] [arg_2]	count=4
function	[function_1] columns used ||| [function_2] [function_1]	count=4
function	the [function_1] [function_2] ||| [function_1] [function_2]	count=6
class	in alphabetical ||| lexicon	count=1
arg	a given ||| node	count=1
function	log probability ||| log prob	count=1
module	canvasframe if this ||| draw	count=1
class	occurs as ||| multi parented	count=1
arg	tree string ||| s	count=1
arg	[arg_1] v this ||| [arg_1] [arg_2]	count=1
function	to realign ||| realign boundaries	count=1
module	method that ||| sem	count=1
class	a spanish ||| spanish stemmer	count=1
function_arg	data for [arg_2] ||| [function_1] [arg_2]	count=3
arg	provercommand provercommand to decorate ||| provercommand	count=1
class	the first element ||| recursive descent parser	count=1
arg	and ranks2 for keys ||| ranks2	count=1
class	of sample outcomes that ||| freq dist	count=1
arg	string of bracketted tagged ||| s chunk_label root_label sep	count=1
function	absolute [function] that it ||| [function]	count=1
class	structure that is ||| struct	count=1
class	called ||| glue demo	count=1
function	and most emoticons ||| and emoticons	count=2
function	[function_1] latex qtree ||| [function_2] [function_1]	count=1
function	a list ||| info	count=1
function_arg	[function_1] tokentablefields ||| [arg_2] [function_1]	count=3
arg	use [arg] rightmost ||| [arg]	count=1
arg	list of characters from ||| fileids	count=1
function	a tgrep search ||| tgrep	count=2
class	build ||| reader	count=1
class	canvas widget [class] a given ||| [class]	count=2
function	from the conjunction ||| conjunction	count=1
function	suffix-removal rule ||| apply rule	count=1
function	(see also str ||| str	count=1
function	the [function] is the ||| calculate [function]	count=1
module	of the remaining ||| parse	count=1
arg	set of reference ||| reference	count=1
arg	of word tag tuples ||| strip_space stem	count=1
class	indicating that a ||| viterbi parser	count=1
module	list ||| core	count=1
class	strings ||| sentence tokenizer	count=1
function	variety of information about ||| info from id	count=1
function_arg	[function_1] a pretty-printed ||| [function_1] [arg_2]	count=3
arg	simple manner ||| follow to_screen stream	count=1
function	hierarchical children ||| child widgets	count=1
arg	is incomplete (i e ||| span lhs rhs dot	count=1
function_arg	[function_1] for translating ||| [function_1] [arg_2]	count=4
class	make up the colorized ||| colorized	count=1
class	to ||| linear logic parser	count=1
function	targets and ||| frames	count=1
class	new feature encoding ||| maxent feature encoding i	count=1
class	pickle corpus and ||| pickle corpus	count=1
module	tweets ||| corpus reader	count=2
function	of fileids that ||| fileids	count=1
class	given ||| classifier i	count=1
arg	the given root directory ||| root fileids encoding	count=1
arg	and returns ||| line primitives families var	count=1
class	proper [class_2] ||| [class_1] [class_2] renormalize r nr	count=1
module	the first element of ||| parse	count=1
class	a dependency graph based ||| probabilistic projective dependency parser	count=1
function	the java binary and ||| config java	count=1
arg	website and ||| fileid urlbase	count=1
arg	website and open it ||| fileid urlbase	count=1
function	tweets by a ||| tweets by	count=1
class	use the heldout estimate ||| heldout	count=1
function	the static ||| static	count=1
class	the path identified ||| path	count=1
class	stream ||| seekable unicode stream reader	count=1
function_arg	a demonstration [arg_2] ||| [function_1] [arg_2]	count=3
function	parse the ||| parse	count=2
class	parsing ||| recursive descent parser	count=1
function	restore ||| restore	count=1
function	str ||| demo str	count=1
function	[function_1] epytext @field ||| [function_2] [function_1]	count=1
function	a dictionary of ||| make predicate dict	count=1
function	[function] scores ||| update [function]	count=2
function	depending on its relation ||| relation	count=1
class	big the tree should ||| chart	count=1
arg	[arg] common top_n ||| [arg] top_n	count=1
function	from [function_2] ||| [function_1] [function_2]	count=1
function	illustrate ||| drt	count=1
function	local ||| retrieve	count=1
function	log [function_2] ||| [function_1] [function_2]	count=1
class	return ||| lexicon corpus reader	count=1
class	which indicates how ||| i	count=1
arg	multi-word ||| mwes separator	count=1
function	pointer lists for the ||| pointer lists	count=1
class	when parsing a ||| recursive descent parser	count=1
module	iso 639-3 ||| reader	count=1
function	variety ||| id	count=1
class	initial tagger ||| brill tagger	count=1
module	element ||| parse	count=1
function	the [function] ||| [function] in	count=1
arg	sequence of items as ||| sequence n k	count=1
function	ipython ||| repr	count=1
class	sentence breaks yielding ||| sentence	count=1
function	string representation [function_2] ||| [function_2] [function_1]	count=1
function_arg	[function_1] words can ||| [arg_2] [function_1]	count=2
class	enter ||| drt glue	count=1
function	words defined ||| words	count=1
function	invalidate the cached ||| setitem	count=1
function	creates a table ||| create token table	count=1
arg	to the window_size ||| window_size	count=1
class	must be ||| drt glue	count=1
class	be ||| chart	count=3
arg	finalize is true it ||| finalize	count=1
arg	*worder* list ||| hypothesis character_based	count=1
class	child's parent ||| stack	count=1
class	constructs a collocation ||| collocation	count=1
class	bounding boxes of ||| scroll watcher widget	count=1
module	an alignment model ||| translate	count=1
class	indicates how ||| edge	count=1
function	realign ||| realign boundaries	count=1
function	friendly error message when ||| error	count=1
arg	[arg_1] expression ||| [arg_2] [arg_1]	count=9
function	of text ||| text	count=1
function	variety ||| from	count=1
function	sentences each ||| sents	count=5
class	move a ||| stepping	count=1
class	feature [class] ||| feat [class]	count=2
module	this scroll-watcher's canvas ||| draw	count=1
arg	python port of ||| return_str	count=1
class	end ||| stepping shift reduce parser	count=1
function	number of entries in ||| size	count=1
arg	[arg] any ||| [arg] k	count=2
function	of abstractvariableexpression appropriate for ||| expression	count=1
function	methods of ||| discourse demo	count=2
class	frequency ||| freq	count=6
class	frequency [class_2] ||| core [class_1] [class_2]	count=1
class	in a sentence ||| sentence tokenizer	count=1
class	list of the transformational ||| brill template	count=1
class	indexes to ||| framenet corpus reader	count=1
function	[function_1] comparison ||| [function_2] [function_1]	count=1
class	the chart rule ||| chart parser	count=1
function	all nodes [function] the given ||| [function]	count=3
class	block ||| text tiling tokenizer	count=1
function	[function_1] alignment ||| [function_1] [function_2]	count=1
function	step 3 from "an ||| step3	count=1
function	return all positive ||| positive	count=1
function	convert a userid ||| by userid	count=1
class	must be called ||| chunk app	count=1
class	tweets as as ||| twitter corpus	count=1
module	users ||| twitter	count=1
function	string ||| str	count=1
arg	given synset [arg_2] ||| [arg_2] [arg_1]	count=2
arg	string to ||| s	count=1
class	beginning ||| stepping shift reduce parser	count=1
class	should be ||| chart view	count=1
arg	[arg] provided ||| [arg]	count=1
class	applied to elements ||| lazy map	count=1
function	[function_1] most emoticons ||| [function_2] [function_1]	count=1
function	tau ||| tau	count=1
module	a ||| corpus	count=1
arg	label pair ||| label	count=1
function	token is ||| is	count=1
function_arg	[function_1] [arg_2] ||| [function_1] nodes [arg_2]	count=1
arg	n-gram f-score ||| hypothesis min_len max_len	count=1
arg	symbol when ||| symbol	count=1
class	joint-feature values ||| maxent feature	count=1
function_arg	sentence and [arg_2] ||| [arg_2] [function_1]	count=2
module_class	will be used by [module_1] [class_2] ||| [module_1] [class_2]	count=4
function	latex [function_2] ||| [function_2] [function_1]	count=2
class	classifier based on ||| classifier based	count=1
function	readme txt ||| readme	count=2
class	of a tree ||| tree	count=1
function	single ||| raw	count=1
arg	into a list of ||| read lexicon	count=1
class	be called if ||| glue demo	count=1
function	variety of information about ||| user	count=1
arg	in filename ||| filename	count=1
function	annotated sentences ||| sents	count=1
class	end ||| shift	count=1
arg	[arg_1] can ||| [arg_1] [arg_2]	count=1
class	from the ||| shift	count=1
class	collocation finder with ||| trigram collocation	count=1
class	this method ||| drt	count=1
module	to ||| corpus reader	count=2
function_arg	tags [arg_2] ||| [arg_2] [function_1]	count=1
class	at the path identified ||| path	count=1
arg	[arg_1] the vectors ||| [arg_2] [arg_1]	count=2
arg	variable v [arg_2] ||| [arg_1] [arg_2]	count=3
module	list ||| corpus reader	count=2
function	about ||| user info from id	count=1
class	logic parsers that ||| logic parser	count=6
class	:return a corpus ||| corpus	count=2
arg	text ||| text	count=7
class	associated with this ||| probabilistic mix in	count=1
module_class	position this table's ||| draw table	count=2
function	node value corresponding ||| symbol	count=1
function	string ||| repr	count=1
class	chunk [class] for ||| chunk parser [class]	count=1
class	a given trigram ||| trigram collocation	count=1
arg	or in ||| fileids	count=1
class	probability state sequence this ||| model tagger	count=1
function	chomsky ||| chomsky	count=1
arg	that encodes the chunking ||| chunk_struct debug_level	count=1
arg	the tokens in unigrams ||| unigrams	count=1
function	a list of tagged ||| tagged	count=5
function	entity ||| entity	count=1
function	the indices where ||| indices	count=1
arg	frame optional frame object ||| frame frame2 type	count=1
class	as a list of ||| tagged	count=1
arg	the symbol [arg_2] ||| [arg_2] [arg_1]	count=4
function	nodes [function] the ||| [function]	count=3
class	table so ||| table	count=1
function	factory method that instantiates ||| variable	count=1
module_class	words [class_2] ||| [module_1] [class_2]	count=3
class	frontier in particular if ||| stepping recursive descent parser	count=1
arg	a bracketed ||| brackets read_node	count=1
class	split the frequency distribution ||| good turing prob dist	count=1
function	tweets by a ||| tweets by user demo	count=1
function	log probability of the ||| logprob	count=1
function	a ||| info from	count=2
class	a dictionary containing the ||| dictionary conditional prob dist	count=1
function_arg	a list [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	[function_1] if with_shutdown ||| [function_1] [arg_2]	count=4
function	to build ||| test build	count=1
class	function must be called ||| parser app	count=1
arg	the complete tree structures ||| tree_class	count=1
class	[class_1] listbox ||| [class_1] [class_2]	count=1
class	structure is consistent with ||| edge i	count=1
class	a token ||| stepping shift reduce parser	count=1
class	overall ||| chunk score	count=2
function	a variety ||| id	count=1
class	[class] an ||| framenet [class]	count=1
function	[function_1] index for ||| [function_2] [function_1]	count=3
function_arg	block from [arg_2] ||| [function_1] [arg_2]	count=1
class	minimal [class_2] ||| [class_2] [class_1]	count=3
class	of the ||| stepping recursive	count=1
arg	other ||| other check_reentrance	count=1
arg	that cover ||| constituents	count=1
class	the feature identifiers used ||| feat	count=1
module	list of ||| corpus	count=1
function	one entity to ||| entity	count=1
arg	to the target ||| target	count=1
arg	in alignment_info, ||| alignment_info j_pegged	count=1
function	helper for ||| fe	count=1
arg	[arg_1] of stack ||| [arg_2] [arg_1]	count=2
arg	other ||| other	count=9
function	help page ||| help page	count=2
arg	the index ||| index	count=1
class	words in ||| opinion lexicon	count=1
arg	segmentations a ||| seg1 seg2 k boundary	count=1
function	depth of ||| depth	count=1
function_arg	log probability [arg_2] ||| [function_1] state [arg_2]	count=1
class	tree or ||| parented tree	count=2
function	categories ||| categories	count=1
function	all variables ||| variables	count=1
function	return the regions ||| regions	count=1
function	a variety of information ||| user	count=1
class	the frontier ||| descent parser	count=1
function	[function] of ||| pretty [function]	count=1
module	framenet ||| corpus reader	count=1
class	[class_1] expression ||| [class_1] [class_2]	count=8
class	move a ||| stepping shift reduce parser	count=1
function	the string value of ||| value	count=1
module	method that instantiates and ||| sem	count=1
function_arg	fringe of [arg_2] ||| [arg_2] [function_1]	count=2
module	return a list ||| corpus reader	count=1
class	tree occurs as a ||| multi parented tree	count=1
function_arg	fringe [arg_2] ||| [arg_2] [function_1]	count=2
arg	devset_name ||| devset_name	count=1
function	[function_1] help ||| [function_1] [function_2]	count=4
class	the neural ||| neural	count=1
arg	binding_list list ||| binding_list	count=1
class	[class_1] reader for ||| [class_2] [class_1]	count=3
arg	a sequence of data ||| data start	count=1
function	node label of ||| label	count=1
class	as in ||| assoc measures	count=1
function	creates a table of ||| token table	count=1
arg	index of the ||| index	count=1
arg	add a ||| add	count=3
class	stack ||| stepping shift reduce parser	count=1
class	in particular if ||| stepping recursive	count=1
function	license ||| license	count=1
arg	expression the expression ||| expression command x	count=1
function	returns only the ||| strings	count=1
arg	to the [arg] this is ||| [arg]	count=1
arg	the l{align_texts} function ||| soft_delimiter hard_delimiter	count=1
class	to the end of ||| shift	count=1
arg	fval1 ||| fval1 fval2 bindings	count=1
class	distribution for ||| dist	count=3
arg	to produce the *worder* ||| reference hypothesis character_based	count=1
module	in ||| reader	count=3
class	contents of the ||| category	count=1
function	variety of information ||| from	count=1
arg	given file s ||| fileids tagset	count=2
function	tgrep search string into ||| tgrep	count=2
arg	a given user ||| user	count=1
arg	a pretty-printed [arg_2] ||| [arg_2] [arg_1]	count=3
arg	produce the *worder* list ||| reference hypothesis character_based	count=1
function	the button ||| cb	count=1
function	this edge's dot position ||| dot	count=1
class	and each feature ||| feat	count=1
function	a variety of information ||| user info from id	count=1
class	return this ||| edge	count=1
class	all bigrams in the ||| bigram	count=1
module_class	[module_1] canvas widget's ||| [module_1] [class_2]	count=4
class	chart ||| chart parser	count=2
module_class	[module_1] canvas widget ||| [module_1] [class_2] tags	count=8
class	with ||| markov	count=1
function	an epytext ||| epytext	count=1
class	:param ||| drs drawer	count=1
arg	a corpus ||| corpus	count=1
module	of [module] canvas ||| [module]	count=1
class	text as a ||| text	count=1
function	each successive ||| span tokenize	count=1
function	plausible semtypes in order ||| get semtypes	count=1
function	[function_1] sibling ||| [function_1] [function_2]	count=4
class	sentence breaks yielding a ||| sentence	count=1
class	probability [class_2] ||| core [class_1] [class_2]	count=1
function	accepts [function] ||| make [function]	count=1
function	from the fulltextindex xml ||| handle fulltextindex	count=1
arg	a new callback ||| callback	count=1
class	text to ||| stepping shift reduce	count=1
function	not absolute [function] that ||| [function]	count=1
arg	train_text can either be ||| train_text	count=1
function	matchs ||| by lemma	count=1
arg	given root directory ||| root omw_reader	count=1
class	of the given element ||| corpus reader	count=1
function	semtypes ||| semtypes	count=1
module	of information about ||| twitter	count=1
class	file underlying ||| lazy	count=2
class	the frontier in ||| stepping recursive descent parser	count=1
class	how big the ||| chart	count=1
arg	the *worder* list ||| hypothesis character_based	count=1
class	the sequence ||| hidden	count=1
function	lemmas that appear ||| lemmas	count=1
function_arg	sentences matching [arg_2] ||| [function_1] [arg_2]	count=1
function	[function_1] tag ||| [function_2] [function_1]	count=2
function	the macro name ||| macro	count=1
arg	word tag tuples ||| speaker stem relation	count=1
arg	tagging of the ||| train_sents	count=1
function	obtained by ||| neighboring	count=1
function	node ||| node	count=4
arg	expression ||| expression command	count=1
function_arg	[function_1] translating ||| [function_1] [arg_2]	count=3
function	return the [function] of this ||| [function]	count=2
arg	words can all appear ||| words fail_on_unknown	count=1
function	the available [function] ||| describe [function]	count=3
function	the [function] ||| slice [function]	count=1
class	parses ||| descent	count=2
function	the various ||| discourse demo	count=2
class	corpus ||| categorized corpus	count=1
arg	items the items at ||| items	count=1
class	danish ||| danish stemmer	count=1
module	a token from ||| parse	count=1
class	unit needs to be ||| chart view	count=1
function	of unigram features reflecting ||| extract unigram feats	count=1
module	the feature [module] the ||| [module]	count=1
class	words in alphabetical order ||| opinion	count=1
class	as a list ||| tagged corpus	count=1
class	uses ||| based	count=2
class	simple linear regression ||| simple good turing prob dist	count=1
function	clustering ||| cluster	count=1
class	the sequence ||| model	count=1
function	not a known abbreviation ||| reclassify abbrev	count=1
class	that can be generated ||| parser	count=2
function	representing a [function_2] ||| [function_1] parse [function_2]	count=1
function_arg	custom [arg_2] ||| [arg_2] [function_1]	count=3
module	it is a ||| chunk	count=1
function	compatible with [function_2] ||| [function_2] [function_1]	count=3
function_arg	[function_1] location is ||| [arg_2] [function_1]	count=4
function	string containing [function] of the ||| [function]	count=2
module	abstractvariableexpression appropriate for the ||| sem	count=1
arg	list of characters from ||| category fileids	count=1
function	true if ||| is	count=4
arg	the utterance identifiers for ||| sex spkrid sent_type	count=1
class	[class_1] if hack=true ||| [class_2] [class_1]	count=8
arg	true if the item ||| item	count=1
function	execute an sql ||| sql	count=1
function	an exemplar sentence ||| exemplar of	count=1
arg	or the list ||| fileids sent tag strip_space	count=1
function	variety of ||| user info from	count=1
module	the internal indexes to ||| reader	count=1
arg	bindings with the ||| bindings	count=1
class	how big a ||| view	count=1
module	return an iterator ||| core	count=1
class	child's ||| stack	count=1
function	by a ||| by	count=1
function	module to find ||| find	count=1
class	element ||| recursive	count=1
arg	[arg_1] and q ||| [arg_1] [arg_2]	count=1
function	a binding to ||| bind	count=1
function	about the users ||| from	count=1
class	the frontier in particular ||| recursive	count=1
function_arg	[function_1] word of ||| [function_1] [arg_2]	count=1
module	return true if self ||| core	count=1
class	the given ||| stream reader	count=1
class	binding operators in store ||| store	count=1
function_arg	[function_1] from a ||| [arg_2] [function_1]	count=3
arg	of a given length ||| length	count=1
arg	synset note that ||| synset	count=1
class	that can be generated ||| arff formatter	count=1
function	the log ||| log	count=1
function	implements step 5a ||| step5b	count=1
function	of unigram ||| extract unigram	count=1
class	the first ||| stepping recursive descent	count=1
function	six ||| w64	count=1
class	stack ||| parser	count=1
class	element ||| recursive descent parser	count=1
module	to figure out ||| app	count=1
arg	[arg] next ||| [arg]	count=2
function	of ||| demo	count=2
arg	a list of word ||| speaker stem	count=1
class	a [class_2] ||| [class_1] [class_2]	count=1
class	frontier in particular ||| recursive descent	count=1
class	function must be called ||| chart parser app	count=1
function	sort ||| sort	count=3
arg	word tag tuples ||| stem relation	count=1
function	lambda functions ||| tgrep	count=1
class	rule and the ||| rule	count=1
module	build the ||| corpus reader	count=1
class	if ||| recursive	count=1
class	[class] ngram ||| [class]	count=1
function	primitive is the special ||| primitive	count=1
function	the ||| user info	count=1
function	lemma ||| lemma	count=1
function	close ||| close	count=2
module	first ||| parse	count=1
function	next best ||| best	count=1
function	the tkinter mainloop this ||| mainloop	count=3
function	the node [function_2] ||| [function_2] [function_1]	count=1
class	move a token from ||| stepping shift reduce	count=1
class	made ||| reviews	count=1
class	given language to ||| corpus reader	count=1
class	probability distribution ||| prob dist	count=8
arg	return a string containing ||| vnframe indent	count=1
arg	the abstractboxerdrs object hierarchy ||| elimeq bin_dir verbose	count=1
function_arg	[function_1] stream until ||| [arg_2] [function_1]	count=2
function	the clustering parameters from ||| cluster	count=1
arg	of its forward ||| forward fs_class visited	count=1
arg	[arg_1] f-score it ||| [arg_2] [arg_1]	count=1
module	return a ||| corpus reader	count=1
class	the ||| nombank	count=2
function	construct a trigramcollocationfinder given ||| init	count=1
class	of this rule ||| chunk rule with context	count=1
class	dependencygrammar ||| probabilistic dependency grammar	count=1
function	a factory ||| expression	count=1
function	chunks each ||| chunks	count=1
function_arg	[function_1] [arg_2] ||| [function_1] wrap [arg_2]	count=2
class	trigram ||| trigram collocation	count=1
function	pass of ||| pass	count=1
function_arg	string [arg_2] ||| [arg_2] [function_1]	count=4
arg	end of stack ||| stack	count=1
class	on the childes ||| childescorpus	count=1
function	number ||| number	count=1
arg	python port of the ||| tokens return_str	count=1
arg	its forward ||| forward fs_class	count=1
class	tags the sequence with ||| hidden markov model tagger	count=1
arg	sole training text ||| verbose	count=1
function_arg	[function_1] item ||| [arg_2] [function_1]	count=1
function	to find a ||| find room	count=1
arg	use [arg] ||| [arg]	count=3
class	the frequency distribution ||| freq dist	count=1
class	that is ||| parser	count=1
class	hypothesized structure ||| edge i	count=1
arg	variable [arg_2] ||| [arg_1] [arg_2]	count=5
function	alignment of two ||| align	count=2
arg	count ||| count alignment_info i trg_classes	count=1
function	an exemplar [function_2] ||| [function_1] [function_2]	count=4
class	in ||| twitter corpus reader	count=2
function_arg	score for [arg_2] ||| [arg_2] [function_1]	count=2
class	the chart rule ||| chart	count=1
module_class	if this [class_2] ||| [module_1] [class_2]	count=6
arg	the token ||| token	count=2
class	up this corpus ||| corpus reader	count=2
arg	the given root directory ||| root	count=5
function	unique counter ||| unique counter	count=1
function	the fileids that ||| fileids	count=1
arg	boundaries ||| boundaries	count=1
function	[function_1] used ||| [function_1] [function_2]	count=3
function	span the entire ||| parses	count=1
class	list's ||| pretty lazy	count=1
function	[function_1] alignments ||| [function_2] [function_1]	count=10
class	file or buffer ||| gzip file	count=1
function	to construct ||| construct	count=2
arg	input string s ||| input encoding	count=1
function	standard interpretations of the ||| r1r2 standard	count=1
arg	counted as a ||| cur_tok next_tok	count=1
function	[function_1] features reflecting ||| [function_1] [function_2]	count=8
class	a list of ||| crubadan corpus	count=1
function	if [function_2] ||| [function_1] [function_2]	count=4
arg	list of reference ||| reference	count=3
function	a ||| from id	count=2
arg	and fstruct2 ||| fstruct2	count=1
class	remaining ||| stepping	count=1
class	list concatenating ||| lazy sequence	count=1
class	the remaining ||| reduce	count=1
class	from ||| stepping shift reduce	count=1
arg	given scoring function ||| score_fn w1 w2	count=2
arg	of word [arg_2] ||| [arg_2] [arg_1]	count=1
class	the chart ||| chart parser	count=2
function	a binding [function_2] ||| [function_2] [function_1]	count=5
function_arg	to configure [arg_2] ||| [function_1] [arg_2]	count=1
class	corpus view ||| propbank corpus reader	count=1
function	[function_1] relations ||| [function_1] [function_2]	count=1
arg	as the predicate ||| predicate	count=1
function	variety of ||| id	count=1
function	the standard interpretations of ||| r1r2 standard	count=1
function	users ||| from id	count=1
class	the first ||| parser	count=1
class	with ||| hidden	count=1
class	be called ||| drt glue	count=1
function	java binary and what ||| config java	count=1
class	of the ||| shift reduce	count=2
class	to be returned ||| comparative sentences	count=1
arg	[arg_1] [arg_2] to ||| [arg_2] [arg_1]	count=2
function	and expected agreements ||| multi kappa	count=1
class	of the ||| shift reduce parser	count=2
class	this tagger to ||| tagger	count=1
arg	data to ||| data	count=1
class	the internal indexes to ||| framenet corpus reader	count=1
arg	symbols encoded as tuples ||| relation	count=1
function	[function_1] file ||| [function_2] [function_1]	count=3
arg	[arg_1] by stems ||| [arg_1] [arg_2]	count=1
arg	quadgramcollocationfinder given freqdists for ||| quadgram_fd ii iii	count=1
class	in the same sentence ||| sentence tokenizer	count=1
function	[function] of this ||| [function]	count=4
function	a block from the ||| block	count=1
function_arg	[function_1] distance ||| [arg_2] [function_1]	count=2
module	for ||| metrics	count=1
arg	number of rows and ||| rows	count=1
class	how much of ||| edge i	count=1
class	to tags ||| tagger	count=1
arg	context [arg_2] ||| add [arg_1] [arg_2]	count=1
arg	labels a ||| labels	count=2
class	the cmudict lexicon as ||| cmudict corpus reader	count=1
function	best incoming ||| best incoming	count=1
class	639-3 ||| corpus reader	count=1
arg	with the l{align_texts} function ||| soft_delimiter hard_delimiter	count=1
function	entities ||| entities	count=1
module	is hypothesized by this ||| parse	count=1
arg	true if [arg] ||| [arg]	count=3
arg	from a corpus ||| corpus	count=1
function	of classified ||| write	count=2
arg	the string for ||| string	count=1
function_arg	[function_1] each rule ||| [arg_2] [function_1]	count=1
class	other logic [class_2] ||| [class_1] [class_2]	count=1
class	how ||| chart	count=2
function_arg	[function_1] [arg_2] ||| [function_1] test_set [arg_2]	count=2
arg	current round ||| upper_date_limit lower_date_limit	count=1
function_arg	fileids [arg_2] ||| [function_1] [arg_2]	count=1
arg	input text ||| text	count=1
arg	if no filename ||| filename	count=1
class	parser state ||| stepping recursive descent parser	count=1
function	expressions as a dictionary ||| expressions	count=1
function	tagged tokens ||| tagged	count=1
function	obtained by deleting any ||| remove variables	count=1
class	of supported languages as ||| reader	count=1
function	the ||| demo	count=2
class	the frequency distribution ||| prob dist	count=1
class	in this object ||| substitute bindings	count=1
function	methods ||| discourse	count=2
module	model and an alignment ||| translate	count=1
arg	refs [arg_2] ||| [arg_1] [arg_2]	count=4
arg	from the source tagset ||| source	count=1
function	the hierarchical children ||| child widgets	count=1
class	supported languages as ||| crubadan corpus	count=1
module	regexpchunkparser class ||| chunk	count=1
arg	pattern ||| pattern	count=2
arg	[arg] the ||| [arg]	count=5
class	by [class_2] ||| [class_2] [class_1]	count=9
function	userid ||| userid demo	count=1
class	classifier based on the ||| classifier based tagger	count=1
arg	given root directory ||| root	count=5
function	[function_1] latex ||| [function_2] [function_1]	count=1
function	about the ||| id	count=1
function	when scored ||| nbest	count=1
arg	and the other ||| other	count=1
class	[class_1] pointer ||| core [class_1] [class_2]	count=2
function	of chunks each ||| chunks	count=1
function_arg	eval [arg_2] ||| [function_1] [arg_2]	count=1
class	frontier in particular if ||| stepping recursive	count=1
arg	symbol for rhs ||| rhs	count=1
arg	n-gram ||| reference hypothesis min_len	count=1
arg	the rule data ||| rule	count=1
class	all ||| corpus reader	count=1
function	tokenize ||| tokenize	count=1
function	consonant is defined in ||| is consonant	count=1
arg	tokens using ||| tokens	count=1
class	list ||| reader	count=1
function	length to ||| length	count=1
arg	the cached n ||| key	count=1
function	a list ||| id	count=1
class	be called if ||| app	count=2
class	[class_1] pointer ||| [class_1] [class_2]	count=3
module	a list of symbol ||| sem	count=1
function_arg	[function_1] alignment ||| [function_1] given s [arg_2]	count=6
function	compute the max ||| compute max	count=2
class	the files that ||| reviews	count=1
class	new classifier based ||| classifier based	count=1
arg	boundaries ||| text boundaries	count=1
function	template sets ||| template sets	count=1
function	classified tokens ||| write	count=2
arg	for translating ||| hypothesis future_score_table sentence_length	count=1
class	mass of probability ||| prob	count=1
class	a variety ||| query	count=1
arg	input dependencygraphs ||| graphs	count=1
class	unicode string ||| unicode	count=1
class	the probability ||| heldout prob	count=1
function	from the url ||| from url	count=3
class	the sequence with ||| markov model	count=1
module	files ||| corpus reader	count=1
module	method ||| sem	count=1
function	generates [function_2] ||| [function_2] [function_1]	count=6
function	a list of ||| info from id	count=1
arg	:param frame optional frame ||| frame	count=1
function	returns a freqdist ||| freq	count=1
function_arg	[function_1] of word ||| [function_1] sents [arg_2]	count=1
class	buffered gzip [class_2] ||| [class_2] [class_1]	count=1
class	the first ||| recursive descent parser	count=1
function	illustrate the various ||| demo	count=2
arg	optional frame object ||| frame frame2 type	count=1
function_arg	representation of [arg_2] ||| [arg_2] [function_1]	count=1
arg	paths where a none ||| paths	count=1
function	texts ||| texts	count=1
function	update ||| update	count=4
arg	features ||| features	count=1
arg	structures ||| tree_class complete	count=1
module	factory method that ||| sem	count=1
function	will be the top ||| top	count=1
function	the read pointer forward ||| forward	count=1
class	given a text returns ||| punkt	count=1
function_arg	[function_1] the vector ||| [arg_2] [function_1]	count=3
class	of ||| recursive descent parser	count=1
function	handle ||| handle	count=1
class	absolute path ||| file system	count=1
module_class	[module_1] space ||| [module_1] [class_2]	count=2
module	feature [module] to the ||| [module]	count=1
function	print trace output ||| trace	count=5
function	list of ||| user info from id	count=1
arg	of a single sentence ||| sentence	count=1
class	colorized [class_2] ||| [class_2] [class_1]	count=1
class	first ||| descent parser	count=1
class	the internal ||| framenet corpus	count=1
module	instance's ||| corpus	count=1
arg	[arg] function produces ||| [arg]	count=3
class	all ||| corpus	count=1
arg	[arg] any sequence ||| [arg] k	count=2
class	this corpus ||| propbank corpus reader	count=1
class	frontier in particular if ||| descent parser	count=1
module	out how big a ||| app	count=1
arg	a subprocess that calls ||| cmd classpath stdin stdout	count=1
function	a friendly error message ||| parse error	count=1
arg	binary with ||| binary args	count=1
function	of information about the ||| info from id	count=1
module	the sequence with the ||| tag	count=1
class	same sentence ||| sentence tokenizer	count=1
class	point to self ||| abstract	count=1
function	edge's dot position which ||| dot	count=1
class	when parsing a text ||| up probabilistic chart parser	count=1
arg	the target tagset ||| target source_tag	count=2
function_arg	[function_1] the expression ||| [arg_2] [function_1]	count=1
function	return the standard ||| standard	count=1
function	the log probability of ||| logprob	count=1
function	fileids that make up ||| fileids	count=1
class	necessary to specified ||| nkjpcorpus reader	count=1
class	when parsing a ||| reduce parser	count=1
arg	in univ_scope ||| univ_scope	count=1
module	remaining ||| parse	count=1
class	context ||| context	count=2
class	smoothing method ||| smoothing	count=1
class	a ||| crubadan corpus reader	count=1
arg	the given file s ||| fileids c5 strip_space	count=2
arg	f-score described in ||| max_len	count=1
function	containing [function] ||| [function]	count=2
function	redirects arcs ||| redirect arcs	count=1
class	with frequency ||| freq dist	count=1
class	to invalidate ||| dist	count=1
class	this ||| i	count=1
class	words ||| bnccorpus reader	count=2
arg	refs list [arg_2] ||| [arg_1] [arg_2]	count=2
class	a corpus ||| nombank corpus	count=1
function	chunk the given ||| chunk	count=2
class	string to figure ||| chart	count=1
class	[class_1] rule given ||| [class_2] [class_1]	count=1
class	must be called ||| drt glue demo	count=1
class	alphabetical order ||| reader	count=1
function	positive words in alphabetical ||| positive	count=1
function	parse a sentence ||| tagged parse	count=1
function	unification ||| unification	count=1
function	the beginning ||| shift	count=2
class	performs a projective dependency ||| projective dependency	count=1
class	with the ||| hidden markov model	count=1
function	beginning of the ||| shift	count=1
class	text to ||| reduce	count=1
function_arg	[function_1] displaying ||| [function_1] [arg_2]	count=2
module	languages as ||| corpus reader	count=1
function	all alphabetic ||| alpha	count=1
function	find the java binary ||| config java	count=1
class	the sentence string ||| view	count=1
class	wordnet corpus ||| word net corpus	count=2
function	return a [function] of ||| [function]	count=1
class	of the remaining text ||| stepping shift	count=1
class	tags ||| hidden	count=1
function_arg	[function_1] the symbol ||| [function_1] state [arg_2]	count=2
function	all nodes [function] the ||| [function]	count=3
function	find a ||| find	count=1
class	of a dependency ||| dependency parser	count=1
module_class	[module_1] corpus ||| [module_1] aligned [class_2]	count=1
arg	true if [arg] terminal ||| [arg]	count=1
class	in an subcorpus of ||| reader	count=1
class	pointer pointing at the ||| pointer	count=1
function	self _sentences to construct ||| construct readings	count=1
class	when parsing a text ||| recursive descent parser	count=1
function	[function_1] sibling ||| [function_2] [function_1]	count=4
class	[class_1] pointer pointing ||| [class_1] [class_2]	count=1
function	a demo showing ||| prob parse demo	count=1
function	remove ||| remove child	count=1
function	remove all ||| clear	count=1
arg	[arg] of ||| [arg]	count=8
module	subtype of ||| sem	count=1
class	token ||| shift reduce parser	count=1
function_arg	training [arg_2] ||| [arg_2] [function_1]	count=2
arg	j of ||| j	count=1
arg	highest information content ||| synset2 ic verbose	count=1
function	of information ||| from	count=1
module	of the ||| parse	count=5
arg	of the tree structures ||| tree_class complete	count=1
arg	sequence of items as ||| sequence n	count=1
arg	to implement the view ||| unit bracket_sent	count=1
function	returns ||| variable	count=1
arg	list of samples given ||| samples store_logs	count=1
function	pointer ||| pointer	count=1
function	bleu for all ||| corpus bleu	count=2
module	values ||| metrics	count=5
module	of information about the ||| twitter	count=1
class	probability [class_2] ||| [class_1] [class_2] renormalize r nr	count=1
module	big the tree ||| app	count=1
class	classifier based ||| classifier based tagger	count=2
function	one entity to ||| descape entity	count=1
class	a distribution [class_2] ||| [class_2] [class_1]	count=2
class	lexicon ||| lexicon	count=1
function	of rows ||| len	count=1
class	is ||| drt expression	count=1
function	likelihood [function_2] ||| [function_1] [function_2]	count=4
function	various ||| discourse demo	count=2
function_arg	[function_1] than min_freq ||| [function_1] [arg_2]	count=3
module	the recursive descent ||| parse	count=1
function	convert ||| make	count=2
class	add to the chart ||| stepping chart	count=1
class	[class_1] [class_2] specified ||| [class_1] [class_2] add	count=4
class	particular if ||| recursive descent parser	count=1
arg	[arg_1] tag tuples ||| [arg_1] [arg_2]	count=4
function_arg	[function_1] of tokentablefields ||| [function_1] [arg_2]	count=3
class	a unit ||| view	count=1
arg	frameid and ||| frameid	count=1
class	positive examples the edges ||| naive bayes dependency scorer	count=1
class	a text returns a ||| punkt	count=1
class	consistent ||| edge	count=1
function_arg	tokenize a string ||| tokenize s	count=2
class	corpus or in the ||| corpus reader	count=1
function	this is a ||| variable expression	count=1
function	lookup 'key' [function_2] ||| [function_2] [function_1]	count=1
module_class	from the [class_2] ||| [module_1] [class_2]	count=2
class	should ||| chart	count=1
function	each ||| tokenize	count=1
arg	the sole training ||| verbose	count=1
class	wrapper for ||| wrapper	count=1
arg	word takes a word ||| word	count=1
class	list ||| corpus	count=1
function	node ||| node label	count=1
arg	the stream and ||| stream	count=1
function	set the probability ||| set	count=1
class	non-terminal ||| nonterminal	count=1
module	etc ||| app	count=1
arg	removes alignments from alignment_infos ||| alignment_infos	count=1
arg	devset_name the name of ||| devset_name devset grammar chunk_label	count=1
class	free ||| possible antecedents	count=1
function	methods ||| drt discourse	count=1
function	various ||| drt	count=1
function	hole that will ||| hole	count=1
arg	can ||| fail_on_unknown	count=1
function	of lemmas ||| lemmas	count=1
class	the minimal [class_2] ||| [class_1] [class_2] add	count=3
function	the chunk ||| chunk	count=1
function	convert a list of ||| user info	count=1
arg	tab file ||| tab_file	count=1
function	compiles and returns ||| re	count=2
class	this variable ||| variable	count=1
function	variety of ||| user info from id	count=1
function	the names ||| names	count=3
function	:rtype ||| match	count=1
class	this corpus or ||| categorized corpus reader	count=1
class	enter ||| regexp	count=1
class	bigram collocation finder with ||| collocation	count=1
class	from ||| trainer	count=1
function	pearson's chi-square as in ||| chi sq	count=1
function	the ||| variable	count=1
function	web help ||| web help	count=2
function	sentence_aligned_corpus and [function] lexical ||| [function]	count=1
function	relation table [function_2] ||| [function_2] [function_1]	count=2
arg	ranks1 and ranks2 ||| ranks1 ranks2	count=3
function	probability [function_2] ||| [function_1] [function_2]	count=14
arg	l{align_texts} function ||| soft_delimiter hard_delimiter	count=1
arg	the vectors to clusters ||| vectors	count=1
class	this sentence boundary ||| punkt sentence	count=1
module	to the end of ||| parse	count=1
arg	containing a ||| vnframe	count=1
class	the moses [class_2] ||| [class_2] [class_1]	count=2
function	returns the probability ||| probability	count=1
function	category ||| category	count=2
module_class	[module_1] [class_2] ||| [module_1] feat [class_2]	count=4
class	s from this synset ||| synset	count=1
function	tkinter mainloop this ||| mainloop	count=3
function	return the fraction ||| precision	count=1
function	[function] samples from ||| [function]	count=1
class	indexes ||| corpus reader	count=1
function	complete ||| process	count=1
arg	set the selected ||| delta see	count=1
class	how big the ||| view	count=1
arg	divide a string ||| s chunk_label root_label sep	count=1
arg	p and [arg_2] ||| [arg_1] [arg_2]	count=4
class	corpus reader using ||| corpus reader	count=2
class	a ||| shift	count=1
function	learned [function] ||| demo serialize [function]	count=3
function	this ||| parse	count=1
arg	sole training ||| verbose	count=1
function	demonstration showing the ||| demo	count=3
function	to construct a value ||| construct	count=2
function	[function] rv and ||| [function]	count=2
arg	of the vector ||| vector	count=1
function	a table of ||| table	count=1
function	static index [function_2] ||| [function_2] [function_1]	count=1
arg	the probability ||| prob log	count=1
class	frontier in ||| recursive descent	count=1
class	internal ||| corpus	count=1
arg	expression and convert ||| expression	count=1
function	[function_1] a category ||| [function_1] parse [function_2]	count=3
function_arg	[function_1] event in ||| [function_1] [arg_2]	count=3
class	the synset ||| synset	count=2
function	is beginning a ||| is	count=1
function_arg	page if [arg_2] ||| [function_1] [arg_2]	count=4
module	stack ||| parse	count=1
function_arg	[function_1] numsamples ||| [arg_2] [function_1]	count=3
function	the root counting ||| hypernym distances	count=1
function	and show the readings ||| readings	count=1
arg	[arg_1] [arg_2] determines ||| [arg_2] [arg_1]	count=4
class	sequence with the ||| hidden	count=1
class	tagger [class_2] ||| [class_2] [class_1]	count=12
function	least common subsumer ||| lcs ic	count=1
class	internal indexes to ||| framenet corpus reader	count=1
arg	name and/or 1-2 fes ||| lunamepattern frame fe fe2	count=1
class	feature identifiers used by ||| feat	count=1
class	inside probabilities of the ||| inside chart parser	count=1
class	encoded as ||| chunked	count=3
module	a list ||| corpus	count=1
class	it would be more ||| map	count=1
function_arg	[function_1] raw_score likelihood ||| [function_1] [arg_2]	count=1
class	feature with ||| feat	count=4
arg	the reading ids in ||| threads	count=1
function_arg	[function_1] expression ||| [arg_2] [function_1]	count=5
arg	of tokentablefields ||| token_sequences par_breaks	count=1
class	[class_1] gzip file ||| [class_1] [class_2]	count=1
class	set ||| mix in	count=1
class	in ||| parser	count=1
function	the present ||| extract	count=1
function	of all possible ||| all	count=2
class	encoded as a ||| chunked	count=2
arg	posted by the ||| screen_name limit include_rts	count=1
class	the frontier in ||| parser	count=1
arg	target of its forward ||| forward fs_class visited	count=1
function	create an instance ||| init	count=1
arg	[arg] values and ||| [arg] test	count=3
function_arg	to indent [arg_2] ||| [function_1] [arg_2]	count=1
function	module to convert ||| taggedsent to	count=2
class	needs to be how ||| chart view	count=1
function	variety of information ||| user info from	count=1
function	find all ||| common	count=1
class	and return new feature ||| feature	count=2
arg	rows and columns ||| rows cols	count=1
class	path pointer pointing at ||| zip file path pointer	count=1
arg	the list ||| fileids	count=1
function	rank [function_2] ||| [function_2] [function_1]	count=4
arg	a valuation ||| valuation lexicon	count=1
class	[class] of the ||| [class] corpus	count=3
function	web help page ||| web help page	count=3
function_arg	[function_1] distance of ||| [function_1] [arg_2]	count=2
arg	[arg_1] label pair ||| [arg_2] [arg_1]	count=3
arg	all_phrases_from that contains words ||| all_phrases_from hypothesis	count=1
class	particular ||| parser	count=1
class	this rule ||| chunk rule with context	count=1
class	distribution mapping each context ||| context index	count=1
class	this object ||| substitute bindings i	count=1
function_arg	header [arg_2] ||| [function_1] [arg_2]	count=1
class	this ||| model tagger	count=2
class	contents of the ||| category corpus reader	count=1
function_arg	construct a [arg_2] ||| [arg_2] [function_1]	count=8
function	sentence from a subcorpus ||| lusentence	count=1
class	given bigram using the ||| bigram collocation	count=1
module	is consistent ||| parse	count=1
class	with ||| model tagger	count=2
arg	[arg_1] [arg_2] any sequence over a ||| metrics pk [arg_2] [arg_1]	count=8
class	if ||| parser	count=2
class	the ||| stepping shift reduce parser	count=4
class	string to ||| chart view	count=1
function	[function_1] of sentence ||| [function_2] [function_1]	count=8
class	underlying [class] decode them ||| seekable unicode [class]	count=1
class	to figure ||| chart	count=1
function	path [function_2] ||| [function_1] [function_2]	count=1
function_arg	[function_1] metric that ||| [arg_2] [function_1]	count=1
function	of target [function_2] ||| [function_2] [function_1]	count=12
arg	[arg_1] with expression ||| [arg_2] [arg_1]	count=9
arg	the vector to ||| vector	count=1
function	top-lebel node in a ||| tgrep exprs	count=1
function	for a ||| for	count=1
function	str ||| str	count=1
arg	q [arg_2] ||| [arg_2] [arg_1]	count=1
arg	[arg] of ||| alignment_info [arg]	count=2
arg	save_classifier ||| training_set save_classifier	count=1
function	variables ||| variables	count=1
function_arg	s-expressions from [arg_2] ||| [function_1] [arg_2] block_size comment_char	count=1
arg	to implement the view ||| bracket_sent	count=1
function	the entire ||| parses	count=1
arg	text if ||| text verbose	count=2
module	iso ||| corpus	count=1
function	[function_1] of all ||| [function_1] [function_2]	count=6
class	this corpus ||| nombank corpus reader	count=1
arg	top n ||| n	count=1
class	to invalidate the cached ||| freq	count=1
class	assignment and update self ||| assignment	count=1
class	given trigram using ||| trigram collocation	count=1
function	return the upper frame ||| static upper	count=1
function	plug the nodes ||| plug nodes	count=2
class	the frontier in particular ||| parser	count=1
module	[module] lexical rules ||| [module]	count=1
arg	and ||| c5 strip_space stem	count=1
arg	consideration given the ||| test_sents	count=1
function	list of [function_2] ||| [function_2] [function_1]	count=4
arg	fit ||| labeled_featuresets	count=1
arg	identifiers for ||| filetype	count=1
class	from two conditionalfreqdists ||| conditional	count=1
function_arg	a new [arg_2] ||| [arg_2] [function_1]	count=1
class	a list of supported ||| crubadan corpus	count=1
class	function ||| parser	count=1
function	applies ||| applies	count=1
function	jaccard index ||| jaccard	count=1
class	[class_1] pickle ||| [class_2] [class_1]	count=1
function	a subcorpus of an ||| lusentence	count=1
function_arg	[function_1] pretty-printed version ||| [arg_2] [function_1]	count=2
arg	speech ||| pos	count=1
function	adds an [function] node specified ||| [function]	count=1
class	a single tree ||| reduce parser	count=1
function	id ||| id	count=2
class	the sequence with ||| hidden	count=1
class	a new iterator over ||| lazy iterator	count=1
function_arg	[function_1] line ||| [arg_2] [function_1]	count=1
class	remaining text to ||| stepping shift reduce	count=1
class	the first element ||| descent parser	count=1
class	tagger on the ||| tagger	count=1
class	a distribution of ||| dist	count=1
class	be called ||| regexp chunk app	count=1
class	return a list ||| reader	count=1
arg	devset_name the ||| devset_name devset grammar chunk_label	count=1
class	this ||| markov model	count=1
class	words in ||| corpus reader	count=1
arg	remaining lines ||| lines	count=1
class	add all edges licensed [class_1] [class_2] edges that are currently ||| [class_2] [class_1] apply everywhere chart grammar	count=2
class	a ||| stepping recursive descent parser	count=1
class	the cross-validation estimate ||| cross validation	count=1
arg	with the highest probability ||| unlabeled_sequence	count=1
module	unit needs to be ||| app	count=1
function	header as a ||| header section	count=1
function	tweets [function_2] ||| [function_1] [function_2]	count=3
function_arg	classify a [arg_2] ||| [function_1] [arg_2]	count=2
module_class	[module_1] [class_2] graphical ||| [module_1] [class_2]	count=4
function_arg	[function_1] [arg_2] ||| [function_1] stack [arg_2]	count=21
class	returns a list of ||| punkt sentence	count=1
function	step 4 ||| step4	count=1
module_class	[module_1] stack ||| [module_1] [class_2]	count=4
class	the pickle ||| pickle	count=1
class	data ||| net corpus reader	count=1
function	[function_1] rule this ||| [function_2] [function_1]	count=3
function	a new index for ||| add index	count=1
function	optionally [function] ||| make [function]	count=1
function_arg	to configure all ||| configure cnf	count=1
arg	a sequence ||| sequence n k	count=1
function	compute the windowdiff score ||| windowdiff	count=1
function	[function] rv ||| [function]	count=2
function	attempts to realign ||| realign boundaries	count=1
module	iso 639-3 ||| corpus	count=1
function	the users ||| id	count=1
class	[class_1] binder ||| [class_1] [class_2]	count=4
arg	and relation type ||| relation	count=1
arg	from a word-aligned sentence ||| srctext trgtext alignment max_phrase_length	count=1
class	probdist ||| cross validation prob dist	count=1
function	str rule and rule ||| str rule	count=1
class	tags ||| hidden markov	count=1
class	of the stack ||| stepping shift	count=1
function	the tag ||| map tag	count=1
module_class	[module_1] tree as ||| [module_1] [class_2]	count=2
class	must be called if ||| drt glue	count=1
arg	[arg_1] version of ||| [arg_1] [arg_2]	count=3
function	pre-calculate of which ||| forms	count=1
function	bounding box for the ||| bbox	count=1
arg	list of ||| conds	count=1
class	list of supported ||| corpus	count=1
arg	subprocess that calls ||| cmd classpath stdin stdout	count=1
class	this ||| chart	count=3
class	the hypothesized ||| edge i	count=1
class	examples (i ||| naive bayes	count=1
function	relation to other nodes ||| relation	count=1
module_class	[module_1] the grammar ||| [module_1] [class_2]	count=2
class	this synset to ||| synset	count=1
module	managed by this ||| draw	count=2
function_arg	to reduce [arg_2] ||| [function_1] [arg_2]	count=1
class	a token from the ||| stepping shift	count=1
class	all parses that ||| recursive descent parser	count=4
function	[function] the ||| [function]	count=3
module	function -- return ||| core	count=1
class	with ||| tagger	count=1
class	a probabilisticdependencygrammar ||| projective dependency parser	count=1
class	the stack ||| shift reduce	count=2
arg	conjunctive normal form cnf ||| univ_scope used_variables	count=1
module	figure ||| app	count=1
class	neural [class_2] ||| [class_1] [class_2]	count=5
class	[class_1] rule ||| [class_2] [class_1] apply chart grammar	count=1
function	entries containing ||| entries	count=1
function	chunk the ||| chunk	count=2
class	by this rule and ||| chart rule i	count=1
function	entries in the ||| size	count=1
class	[class_1] distribution in ||| [class_1] [class_2]	count=2
class	state sequence ||| tagger	count=1
class	the tree ||| tree	count=7
arg	as the predicate ||| predicate signature	count=1
arg	bncwordviews or the list ||| fileids sent	count=1
arg	child ||| child index	count=2
class	as ||| tagged corpus	count=1
function	f ||| f	count=1
arg	raw_score likelihood ||| raw_score	count=1
class	container ||| abstract container	count=2
arg	address node_index ||| node_index	count=1
arg	expression the expression to ||| expression	count=1
module	object's probability this ||| core	count=1
function	top-lebel ||| exprs action	count=2
arg	the specified entry in ||| entry	count=1
module	a ||| reader	count=1
arg	specifying the fileids ||| fileids	count=2
function	convert a list of ||| user	count=1
arg	of augmented word tokens ||| tokens	count=1
arg	tokens [arg_2] ||| [arg_2] [arg_1]	count=1
module	instance's ||| reader	count=1
function	an exemplar sentence and ||| exemplar of fes	count=1
class	this sentence boundary ||| punkt sentence tokenizer	count=2
arg	left-hand side or ||| lhs rhs	count=2
function_arg	[function_1] documents ||| [function_1] [arg_2]	count=1
arg	be used ||| tokens	count=1
class	probability ||| markov	count=1
function	of labels [function_2] ||| [function_2] [function_1]	count=4
function	convert a userid to ||| by userid demo	count=1
class	joint-feature vectors ||| maxent feature	count=1
arg	a sentence as a ||| sentence verbose	count=1
function	truncation line ||| truncation coordinates	count=1
function	where nr ||| nr	count=1
arg	that thread ||| thread_id	count=1
function	to prove ||| prove	count=1
function	s the grammar ||| grammar	count=1
module	supported languages ||| corpus	count=1
function	[function_1] interpretations of ||| [function_2] [function_1]	count=6
arg	:param show all ||| show	count=1
class	a danish ||| danish stemmer	count=1
function	arcs to any ||| redirect arcs	count=1
function	:return a tuple of ||| entries	count=1
function	[function_1] in ||| [function_1] [function_2]	count=3
arg	sequence ||| sequence n k	count=1
class	text to ||| shift	count=1
arg	a list ||| category fileids	count=1
function	node into the ||| node label	count=1
module	widget used for ||| draw	count=1
module	all appear and return ||| core	count=1
arg	s ||| fileids speaker stem relation	count=1
module	supported languages as iso ||| corpus	count=1
class	elements ||| lazy map	count=1
class	contents of the corpus ||| reviews corpus reader	count=1
class	the tree should be ||| chart	count=1
class	alphabetical order ||| lexicon	count=1
function	construct a ||| construct readings	count=1
module	exemplify repr rule ||| tbl	count=1
arg	phrase_table table of translations ||| phrase_table language_model	count=1
function_arg	lin similarity [arg_2] ||| [arg_2] [function_1]	count=4
arg	a baseline ||| initial_tagger templates	count=1
class	the ||| corpus reader	count=1
class	joint-feature values ||| maxent feature encoding i	count=1
function	top-lebel ||| tgrep exprs	count=1
module	depends on whether tweets ||| twitter	count=1
function_arg	training corpus train_toks ||| train cls train_toks	count=1
arg	database ||| dbname	count=1
class	with ||| model	count=1
class	object ||| substitute bindings i	count=1
class	this canvasframe ||| frame	count=1
arg	string and ||| cls s	count=2
module	move ||| parse	count=1
function_arg	[function_1] [arg_2] takes into account partial ||| [function_1] [arg_2]	count=1
function	[function_1] incoming arc ||| [function_2] [function_1]	count=3
class	this ||| markov	count=1
function_arg	[function_1] quadgramcollocationfinder given ||| [arg_2] [function_1]	count=1
class	must be called if ||| drt	count=1
function	to the chunk ||| chunk parse	count=1
class	expression ||| lambda expression	count=2
function_arg	result [arg_2] ||| [arg_2] [function_1]	count=1
arg	starts the hunpos-tag ||| path_to_bin	count=1
class	the corpus ||| sentences corpus	count=1
module	be ||| app	count=4
arg	synset ||| word synset	count=1
class	[class_1] tagger ||| [class_2] [class_1]	count=2
class	of [class] ||| [class]	count=1
class	the feature ||| feat dict	count=1
module_class	is [class_2] ||| [module_1] [class_2] recursive descent parser	count=1
function	get [function_2] ||| [function_2] [function_1]	count=7
class	frontier ||| stepping recursive	count=1
module	in ||| corpus reader	count=4
class	supported ||| crubadan	count=1
function	tweets ||| tweets	count=5
class	aligned ||| aligned	count=1
arg	number of rows and ||| rows cols	count=1
function	of citation bib file ||| citation	count=1
class	the stack ||| stepping shift	count=1
module	this widget use ||| draw	count=1
function	binary [function_2] ||| [function_2] [function_1]	count=4
class	from the ||| stepping shift reduce	count=1
function	this is a factory ||| variable	count=1
arg	to arrange [arg] into ||| [arg] rows cols	count=1
module	path identified by this ||| core	count=1
class	the corpus ||| sentences corpus reader	count=3
arg	tagset ||| source_tag	count=1
function_arg	[function_1] [arg_2] using this reader's encoding ||| [function_1] [arg_2]	count=4
class	the ||| shift reduce parser	count=4
class	of the table ||| table	count=2
class	the sequence with the ||| markov model	count=1
class	words ||| opinion lexicon	count=1
class	corpus and ||| corpus	count=1
class	source language phrase ||| phrase	count=1
arg	list of text label ||| label word_tokenizer	count=1
module_class	[module_1] [class_2] ||| [module_1] swadesh [class_2]	count=3
arg	with 'expression' ||| expression replace_bound alpha_convert	count=1
class	simple linear regression to ||| simple good turing prob dist	count=1
arg	attributes aka restriction keys ||| restr_keys	count=1
module_class	[module_1] corpus ||| [module_1] pickle [class_2]	count=1
function	all roots of ||| roots	count=1
class	rule ||| chunk rule with	count=1
function	networkx labeled directed ||| nx	count=1
class	a token ||| shift	count=1
arg	print ||| num	count=1
function	status_code ||| on error	count=1
class	the remaining text ||| stepping shift reduce	count=1
function	sets in this demo ||| sets	count=1
function	subcorpus of an ||| handle lusentence	count=1
function	[function_1] url ||| [function_1] [function_2]	count=5
class	for ||| nombank corpus reader	count=1
function	nodes ||| nodes	count=3
class	this corpus ||| categorized corpus reader	count=1
class	header_mode a ||| header	count=1
arg	a symbol when entering ||| symbol	count=1
arg	in the ||| tr nr n	count=1
function	the bigram ||| bigram	count=1
class	in the [class_2] ||| [class_2] [class_1]	count=8
function	perform the first ||| annotate first	count=1
module	a list ||| core	count=1
function	sentence and a ||| of fes	count=1
function	status of ||| status	count=1
class	[class_1] classifier ||| [class_2] [class_1]	count=4
class	a probabilisticdependencygrammar based on ||| probabilistic projective dependency parser	count=1
arg	must be trained ||| unk trained n c	count=1
class	perl unicode properties ||| unichars corpus reader	count=1
arg	baseline ||| initial_tagger templates	count=1
module_class	exists return [class_2] ||| [module_1] feat [class_2]	count=1
arg	models a ||| source_word_classes target_word_classes	count=2
function	left-hand side which specifies ||| lhs	count=1
arg	child of parent ||| parent	count=1
arg	the expression ||| expression command x y	count=1
function_arg	[function_1] the terminal ||| [arg_2] [function_1]	count=4
function	search for past tweets ||| search demo	count=1
function	the latex ||| latex	count=1
class	split the frequency distribution ||| turing prob dist	count=1
class	score ||| abstract collocation finder	count=1
class	instance's predicate ||| nombank	count=1
function	add an [function_2] ||| [function_2] [function_1]	count=4
function_arg	[function_1] graph ||| [arg_2] [function_1]	count=1
function_arg	[function_1] hypothesis ||| [arg_2] [function_1]	count=1
module	that is the ||| translate	count=1
function	process length six patterns ||| pro w64	count=1
function	pretty-printed representation ||| pprint	count=6
class	as a pickle corpus ||| pickle corpus	count=1
class	token and return that ||| sequential backoff	count=1
class	be applied to elements ||| lazy map	count=1
class	must be ||| demo	count=1
class	single parsing ||| recursive descent parser	count=1
function	subcorpus ||| lusentence	count=1
function	pointer [function_2] ||| [function_1] [function_2]	count=4
arg	a list of text ||| word_tokenizer sent_tokenizer	count=1
arg	[arg_1] can all ||| [arg_1] [arg_2]	count=1
function	sentences in ||| sentences from	count=1
class	new feature encoding based ||| maxent feature encoding	count=2
module	for the ||| translate	count=1
class	new iterator ||| lazy iterator	count=1
function	bigram features reflecting ||| bigram feats	count=1
class	[class_1] distribution if ||| [class_1] [class_2]	count=1
function	chart into ||| set	count=1
function_arg	[function_1] p and ||| [function_1] [arg_2]	count=3
module	various methods ||| inference	count=2
arg	file ||| fileid	count=1
class	function must be called ||| regexp chunk app	count=1
function	abstractvariableexpression ||| expression	count=1
function	chunks each of ||| chunks	count=1
module	a ||| corpus reader	count=2
class	text to the ||| shift reduce parser	count=1
function	between phonetic segments ||| diff	count=1
class	tags the ||| markov model	count=1
function	fertility ||| fertility	count=1
arg	label pair return the ||| label	count=1
class	token from ||| shift reduce parser	count=1
class	corpus or for the ||| categorized corpus reader	count=1
class	state ||| markov model tagger	count=2
class	this rule ||| chunk rule	count=1
function	a list ||| from id	count=1
function_arg	a table [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	categories [arg_2] ||| [arg_2] [function_1]	count=1
module	alphabetical ||| corpus reader	count=2
class	set ||| ney prob dist	count=1
class	big a unit ||| view	count=1
function	[function_1] pcfg grammar ||| [function_1] [function_2]	count=1
class	the frontier ||| descent	count=1
class	canvas widget's bounding ||| canvas widget	count=2
function	methods ||| discourse demo	count=2
arg	trees which [arg_2] ||| [arg_2] [arg_1]	count=3
function	or ||| setitem	count=2
module	hypothesized structure is ||| parse	count=1
arg	to implement the ||| fileid bracket_sent tag strip_space	count=1
arg	consideration given ||| train_sents test_sents	count=1
function	get ||| get	count=2
function	megam based on ||| megam	count=1
arg	src_sentence ||| src_sentence	count=1
function	the upper frame ||| static upper	count=1
function	[function_1] parse ||| [function_2] [function_1]	count=3
class	that is licensed by ||| descent parser	count=1
class	:param ||| theorem tool command	count=1
class	calculates ||| bigram assoc measures	count=1
arg	the binary with the ||| binary args verbose	count=1
class	periods as sentence ||| sentence	count=1
arg	word tokens construct ||| tokens	count=1
arg	[arg_1] if ||| [arg_1] [arg_2]	count=4
function	fulltextindex xml file ||| fulltextindex	count=1
function	finder with the bigram ||| bigram	count=1
function	a local file if ||| retrieve	count=1
class	this function ||| chunk app	count=1
function_arg	[function_1] string to ||| [arg_2] [function_1]	count=1
function	pointer ||| delparent	count=1
class	languages as iso ||| crubadan corpus reader	count=1
class	tagger on the ||| tagger trainer	count=1
class	editing ||| cfgeditor	count=1
module	name of the ||| corpus reader	count=1
class	to be how ||| view	count=1
arg	list of word ||| c5 strip_space stem	count=1
class	best ||| brill tagger trainer	count=1
arg	binding_list list of ||| binding_list	count=1
arg	words can all ||| words fail_on_unknown	count=2
function	to invalidate the cached ||| setitem	count=1
class	tags ||| model tagger	count=2
module	as an ||| corpus	count=1
function	of child pointer lists ||| child pointer lists	count=1
module	list of ||| twitter	count=1
arg	status_code the status ||| status_code data	count=1
function	[function_1] chunks represented ||| [function_1] [function_2]	count=3
arg	[arg_1] of productions ||| [arg_2] [arg_1]	count=1
function	maltparser command use ||| malt command	count=1
function	function to remove ||| remove	count=1
function	decide which ||| choose	count=1
module	values as ||| metrics	count=1
arg	matrix s ||| s s	count=1
function	information ||| user	count=1
function	frames that ||| frames	count=1
class	[class_1] [class_2] specified ||| [class_1] [class_2]	count=4
function	about the ||| user info from id	count=1
arg	dot-product the features ||| features	count=1
arg	head_address to the ||| head_address	count=1
class	how much of ||| edge	count=1
class	this rule and the ||| rule	count=1
class	sentences [class_2] ||| [class_1] [class_2]	count=1
module	enter ||| sem	count=1
class	its classifier ||| classifier	count=1
module	in this semantic ||| sem	count=1
class	to 0 75 ||| kneser ney prob dist	count=1
class	first ||| stepping recursive descent parser	count=1
function	apply the ||| apply	count=1
class	first ||| recursive descent	count=1
class	function must be ||| parser	count=1
function	the set of rules ||| rules	count=1
class	[class_1] the expression ||| [class_2] [class_1]	count=5
class	files that have ||| reviews corpus	count=1
class	frontier in ||| stepping	count=1
arg	database table ||| dbname	count=1
class	the lidstone estimate ||| lidstone	count=1
class	returned ||| comparative sentences	count=1
class	of the synset ||| corpus reader	count=1
class	the neural dependency parser ||| stanford neural dependency parser	count=1
arg	binding_list list of (abstractvariableexpression, ||| binding_list	count=1
class	[class_1] based ||| [class_2] [class_1]	count=4
function	[function_1] the top ||| [function_2] [function_1]	count=2
class	a [class] ||| abstract [class]	count=1
module	a list ||| reader	count=1
function	sibling ||| sibling	count=2
module	of supported languages ||| corpus	count=1
class	return a ||| crubadan corpus	count=1
function	label for the given ||| classify	count=1
class	tree should be ||| chart view	count=1
arg	sequence of items ||| sequence	count=3
arg	override counter __setitem__() ||| val	count=1
module_class	[module_1] [class_2] ||| [module_1] aligned [class_2]	count=5
function	that ||| check	count=1
arg	return ||| lang	count=1
class	a sentence in ||| corpus reader	count=1
class	from the ||| stepping	count=1
function	sentence and a set ||| of	count=1
module_class	that this [class_2] ||| [module_1] zip file [class_2]	count=2
function	a ||| info	count=2
function	rows ||| len	count=1
arg	execute with the assumptions ||| goal assumptions	count=1
function	words chunks or ||| words	count=1
class	store if [class_2] ||| [class_2] [class_1]	count=2
class	probdist ||| eleprob dist	count=1
class	text returns ||| punkt	count=1
arg	unigrams ||| unigrams	count=1
class	each context ||| context index	count=1
class	processing ||| handler i	count=1
class	oval ||| oval	count=1
function	best [function_2] ||| [function_1] model2 [function_2]	count=1
function	edge ||| edge	count=2
function_arg	check whether [arg_2] ||| [arg_2] [function_1]	count=2
function	chunks ||| chunk	count=1
class	move a token ||| stepping	count=1
function_arg	demonstration [arg_2] ||| [arg_2] [function_1]	count=3
function_arg	[function_1] input stream ||| [function_1] [arg_2]	count=3
class	list's ||| abstract lazy sequence	count=1
function_arg	update the [arg_2] ||| [function_1] sample [arg_2]	count=1
class	the tree should be ||| chart view	count=1
arg	the given root directory ||| root omw_reader	count=1
function_arg	[function_1] samples ||| [arg_2] [function_1]	count=1
arg	probabilistic parsers the user ||| choice draw_parses print_parses	count=1
class	this function must ||| chart	count=1
class	element ||| descent parser	count=1
arg	whether a feature is ||| feat flag	count=1
function	positive words ||| positive	count=1
arg	list of word ||| strip_space stem	count=1
class	in an ||| reader	count=1
function	a list of ||| list	count=2
function_arg	update the [arg_2] ||| [function_1] [arg_2]	count=1
class	sentences [class_2] ||| [class_2] [class_1]	count=1
arg	[arg_1] j ||| [arg_2] [arg_1]	count=1
arg	input expression ||| assumptions timeout prover	count=1
class	state ||| markov	count=1
class	the frequency distribution ||| turing prob dist	count=1
function	[function] in this ||| [function]	count=1
function_arg	[function_1] a synset ||| [function_1] [arg_2]	count=4
function_arg	[function_1] associated with ||| [function_1] [arg_2]	count=3
class	over sets ||| multi classifier i	count=1
function	children ||| children	count=1
class	frontier in particular if ||| recursive descent	count=1
module	convert a list of ||| twitter	count=1
function	six patterns and extract ||| pro w64	count=1
arg	sequence of items ||| sequence n	count=1
arg	node with address node_index ||| node_index	count=1
function	construct a value ||| construct readings	count=1
function	method that ||| expression	count=1
function	tadm based on the ||| tadm	count=1
function	new index ||| add index	count=1
class	from the ||| parser	count=1
class	perform a single parsing ||| recursive descent parser	count=1
arg	and returns ||| line primitives families	count=1
function	sentence from a subcorpus ||| handle lusentence	count=1
arg	of child to not ||| child	count=1
function_arg	[function_1] of word ||| [arg_2] [function_1]	count=8
function	about the users ||| user info	count=1
module	this ||| corpus	count=1
arg	tree structures that ||| tree_class complete	count=1
class	the sequence with the ||| hidden markov model tagger	count=1
class	rule it has the ||| rule with	count=1
function	node into ||| node	count=1
class	internal indexes ||| framenet	count=1
function_arg	[function_1] given ||| [function_1] queue queue [arg_2]	count=1
module_class	this [class_2] ||| [module_1] zip file [class_2]	count=2
class	must be called ||| regexp chunk	count=1
class	how big a unit ||| view	count=1
class	feature ||| feat struct	count=1
class	path ||| zip file path	count=1
arg	position in positions where ||| tokens positions	count=1
module	encode ||| app	count=1
function	list of the productions ||| productions	count=1
module	otherwise return ||| core	count=1
arg	strings is ||| strings	count=1
arg	documents located at ||| fileids sep word_tokenizer	count=2
class	must ||| drt glue	count=1
function	convert a ||| id	count=1
class	big the tree ||| chart view	count=1
function_arg	[function_1] given text ||| [arg_2] [function_1]	count=1
function	the predicate-argument annotation ||| lines	count=2
class	move a token from ||| shift	count=1
function_arg	[function_1] boxer_drs_interpreter ||| [function_1] [arg_2]	count=1
function	userid to a ||| userid demo	count=1
function_arg	similarity [arg_2] ||| [function_1] [arg_2]	count=16
function	calculates the average of ||| average	count=1
arg	the specified fileids ||| fileids	count=1
function	for a source ||| for	count=1
class	binder [class_2] ||| [class_2] [class_1]	count=2
arg	divide a string ||| s	count=1
function	counter [function_2] ||| [function_2] [function_1]	count=3
arg	given the tuple representation ||| tagged_token sep	count=1
function	method that instantiates ||| variable expression	count=1
class	text ||| stepping shift	count=1
class	in the chart ||| chart parser	count=1
function	helper ||| ascii fe	count=1
function_arg	of tagged [arg_2] ||| [arg_2] [function_1]	count=1
arg	of userids into ||| userids	count=1
function	test ||| test	count=2
class	of the files that ||| reviews corpus reader	count=1
arg	user ||| user count	count=1
arg	into a list ||| read lexicon	count=1
function	for ||| expression	count=1
class	dictionary containing ||| dictionary conditional prob	count=1
class	scores bigrams using ||| bigram assoc measures	count=1
function	a demonstration of ||| demo	count=5
arg	a collection of documents ||| documents	count=1
arg	[arg] state ||| [arg]	count=3
function	java binary and ||| java	count=1
arg	reference that ||| references hyp_len	count=1
class	i ||| tokenizer i	count=2
function	abstractvariableexpression appropriate for the ||| variable expression	count=1
class	the brill tagger on ||| brill tagger trainer	count=1
class	name of ||| instance	count=1
function	have frequency ||| freq	count=1
class	a corpus view ||| nombank corpus reader	count=1
class	for this corpus ||| string category corpus	count=1
function_arg	score [arg_2] ||| [function_1] [arg_2]	count=2
module	the remaining ||| parse	count=1
function	bounds ||| bounds	count=1
class	match ||| recursive descent parser	count=1
arg	positive_featuresets a list of ||| positive_featuresets	count=1
class	positive examples ||| naive bayes dependency scorer	count=1
function	evaluate and ||| evaluate	count=1
arg	in the dependencygraph graph ||| graph	count=1
class	the opinion lexicon note ||| opinion lexicon	count=1
class	token ||| stepping shift	count=1
class	sequence ||| model tagger	count=4
arg	a pretty-printed version of ||| width prefix depth	count=1
class	trigram using ||| trigram collocation	count=1
function_arg	[function_1] sequence ||| [arg_2] [function_1]	count=4
function	recursive function to indent ||| indent	count=1
function	lowercase 'e' ||| is eventvar	count=1
module	particular ||| parse	count=1
function	[function_1] [function_2] ||| parse find [function_1] [function_2]	count=1
module	be ||| sem	count=1
arg	the expression to ||| expression command x	count=1
class	returns a list of ||| punkt	count=1
function	the hole that ||| hole	count=1
arg	one [arg] ||| [arg]	count=6
class	out how ||| chart	count=1
module	instantiates and returns ||| sem	count=1
arg	token should be ||| tokens	count=1
class	be ||| view	count=2
arg	:param positive_featuresets a list ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
arg	filtered by the ||| rhs empty	count=2
class	reader for ||| reader	count=3
function_arg	[function_1] file ||| [function_1] [arg_2]	count=2
class	wordnet [class_2] ||| [class_2] [class_1]	count=5
module	appropriate for ||| sem	count=1
function	propositional model ||| propdemo	count=1
class	information ||| query	count=1
arg	(except arrow and sel) ||| linenum	count=1
module	of the ||| corpus	count=1
function	replace every instance of ||| replace	count=1
class	first element ||| descent parser	count=1
class	the first element of ||| recursive descent parser	count=1
arg	tokens ||| tokens tags	count=1
function_arg	of fileids [arg_2] ||| [function_1] [arg_2]	count=1
class	a collocation finder ||| collocation finder	count=1
function	the table's ||| table	count=1
class	from the given ||| corpus reader	count=1
class	in the corpus or ||| corpus	count=1
function	of an error ||| error	count=1
function	from the given ||| from	count=1
class	for ||| thesaurus corpus reader	count=1
arg	the pairs generated by ||| pairs	count=1
arg	write the given sequence ||| sequence	count=1
class	list of supported languages ||| corpus reader	count=1
class	if ||| chart	count=1
function	for pretty-printing a ||| pretty	count=2
arg	structures that are associated ||| tree_class complete	count=1
function	compute the [function_2] ||| [function_2] [function_1]	count=1
arg	lines ||| lines wrap_at	count=1
function	applicable suffix-removal rule to ||| rule	count=1
class	mutable probdist ||| mutable prob dist	count=1
class	a ||| widget	count=4
function	information about ||| from	count=1
class	trigram ||| trigram collocation finder	count=1
class	processing ||| tweet handler i	count=1
class	for the given ||| nombank corpus reader	count=1
arg	an ||| limit	count=1
function_arg	[function_1] context_to_tag ||| [arg_2] [function_1]	count=1
module	full tweets if ||| twitter	count=1
class	when parsing a ||| descent parser	count=1
module	this function ||| draw	count=2
class	repp [class_2] ||| [class_1] [class_2]	count=3
module_class	of this frequency ||| core freq	count=1
function	input expression to prove ||| prove	count=1
class	self ||| struct	count=1
module	this function ||| core	count=1
class	iterator over ||| iterator	count=1
function	concise string representation ||| repr	count=2
function	get the topmost hypernyms ||| root hypernyms	count=1
module	illustrate the various ||| inference	count=2
module	attribute [module] ||| [module]	count=3
function	positions in ||| tgrep positions	count=1
function	recorded by this freqdist ||| n	count=1
function	for the given ||| classify	count=1
arg	specified entry in ||| entry	count=1
arg	:param status_code the ||| status_code data	count=1
class	true if the token's ||| punkt token	count=1
function	strings indicating [function] ||| [function]	count=1
function	of all words defined ||| words	count=1
arg	implement the ||| bracket_sent	count=1
arg	the index of ||| index depth	count=1
class	the tree should ||| view	count=1
class	collocation ||| collocation finder	count=1
class	the review ||| review	count=1
function	word tokenization ||| word tokenizer	count=1
class	of the stack ||| shift reduce	count=1
function	information ||| info from	count=1
class	reader ||| reader	count=5
class	canvas widget's bounding ||| canvas	count=2
function_arg	rules from [arg_2] ||| [arg_2] [function_1]	count=2
class	internal indexes ||| framenet corpus	count=1
arg	other ||| other check_reentrance visited_self visited_other	count=1
class	synset to ||| synset	count=2
function	[function_1] string representing ||| [function_2] [function_1]	count=2
function	to a ||| to	count=1
module	tagger ||| tag	count=1
class	german ||| german	count=1
arg	scores for a text ||| text	count=1
arg	thread ||| thread_id	count=1
arg	*worder* list ||| reference hypothesis character_based	count=1
class	grammar from the ||| grammar	count=1
class	up this corpus ||| timit corpus	count=1
class	[class_1] frequency ||| core [class_1] [class_2]	count=1
class	the sequence with ||| hidden markov	count=1
class	repp tokenizer binary and ||| repp tokenizer	count=1
class	format ||| format	count=2
arg	in the trees ||| trees	count=1
class	this encoding ||| maxent feature encoding	count=2
module	labels and feature types ||| classify	count=1
class	the internal ||| framenet corpus reader	count=1
function	tree :return the tree ||| tree	count=1
arg	tuple representation ||| tagged_token	count=1
class	tags the ||| hidden	count=1
class	for this corpus ||| string category corpus reader	count=1
function	slice ||| slice	count=1
module	subtype of abstractvariableexpression ||| sem	count=1
function	[function_1] [function_2] for an app and ||| [function_1] [function_2]	count=1
function	returns a ||| variable	count=1
class	function must ||| chunk app	count=1
function	the approximate score ||| score	count=1
class	the end of the ||| stepping	count=1
function_arg	[function_1] temporary file ||| cache [function_1] tempfile cls sequence [arg_2]	count=1
module	internal ||| corpus reader	count=2
arg	'head' ||| mod	count=2
class	structure and each feature ||| feat	count=1
class	file underlying this corpus ||| lazy sequence	count=1
function	sentence_aligned_corpus and [function] ||| [function]	count=1
function_arg	self with other ||| add other	count=1
class	this rule ||| rule with context	count=1
arg	associated with edge ||| edge	count=1
arg	a baseline ||| initial_tagger	count=1
function	with ||| register with	count=2
arg	the item is ||| item	count=1
function	the node label ||| node label	count=1
class	needs ||| chart	count=1
class	particular ||| stepping	count=1
class	the first element of ||| descent	count=1
arg	root ||| root	count=2
class	a dutch ||| dutch stemmer	count=1
class	a token from the ||| parser	count=1
class	first element of ||| descent parser	count=1
class	with ||| hidden markov model tagger	count=2
arg	it precedes [arg] beginning with ||| [arg]	count=1
class	this corpus ||| timit corpus reader	count=1
arg	s as a ||| fileids tagset	count=2
function	a demonstration ||| demo	count=7
class	frontier in particular if ||| descent	count=1
function	list of paragraphs each ||| paras	count=5
function_arg	rule to [arg_2] ||| [function_1] [arg_2]	count=1
class	internal ||| framenet corpus reader	count=1
class	indicates how much of ||| edge i	count=1
function_arg	[function_1] ranks1 ||| [arg_2] [function_1]	count=1
arg	creates the sentence alignment ||| source_blocks target_blocks	count=1
function	illustrate the various ||| discourse demo	count=2
arg	takes a sentence ||| sentence	count=1
class	structure is consistent ||| edge i	count=1
class	files ||| reviews corpus	count=1
module	text widget ||| draw	count=1
arg	by ||| cutlength	count=1
function_arg	move the file [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
class	counts ||| model5counts	count=1
function	comparison ||| comparison	count=1
module_class	[module_1] for ||| [module_1] swadesh [class_2]	count=1
function	return a [function] of this ||| [function]	count=1
function	item, ||| if possible	count=2
function	wrap the first ||| wrap	count=1
function	a variety of ||| info from	count=1
class	non-terminal from ||| nonterminal	count=1
function_arg	train [arg_2] ||| [arg_2] [function_1]	count=1
class	this tagger [class_2] ||| [class_2] [class_1]	count=12
function_arg	[function_1] word using ||| [arg_2] [function_1]	count=1
class	of probability ||| prob	count=1
function	return the classifier ||| classifier	count=1
class	languages as iso ||| corpus	count=1
class	to ||| chart	count=2
function	first [function_2] ||| [function_2] [function_1]	count=4
arg	s as ||| fileids speaker stem relation	count=1
arg	trained ||| trained	count=1
arg	highest probability ||| unlabeled_sequence	count=1
function	demonstration showing the ||| rule parse demo	count=1
module	[module] feature structure ||| [module]	count=1
class	for this corpus or ||| corpus reader	count=1
function	path distance ||| path	count=1
function	the number of ||| num	count=3
function	arc to the node ||| arc	count=1
function	for word tokenization ||| word tokenizer	count=2
module	:return ||| corpus reader	count=1
function_arg	given a [arg_2] ||| [arg_2] [function_1]	count=2
function	checksum for a ||| hexdigest	count=1
arg	[arg_1] span ||| [arg_2] [arg_1]	count=8
class	contents of ||| category corpus reader	count=1
function	value of ||| value	count=1
arg	a text ||| text	count=1
module	of ||| sem	count=4
function	tags ||| tags	count=1
arg	up to size bytes ||| size	count=1
function	in ||| rank	count=1
arg	[arg] has a ||| [arg] forward fs_class	count=1
function	the unique ||| unique	count=1
class	return the unicode encoding [class_1] [class_2] if known ||| [class_2] [class_1]	count=2
arg	and returns a tuple ||| line primitives families	count=1
function	various ||| drt discourse	count=1
class	a unit ||| chart view	count=1
module	corpus using an ||| corpus reader	count=1
function_arg	average of [arg_2] ||| [arg_2] [function_1]	count=4
arg	the rule ||| rule	count=1
class	by this variable ||| variable	count=1
arg	:param data bytes to ||| data size	count=1
function	maltparser [function_2] ||| [function_2] [function_1]	count=1
class	a corpus ||| propbank corpus reader	count=1
class	smoothing method 4 ||| smoothing	count=1
function	used to resize a ||| resize	count=1
function_arg	[function_1] symbol ||| [arg_2] [function_1]	count=1
class	in a ||| framenet corpus reader	count=1
class	a new classifier based ||| classifier based tagger	count=1
function	of the table's _rows ||| table	count=1
function	of information ||| info from	count=1
class	to the minimal ||| minimal	count=1
function	build a nltk sem ||| test build	count=1
function	the right sibling ||| right sibling	count=1
class	function must be called ||| regexp chunk	count=1
arg	[arg] starting at ||| i j [arg]	count=3
class	element ||| recursive descent	count=1
class	words in alphabetical ||| lexicon corpus reader	count=1
module	function for ||| corpus reader	count=2
class	function must ||| parser app	count=1
class	[class_1] iso 639-3 ||| [class_2] [class_1]	count=2
function	press ||| press	count=1
class	rule it ||| rule with context	count=1
function	as the training ||| train	count=1
class	that a token has ||| shift reduce parser	count=1
arg	file s as ||| fileids c5 strip_space	count=2
function	[function] character ||| [function]	count=1
class	a corpus view ||| propbank corpus	count=1
class	minimal set ||| minimal set add	count=1
function	read a [function_2] ||| [function_2] [function_1]	count=3
function	f measure ||| f measure	count=2
arg	[arg_1] bytes ||| [arg_1] [arg_2]	count=2
arg	of parent ||| parent	count=1
function_arg	xml index [arg_2] ||| [function_1] [arg_2]	count=2
class	in ||| corpus reader	count=6
module_class	by this canvas ||| draw canvas	count=2
class	is the probability ||| heldout prob	count=1
module	the tree ||| app	count=1
function	primitive [function_2] ||| [function_2] [function_1]	count=1
function_arg	category [arg_2] ||| [arg_2] [function_1]	count=5
class	this corpus ||| string category corpus reader	count=1
function	prove a ||| prove	count=1
class	of a bigram ||| bigram	count=1
function	of all ||| all	count=2
arg	of samples ||| samples store_logs	count=1
class	heldout estimate ||| heldout	count=1
class	a sentence in ||| reader	count=1
function_arg	[function_1] limit ||| [arg_2] [function_1]	count=1
function	draw ||| draw	count=1
module	must be called if ||| app	count=2
function	the dendrogram ||| dendrogram	count=1
function	perform a projective dependency ||| projective	count=1
class	a proper [class_2] ||| [class_2] [class_1]	count=3
class	to tags ||| context tagger	count=1
function	:return the log probability ||| output logprob	count=1
arg	determined [arg] provided ||| [arg]	count=1
function	first applicable suffix-removal rule ||| apply rule	count=1
function	illustrate ||| discourse	count=2
function_arg	alignments expressed as ||| alignments src_sentence trg_sentence	count=2
arg	make sure that s ||| s	count=1
class	over ||| classifier i	count=2
arg	documents each of which ||| documents	count=1
arg	specified number of rows ||| rows cols attempts	count=1
class	probability state sequence this ||| markov model	count=1
function	tagged ||| tagged	count=7
class	be called ||| chunk	count=1
arg	information content value ||| ic	count=1
function	next best rule this ||| best rule	count=1
function_arg	training data [arg_2] ||| [arg_2] [function_1]	count=6
arg	sentence takes a sentence ||| sentence verbose	count=1
class	[class_1] binder in ||| [class_2] [class_1]	count=4
function	to ||| to bindings	count=1
class	unimplemented because the neural ||| neural	count=1
function	is a factory method ||| variable	count=1
class	the remaining text ||| shift reduce parser	count=1
class	sequence this ||| markov model	count=1
function	[function_1] word alignments ||| [function_1] [function_2]	count=10
arg	for a synset ||| synset	count=1
function	is run [function] within the ||| import [function]	count=1
function	appropriate for the ||| expression	count=1
class	codes ||| crubadan corpus reader	count=1
arg	consideration given ||| test_sents	count=1
class	corresponding vector of joint-feature ||| maxent feature	count=1
arg	if finalize ||| verbose finalize	count=2
function	given ||| remove by	count=1
arg	the current round of ||| upper_date_limit lower_date_limit	count=1
class	a list's ||| pretty lazy	count=1
arg	display ||| display	count=1
function	line of text ||| text	count=1
module	helper function given ||| corpus reader	count=1
function	for the ||| expression	count=1
class	given the ||| corpus reader	count=1
function	the given ||| range	count=1
function	[function_1] all ||| [function_2] [function_1]	count=6
class	brill tagger ||| brill tagger trainer	count=2
class	out how big ||| chart	count=1
arg	takes multiple ||| verbose top_relation_label	count=1
class	the sequence with the ||| markov model tagger	count=1
arg	single pos tagged sentence ||| sentence	count=1
arg	be [arg_2] ||| [arg_1] index [arg_2]	count=1
function	present ||| extract	count=1
function	entity in the model ||| model var	count=1
function	the special category ||| category	count=1
module_class	of this expression ||| sem expression	count=1
class	hypothesized structure is consistent ||| edge	count=1
class	:return the text contents ||| senseval corpus	count=1
function	arc from ||| add arc	count=1
class	:return the cmudict lexicon ||| cmudict	count=1
class	parsing a [class_2] ||| [class_2] [class_1]	count=2
class	called if ||| glue demo	count=1
function	set the ||| set	count=6
function	table's ||| table	count=1
function	read a sequence of ||| read	count=1
arg	bracketed tree string and ||| cls s brackets read_node	count=1
class	be ||| glue	count=1
arg	span ||| span	count=2
function	convert this ||| to	count=1
function	number of left ||| left	count=1
function	a subcorpus ||| lusentence	count=1
class	be called if ||| regexp chunk	count=1
arg	expression to ||| expression command x y	count=1
function_arg	indent [arg_2] ||| [arg_2] [function_1]	count=1
class	in an subcorpus ||| reader	count=1
class	verb ||| verbnet corpus reader	count=1
class	parses that can be ||| descent parser	count=2
module	probability this ||| core	count=1
class	text ||| stepping shift reduce	count=1
class	the brill tagger ||| brill tagger trainer	count=2
function	of sentences each encoded ||| sents	count=2
class	set having ||| set	count=1
arg	sample the ||| sample	count=1
function	raw string ||| raw	count=2
function	of the productions ||| productions	count=1
class	sentence ||| punkt sentence tokenizer	count=1
class	the remaining text to ||| shift	count=1
class	of the remaining ||| reduce parser	count=1
class	of witten-bell probability estimates ||| witten bell prob	count=1
function	abstractvariableexpression appropriate for ||| variable expression	count=1
class	rule ||| chart rule	count=2
class	big the ||| chart view	count=1
function	freqdist containing ||| freq threshold	count=1
arg	by production ||| production	count=1
function	return the [function] to this ||| [function]	count=1
function	string representation of ||| repr	count=2
module_class	[module_1] path ||| [module_1] zip file [class_2]	count=2
arg	rest ||| keywords	count=1
class	enter ||| parser app	count=1
module	from a single corpus ||| corpus reader	count=1
arg	licensed by production ||| production	count=1
arg	used to generate base_fdist ||| base_fdist	count=1
module	in self ||| sem	count=1
module	return a ||| reader	count=1
class	moses machine translation community ||| moses	count=1
arg	of text label ||| label word_tokenizer	count=1
class	supported ||| reader	count=1
function	a vector ||| vector	count=1
function	the ||| drt discourse demo	count=1
arg	string ||| s chunk_types root_label	count=1
function	arcs to any of ||| redirect arcs	count=1
arg	in ||| tr	count=1
function	_readings to construct ||| construct	count=1
class	widget [class] a given ||| [class]	count=2
function	the corresponding ||| tuple2str	count=1
class	should be provided to ||| prover9parent	count=1
arg	lines at exactly the ||| lines wrap_at	count=1
arg	[arg] rightmost stack ||| [arg]	count=1
function	and then following the ||| join	count=1
class	remaining text to ||| reduce parser	count=1
arg	a sequence of data ||| data	count=1
class	the remaining text to ||| stepping shift reduce	count=1
class	feature encoding based on ||| maxent feature encoding	count=2
arg	to generate base_fdist ||| base_fdist heldout_fdist bins	count=1
class	[class] given ||| [class]	count=4
arg	single sentence ||| sentence threaded verbose filter	count=1
arg	given file s ||| fileids strip_space	count=1
class	of the frontier in ||| recursive descent parser	count=1
arg	of documents located at ||| fileids word_tokenizer sent_tokenizer	count=1
class	languages ||| crubadan corpus	count=1
function	log probability of ||| logprob	count=1
function	of a [function] values ||| [function]	count=1
class	make up this corpus ||| corpus reader	count=2
arg	[arg_1] relation type ||| [arg_2] [arg_1]	count=3
class	of all parses ||| recursive descent	count=2
arg	match the ||| search_leaves	count=2
arg	feature f ||| f	count=1
class	must be called ||| regexp chunk app	count=1
function	[function_1] category ||| [function_1] parse [function_2]	count=3
function	given the ||| given	count=2
function	entropy over the ||| entropy	count=1
function_arg	[function_1] documents each ||| [function_1] [arg_2]	count=1
function	to indent ||| indent	count=1
arg	of tokens ||| tokens	count=5
module	as ||| corpus reader	count=3
function_arg	positions [arg_2] ||| [function_1] [arg_2]	count=1
module_class	[module_1] may cause ||| [module_1] [class_2]	count=2
function	an epytext @field to ||| epytext	count=1
arg	'predicate' as the predicate ||| predicate signature	count=1
arg	or the list ||| fileids	count=1
arg	with address node_index ||| node_index	count=1
module	error-rate relative ||| metrics	count=1
function_arg	[function_1] of *regexp* ||| [function_1] s [arg_2]	count=1
arg	pairs ||| pairs	count=1
function	:return the width ||| width	count=1
function	about ||| user	count=1
function	of tweet ids fetch ||| expand tweetids demo	count=1
arg	done by repeatedly taking ||| train_sents test_sents min_score min_acc	count=1
class	in the chart ||| stepping chart parser	count=1
function	for the fileids that ||| fileids	count=1
function	[function_1] scrollregion ||| [function_2] [function_1]	count=1
class	if ||| glue	count=1
function	_readings to construct a ||| construct threads	count=1
class	function must ||| chart parser app	count=1
module	this ||| parse	count=5
arg	bytes ||| size	count=1
function	of information ||| info	count=1
class	*sentences* [class] ||| tagger [class]	count=2
module	-- return ||| core	count=1
arg	expression, for the ||| argument	count=1
class	scores ||| assoc measures	count=3
arg	score aka system-level ||| list_of_references hypotheses weights smoothing_function	count=1
module	out how big ||| app	count=1
arg	string containing a ||| vnframe indent	count=1
class	that have ||| parser	count=1
class	out ||| chart view	count=1
class	the hypothesized structure ||| edge	count=1
function	[function_1] pointer lists ||| [function_1] [function_2]	count=4
arg	s ||| s s	count=1
class	number ||| cluster i	count=1
arg	that matches tagspec, and ||| tagspec elt_handler	count=1
class	[class_1] parsers that ||| [class_2] [class_1]	count=3
function	nodes traversed on ||| hypernym paths	count=1
module	words ||| reader	count=1
module	of times this ||| core	count=1
function	from the fulltextindex xml ||| fulltextindex elt	count=1
class	files that ||| reviews corpus	count=1
class	based on ||| based tagger	count=1
function	given a sequence yields ||| sequence	count=1
function	weighted sum ||| delta	count=1
function	crosses the truncation line ||| get truncation	count=1
function	or disable warnings ||| warnings	count=1
function	for the data server's ||| get	count=1
class	of a dependency graph ||| dependency parser	count=1
arg	if with_shutdown is true ||| with_shutdown	count=1
class	this function must ||| parser app	count=1
class	words ||| reader	count=1
arg	callback that will be ||| callback	count=1
function	convert a list ||| user info from id	count=1
arg	the given item at ||| item	count=1
function	[function_1] words ||| [function_1] [function_2]	count=6
function	grammar ||| grammar	count=2
function	the grammar [function_2] ||| [function_2] [function_1]	count=2
function	sentence [function_2] ||| [function_2] [function_1]	count=1
function	all positive words ||| positive	count=1
arg	the trees which match ||| trees search_leaves	count=1
function	score ||| score	count=6
function	[function_1] rule ||| [function_2] [function_1]	count=3
class	given [class_2] ||| [class_2] [class_1]	count=8
class	alphabetical ||| lexicon corpus	count=1
module	build the internal indexes ||| corpus	count=1
class	token's ||| token	count=1
function	list of productions ||| productions	count=1
function	print trace output ||| trace shift	count=1
function	normal ||| normal	count=1
class	corpus reader using data ||| corpus reader	count=1
arg	return a score denoting ||| other ic	count=1
function	parse the current ||| parse	count=1
arg	quadgramcollocationfinder given ||| quadgram_fd ii iii	count=1
class	with the ||| markov	count=1
function	unigram ||| unigram	count=1
function	and then following ||| join	count=1
class	[class_1] sentences in ||| [class_2] [class_1]	count=1
function_arg	[function_1] function results ||| [function_1] [arg_2]	count=3
function	and ||| and	count=2
function	use of a previously ||| use	count=1
module	return an iterable ||| core	count=1
arg	forward ||| forward fs_class	count=1
class	text to the end ||| stepping shift reduce parser	count=1
module	this corpus or ||| corpus	count=1
function_arg	a local [arg_2] ||| [function_1] resource_url [arg_2]	count=1
module	structure is ||| parse	count=1
function	unification of the two ||| unification	count=1
class	of ||| query	count=2
module	this canvaswidget has a ||| draw	count=2
arg	freqdists for appearances of ||| word_fd	count=1
function	the data file ||| data file	count=2
module	the recursive ||| parse	count=1
class	an ||| abstract	count=2
module	bounding box for this ||| draw	count=1
class	must be called ||| demo	count=1
module_class	[module_1] [class_2] ||| [module_1] plaintext [class_2]	count=5
arg	of several other such ||| join_char	count=1
module	return true if the ||| core	count=1
function	tokenize() to each element ||| tokenize sents	count=1
function	[function_1] of chomsky ||| [function_1] [function_2]	count=1
class	supported languages as iso ||| corpus reader	count=1
arg	bncwordviews or the list ||| fileids sent tag strip_space	count=1
function	top-lebel node in a ||| exprs action	count=1
class	of tweets as as ||| twitter corpus	count=1
function_arg	in ranks1 and ||| rank dists ranks1	count=1
function	freqdist containing only ||| freq	count=1
class	tags the sequence ||| markov model tagger	count=1
function	[function_1] max ||| [function_1] [function_2]	count=1
function	string containing ||| pretty format	count=1
arg	:param valuation_str str with ||| valuation_str format	count=1
class	[class_1] matrix ||| [class_1] [class_2]	count=4
class	must be called if ||| parser app	count=1
class	end of ||| reduce	count=1
function	single [function] character followed ||| [function]	count=2
arg	the index of ||| index	count=1
function	a text generates ||| from	count=1
class	pickled model ||| perceptron	count=2
class	the moses machine ||| moses	count=1
arg	of documents each of ||| documents	count=1
function	the ||| info from	count=1
function	length to the ||| length	count=1
arg	sequence of items as ||| sequence	count=3
function	top-lebel node ||| exprs action	count=1
class	for this corpus ||| corpus reader	count=5
module	string and return ||| core	count=1
arg	print ||| num window_size	count=1
class	classifier ||| bayes classifier	count=1
class	bigram ||| bigram collocation finder	count=1
class	function must be called ||| demo	count=1
class	from the ||| reduce parser	count=1
class	by this ||| i	count=3
class	list of ||| crubadan	count=1
function	a known abbreviation ||| reclassify abbrev	count=1
arg	[arg_1] [arg_2] ||| [arg_2] [arg_1]	count=267
arg	given file s as ||| fileids tagset	count=2
module	the ||| translate	count=11
module	iso ||| corpus reader	count=2
function	for ||| variable expression	count=1
function_arg	evaluate and [arg_2] ||| [function_1] test_set [arg_2]	count=1
class	a lexical translation model ||| ibmmodel2	count=1
module	probability ||| tag	count=1
class	first element ||| stepping recursive	count=1
module	big ||| app	count=2
function_arg	[function_1] remaining_text to ||| [arg_2] [function_1]	count=3
arg	file s as ||| fileids c5	count=2
arg	id luname [arg_2] ||| [arg_2] [arg_1]	count=4
function	exemplar sentence ||| exemplar of	count=1
arg	feature structure that ||| fstruct	count=1
function	all ||| all	count=2
module	number of times this ||| core	count=1
function	the given ||| classify	count=1
class	probability state sequence this ||| tagger	count=1
module_class	all the subtrees of [module_1] [class_2] optionally restricted ||| [module_1] [class_2] subtrees	count=1
arg	sequence if the sequence ||| sequence	count=1
module	return true if this ||| core	count=6
function	node label of the ||| label	count=1
module	that ||| sem	count=1
module	supported languages as ||| reader	count=1
class	this sentence ||| sentence	count=1
class	against ||| parser i	count=1
arg	size bytes from ||| size	count=1
arg	to generate base_fdist ||| base_fdist	count=1
class	probability state sequence this ||| markov model tagger	count=1
function	of synsets for ||| synsets	count=1
module	chunk ||| chunk	count=2
function	shift ||| shift	count=1
class	if ||| recursive descent parser	count=1
function	remove all [function_2] ||| [function_1] [function_2]	count=1
arg	the predicate ||| predicate signature	count=1
class	a probabilisticdependencygrammar based on ||| projective dependency parser	count=1
function	a variety of ||| user info from	count=1
class	a probabilisticdependencygrammar ||| probabilistic projective dependency parser	count=1
arg	alignment_info, ||| alignment_info	count=1
class	words ||| lexicon corpus	count=1
class	tags the ||| hidden markov model	count=1
class	rule it ||| rule with	count=1
module	the internal indexes ||| corpus	count=1
function	names of ||| names	count=2
class	frontier ||| recursive	count=1
function	the likelihood of ||| likelihood	count=1
class	file identified by this [class_1] [class_2] ||| [class_1] [class_2]	count=1
class	indicates how much ||| edge i	count=1
module	the ||| core	count=1
function	function for pretty-printing ||| pretty	count=2
function	optionally [function] object ||| make [function]	count=1
function	to configure ||| configure	count=1
arg	positions where it applies ||| positions	count=1
function	a slice ||| slice	count=1
class	the ||| nombank instance	count=2
class	file identifiers for the ||| ycoecorpus reader	count=1
arg	of word tag ||| strip_space stem	count=1
class	ensure a proper probability ||| simple good turing prob	count=1
function	implements step 1c from ||| step1c	count=1
function_arg	[function_1] rule data ||| [arg_2] [function_1]	count=1
arg	the original text ||| text	count=1
class	buffered [class_2] ||| [class_1] [class_2]	count=2
arg	assigns [arg_2] ||| [arg_2] [arg_1]	count=6
module	the [module] a ||| [module]	count=1
function	and returns ||| expression	count=1
function	given chart into the ||| set	count=1
function	of all variables ||| variables	count=1
class	move ||| stepping shift reduce	count=1
arg	list of items ||| items	count=1
class	of ||| descent parser	count=1
module	a subtype of ||| sem	count=1
class	chart rule ||| stepping chart parser	count=1
class	how big the ||| chart view	count=1
function	[function_1] in that ||| [function_2] [function_1]	count=3
function	an integer begins at ||| int	count=1
function	highest score ||| best	count=1
class	dependency graph based on ||| projective dependency	count=1
class	the sentence string to ||| view	count=1
class	this probability ||| prob	count=2
arg	relation type ||| relation	count=1
class	i e : ||| i	count=6
function	grammar [function_2] ||| [function_2] [function_1]	count=2
class	to file or ||| buffered gzip file	count=1
arg	over a database ||| dbname	count=1
module	indicates how much of ||| parse	count=1
arg	the input string s ||| input	count=1
class	the first element ||| recursive descent	count=1
arg	[arg_1] f-score ||| [arg_2] [arg_1]	count=2
function	of information about the ||| from	count=1
function	url ||| url	count=4
arg	the proof string ||| format	count=1
class	a feature with the ||| feat	count=2
function	status of the given ||| status	count=1
function	region [function] ||| [function]	count=3
function_arg	[function_1] [arg_2] ||| [function_1] synset [arg_2]	count=2
arg	[arg_1] given zipfile ||| [arg_2] [arg_1]	count=2
class	sequence with the ||| markov model	count=1
arg	csv ||| outfile encoding	count=1
function	size ||| file size	count=1
arg	probability ||| prob	count=1
module	list of supported languages ||| corpus	count=1
function	a word type ||| type	count=1
module	of [module] ||| [module]	count=3
class	build the internal ||| corpus	count=1
arg	in ||| tr nr	count=1
arg	:return a list of ||| fileids	count=1
arg	devset_name the name ||| devset_name devset grammar	count=1
arg	the boundaries ||| text boundaries	count=1
function	[function_1] counter from ||| [function_1] [function_2]	count=3
class	eval(), [class] lists all ||| [class]	count=1
arg	methods of discoursetester ||| reading_command	count=2
module	function must be called ||| app	count=2
function_arg	[function_1] under the ||| [function_1] [arg_2]	count=5
arg	in the trees which ||| trees	count=1
function_arg	[function_1] pretty-printed ||| [function_1] [arg_2]	count=2
function	is not yet covered ||| remaining	count=1
class	the frequency distribution ||| good turing prob dist	count=1
module	languages as iso ||| corpus reader	count=1
arg	segmentations a [arg_2] ||| [arg_1] [arg_2]	count=1
arg	[arg_1] v this ||| [arg_2] [arg_1]	count=1
class	true if the graph ||| dependency graph	count=1
module_class	[module_1] feature ||| [module_1] [class_2] struct	count=1
function	the distance of the ||| distance	count=1
arg	a word using the ||| word	count=1
arg	uses grammar ||| grammar	count=1
class	depth ||| tiling tokenizer	count=1
module_class	of this tree ||| core parented tree	count=2
arg	tagging of ||| train_sents	count=1
module_class	this edge ||| parse edge i	count=2
class	to ||| framenet	count=1
arg	the hunpos-tag ||| path_to_bin	count=1
function	lemmas in the ||| lemmas	count=1
class	to ||| freq	count=1
arg	highest probability state ||| unlabeled_sequence	count=1
function	get the static index ||| get static index	count=1
function	as a raw string ||| raw	count=1
class	how much of the ||| edge i	count=1
class	a collocation ||| abstract collocation	count=1
arg	of tree [arg_2] ||| [arg_2] [arg_1]	count=1
class	element in a ||| reader	count=1
module	this instance's ||| reader	count=1
function_arg	[function_1] tab file ||| [arg_2] [function_1]	count=3
function	[function_1] all alphabetic ||| [function_2] [function_1]	count=1
arg	information content value ||| synset2 ic	count=1
function	illustrate ||| discourse demo	count=2
function	instantiates and returns a ||| variable	count=1
class	return all sentences in ||| comparative sentences	count=1
function	[function] samples ||| [function]	count=1
module	to ||| core	count=1
function_arg	pcfg grammar [arg_2] ||| [arg_2] [function_1]	count=5
module	[module] between ||| [module]	count=1
arg	root the root directory ||| root nomfile framefiles nounsfile	count=1
arg	from consideration given the ||| train_sents test_sents	count=1
class	[class] be loaded ||| [class] reading	count=3
module_class	[module_1] corpus ||| [module_1] tagged [class_2]	count=1
class	can ||| cfg	count=1
function	illustrate ||| demo	count=2
function_arg	index [arg_2] ||| [function_1] [arg_2]	count=2
module	for the best ||| translate	count=1
function	dictionary of ||| dict	count=1
class	be called if ||| parser	count=1
function	pre-calculate ||| forms	count=1
class	to ibm ||| ibmmodel	count=1
function	a subcorpus of an ||| handle lusentence	count=1
module	tag dictionary for ||| tag	count=1
class	other logic ||| logic	count=1
function	distance of ||| distance	count=1
class	a corpus ||| nombank corpus reader	count=1
function	of ||| info from	count=2
class	rule given ||| chart rule	count=1
arg	a single sentence ||| sentence	count=1
function	[function_1] children ||| [function_2] [function_1]	count=3
function_arg	[function_1] distance ||| [function_1] [arg_2]	count=2
class	the sequence with ||| model tagger	count=1
class	a dictionary ||| dictionary	count=1
function	method ||| variable	count=1
function	the primitive [function_2] ||| [function_1] [function_2]	count=1
function	given ||| given	count=2
function	process length six ||| w64	count=1
function	illustrate ||| drt discourse	count=1
class	list of supported ||| reader	count=1
arg	and returns a tuple ||| line	count=1
function	load the ||| load	count=1
function	list ||| info	count=1
class	probability state sequence this ||| model	count=1
function	information ||| id	count=1
class	this variable binder in ||| variable binder	count=1
function	a userid to ||| by userid demo	count=1
function	representation but if ||| repr	count=5
arg	creates ||| source_blocks target_blocks	count=1
function	a tgrep ||| tgrep tokenize	count=1
class	an em clusterer ||| emclusterer	count=1
arg	size bytes from the ||| size	count=1
class	corpus ||| category corpus reader	count=1
module	alphabetical ||| corpus	count=1
class	of the stack ||| shift reduce parser	count=1
arg	:param status_code ||| status_code data	count=1
module	for the [module] a ||| [module]	count=1
function	[function] of *sentences* ||| tag [function]	count=3
arg	if finalize is ||| verbose finalize	count=2
function	java binary ||| config java	count=1
class	function ||| glue	count=1
arg	to the input string ||| input encoding	count=1
class	decision ||| decision	count=1
arg	[arg_1] ranks2 for ||| [arg_1] [arg_2]	count=1
arg	actual ||| intact_word	count=1
arg	callback ||| event	count=1
function	input file for tadm ||| tadm file	count=1
arg	index ||| index	count=8
class	tokenizer binary and ||| tokenizer	count=1
arg	given scoring function ||| score_fn w1 w2 w3	count=1
arg	a string representation of ||| format	count=1
class	should be ||| chart	count=1
function	[function_1] data ||| [function_2] [function_1]	count=3
class	text ||| shift reduce	count=1
function	sets in this ||| sets	count=1
class	list's ||| pretty lazy iterator list	count=1
class	[class] on the ||| function [class]	count=1
function	the users ||| user info from id	count=1
function	sentences in that ||| sentences from	count=1
class	this ||| chunk app	count=1
class	the end ||| shift reduce	count=1
class	[class] given the ||| [class]	count=3
module	the name of the ||| reader	count=1
class	structure is consistent with ||| edge	count=1
class	the grammar ||| cfg	count=1
class	structure is ||| i	count=1
arg	the fileids that ||| fileids	count=1
class	a probability distribution for ||| prob dist	count=3
module	example of a ||| sem	count=1
arg	this split disjunction ||| first second	count=1
function_arg	result of [arg_2] ||| [function_1] [arg_2]	count=1
arg	xml ||| tagspec	count=1
class	languages as ||| crubadan corpus	count=1
class	[class_1] dependency ||| [class_2] [class_1]	count=15
arg	'variable' with 'expression' ||| expression replace_bound alpha_convert	count=1
class	a given bigram ||| bigram collocation	count=1
class	tree ||| tree classifier	count=2
function	conll format ||| conll	count=1
arg	corpus train_toks ||| cls train_toks	count=1
arg	feature ||| feat flag	count=1
module	in the ||| translate	count=1
function_arg	data [arg_2] ||| [function_1] [arg_2]	count=2
function	fulltextindex ||| handle fulltextindex	count=1
function	information about the users ||| info	count=1
class	sentence boundary ||| punkt sentence	count=1
class	for the feature ||| feat list	count=1
arg	implement the ||| unit bracket_sent	count=1
arg	sentence as a list ||| sentence verbose	count=1
function	to write to ||| write	count=1
function	construct a ||| construct	count=2
function	the experiment _create_rand_fdist ||| create sum pdist	count=1
function	the alpha ||| alpha	count=1
class	[class_1] wordnet 3 ||| [class_2] [class_1]	count=2
class	return ||| crubadan corpus reader	count=1
class	beginning ||| shift reduce parser	count=2
class	state sequence ||| markov model	count=1
class	the text contents ||| senseval	count=1
arg	train and test ||| trainer save_analyzer n_instances	count=1
function	an exemplar ||| exemplar	count=1
function_arg	page if with_shutdown ||| page with_shutdown	count=2
class	to prevent unnecessary ||| resolution prover	count=1
class	marker ||| standard format	count=1
class	parsing a ||| recursive descent parser	count=2
function_arg	[function_1] limit the ||| [arg_2] [function_1]	count=1
function	given training ||| train	count=2
function	uniform ||| set uniform	count=1
class	sequence with ||| markov	count=1
arg	symbol when entering states ||| symbol	count=1
arg	string ||| s encoding	count=1
function	constants() ||| constants	count=2
function	[function_1] [function_2] directly as part of ||| [function_2] [function_1]	count=8
function	of all roots ||| roots	count=1
arg	implement the view methods ||| fileid unit bracket_sent	count=1
function	a factory method that ||| expression	count=1
arg	:param data ||| data	count=2
function	static index [function_2] ||| [function_1] [function_2]	count=1
arg	of remaining_text to ||| remaining_text	count=1
arg	s [arg_2] ||| [arg_1] [arg_2]	count=1
class	where this tree ||| tree	count=1
arg	implement the view methods ||| fileid bracket_sent tag strip_space	count=1
arg	return a ||| other verbose simulate_root	count=3
arg	a string to ||| s	count=1
function	rule format("verbose") ||| verbose rule	count=2
arg	a [arg] canvas widget ||| index [arg]	count=2
function	phonetic segments ||| diff	count=1
arg	that s ||| s verify_tags	count=1
arg	documents located at ||| fileids word_tokenizer sent_tokenizer	count=1
class	[class_1] file ||| [class_2] [class_1]	count=4
function	read a block from ||| read block	count=1
function	initialize this ||| init	count=1
class	single parsing ||| stepping recursive descent parser	count=1
module	tree should be ||| app	count=1
class	of supported ||| crubadan corpus reader	count=1
class	this function must be ||| chunk	count=1
function	compute the [function_2] ||| [function_1] [function_2]	count=1
function	adds an [function] node ||| [function]	count=1
function	to combine ||| combine	count=1
arg	divide a string of ||| s	count=1
class	file identifiers for ||| ycoecorpus	count=1
function	[function] falls after ||| [function]	count=2
class	be called if ||| chart parser app	count=1
arg	modelbuilder the ||| modelbuilder	count=1
function	that are before ||| before	count=1
module	corpus view ||| corpus reader	count=4
function_arg	[function_1] metric that ||| metrics masi [function_1] [arg_2]	count=1
function_arg	add [arg_2] ||| [function_1] [arg_2]	count=1
arg	of segmentations ||| seg1 seg2 k boundary	count=1
function	the url for the ||| get url	count=1
class	that are generated [class_1] [class_2] ||| [class_2] [class_1] length	count=2
function	about the users ||| info	count=1
function	the static index page ||| static index page	count=1
arg	alignment_info, ||| alignment_info j_pegged	count=1
class	constructs a bigram collocation ||| collocation finder	count=1
arg	:param loc ||| loc	count=1
function	[function_1] lists for ||| [function_1] [function_2]	count=5
arg	separate the string for ||| string	count=1
function_arg	[function_1] variable ||| [function_1] [arg_2]	count=3
function	parse a sentence takes ||| parse	count=1
function	print the contents ||| print	count=1
function	[function_1] ratios as ||| [function_1] [function_2]	count=1
arg	a given length ||| length	count=1
arg	word back ||| word	count=1
module	for this corpus view ||| corpus	count=4
function	add root ||| add root	count=2
function	given roleset ||| roleset	count=2
class	remaining ||| reduce	count=1
function	about the users ||| user info from id	count=1
function	search ||| search demo	count=1
function	single string ||| raw	count=1
module	text widget used ||| draw	count=1
function	read from ||| read block	count=1
function	of information about ||| user	count=1
function	file ||| webview file	count=1
arg	original text ||| text	count=1
function	tree ||| breadth first	count=1
module	methods ||| inference	count=2
function	users ||| id	count=1
class	convert a ||| query	count=1
function_arg	[function_1] posted by ||| [function_1] [arg_2]	count=4
module	function must ||| sem	count=1
class	this classifier ||| classifier	count=1
function_arg	[function_1] given edge ||| [arg_2] [function_1]	count=6
arg	be trained ||| trained n c	count=1
module	sentence string to figure ||| app	count=1
module	with ||| cluster	count=1
function	paragraphs each encoded as ||| tagged paras	count=1
class	to the end of ||| reduce parser	count=1
function	describes the use of ||| pred use	count=1
module	to ||| reader	count=1
arg	specified fileids ||| fileids	count=1
class	internal ||| framenet	count=1
function	str rule and rule ||| str rule format	count=1
function	update ||| update tag	count=1
function	of information about the ||| user info from id	count=1
class	in an subcorpus of ||| corpus reader	count=1
class	each line in ||| twitter corpus reader	count=1
function	rule and rule ||| rule format	count=1
class	unit needs ||| chart	count=1
arg	training text for this ||| verbose	count=1
class	move a token from ||| shift reduce	count=1
module_class	re-download any packages ||| core downloader	count=1
class	first ||| stepping	count=1
class	particular if ||| parser	count=1
class	tokens using the punkt ||| punkt	count=1
class	function must ||| chart parser	count=1
function	parse on ||| parse	count=1
arg	nodes [arg] ||| [arg]	count=3
function	the top of the ||| find top	count=1
function_arg	[function_1] a string ||| [arg_2] [function_1]	count=1
function	given ||| by	count=1
module	conjunctive ||| sem	count=1
module_class	[module_1] tree ||| [module_1] [class_2]	count=7
function	[function_1] less ||| [function_1] [function_2]	count=2
class	and update the transition ||| transition	count=1
class	a text returns ||| punkt sentence tokenizer	count=1
arg	for one [arg] corpus that ||| [arg]	count=2
function	(see also str ||| demo str	count=1
arg	to implement the view ||| bracket_sent tag strip_space	count=1
class	up this corpus ||| timit corpus reader	count=1
function	reduce ||| reduce	count=2
arg	from an association measure ||| measures	count=1
module	this ||| tag	count=1
function	print ||| print	count=2
function	primitive ||| primitive	count=1
arg	to generate freqdist ||| freqdist gamma	count=1
class	all ||| opinion lexicon	count=1
class	return ||| edge i	count=1
arg	the given span ||| span	count=1
function_arg	the [function_1] [arg_2] ||| [function_1] pattern [arg_2]	count=17
arg	data [arg_2] ||| [arg_1] [arg_2]	count=2
arg	from the assumptions ||| assumptions	count=1
function_arg	given a [arg_2] ||| [function_1] [arg_2]	count=2
module	variety of information about ||| twitter	count=1
class	wordnet corpus [class_2] ||| [class_2] [class_1]	count=4
class	the tag ||| tag	count=1
function	tree positions in ||| positions	count=1
class	this ||| hidden markov model	count=1
function	distance metric >>> ||| distance	count=1
function	probability of [function_2] ||| [function_2] [function_1]	count=16
module	api ||| twitter	count=4
function	for ||| get	count=1
class	needs to ||| chart view	count=1
class	table ||| table	count=3
function_arg	[function_1] of child ||| [function_1] [arg_2]	count=1
function	age ||| age	count=1
class	corpus view ||| nombank corpus reader	count=1
class	of the lancaster ||| lancaster	count=1
function	the best [function_2] ||| [function_1] model2 [function_2]	count=1
arg	binary with the given ||| binary args verbose	count=1
arg	implement ||| unit bracket_sent	count=1
arg	the given file s ||| fileids tag	count=1
class	the ||| view	count=2
function	not a known abbreviation ||| abbrev	count=1
function	[function_1] incoming ||| [function_1] [function_2]	count=3
function	a single string ||| raw	count=1
arg	list of [arg_2] ||| [arg_2] [arg_1]	count=2
function	of target ||| a	count=2
function	check to make ||| check grammar	count=1
class	canvas widget [class] a ||| [class]	count=2
function	of a number ||| number	count=1
arg	val ||| index val	count=1
function	representing a category ||| aug parse category	count=2
class	to ||| framenet corpus reader	count=1
function	encoded as a list ||| chunked	count=1
class	contents of the corpus ||| categorized sentences corpus reader	count=1
function	:return a tuple ||| entries	count=1
arg	phrase_table table ||| phrase_table language_model	count=1
function	macro name ||| macro	count=1
class	calculates ||| ngram assoc measures	count=1
function	value of a ||| value	count=1
function	a friendly error message ||| error	count=1
class	collocation finder with ||| collocation	count=1
function	check ||| check	count=3
arg	specified xml [arg_2] ||| [arg_2] [arg_1]	count=2
class	fileids a list specifying ||| mtecorpus	count=1
class	move a ||| reduce	count=1
class	be called if ||| drt glue	count=1
arg	of drtindividualvariableexpression for the ||| consequent	count=1
function	print the available [function_1] [function_2] ||| [function_1] [function_2]	count=4
function	[function_1] sentences ||| [function_2] [function_1]	count=6
class	bigram collocation finder ||| collocation	count=1
function	[function_1] a category ||| [function_2] [function_1]	count=4
arg	subcorpus ||| subcorpus	count=1
module	widget ||| draw	count=2
arg	with [arg] across ||| variable [arg]	count=1
arg	string containing ||| vnframe	count=1
function	:return a [function] of ||| [function]	count=1
class	languages as iso 639-3 ||| corpus reader	count=1
function	sequence of s-expressions from ||| sexpr	count=1
module	this function must ||| sem	count=1
class	rule it ||| chunk rule with context	count=1
class	that is consistent with ||| edge	count=1
arg	the index ||| index depth	count=1
function	subtype of abstractvariableexpression ||| variable expression	count=1
arg	string of ||| s chunk_label root_label	count=1
class	token from ||| reduce	count=1
class	be how ||| view	count=1
module	that this ||| draw	count=1
arg	s as a list ||| fileids c5 strip_space	count=2
class	when parsing a text ||| probabilistic chart parser	count=1
class	expression to ||| expression	count=2
class	alphabetical order ||| lexicon corpus	count=1
function	for a source language ||| for	count=1
arg	identifiers ||| filetype	count=1
function	applies at ||| rule applies	count=1
function	the table's ||| check table	count=1
class	[class_1] corpus reader ||| [class_2] [class_1]	count=1
function	the unique counter ||| get unique counter	count=2
class	a tuple made ||| reviews	count=1
arg	for the given synset ||| synset	count=1
class	corpus or ||| categorized corpus reader	count=1
function	which accepts [function] ||| make [function]	count=1
function	write the output of ||| output	count=1
arg	numsamples ||| numsamples	count=1
module	list of ||| reader	count=1
arg	bindings with ||| bindings	count=1
class	match ||| stepping recursive descent parser	count=1
arg	train and test ||| trainer	count=1
class	unit needs to ||| chart	count=1
class	languages as ||| crubadan corpus reader	count=1
module	make up this corpus ||| corpus	count=1
module	corpus import ||| corpus reader	count=1
function	determine an appropriate tag ||| one	count=1
class	frontier in ||| stepping recursive descent parser	count=1
class	frontier in particular ||| stepping recursive	count=1
function_arg	given [arg_2] ||| [function_1] [arg_2]	count=5
class	the cross-validation estimate to ||| cross validation	count=1
function	2 retrieve an access ||| add access	count=1
arg	[arg_1] segmentation is ||| metrics pk [arg_2] [arg_1]	count=3
arg	of segmentations a segmentation ||| hyp k boundary	count=1
class	frontier in ||| descent parser	count=1
function	krippendorff's interval [function_2] ||| [function_2] [function_1]	count=4
function	given a collection of ||| from	count=1
function	various methods ||| discourse demo	count=2
class	for editing the ||| cfgeditor	count=1
class	this ||| edge i	count=1
class	[class_1] or ||| [class_2] [class_1]	count=8
arg	text this sets ||| tokens	count=1
class	for a given bigram ||| bigram collocation	count=1
function	[function_1] chomsky normal ||| [function_2] [function_1]	count=1
function	union ||| or	count=2
class	a bigram collocation ||| collocation	count=1
class	true if this dependencygrammar ||| probabilistic dependency grammar	count=1
arg	used to look up ||| history	count=1
module	the remaining text ||| parse	count=1
class	toolbox settings file with ||| toolbox settings	count=1
function	the maltparser command use ||| malt command	count=1
function_arg	trace output [arg_2] ||| [arg_2] [function_1]	count=1
class	examples ||| naive bayes classifier	count=2
function	return all sentences in ||| sents	count=1
class	token from ||| parser	count=1
arg	forward pointer ||| forward fs_class visited	count=1
class	return that ||| backoff	count=1
function	synset relations ||| relations	count=1
module	a factory method ||| sem	count=1
class	text for this sentence ||| sentence tokenizer	count=1
function	adjust [function_2] ||| [function_1] [function_2]	count=1
function	lemma objects ||| lemmas	count=1
function	into ||| set	count=1
class	to ensure a proper ||| simple good turing	count=1
function	convert a list of ||| info from	count=1
function_arg	to a [arg_2] ||| [arg_2] [function_1]	count=3
function	the [function_1] [function_2] ||| [function_2] [function_1]	count=8
module	tweets if ||| twitter	count=1
function	negate() ||| negate	count=1
class	:return a corpus view ||| propbank corpus	count=1
function	projective dependency ||| projective rule	count=1
class	sequence with the ||| model	count=1
class	standard ||| standard	count=1
class	the lancaster [class_2] ||| [class_1] [class_2]	count=1
arg	iff self and other ||| other check_reentrance visited_self visited_other	count=1
class	about the users ||| query	count=1
arg	determine the neighbors ||| j_pegged	count=1
arg	into a list ||| read	count=1
function	a variety of ||| id	count=1
module_class	this canvaswidget is ||| draw canvas widget	count=1
function	the static web help ||| get static web help	count=1
class	for a given trigram ||| trigram collocation finder	count=1
function	assumptions ||| assumptions	count=4
class	offset ||| local timezone offset	count=1
class	alphabetical ||| lexicon	count=1
class	parses [class_2] ||| [class_1] [class_2]	count=8
class	when [class_2] ||| [class_2] [class_1]	count=2
class	[class_1] corpus reader ||| [class_1] [class_2]	count=1
class	unit needs to ||| chart view	count=1
module	illustrate the various methods ||| inference	count=2
module_class	[module_1] corpus ||| [module_1] [class_2]	count=4
module_class	[module_1] [class_2] ||| [module_1] colorized [class_2]	count=1
function	relations involving ||| relations	count=1
class	the same sentence ||| punkt sentence tokenizer	count=1
function	token return the corresponding ||| tuple2str	count=1
function	all [function_2] ||| [function_2] [function_1]	count=2
class	enter the ||| demo	count=1
function	the token is ||| is	count=1
arg	forward pointer ||| forward fs_class	count=1
arg	:type root ||| root	count=1
function_arg	[function_1] expression and ||| [function_1] [arg_2]	count=1
function	kendall's [function] correlation coefficient ||| kendall [function]	count=1
function	information about the ||| user info from	count=1
function	creates a table of ||| create token table	count=1
class	if the feature with ||| feat	count=2
class	to the end ||| parser	count=1
arg	s as ||| fileids	count=18
class	set [class] ||| framenet [class]	count=1
class	in ||| framenet corpus reader	count=1
function_arg	[function_1] edge ||| [arg_2] [function_1]	count=6
function	[function_1] page if ||| [function_1] [function_2]	count=3
function	that instantiates and ||| variable expression	count=1
class	[class_1] bigram ||| [class_2] [class_1]	count=2
function	of http //stackoverflow ||| synset from pos and offset	count=1
function_arg	[function_1] child to ||| [arg_2] [function_1]	count=1
function	which have frequency less ||| freq filter	count=1
class	all ||| opinion	count=1
arg	offset ||| offset	count=2
function	number of ||| num	count=3
arg	luname frameid and ||| luname frameid	count=1
function	return a string representation ||| repr	count=1
arg	-- ie tags are ||| fileid	count=1
class	the frequency distribution in ||| prob dist	count=1
function	arc ||| arc	count=2
arg	dialect ||| dialect	count=1
arg	matched substrings ||| string left right	count=1
function	the first expression ||| first	count=1
function	that *rule* applies ||| applies	count=1
function	[function_1] counter from ||| [function_2] [function_1]	count=3
class	name ||| nombank	count=1
arg	to generate freqdist ||| freqdist	count=1
class	given trigram ||| trigram collocation	count=1
arg	devset_name ||| devset_name devset grammar chunk_label	count=1
class	text to the end ||| stepping shift reduce	count=1
function	all positive ||| positive	count=1
module	words in alphabetical ||| reader	count=1
class	enter ||| parser	count=1
function	primitive is the ||| primitive	count=1
function	pop the ||| pop	count=1
arg	which are preceded by ||| stream	count=1
function	1c ||| step1c	count=1
function	create a copy ||| copy	count=1
function	of ||| from id	count=2
arg	segmentations a [arg_2] ||| metrics pk [arg_2] [arg_1]	count=1
arg	and consequent of 'self' ||| other bindings	count=1
class	sequence ||| hidden markov model	count=2
function	information about the users ||| user info from id	count=1
arg	devset_name the ||| devset_name devset grammar	count=1
arg	apply ||| chunk_struct	count=1
class	the given [class_2] ||| [class_2] [class_1]	count=2
class	[class_1] tree ||| [class_2] [class_1]	count=3
function	the word ||| head word	count=1
function	upper frame page ||| get static upper page	count=1
module	all ||| reader	count=1
function_arg	custom [arg_2] ||| [function_1] lemmas [arg_2]	count=3
class	function must be called ||| chunk	count=1
arg	string ||| s chunk_label root_label sep	count=1
module	make this ||| core	count=2
class	the ||| stepping	count=6
function	input file for megam ||| megam file	count=1
function	the given roleset ||| roleset	count=1
function	illustrate the various methods ||| discourse	count=2
function	from the ||| from	count=1
function	tree positions in the ||| tgrep positions	count=1
class	holes of this semantics ||| hole semantics	count=1
arg	the *worder* ||| character_based	count=1
class	return all ||| opinion lexicon	count=1
arg	information content value ||| ic verbose	count=1
class	with the ||| tagger	count=1
arg	the given resource ||| resource_url	count=1
function	return the [function] of ||| [function]	count=2
class	a list ||| corpus	count=1
function	index [function_2] ||| [function_2] [function_1]	count=1
class	of the corpus ||| corpus reader	count=4
class	in particular if ||| stepping	count=1
function	given ||| range	count=1
class	encoded as a list ||| chunked corpus	count=2
function	tree positions ||| tgrep positions	count=1
class	state sequence this ||| hidden markov model tagger	count=1
class	[class_1] that ||| [class_1] [class_2]	count=11
arg	[arg_1] [arg_2] vocabulary of two items ||| [arg_2] [arg_1]	count=8
arg	tree ||| tree treeloc	count=1
class	edges licensed [class] ||| [class]	count=4
function_arg	[function_1] specified criteria ||| [function_1] [arg_2]	count=2
class	called if ||| chunk app	count=1
function	sets in ||| sets	count=1
function	the predicate-argument annotation file ||| lines	count=2
function	reader for timit ||| read timit	count=1
arg	goal sem ||| goal assumptions	count=1
class	absolute ||| file system	count=1
function	5a from ||| step5b	count=1
class	:return a corpus view ||| corpus reader	count=2
function	:return the hierarchical parent ||| parent	count=1
arg	a sequence ||| sequence n	count=1
arg	any [arg] ||| [arg] forward fs_class	count=1
arg	i [arg_2] ||| metrics retrieve [arg_1] [arg_2]	count=1
function	targets ||| frames	count=1
function	precision for all texts ||| precision	count=1
function	binary [function_2] ||| [function_1] [function_2]	count=4
class	as positive examples (i ||| positive naive bayes	count=1
arg	to implement the ||| bracket_sent tag strip_space	count=1
function	partial structure ||| tree	count=1
class	function must be ||| chart parser app	count=1
function	search ||| search	count=1
function	and ||| expression	count=1
function	positions ||| positions	count=1
arg	of file identifiers for ||| filetype	count=1
arg	position in positions where ||| positions	count=1
function_arg	tokenize a [arg_2] ||| [arg_2] [function_1]	count=2
function_arg	[function_1] rule ||| [function_1] applies [arg_2]	count=1
module_class	[module_1] multi-column ||| [module_1] [class_2]	count=2
class	sentence ||| chart view	count=1
class	token in a ||| tokenizer	count=1
class	corpus reader ||| corpus reader	count=10
class	verb ||| verbnet corpus	count=1
function	flatten a ||| flatten	count=1
function	a ||| user info	count=2
arg	list of tokens segmented ||| pos_tag	count=1
module	or path exists return ||| core	count=1
function	a userid ||| userid demo	count=1
function_arg	[function_1] *regexp* ||| [function_1] s [arg_2]	count=1
module_class	[module_1] [class_2] ||| [module_1] element [class_2]	count=2
module_class	return its ||| core feat dict	count=1
function	lin [function_2] ||| [function_2] [function_1]	count=1
class	the hypothesized structure is ||| i	count=1
function	[function] unary rules ||| [function]	count=1
function	methods ||| demo	count=2
class	complete ||| logic parser	count=1
class	container widget ||| abstract container widget	count=2
function	input string ||| input	count=1
arg	the expression ||| expression command	count=1
function	main frame widget in ||| grid	count=1
class	simple [class_2] ||| [class_2] [class_1]	count=2
class	return a list ||| crubadan corpus	count=1
function	fraction ||| precision	count=1
class	the frontier in ||| stepping	count=1
class	tags the sequence ||| tagger	count=1
function_arg	rule [arg_2] ||| [function_1] [arg_2]	count=1
class	element wrapper for ||| element wrapper	count=2
function	[function_1] texts ||| [function_2] [function_1]	count=4
class	in alphabetical ||| corpus	count=1
function	about the users ||| info from id	count=1
class	first ||| stepping recursive	count=1
class	this ||| instance	count=1
class	frequency distribution in two ||| good turing prob dist	count=1
class	store if hack=true ||| cooper store	count=3
function_arg	skolemize [arg_2] ||| [function_1] [arg_2]	count=3
class	predicate ||| nombank instance	count=1
class	generated [class] ||| maxent feature [class]	count=1
function	step 1c from ||| step1c	count=1
arg	is already bound ||| binding	count=1
arg	for a synset note ||| word synset	count=1
module_class	this canvas widget ||| draw canvas widget	count=4
class	n ||| freq	count=1
function	of the indices where ||| parent indices	count=1
function	categories for ||| categories	count=1
function	tweets tokenized using tweettokenizer ||| tweets	count=1
arg	between tagsets ||| source target	count=1
class	the sequence with ||| model	count=1
arg	start ||| start	count=2
arg	appearances of words bigrams ||| word_fd bigram_fd	count=1
arg	bleu score aka system-level ||| list_of_references hypotheses weights smoothing_function	count=1
class	alignedsent ||| aligned sent	count=3
function	a module to convert ||| taggedsent to	count=1
function	a freqdist ||| freq threshold	count=1
class	currently ||| stepping	count=1
class	users ||| query	count=1
function	exemplar sentence and a ||| exemplar of	count=1
arg	file specified by save_classifier ||| training_set save_classifier	count=1
class	function must ||| regexp chunk	count=1
class	canvasframe to a ||| canvas frame	count=1
class	end of the stack ||| shift	count=1
function_arg	[function_1] return a ||| [function_1] [arg_2]	count=9
class	unicode encoding [class] file if ||| [class]	count=1
function	leacock chodorow [function_2] ||| [function_2] [function_1]	count=1
arg	tagging of the corpus ||| train_sents	count=1
function	node into ||| node label	count=1
function_arg	the fringe [arg_2] ||| [function_1] [arg_2]	count=2
class	representing the chart ||| chart	count=1
module	caller method and return ||| core	count=1
arg	word with ||| word	count=1
function	size of the ||| file size	count=1
class	all verb ||| verbnet corpus	count=1
class	returns words [class_2] ||| [class_1] [class_2]	count=1
class	feature structures assign the ||| feat	count=1
function	information ||| info from id	count=1
class	[class_1] dictionary ||| [class_1] [class_2]	count=1
class	the given ||| corpus reader	count=5
module	as iso 639-3 ||| corpus	count=1
function	projective dependency parser ||| projective	count=1
function	to make look-ups faster ||| buildindexes	count=1
function	to construct a ||| construct	count=2
arg	a single sentence ||| sentence threaded	count=1
module	convert ||| twitter	count=1
class	this rule and ||| rule	count=1
arg	chart parsers ||| choice print_times print_grammar print_trees	count=1
function	the latex qtree package ||| latex qtree	count=1
class	as in manning and ||| ngram assoc measures	count=1
arg	synset note that this ||| word synset	count=1
class	list of text ||| list	count=1
arg	from [arg_2] ||| [arg_1] [arg_2]	count=1
arg	strings is provided ||| strings	count=1
function_arg	tokenize [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	list [arg_2] ||| [function_1] word [arg_2]	count=1
function	[function_1] to parse ||| [function_2] with [function_1]	count=1
arg	of word ||| stem	count=2
arg	of its forward ||| forward fs_class	count=1
function	sentences matching ||| sents	count=1
function	639-3 codes ||| langs	count=1
function	[function_1] [function_2] ||| [function_1] t [function_2]	count=4
arg	user ||| user	count=1
function	dictionary of bigram ||| extract bigram	count=1
function	to each element ||| tokenize sents	count=1
class	given ||| reader	count=1
class	be called ||| regexp	count=1
arg	tokens using a ||| tokens	count=1
arg	widget's top-left corner ||| row col	count=1
module	[module] concept ||| [module]	count=1
class	tags the ||| model tagger	count=1
class	this ||| chart parser app	count=1
arg	[arg_1] if finalize ||| [arg_1] [arg_2]	count=4
function_arg	[function_1] consideration given ||| [arg_2] [function_1]	count=1
function	[function_1] [function_2] of ||| [function_1] [function_2]	count=18
module	hypothesized by this ||| parse	count=2
module	it is a string ||| chunk	count=1
arg	the [arg] ||| [arg]	count=4
arg	of documents ||| cls documents	count=1
function	sentence and an ||| t	count=2
class	based on the ||| based tagger	count=1
arg	filename ||| filename verbose	count=1
function	in the tree ||| draw	count=1
class	:param ||| binder expression	count=1
module	as iso ||| corpus	count=1
class	how much of the ||| edge	count=1
function	demo showing the training ||| prob parse demo	count=1
class	parses [class_2] ||| [class_2] [class_1]	count=8
class	of ||| crubadan	count=1
class	for this corpus ||| nombank corpus	count=1
function	sentences ||| sentences	count=3
class	element ||| stepping recursive	count=1
arg	given zipfile ||| zipfile	count=1
arg	[arg] common ||| [arg] top_n	count=1
class	result to prevent unnecessary ||| resolution prover command	count=1
function_arg	read from stream ||| read block stream	count=1
function_arg	[function_1] corpus train_toks ||| [arg_2] [function_1]	count=8
function	are "preterminals", [function] unary ||| [function]	count=1
function	representation of ||| repr	count=2
class	[class_1] [class_2] ||| [class_2] corpus [class_1]	count=3
function	probability state sequence this ||| tag	count=1
module_class	[module_1] canvasframe to ||| [module_1] [class_2]	count=2
class	scores ||| assoc	count=3
function	frame xml file ||| frame	count=1
function	string containing [function] of ||| [function]	count=2
class	a bigram collocation ||| trigram collocation finder	count=1
function	patterns ||| pro	count=2
class	ibm model 2 ||| ibmmodel	count=1
function	chapters each encoded ||| chapters	count=1
arg	collection of documents ||| cls documents	count=1
function	[function_1] the static ||| [function_1] [function_2]	count=1
class	the end of ||| stepping shift reduce parser	count=1
arg	abstractboxerdrs object hierarchy ||| elimeq bin_dir verbose	count=1
module	figure out how big ||| app	count=1
class	a marker value ||| standard format	count=1
function	change the text that ||| set	count=1
function	list of alignedsent objects ||| aligned sents	count=1
class	canvasframe the ||| frame	count=1
class	much of ||| edge	count=1
function	if the given ||| in range	count=1
function	portion of the text ||| text	count=2
module	element of the frontier ||| parse	count=1
class	this ||| regexp chunk	count=1
function	node into the tgrep2 ||| node	count=1
arg	by the scoring function ||| score_fn	count=1
function	returns the type ||| get type	count=2
class	set ||| prob dist	count=1
class	of this rule it ||| rule with context	count=1
function_arg	[function_1] ranks1 and ||| [arg_2] [function_1]	count=1
function_arg	[function_1] synset ||| [arg_2] [function_1]	count=4
class	the end of ||| stepping	count=1
arg	the highest probability state ||| unlabeled_sequence	count=1
class	[class_1] as a ||| [class_2] [class_1]	count=3
function	beginning ||| shift	count=2
module	return a list of ||| reader	count=1
class	standard format marker file ||| standard format	count=1
class	lexical translation model vacancy ||| ibmmodel5	count=1
arg	lists frame element ||| frame	count=1
class	how ||| i	count=1
function	lemmas ||| lemmas	count=2
class	contents of the corpus ||| comparative sentences corpus reader	count=1
class	corpus view that acts ||| propbank corpus	count=1
function	section for the given ||| section	count=1
module	subtype of abstractvariableexpression appropriate ||| sem	count=1
function	output ||| output	count=1
function_arg	new [arg_2] ||| [function_1] [arg_2]	count=1
class	overridden ||| drt	count=1
class	return all [class_2] ||| [class_2] [class_1]	count=4
class	end of the ||| shift reduce	count=1
arg	variable [arg_2] ||| [arg_2] [arg_1]	count=5
class	spanish ||| spanish	count=1
function_arg	representation [arg_2] ||| [arg_2] [function_1]	count=1
arg	a word and ||| word	count=1
class	elements of lists ||| lazy map	count=1
arg	bytes to ||| size	count=1
class	other logic [class_2] ||| [class_2] [class_1]	count=1
function	string representation [function_2] ||| [function_1] [function_2]	count=1
function	upper frame page if ||| upper page	count=1
function	entropy over ||| entropy	count=1
function	the next best ||| best	count=1
module	given ||| core	count=1
class	and current weights and ||| averaged perceptron	count=1
arg	:param positive_featuresets a ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
arg	iff self and other ||| other check_reentrance	count=1
arg	[arg_1] be used ||| [arg_2] [arg_1]	count=2
arg	optional frame object ||| frame frame2	count=1
function	analyze the sentence string ||| analyze	count=1
class	token ||| stepping shift reduce parser	count=1
class	of the tree ||| tree	count=5
function	be ||| save file	count=1
class	classifier [class_2] ||| [class_1] [class_2]	count=3
function_arg	[function_1] [arg_2] account partial agreement when ||| metrics masi [function_1] [arg_2]	count=1
arg	tokens segmented ||| pos_tag	count=1
function	of edges contained in ||| edges	count=1
arg	the given item ||| item x y	count=1
arg	in unigrams ||| unigrams	count=1
class	by this tagger ||| tagger	count=1
arg	positive_featuresets ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
class	this tagger uses ||| based tagger	count=2
class	quadgram ||| quadgram	count=1
module	this corpus view ||| corpus reader	count=4
function	chunks represented in tree ||| chunks	count=1
class	use repp to ||| repp	count=1
arg	from ||| n_ii	count=1
class	[class_1] matrix from ||| [class_2] [class_1]	count=1
arg	'self' ||| other bindings	count=1
function	create a lexical translation ||| init	count=1
class	a single [class_2] ||| [class_1] [class_2]	count=1
class	text returns ||| punkt sentence	count=1
function	create a new ||| create	count=1
function	from ||| from	count=2
class	element of the ||| descent parser	count=1
arg	different subtypes of tree ||| tree	count=1
class	chart rule used to ||| stepping chart	count=1
class	the parent ||| parented tree	count=2
arg	positive_featuresets a list ||| positive_featuresets	count=1
function	variety of information ||| info	count=1
arg	object ||| tokens name	count=1
function_arg	[function_1] [arg_2] ||| [function_1] vectorspace [arg_2]	count=7
class	(corpus_property_key value) ||| childescorpus reader	count=1
function	binding operators to ||| bindops	count=1
function_arg	[function_1] load load ||| [arg_2] [function_1]	count=1
module	configure this widget ||| draw	count=1
arg	fileids that have ||| fileids	count=1
class	must ||| parser app	count=1
function	error ||| parse error	count=1
class	the given corpus ||| corpus	count=1
arg	single instance applying the ||| instance	count=1
class	the given ||| reader	count=1
function	of tagged chunks represented ||| tagged chunks	count=1
class	the end of ||| reduce	count=1
class	[class_1] grammar ||| [class_2] [class_1]	count=1
function	list ||| user	count=1
class	uses to generate ||| based	count=1
function	the grammar used ||| grammar	count=2
arg	csv ||| outfile	count=1
class	out ||| view	count=1
function	fulltextindex xml ||| handle fulltextindex	count=1
class	modify ||| base prover command	count=1
class	corpus file underlying ||| lazy	count=2
arg	the features ||| features	count=1
arg	of text ||| word_tokenizer sent_tokenizer	count=1
class	words ||| corpus reader	count=2
class	[class_1] [class_2] ||| [class_1] [class_2] add	count=8
function	words ||| words	count=11
arg	from the given start ||| start	count=2
arg	try ||| desired_x desired_y	count=1
module	the sequence with ||| tag	count=1
arg	luname ||| ignorekeys luname	count=1
function	probability of [function_2] ||| [function_1] t [function_2]	count=2
class	because the neural dependency ||| stanford neural dependency	count=1
arg	the reading ids ||| threads	count=1
arg	a child of parent ||| parent	count=1
function	about ||| info from id	count=1
function	crosses the truncation line ||| truncation coordinates	count=1
class	build the internal indexes ||| reader	count=1
function	which [function] not referenced ||| [function] most	count=1
function	parse [function_2] ||| [function_2] [function_1]	count=4
function_arg	by a [arg_2] ||| [arg_2] [function_1]	count=1
function	list of entries containing ||| entries	count=1
class	returns a ||| punkt	count=1
function_arg	tree positions [arg_2] ||| [function_1] [arg_2]	count=1
function	return the upper frame ||| get static upper	count=1
function	recommended word tokenizer ||| word	count=1
function	a list ||| list	count=2
function_arg	[function_1] [arg_2] ||| [function_1] conll [arg_2]	count=9
function_arg	[function_1] with_shutdown is ||| [arg_2] [function_1]	count=4
arg	the binary with ||| binary args verbose	count=1
class	as positive examples ||| positive naive bayes classifier	count=1
arg	count ||| count alignment_info i	count=1
class	counts ||| dist	count=1
arg	of tree the ||| tree	count=1
arg	the [arg] this is ||| [arg]	count=1
function	a line of text ||| text	count=1
function	compute the ||| compute	count=1
arg	should ||| index	count=1
class	a proper probability ||| simple good turing prob	count=1
arg	bayes classifier on 10000 ||| trainer n_instances output	count=1
function	save a [function_2] ||| [function_1] [function_2]	count=4
module	called if ||| sem	count=1
class	the punkt word ||| punkt	count=1
class	given a text returns ||| punkt sentence tokenizer	count=1
function	of the hierarchical children ||| child widgets	count=1
module_class	widget [class_2] ||| [module_1] [class_2]	count=4
function	a userid ||| by userid	count=1
class	element of ||| parser	count=1
function	for the data ||| get	count=1
class	previous ||| alignment info	count=1
class	state ||| model tagger	count=2
function	sentence and ||| of fes	count=1
function	an information content ||| ic	count=2
class	:param ||| command decorator	count=2
class	the sentence string ||| chart	count=1
class	as ||| assoc measures	count=1
function	nodes [function] the given ||| [function]	count=3
arg	alignment_infos ||| alignment_infos	count=1
class	a bigram collocation ||| trigram collocation	count=1
function	redirects arcs to any ||| redirect arcs	count=1
class	remaining text ||| reduce parser	count=1
class	to figure out ||| view	count=1
function	label_* to configure ||| configure	count=1
class	path pointer pointing ||| file path pointer	count=1
class	as positive examples ||| positive naive bayes	count=1
function	python 2 ||| python 2	count=1
function	into the cyrillic ||| cyrillic	count=1
class	of ||| reduce	count=2
function	of features each feature ||| features	count=1
function	parser's current state represents ||| currently	count=1
function	abstractvariableexpression ||| variable	count=1
class	for this encoding ||| typed maxent feature encoding	count=1
class	corpus view ||| nombank corpus	count=1
class	positive examples ||| naive bayes	count=1
class	position ||| alignment info	count=1
class	file underlying ||| lazy sequence	count=1
class	return all ||| lexicon corpus	count=1
arg	index the index of ||| index	count=1
arg	tree string and ||| cls s	count=2
arg	id luname frameid ||| fn_luid ignorekeys luname frameid	count=1
function	the fringe of ||| fringe	count=1
arg	utterance identifiers for all ||| sex spkrid sent_type	count=1
function_arg	:param context_to_tag a ||| init context_to_tag backoff	count=1
function	[function] in the ||| [function]	count=1
module	alphabetical order ||| corpus	count=1
arg	the sole training text ||| verbose	count=1
arg	one [arg] each ||| cls starts [arg]	count=1
module	is a factory method ||| sem	count=1
module	token ||| parse	count=1
class	the probability of a ||| parser	count=1
arg	a [arg] canvas ||| index [arg]	count=2
class	xml element in ||| reader	count=1
class	probability ||| model tagger	count=3
arg	[arg_1] is ||| [arg_2] [arg_1]	count=5
function	suffix-removal rule to the ||| apply rule	count=1
function_arg	pointer lists [arg_2] ||| [function_1] [arg_2]	count=1
function	the node ||| tgrep node	count=1
class	is a substitution corresponding ||| ccgvar	count=1
class	:param ||| model builder command decorator	count=1
class	using the punkt ||| punkt	count=1
arg	or the list of ||| fileids sent	count=1
function	a ||| variable	count=2
function	instantiates ||| variable expression	count=1
class	variable ||| variable	count=1
function	delete ||| delitem	count=1
arg	into a list of ||| read	count=1
function	parse a string ||| parse	count=1
function	right-hand side ||| rhs	count=2
class	supported languages ||| crubadan	count=1
class	annotation set [class] ||| framenet [class]	count=1
function	sentences matching the ||| sents	count=1
function_arg	[function_1] location ||| [arg_2] [function_1]	count=4
class	minimal set ||| minimal set	count=1
class	block ||| tiling tokenizer	count=1
class	[class] structure ||| [class] struct	count=1
function	data file for ||| data file	count=1
class	[class_1] rule ||| [class_2] [class_1]	count=2
class	list of ||| crubadan corpus reader	count=1
class	of supported languages ||| corpus	count=1
module	over this ||| core	count=1
module	in particular if ||| parse	count=1
class	element ||| stepping	count=1
class	mapping each context ||| context index	count=1
class	list of supported languages ||| crubadan corpus reader	count=1
class	alphabetical ||| corpus reader	count=1
class	must be ||| app	count=2
class	instance's predicate ||| nombank instance	count=1
arg	[arg] corpus that ||| [arg]	count=2
arg	list ||| category fileids	count=1
class	with ||| edge i	count=1
function	1a from ||| step1a	count=1
function	pretty-printing a list ||| pretty	count=2
function	factory method that ||| variable expression	count=1
class	as in manning and ||| measures	count=1
function_arg	[function_1] filename ||| [function_1] resource_url [arg_2]	count=1
arg	the binary ||| binary args verbose	count=1
arg	a word ||| word	count=5
arg	expression to ||| expression	count=1
arg	one [arg] corpus ||| [arg]	count=2
class	:see ||| negated expression	count=1
class	must be called if ||| chart parser	count=1
arg	[arg_1] version of ||| [arg_2] [arg_1]	count=3
class	[class_1] [class_2] cumulative displaying the most ||| [class_1] [class_2] tabulate	count=4
class	languages as iso ||| crubadan corpus	count=1
function	the windowdiff score ||| windowdiff	count=1
class	move ||| parser	count=1
function	demonstration of the ||| malt demo	count=1
arg	train and ||| trainer save_analyzer	count=1
class	all parses [class_2] ||| [class_1] [class_2]	count=8
function_arg	tweets by [arg_2] ||| [arg_2] [function_1]	count=1
class	to ||| reduce	count=1
function_arg	average of function ||| average function	count=2
arg	the highest information content ||| synset1 synset2 ic verbose	count=1
class	of the remaining text ||| reduce	count=1
function	leaf ||| leaves	count=1
class	boundary detector or ||| punkt	count=1
function_arg	[function_1] [arg_2] takes into account partial ||| metrics masi [function_1] [arg_2]	count=1
function	adjust ||| adjust	count=1
function	compiles and ||| re	count=2
class	words for the ||| swadesh corpus	count=1
module	list of supported ||| reader	count=1
arg	the list of ||| fileids	count=1
class	the frequency [class_2] ||| [class_1] [class_2] tabulate	count=1
function	abbreviation or ||| reclassify abbrev	count=1
class	in ||| opinion lexicon	count=1
function	rule and rule format("verbose")) ||| rule	count=1
class	path pointer pointing at ||| file path pointer	count=1
arg	:param positive_featuresets a list ||| positive_featuresets	count=1
function_arg	[function_1] the cluster ||| [function_1] vector [arg_2]	count=1
arg	from a word-aligned ||| srctext	count=1
class	ngram [class] pairs ||| [class]	count=1
function	[function] consisting of ||| ne chunk [function]	count=1
class	[class] edges that ||| [class]	count=2
function	is of chomsky ||| is chomsky	count=3
function	sequence yields each ||| sequence	count=1
class	remaining text ||| reduce	count=1
module_class	:return the document that [module_1] [class_2] ||| [module_1] [class_2]	count=2
function	the configure ||| configure	count=1
function_arg	[function_1] with other ||| [function_1] [arg_2]	count=2
module	some full [module] in ||| [module]	count=1
class	words for the ||| swadesh corpus reader	count=1
function	six [function_2] ||| [function_2] [function_1]	count=16
arg	set of augmented tokens ||| tokens	count=1
class	first element of ||| recursive	count=1
arg	labels ||| labels	count=2
function	tgrep search ||| tgrep	count=2
arg	luname [arg_2] ||| [arg_2] [arg_1]	count=4
class	tree should ||| chart view	count=1
class	identifiers ||| categorized	count=1
arg	and q [arg_2] ||| [arg_2] [arg_1]	count=1
arg	match the given ||| search_leaves	count=2
function	to ||| setitem	count=1
module	pickle ||| corpus reader	count=1
function	synset relations [function_2] ||| [function_2] [function_1]	count=3
function	number of words ||| num	count=1
function	either a number or ||| non punct	count=1
class	corpus ||| twitter corpus reader	count=1
function	convert a userid to ||| userid	count=1
class	graph ||| graph	count=2
function	previously bound node label ||| node label	count=1
function	[function_1] category ||| [function_2] [function_1]	count=5
class	:return a corpus view ||| nombank corpus reader	count=1
class	text returns ||| punkt sentence tokenizer	count=1
arg	refs ||| refs	count=1
class	end of ||| shift reduce	count=1
class	the punkt ||| punkt	count=1
class	end of ||| stepping shift reduce	count=1
arg	distance of each ||| distance	count=1
arg	positive_featuresets a list of ||| positive_featuresets unlabeled_featuresets	count=1
function	projective dependency ||| projective rule parse	count=1
function	right [function_2] ||| [function_1] [function_2]	count=1
module	iso ||| reader	count=1
arg	v this ||| v	count=1
function	primitive is ||| primitive	count=1
function	subtype of abstractvariableexpression appropriate ||| variable expression	count=1
function	realign ||| realign	count=1
arg	segmentations a segmentation ||| hyp k boundary	count=3
function	returns the number ||| num	count=1
function	_readings to construct a ||| construct	count=1
arg	the input text ||| text	count=1
class	of the remaining ||| stepping shift	count=1
function	left corner ||| leftcorner parents	count=1
function	[function] for ||| reducible [function]	count=3
class	sequence with the ||| markov model tagger	count=1
function	step 1a from ||| step1a	count=1
function_arg	[function_1] [arg_2] variable ||| [function_1] [arg_2]	count=1
function_arg	ending step word ||| end w5 word	count=1
arg	[arg_1] bytes to ||| [arg_1] [arg_2]	count=2
arg	return ||| other verbose	count=3
class	this instance's ||| nombank	count=1
arg	in the given zipfile ||| zipfile	count=1
function	returns the distance of ||| distance	count=1
arg	rule data tables ||| rule	count=1
function	to the present ||| extract	count=1
module_class	[module_1] [class_2] including ||| [module_1] [class_2] tags	count=4
module	for the [module] a single ||| [module]	count=1
function	contingency table ||| contingency	count=1
function	apply self classify() ||| classify many	count=2
function	a variety of information ||| id	count=1
function	chunkstr, ||| notrace	count=1
arg	root directory ||| root	count=5
class	sequence with the ||| model tagger	count=1
function	returns the euclidean ||| euclidean	count=1
class	frontier in particular if ||| stepping	count=1
function	condition *d from the ||| ends double consonant	count=1
function	a binding to ||| bind to columns	count=2
class	inside probabilities ||| inside chart	count=1
function	overall score of ||| score	count=1
arg	forward ||| forward	count=2
class	much of the ||| edge	count=1
function	the best alignment ||| best model2 alignment	count=1
function	words and punctuation ||| words	count=1
class	contents of the given ||| category	count=1
module	supported ||| corpus reader	count=2
class	frequency distribution in ||| good turing prob dist	count=1
function	of the table's ||| table	count=1
arg	given file s as ||| fileids c5 strip_space	count=2
class	in particular ||| stepping recursive descent	count=1
class	token ||| stepping shift reduce	count=1
class	tagger to [class_2] ||| [class_2] [class_1]	count=4
function	input file ||| file	count=2
arg	apply ||| chunk_struct trace	count=1
function	height ||| height	count=3
arg	pairs generated by ||| pairs window trace	count=1
arg	of augmented tokens ||| tokens	count=1
class	tweets as as a ||| twitter corpus	count=1
function	function generates the ||| generate	count=1
function	upper frame page if ||| get static upper page	count=1
class	:type ||| resolution prover	count=1
class	function must ||| demo	count=1
class	by [class_2] ||| [class_2] [class_1] apply everywhere chart grammar	count=5
module	corpus view ||| corpus	count=4
function	tree ||| tree	count=2
function_arg	[function_1] false otherwise ||| [function_1] [arg_2]	count=3
function	logged values returning ||| log add	count=1
class	for this corpus ||| category corpus	count=1
class	all tree ||| tree	count=2
class	this pointer ||| pointer	count=1
arg	the earley parsers ||| print_times print_grammar print_trees trace	count=1
function	function to indent ||| indent	count=1
arg	takes a word ||| word	count=1
arg	of rows and ||| rows cols	count=1
arg	:param show ||| show	count=1
class	tuple made ||| reviews	count=1
arg	positions where it ||| positions	count=1
class	will only succeed ||| immutable tree	count=1
function	subtype of abstractvariableexpression ||| variable	count=1
arg	:param positive_featuresets a list ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
class	the end of the ||| shift reduce	count=1
arg	rhs ||| rhs	count=1
function	the block [function_2] ||| [function_1] [function_2]	count=2
class	in ||| stepping recursive	count=1
arg	used to implement the ||| fileid unit bracket_sent	count=1
function	a valuation file ||| valuation	count=1
function	child pointer ||| child pointer	count=2
arg	[arg] chart ||| [arg]	count=1
arg	used to implement ||| bracket_sent tag strip_space	count=1
arg	the given fileids ||| fileids	count=2
arg	python port of ||| tokens return_str	count=1
class	a german ||| german	count=1
module	this corpus ||| corpus reader	count=5
function	expression to prove ||| prove	count=1
function	appropriate for ||| expression	count=1
class	this canvas [class] and all ||| canvas [class]	count=1
function	expression for word ||| word	count=1
function	info from the fulltextindex ||| fulltextindex elt	count=1
function	of defaultdict dict s ||| defaultdict	count=1
function	a list ||| info from id	count=1
class	list of ||| corpus reader	count=1
class	rule ||| rule	count=9
class	path pointer ||| path pointer	count=5
class	tree should ||| view	count=1
class	words ||| semcor corpus reader	count=1
module	move a ||| parse	count=1
class	this function must ||| drt glue demo	count=1
module	a single corpus using ||| corpus reader	count=1
function_arg	[function_1] the distance ||| [function_1] [arg_2]	count=3
arg	refs list [arg_2] ||| [arg_2] [arg_1]	count=2
function	containing the names of ||| names	count=1
function	friendly error ||| error	count=1
class	grammar ||| feature grammar	count=1
function	convert a list of ||| user info from	count=1
arg	with fstruct2, ||| fstruct2 bindings trace	count=1
module	be called if ||| sem	count=1
arg	highest information content ||| ic verbose	count=1
arg	tokens [arg_2] ||| [arg_1] [arg_2]	count=1
class	first token in a ||| tokenizer	count=1
function	tags ||| tag	count=1
function_arg	[function_1] boundaries ||| [function_1] [arg_2]	count=1
function	fulltextindex xml ||| fulltextindex elt	count=1
function	the given ||| in range	count=1
arg	reference that ||| references	count=1
function	tagger ||| tagger	count=1
function	generates the sentences ||| sentences from	count=3
function	given the ||| given s	count=2
class	element of the ||| recursive	count=1
class	as sentence breaks yielding ||| sentence	count=1
class	out how big a ||| view	count=1
function	dictionary of ||| make predicate dict	count=1
function_arg	[function_1] child ||| [arg_2] [function_1]	count=1
function	next field in ||| raw fields	count=1
class	size of the fixed-length [class_1] [class_2] ||| [class_1] [class_2]	count=1
function_arg	table [arg_2] ||| [arg_2] [function_1]	count=1
arg	the reference that ||| references	count=1
module	a list of ||| corpus reader	count=1
function	similarity score ||| similarity	count=1
function	url for the data ||| get url	count=1
class	the internal indexes to ||| framenet	count=1
module	the text widget ||| draw	count=1
function	string containing a ||| format	count=1
class	sequence ||| markov model	count=2
class	corpus view that ||| nombank corpus	count=1
class	[class_1] boundary ||| [class_2] [class_1]	count=8
function	change the text ||| set	count=1
class	corpus view [class_2] ||| [class_2] corpus [class_1]	count=1
function	score for a ||| score ngram	count=2
function_arg	[function_1] the trees ||| [arg_2] [function_1]	count=6
arg	return a string containing ||| vnframe	count=1
module	build ||| reader	count=1
class	if ||| stepping	count=1
class	given a ngramassocmeasures class ||| contingency measures	count=1
function	best incoming arc ||| best incoming arc	count=2
arg	cover ||| constituents	count=1
class	the end ||| shift	count=1
class	[class] the ||| [class]	count=4
function	returns a subtype of ||| variable	count=1
function	a demo showing the ||| prob parse demo	count=1
function	a ||| user info from	count=2
class	a french ||| french stemmer	count=1
class	invalidate the cached ||| freq	count=1
function	returns the node label ||| node label	count=1
module	indexes to ||| corpus reader	count=1
class	be called ||| chart parser	count=1
class	the first ||| descent parser	count=1
module	for the given ||| corpus reader	count=1
module	method and return ||| core	count=1
arg	bracketed [arg_2] ||| [arg_2] [arg_1]	count=4
class	token from the ||| stepping	count=1
function	the most recent edge ||| current chartrule	count=1
arg	ngram is in the ||| ngram	count=1
function	of information ||| user info from	count=1
function	edge's left-hand side ||| lhs	count=1
arg	[arg_1] which match ||| [arg_1] [arg_2]	count=3
class	characters ||| seekable unicode stream reader	count=2
arg	j of the target ||| j	count=1
class	frontier ||| recursive descent	count=1
arg	version of ||| prefix depth	count=1
class	inside probabilities of ||| inside	count=1
function	a rare abbreviation ||| rare abbrev	count=2
module	the corresponding full tweets ||| twitter	count=1
class	in alphabetical order ||| lexicon corpus	count=1
class	parsing a ||| chart parser	count=1
function	a factory method ||| expression	count=1
class	for the current ||| lin thesaurus corpus reader	count=1
class	a dictionary containing the ||| dictionary conditional prob	count=1
class	return all [class_2] ||| [class_1] [class_2]	count=4
arg	or the list of ||| fileids	count=1
class	the end ||| stepping	count=1
class	particular ||| stepping recursive descent parser	count=1
class	by this classifier ||| classifier	count=1
arg	[arg_1] tag tuples ||| [arg_2] [arg_1]	count=4
function	[function_1] sets ||| [function_2] [function_1]	count=1
function	-- i e a ||| mro	count=1
function	to the present ||| extract features	count=1
class	not the given ||| corpus reader	count=1
function_arg	pointer lists [arg_2] ||| [arg_2] [function_1]	count=1
arg	translating the ||| hypothesis future_score_table sentence_length	count=1
function	of ||| user info from id	count=2
function	best alignment ||| best model2 alignment	count=1
function	load ||| load	count=3
class	should be generated when ||| bottom up probabilistic	count=1
class	tags the sequence with ||| model tagger	count=1
class	languages as iso 639-3 ||| corpus	count=1
function	a variety of ||| from id	count=1
arg	separate the string ||| string	count=1
class	to the end of ||| stepping shift reduce parser	count=1
arg	the target ||| target	count=1
class	remaining ||| stepping shift	count=1
arg	show ||| show	count=1
function	speech [function_2] ||| [function_1] [function_2]	count=2
function	is run [function] within ||| import [function]	count=1
class	bigram using the ||| bigram collocation	count=1
class	enter the ||| drt glue demo	count=1
function	the log [function_2] ||| [function_1] [function_2]	count=1
arg	colors ||| linecolor textcolor	count=1
arg	[arg_1] relation ||| [arg_2] [arg_1]	count=3
class	the text contents of ||| senseval corpus	count=1
class	a unit needs to ||| view	count=1
class	corpus ||| twitter corpus	count=1
arg	opening a subprocess that ||| cmd classpath stdin stdout	count=1
module	corpus view that is ||| corpus reader	count=4
class	enter the ||| app	count=2
class	when parsing a text ||| descent parser	count=1
class	build the internal indexes ||| framenet corpus reader	count=1
class	unit needs to ||| view	count=1
function	_sentences to construct ||| construct readings	count=1
function	[function_1] checksum for ||| [function_1] [function_2]	count=1
function	various methods ||| drt discourse	count=1
arg	boxer_drs_interpreter a class that ||| boxer_drs_interpreter	count=1
function	[function_1] clusters ||| [function_1] [function_2]	count=3
function_arg	[function_1] a given ||| [arg_2] [function_1]	count=1
function	train a new conditionalexponentialclassifier, ||| train	count=1
class	of this rule ||| rule with context	count=1
function	the average log likelihood ||| log likelihood	count=1
function	a list of ||| info from	count=1
class	identifiers ||| ycoecorpus	count=1
class	returns a ||| punkt sentence	count=1
arg	a bracketed tree string ||| s brackets read_node	count=1
function	parse the current contents ||| parse	count=1
arg	threshold as well as ||| fdist threshold	count=1
class	state sequence this ||| markov model	count=1
function	length six ||| w6	count=1
class	minimal set having the ||| minimal set	count=1
arg	generate freqdist ||| freqdist gamma	count=1
function	be overridden ||| get all symbols	count=1
function	build ||| build	count=2
function	given a ||| from documents	count=1
function	returns a list ||| list	count=1
arg	input ||| assumptions timeout prover	count=1
class	to to every feature ||| feat	count=1
function	to the list ||| add	count=1
arg	bncwordviews or the list ||| fileids	count=1
class	of the hypothesized ||| edge	count=1
class	frontier in ||| parser	count=1
class	the frontier in particular ||| stepping recursive descent	count=1
arg	list ||| fileids sent tag strip_space	count=1
class	element of the frontier ||| recursive	count=1
arg	file s as ||| fileids tagset	count=2
arg	and ||| stem	count=3
class	this function ||| glue demo	count=1
class	model ||| command decorator	count=1
function	[function_1] pointer ||| [function_2] [function_1]	count=4
function	curve ||| curve	count=1
arg	appearances of words bigrams ||| word_fd	count=1
class	stack ||| shift reduce	count=2
function	a tgrep ||| tgrep	count=2
function	[function_1] root ||| [function_1] [function_2]	count=1
class	to the end ||| stepping shift reduce parser	count=1
class	the frontier ||| recursive descent parser	count=1
arg	xml file ||| fileid tagspec	count=2
arg	initialize the multi-word tokenizer ||| mwes separator	count=1
arg	[arg_1] pattern ||| [arg_2] [arg_1]	count=9
function	frames that contain lus ||| frames	count=1
module	order ||| corpus	count=1
class	unit ||| chart view	count=1
class	with the ||| i	count=1
function	the hole that will ||| hole	count=1
arg	a given ||| node ancestors	count=1
arg	presence/absence in the document ||| document	count=2
arg	to invalidate the cached ||| key	count=1
class	reader using data ||| reader	count=1
function	representing [function_2] ||| [function_1] parse [function_2]	count=1
module	is the ||| translate	count=1
class	parses that ||| descent parser	count=2
class	wordnet corpus [class_2] ||| [class_1] [class_2]	count=4
arg	n-gram f-score described in ||| reference hypothesis min_len max_len	count=1
arg	[arg_1] q for ||| [arg_2] [arg_1]	count=1
module	a token ||| parse	count=1
arg	precedes [arg] ||| [arg]	count=1
function	[function_1] comparison method ||| [function_2] [function_1]	count=1
function	contains a ||| contains	count=4
arg	predicate ||| predicate signature	count=1
class	perl unicode properties ||| unichars corpus	count=1
class	chart ||| stepping chart	count=3
function	is informative ||| informative	count=1
arg	word tag ||| c5 strip_space stem	count=1
class	a substitution ||| ccgvar	count=1
class	a new maxent ||| maxent	count=1
class	feature encoding based ||| backed maxent feature encoding	count=1
arg	source-to-target and ||| trglen e2f	count=1
class	that ||| nonprojective parser	count=2
function	of chomsky normal ||| chomsky normal	count=2
class	cached ||| freq	count=1
function	returns the log probability ||| log prob	count=1
arg	sequence with the highest ||| unlabeled_sequence	count=1
function	euclidean [function_2] ||| [function_2] [function_1]	count=1
class	the sequence ||| markov model tagger	count=1
function	exists to be overridden ||| get all symbols	count=1
class	text to the end ||| reduce parser	count=1
arg	"gold standard" [arg] alignment ||| [arg] hypothesis	count=1
module	[module] a ||| [module]	count=23
function	probability ||| tag	count=1
function	tagged [function] consisting of ||| ne chunk [function]	count=1
function	invalidate ||| setitem	count=1
arg	a word using ||| word	count=1
class	corpus or ||| timit corpus	count=1
arg	should be [arg_2] ||| [arg_2] [arg_1]	count=1
arg	threshold as well as ||| threshold	count=1
function_arg	evaluate and [arg_2] ||| [function_1] [arg_2]	count=2
function	trigrams generated from a ||| trigrams	count=1
function	right-hand side length ||| len	count=2
function	all the lemma objects ||| lemmas	count=1
function_arg	average [arg_2] ||| [arg_2] [function_1]	count=3
function	the fringe ||| fringe	count=1
arg	string ||| s chunk_types	count=1
class	representation for this alignedsent ||| aligned sent	count=1
class	must ||| app	count=2
class	called ||| drt glue demo	count=1
class	called ||| regexp chunk	count=1
class	tags the sequence with ||| tagger	count=1
class	this ||| glue demo	count=1
function	a string representation of ||| repr	count=2
arg	train_text can ||| train_text	count=1
function	of bigram [function_2] ||| [function_2] [function_1]	count=3
function	this is a factory ||| expression	count=1
arg	for ||| winlens	count=1
arg	file identifiers for ||| filetype	count=1
arg	given text ||| text	count=1
arg	is ||| ref	count=1
function_arg	[function_1] [arg_2] them using this reader's ||| [function_1] [arg_2]	count=4
arg	the left-hand side ||| lhs	count=2
class	this decision tree ||| decision tree classifier	count=2
arg	list of fileids ||| fileids	count=1
function	to this ||| parse	count=1
function_arg	mapping dictionary [arg_2] ||| [function_1] [arg_2]	count=1
class	for the [class_2] ||| [class_2] [class_1] encoding file	count=3
module	a variety of information ||| twitter	count=1
function	discoursetester ||| drt discourse demo	count=1
arg	reading ids in that ||| threads	count=1
function	macro name used ||| macro use	count=2
function	text generates ||| from	count=1
class	uses to ||| based	count=2
arg	all_phrases_from ||| all_phrases_from hypothesis	count=1
arg	source-to-target ||| srclen trglen e2f	count=1
class	creating defaultdict ||| lin thesaurus	count=1
function	any ||| freeze	count=1
function_arg	data for [arg_2] ||| [arg_2] [function_1]	count=3
class	for this encoding ||| encoding	count=2
arg	file s as a ||| fileids speaker stem relation	count=1
function	first pass of annotation ||| first pass	count=1
arg	fstruct1 [arg_2] ||| [arg_1] [arg_2]	count=2
function	plot the given ||| plot	count=1
class	this function must ||| chart parser	count=1
class	the hypothesized structure is ||| edge	count=1
class	initial tagger ||| tagger	count=1
arg	of rows and columns ||| rows cols attempts	count=1
function_arg	tagged words [arg_2] ||| [function_1] [arg_2]	count=5
class	the expression ||| lambda expression	count=1
function_arg	a custom [arg_2] ||| [function_1] lemmas [arg_2]	count=3
function	parameters to the present ||| extract features	count=1
class	of supported languages as ||| corpus	count=1
module	this instance's ||| corpus reader	count=1
arg	given synset and ||| synset	count=1
function	subtype of ||| expression	count=1
function	the training ||| train	count=1
arg	a list of tokens ||| tokens tags	count=1
function	'key' there ||| unique	count=1
function	self _readings to construct ||| construct	count=1
function_arg	[function_1] consideration given ||| [function_1] [arg_2]	count=1
class	the corpus ||| categorized sentences corpus reader	count=2
arg	refs [arg_2] ||| [arg_2] [arg_1]	count=4
function	returns the distance ||| distance	count=1
arg	save_classifier ||| save_classifier	count=1
function	xml index ||| index	count=1
function	on its relation to ||| tgrep relation	count=1
arg	[arg] leave the ||| [arg] block_size	count=2
arg	[arg_1] be ||| [arg_2] [arg_1]	count=2
arg	string ||| format	count=1
function	[function_1] abbreviation ||| [function_2] [function_1]	count=2
function	a uniform ||| set uniform	count=1
function	determine ||| one	count=1
class	state ||| hidden	count=1
class	of the frontier ||| recursive descent	count=1
function	entities ||| replace html entities	count=1
module	this function must be ||| draw	count=2
arg	documents ||| documents labeled	count=1
function	the ||| info	count=1
function	bigram [function_2] ||| [function_1] [function_2]	count=3
class	size of the fixed-length [class_1] [class_2] ||| classify [class_1] [class_2]	count=1
class	the internal indexes ||| framenet corpus	count=1
class	of processing ||| handler i	count=1
function	cyrillic alphabet ||| cyrillic	count=1
function	the score for ||| score	count=2
arg	in the base ||| tr	count=1
class	given bigram ||| bigram collocation finder	count=1
class	that have ||| nonprojective parser	count=1
class	this function must be ||| parser	count=1
class	[class] cumulative displaying ||| [class]	count=3
class	big the ||| view	count=1
arg	[arg_1] appearances ||| [arg_2] [arg_1]	count=2
function	disable warnings of data ||| warnings	count=1
function	generates the ||| from	count=1
module_class	this [class_2] ||| [module_1] [class_2] struct	count=1
arg	instances of variable v ||| variable	count=3
class	[class_1] tokenizer ||| [class_1] [class_2]	count=4
class	rule it ||| chunk rule with	count=1
class	probability ||| hidden markov model tagger	count=3
arg	if with_shutdown is ||| with_shutdown	count=1
class	first element of ||| descent	count=1
class	about ||| query	count=1
arg	word tag ||| strip_space stem	count=1
function	an error in ||| error	count=1
function	table ||| create token table	count=1
function	for word [function_2] ||| [function_2] [function_1]	count=1
arg	of tweet ids ||| ids_f	count=1
arg	from a given text ||| text	count=1
function_arg	to a [arg_2] ||| cache [function_1] tempfile cls sequence [arg_2]	count=3
function	set of child ||| child	count=1
function	a rare ||| rare	count=1
class	must be ||| chunk app	count=1
function	learning curve -- ||| demo learning curve	count=1
function_arg	[function_1] match ||| [arg_2] [function_1]	count=1
function	the shortest ||| min	count=1
function	index ||| index	count=3
class	new classifier based on ||| classifier based	count=1
module	the remaining text to ||| parse	count=1
arg	of function results ||| function	count=1
class	from ||| parser	count=1
class	as as ||| corpus reader	count=1
function	[function_1] [function_2] ||| [function_2] [function_1]	count=519
arg	list of lists ||| fileids	count=1
module	tree should be etc ||| app	count=1
class	[class_1] set having ||| [class_2] [class_1]	count=4
function	best rule this is ||| best rule	count=1
function	best rule this ||| best rule	count=1
function	list of the indices ||| indices	count=1
arg	expression the expression to ||| expression command x y	count=1
class	to map from contexts ||| context	count=1
class	corpus reader for ||| corpus reader	count=6
function	for megam based ||| megam	count=1
function	previous ||| previous	count=2
arg	from ||| srctext trgtext alignment	count=1
arg	tree cls ||| cls tree	count=1
arg	file s ||| fileids tagset	count=2
class	words ||| childescorpus reader	count=1
class	parsing a ||| descent parser	count=2
class	punkt word segmentation ||| punkt	count=1
function	number of clusters ||| num clusters	count=2
function	[function_1] chomsky ||| [function_2] [function_1]	count=1
arg	model typically ||| encoding weights logarithmic	count=1
arg	marker file for sequential ||| sfm_file	count=1
class	of all verb ||| verbnet corpus	count=1
arg	luname frameid and ||| fn_luid ignorekeys luname frameid	count=1
function_arg	[function_1] return ||| [function_1] [arg_2]	count=9
function	the type ||| type	count=3
function	classified ||| write	count=2
arg	callback that will ||| callback	count=1
function	that *rule* applies ||| rule applies	count=1
class	remaining text to ||| parser	count=1
function	list of plausible semtypes ||| get semtypes	count=1
class	substitution corresponding to this ||| ccgvar	count=1
function_arg	a new [arg_2] ||| [function_1] [arg_2]	count=1
class	:param ||| mace command	count=1
class	pickled model weights ||| averaged perceptron	count=4
class	a distribution ||| dist	count=1
class	of a [class_2] ||| [class_2] [class_1]	count=8
arg	a word with ||| word	count=1
arg	list of ||| fileids sent	count=1
function	sequence ||| sequence	count=1
function_arg	words [arg_2] ||| [function_1] [arg_2]	count=5
function	tree :return the tree ||| to tree	count=1
class	state sequence this ||| hidden markov model	count=1
arg	multi-word tokenizer with a ||| mwes separator	count=1
module	value [module] an ||| corpus [module]	count=1
arg	[arg] still corresponds ||| [arg]	count=3
module_class	[module_1] [class_2] including ||| [module_1] [class_2]	count=4
class	in ||| corpus	count=1
module	name ||| reader	count=1
arg	return a score ||| other	count=4
function_arg	fileids that [arg_2] ||| [arg_2] [function_1]	count=1
arg	of word tag ||| speaker stem	count=1
class	chart ||| stepping chart parser	count=2
arg	divide a string of ||| s chunk_label root_label sep	count=1
arg	given length this ||| length	count=1
module_class	tweets [class_2] ||| [module_1] twitter [class_2]	count=3
arg	a synset note ||| word synset	count=1
function	convert a ||| user info from	count=1
function	meaning ||| get meaning	count=1
class	canvas ||| canvas	count=10
function_arg	each [arg_2] ||| [function_1] s [arg_2]	count=1
arg	of tree ||| tree	count=2
function_arg	reduce stack ||| reduce stack	count=1
arg	boxer_drs_interpreter ||| boxer_drs_interpreter	count=1
class	the internal indexes ||| framenet	count=1
class	file [class_2] ||| [class_2] [class_1]	count=4
function	unigram [function_2] ||| [function_2] [function_1]	count=3
function	the various methods of ||| drt discourse	count=1
function	is obtained by deleting ||| remove variables	count=1
class	needs to be ||| chart	count=1
function	dendrogram ||| dendrogram	count=1
function	to construct ||| construct readings	count=1
function	incoming ||| incoming	count=1
arg	of 'self' ||| other bindings	count=1
class	confusion matrix from ||| confusion matrix	count=2
arg	given file s ||| fileids c5	count=2
arg	the tuple representation of ||| tagged_token	count=1
arg	list of ||| fileids tagset	count=1
function	nodes in the ||| nodes	count=1
function_arg	pointer [arg_2] ||| [arg_2] [function_1]	count=3
function	a demonstration showing the ||| parse demo	count=1
arg	by stems defined by ||| cutlength	count=1
class	a spanish ||| spanish	count=1
function	a factory method that ||| variable expression	count=1
class	this rule it has ||| chunk rule with	count=1
function	the various methods of ||| drt	count=1
class	first element of ||| recursive descent parser	count=1
function	[function_1] file for ||| [function_2] [function_1]	count=3
class	the module ||| module	count=1
class	must be called if ||| drt glue demo	count=1
class	new classifier [class_2] ||| [class_1] [class_2]	count=3
class	corpus ||| categorized corpus reader	count=1
function	state sequence ||| tag	count=1
function	dictionary of unigram ||| extract unigram	count=1
function	replace every instance ||| replace	count=1
arg	a featureset [arg_2] ||| [arg_1] [arg_2]	count=4
function_arg	pointer of [arg_2] ||| [function_1] [arg_2]	count=4
class	a corpus view ||| corpus reader	count=2
arg	database ||| dbname verbose	count=1
class	feature with the ||| feat	count=4
function	a meaning ||| meaning	count=1
function	set of all conditions ||| conditions	count=1
function_arg	[function_1] location ||| [function_1] [arg_2]	count=4
module	tags the sequence with ||| tag	count=1
function	is beginning ||| is	count=1
class	probability state sequence this ||| hidden	count=1
module	helper function given ||| corpus	count=1
function	modifiers is listed ||| arity parse	count=1
class	context to the ||| context	count=1
arg	level chrf character [arg_1] [arg_2] ||| chrf list_of_references hypotheses [arg_1] [arg_2]	count=4
arg	[arg_1] label ||| [arg_1] [arg_2]	count=3
function	function generates ||| generate	count=1
arg	input ||| assumptions timeout	count=1
arg	to the input ||| input encoding	count=1
class	the sequence ||| markov model	count=1
function	a valuation ||| valuation	count=2
module	which indicates how much ||| parse	count=1
function	a userid to a ||| by userid demo	count=1
class	set having the ||| set	count=1
function	a [function] of ||| [function]	count=2
arg	assumptions ||| goal assumptions	count=1
function	relation to other ||| tgrep relation	count=1
class	of ||| crubadan corpus reader	count=1
function	tgrep search string ||| tgrep	count=2
class	the given language ||| corpus reader	count=1
function	each element ||| sents	count=2
module	structure is consistent ||| parse	count=1
class	dependencygrammar ||| dependency grammar	count=3
arg	located at [arg_2] ||| [arg_2] [arg_1]	count=2
arg	head_address to the node ||| head_address	count=1
arg	the matched substrings ||| string left right	count=1
arg	expression to ||| expression command	count=1
function	[function_1] the first ||| [function_1] [function_2]	count=1
arg	pretty-printed version of ||| width prefix depth	count=2
arg	add more [arg] to ||| [arg]	count=1
function	of the columns ||| column	count=1
function	of abstractvariableexpression appropriate ||| variable expression	count=1
arg	with other ||| other	count=3
function	to truncation errt ||| errt	count=1
class	end of ||| stepping	count=1
function	template sets in ||| template sets	count=1
function	parse a ||| parse	count=3
function	average log likelihood of ||| log likelihood	count=1
class	of the frontier in ||| stepping recursive	count=1
function_arg	edge [arg_2] ||| [function_1] [arg_2]	count=1
class	the ||| demo	count=1
function_arg	new [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] tree [arg_2]	count=1
arg	show all neg ||| show	count=1
class	discourse or of a ||| discourse tester	count=1
function	of synsets ||| synsets	count=1
function	returns the euclidean distance ||| euclidean distance	count=1
class	must ||| chart parser	count=1
function	is in the ||| in	count=1
class	frequency ||| freq dist	count=2
class	of the predicate ||| propbank instance	count=1
function	a subcorpus of ||| handle lusentence	count=1
function	the fulltextindex ||| fulltextindex	count=1
function	various methods of ||| drt discourse	count=1
arg	a bracketed [arg_2] ||| [arg_2] [arg_1]	count=4
class	a single ||| tn	count=1
function	data file for the ||| data file	count=1
class	called if ||| regexp chunk	count=1
arg	generate base_fdist ||| base_fdist	count=1
class	words in ||| opinion lexicon corpus reader	count=1
function	file for the given ||| file	count=1
arg	text :type text list ||| text	count=1
class	logic ||| logic	count=2
arg	frame object name ||| frame frame2	count=1
function_arg	target sentence [arg_2] ||| [function_1] given s [arg_2]	count=2
function	[function] for the ||| [function]	count=2
function	the fraction ||| precision	count=1
function	of tagged tokens ||| tagged	count=1
function	fulltextindex xml ||| fulltextindex	count=1
function	of information about ||| from id	count=1
arg	its forward pointer to ||| forward	count=1
function	[function_1] help ||| [function_2] [function_1]	count=4
class	function must ||| glue	count=1
function	each element of ||| sents	count=1
class	function ||| chunk app	count=1
function_arg	[function_1] cluster ||| [arg_2] [function_1]	count=1
arg	try all possible ways ||| ancestors0 queue potential_labels0	count=1
function	user ||| user	count=1
module	the frontier in ||| parse	count=1
class	return ||| reader	count=2
function	to build a ||| test build	count=1
function_arg	[function_1] feature is ||| [function_1] informative [arg_2]	count=1
class	codes ||| corpus reader	count=1
function	underlying byte ||| tell	count=1
class	a unicode ||| unicode stream	count=1
class	this function must ||| regexp chunk app	count=1
class	[class_1] occurs as ||| [class_2] [class_1]	count=6
arg	highest probability state sequence ||| unlabeled_sequence	count=1
class	tree as ||| tree	count=1
class	wordnet corpus reader ||| word net corpus reader	count=1
class	first element of ||| parser	count=1
function	to [function] ||| [function] by user	count=1
arg	the window_size ||| window_size pad_left	count=1
class	sample outcomes that ||| freq dist	count=1
arg	in the base ||| tr nr	count=1
class	dictionary ||| dictionary	count=1
class	parser and ||| parser	count=1
arg	devset_name the name of ||| devset_name	count=1
function_arg	parse a [arg_2] ||| [arg_2] [function_1]	count=1
class	the frequency distribution in ||| turing prob dist	count=1
class	[class_1] pointer ||| [class_2] [class_1]	count=5
class	element ||| descent	count=1
arg	model distortion [arg] ||| sentence_aligned_corpus iterations [arg]	count=3
function	of an error in ||| error	count=1
class	indexes ||| reader	count=1
function	all roots ||| roots	count=1
class	remaining text to the ||| parser	count=1
function	factory method ||| variable expression	count=1
class	[class_1] this encoding ||| [class_2] [class_1]	count=1
function	appropriate for ||| variable expression	count=1
function	normal [function_2] ||| [function_1] [function_2]	count=2
class	token and return that ||| backoff	count=1
function	list of sentences each ||| sents	count=4
module	to figure out how ||| app	count=1
module	instance's predicate ||| reader	count=1
class	be ||| app	count=2
class	feature encoding based ||| binary maxent feature encoding	count=1
module	twitter ||| twitter	count=4
arg	s as ||| fileids c5 strip_space	count=2
class	function ||| chart	count=1
class	the first element of ||| stepping	count=1
function	a table ||| create token table	count=1
function	[function_1] normal ||| [function_1] [function_2]	count=3
class	must be called ||| chart parser	count=1
class	of this alignedsent ||| aligned	count=1
function	rare abbreviation ||| rare abbrev	count=2
function	a list of ||| user info	count=1
arg	pretty-printed ||| width	count=1
function	with all existing indexes ||| with indexes	count=2
arg	train and test a ||| trainer	count=1
arg	s ||| fileids c5 strip_space	count=2
function	table ||| token table	count=1
function	restore selection & color ||| restore	count=1
arg	[arg] in the ||| [arg]	count=3
arg	of input dependencygraphs ||| graphs	count=1
class	the dependencygrammar ||| dependency grammar	count=1
class	for the specified ||| corpus reader	count=1
module	of ||| reader	count=2
function	induce ||| induce	count=1
module	widget contained by this ||| draw	count=1
function	leacock chodorow [function_2] ||| [function_1] [function_2]	count=1
class	path pointer in bytes ||| path pointer	count=1
arg	s as a list ||| fileids	count=17
class	[class_1] quadgram ||| [class_2] [class_1]	count=2
arg	fileids as a ||| fileids	count=2
class	big a unit needs ||| chart	count=1
class	enter the ||| chart parser app	count=1
class	synset ||| synset	count=8
function_arg	belonging to [arg_2] ||| [function_1] vector [arg_2]	count=1
class	transition dictionary ||| transition	count=1
function	likelihood a float ||| likelihood	count=1
class	corpus view ||| view	count=2
class	the first ||| stepping recursive descent parser	count=1
function	the java binary ||| java	count=1
module	function given ||| corpus	count=1
class	[class_1] reader ||| [class_1] [class_2]	count=6
class	maxent [class_2] ||| [class_2] [class_1]	count=1
function_arg	parse on [arg_2] ||| [function_1] [arg_2]	count=1
class	must be called ||| parser app	count=1
function	url for ||| get url	count=2
class	end ||| reduce	count=1
class	the ||| edge i	count=2
function	the best [function_2] ||| [function_2] [function_1]	count=6
class	consistent with ||| i	count=1
arg	row to the ||| rowvalue	count=1
module	a unit needs ||| app	count=1
function	top-lebel node in ||| tgrep exprs action	count=1
function	various methods of ||| demo	count=2
class	which indicates ||| i	count=1
function	page ||| page	count=3
class	move a token from ||| reduce parser	count=1
module	frontier in ||| parse	count=1
class	of the predicate ||| instance	count=1
module	in alphabetical order ||| corpus	count=1
module	instantiates ||| sem	count=1
arg	optional frame ||| frame	count=1
function	synset ||| synset relation	count=1
function_arg	[function_1] dependencygraph graph ||| [function_1] [arg_2]	count=1
class	the name of ||| instance	count=1
function	the various methods of ||| discourse	count=2
arg	distance of ||| distance simulate_root	count=1
arg	sequence of ||| sequence n	count=1
class	probability state ||| tagger	count=1
class	a given trigram using ||| trigram collocation	count=1
arg	file s ||| fileids c5 strip_space	count=2
class	this corpus or ||| timit corpus reader	count=2
arg	text if finalize ||| text verbose finalize	count=3
function	table's _rows variable match ||| check table	count=1
class	the expression to ||| drt lambda expression	count=1
function	vowel else false ||| vowel	count=1
module	various ||| inference	count=2
function	a ||| from	count=2
arg	ranks1 [arg_2] ||| [arg_1] [arg_2]	count=3
arg	target of its forward ||| forward	count=2
arg	temporary file as ||| delete_on_gc	count=1
class	method serves as ||| drt	count=1
class	probability state sequence ||| hidden markov model	count=1
function	approximate score for ||| future score	count=1
arg	substrings ||| string left	count=1
function	[function_1] first expression ||| [function_2] [function_1]	count=1
class	of this semantics ||| hole semantics	count=1
function	a sequence yields ||| sequence	count=1
class	first ||| descent	count=1
module	returns a subtype ||| sem	count=1
function_arg	apply [arg_2] ||| [function_1] [arg_2]	count=2
module	a unit ||| app	count=1
class	a ||| dependency parser	count=1
function	the right ||| right	count=1
arg	to invalidate the ||| key	count=1
class	[class_1] occurs ||| [class_2] [class_1]	count=6
arg	production ||| production	count=3
function	a new ||| init	count=39
class	log ||| mix in	count=1
function	reader for timit ||| timit	count=1
arg	classify 10000 ||| n_instances output	count=1
arg	the input ||| input encoding	count=1
class	german ||| german stemmer	count=1
class	in the expression ||| lambda expression	count=1
arg	modelbuildercommand modelbuildercommand to ||| modelbuildercommand	count=1
module	corpus view that ||| corpus	count=4
arg	[arg_1] relation type ||| [arg_1] [arg_2]	count=3
module	a factory ||| sem	count=1
function	list of all variables ||| variables	count=1
class	file or ||| file	count=1
arg	a list ||| fileids	count=4
class	collocation finder ||| collocation	count=1
arg	the trees [arg_2] ||| [arg_1] [arg_2]	count=3
arg	the given file s ||| fileids	count=20
arg	hunpos-tag ||| path_to_bin encoding verbose	count=1
function	equal ||| eq	count=2
class	called ||| regexp chunk app	count=1
class	:param ||| abstract variable expression	count=1
function	string representation ||| format	count=3
arg	[arg_1] match ||| [arg_1] [arg_2]	count=3
arg	possible ways ||| ancestors0 queue potential_labels0	count=1
arg	website and open ||| fileid urlbase	count=1
function	tokenize a ||| tokenize	count=1
class	crfsuite ||| crftagger	count=1
function	eval ||| eval	count=1
class	state ||| hidden markov model	count=1
class	the feature ||| feat list	count=1
function	list of tagged tokens ||| tagged	count=1
class	return ||| lexicon	count=1
function	a dictionary ||| dict	count=2
class	pickle corpus ||| pickle corpus	count=1
function	binary ||| binary	count=1
class	generated when parsing a ||| bottom up probabilistic chart parser	count=1
class	spanish ||| spanish stemmer	count=1
class	sequence ||| hidden	count=2
arg	that make up this ||| vnclass_ids	count=1
arg	split the [arg] in half ||| [arg]	count=1
arg	f ||| f	count=1
class	classifier based ||| classifier based	count=1
class	the files ||| reviews corpus	count=1
class	creates an em clusterer ||| emclusterer	count=1
arg	train and test a ||| trainer save_analyzer	count=1
function	internal crubadan ||| to crubadan	count=1
function_arg	normalize the [arg_2] ||| [arg_2] [function_1]	count=1
class	mutable probdist based ||| mutable prob dist	count=1
function	closest ||| closest ref	count=1
arg	expressed as a marginal ||| src_sentence trg_sentence	count=2
module_class	[module_1] list ||| [module_1] lazy iterator [class_2]	count=2
class	cached n ||| freq	count=1
function_arg	[function_1] classifier ||| [function_1] test_set [arg_2]	count=1
class	be called ||| parser app	count=1
class	token ||| stepping	count=1
function	generate an input file ||| file	count=2
class	[class_1] frequency ||| [class_1] [class_2]	count=1
arg	boxer_drs_interpreter a class ||| boxer_drs_interpreter	count=1
arg	limit the ||| limit	count=1
arg	fileid ||| fileid	count=1
arg	resolution order for cls ||| cls	count=1
function	the fraction ||| recall	count=1
class	the remaining text to ||| reduce parser	count=1
arg	positive_featuresets a ||| positive_featuresets	count=1
class	[class_1] given corpus ||| [class_2] [class_1]	count=1
function	initialize this object's ||| init	count=1
module	must be called ||| app	count=2
function	are both ||| eq	count=1
function	training data from ||| train	count=1
class	first element of the ||| recursive	count=1
function	proofs and ||| model	count=1
function	:return whether the word ||| head word	count=1
class	639-3 ||| corpus	count=1
module_class	[module_1] [class_2] ||| [module_1] simple good turing [class_2]	count=1
function	sequence of s-expressions from ||| sexpr block	count=1
arg	segmentations ||| k boundary	count=1
function	add an epytext @field ||| add epytext	count=1
module_class	plaintext [class_2] ||| [module_1] plaintext [class_2]	count=5
class	in this corpus ||| corpus	count=2
arg	a sequence of ||| sequence n	count=1
class	in store [class_2] ||| [class_2] [class_1]	count=2
arg	given item at ||| item x	count=1
class	the name of the ||| nombank instance	count=1
arg	f-score described ||| max_len	count=1
function	to chunk the given ||| chunk	count=2
function	plug the ||| plug	count=1
class	the ||| stepping recursive descent	count=2
function	get synset relations ||| get relations	count=3
function	upon ||| compute	count=1
arg	abstractboxerdrs object hierarchy to ||| elimeq bin_dir verbose	count=1
class	[class_1] stream ||| [class_1] [class_2]	count=4
function_arg	tree [arg_2] ||| [arg_2] [function_1]	count=1
function	userid to a screen ||| lookup by userid	count=1
function	this is a ||| variable	count=1
arg	expression the expression ||| expression command	count=1
class	[class_1] wordnet ||| [class_2] [class_1]	count=2
class	dictionary containing the probdists ||| dictionary conditional	count=1
class	samples ||| good turing prob dist	count=1
arg	segmentations ||| seg1 seg2 k boundary	count=1
class	tags the sequence ||| markov	count=1
class	how much ||| edge	count=1
class	table so that ||| table	count=1
function_arg	adds an [function_1] [arg_2] ||| [function_1] [arg_2] mod_address	count=6
function_arg	[function_1] chart parsers ||| [arg_2] [function_1]	count=2
class	a marker value tuple ||| standard format	count=1
arg	bigrams ||| bigrams	count=1
function	common ||| common	count=1
function	of child [function_2] ||| [function_2] [function_1]	count=5
module	tweets if available ||| twitter	count=1
arg	containing a ||| vnframe indent	count=1
class	store ||| store	count=1
function_arg	[function_1] trees which ||| [arg_2] [function_1]	count=3
class	function must ||| app	count=2
arg	drs drtexpression, the drs ||| drs size_canvas canvas	count=1
class	for the feature ||| feat	count=2
class	the ||| markov	count=2
module_class	aligned [class_2] ||| [module_1] aligned [class_2]	count=5
module	state [module] productions ||| [module]	count=1
class	token ||| reduce	count=1
class	the corpus ||| reviews corpus	count=1
class	swedish ||| swedish stemmer	count=1
class	the ||| drt glue	count=1
arg	the predicate ||| predicate	count=1
arg	remaining_text to the ||| remaining_text	count=1
function	dominating ||| ancestors	count=2
class	first element ||| stepping	count=1
arg	precedes [arg] beginning with ||| [arg]	count=1
class	the feature with ||| feat dict	count=1
class	move ||| shift	count=1
class	this function must ||| chunk	count=1
module	whether tweets are ||| twitter	count=1
module	that instantiates and ||| sem	count=1
arg	tokens in unigrams ||| unigrams handle_negation	count=1
function	a binding to ||| bind to	count=3
module	illustrate ||| inference	count=2
function	a variety ||| from id	count=1
class	same sentence ||| punkt sentence tokenizer	count=1
arg	:return a list ||| fileids tagset	count=1
class	single parsing ||| descent parser	count=1
function_arg	[function_1] [arg_2] ||| [function_1] applies [arg_2]	count=4
class	supported languages ||| crubadan corpus	count=1
class	frontier in ||| recursive	count=1
function	concise string representation of ||| repr	count=2
arg	must be trained ||| trained n c	count=1
function	thread ||| expand threads	count=1
module	of supported ||| corpus reader	count=1
arg	the pairs generated by ||| pairs window trace	count=1
arg	it precedes [arg] beginning ||| [arg]	count=1
function	of lemmas in ||| lemmas	count=1
function	the data file for ||| data file	count=1
class	element of the frontier ||| parser	count=1
function	of information about ||| info from	count=1
class	vacancy ||| ibmmodel5	count=2
arg	on the given prob_dist ||| prob_dist	count=1
class	remaining text to the ||| shift	count=1
function	which describes the use ||| pred use	count=1
class	other logic parsers that ||| logic parser	count=1
arg	target and display form ||| target display	count=1
arg	target-to-source word alignment ||| f2e	count=1
class	of the frontier in ||| stepping recursive descent	count=1
arg	the dependencygraph graph ||| graph	count=1
function	[function_1] sentence and ||| [function_1] [function_2]	count=2
module	the frontier in particular ||| parse	count=1
arg	dependencygraphs ||| graphs	count=1
class	document ||| framenet corpus reader	count=1
class	lexical translation model ||| ibmmodel2	count=1
function_arg	from stream until ||| block stream	count=1
class	from the ||| shift reduce	count=1
function	a local file ||| retrieve	count=1
arg	present in graphs list ||| graphs	count=1
function	child pointer [function_2] ||| [function_1] [function_2]	count=4
arg	more [arg] to ||| [arg]	count=1
class	n ||| dist	count=1
function	info from the fulltextindex ||| handle fulltextindex	count=1
module	needs to be ||| app	count=1
function	function generates [function_2] ||| [function_2] [function_1]	count=1
module	the name of the ||| corpus reader	count=1
function	freqdist containing only ||| freq threshold	count=1
class	as [class] ||| [class]	count=3
arg	given file s ||| fileids	count=20
arg	s as ||| fileids strip_space	count=1
function	check whether a ||| check	count=1
function	positions in the ||| positions	count=1
function	truncation line ||| truncation	count=1
function	calculates the depth of ||| depth	count=1
class	the heldout estimate ||| heldout	count=1
class	needs to ||| chart	count=1
module	corpus using ||| corpus reader	count=1
function	number [function_2] ||| [function_1] [function_2]	count=1
function	information about the ||| from id	count=1
class	the ||| hidden markov model tagger	count=4
function_arg	[function_1] with_shutdown ||| [function_1] [arg_2]	count=4
class	contexts ||| context	count=1
class	'tree position' [class] given ||| [class]	count=2
function	methods of ||| drt discourse	count=1
function	values for a ||| values	count=1
class	[class_1] reader for ||| [class_1] [class_2]	count=3
function	_tag_positions ||| positions	count=1
class	a pickle [class_2] ||| [class_1] [class_2]	count=4
class	a dictionary ||| dictionary conditional prob dist	count=1
class	must be called ||| chunk	count=1
class	that this probability ||| heldout prob	count=1
arg	status_code ||| status_code	count=1
function	set of all roots ||| roots	count=1
function	method that instantiates and ||| variable expression	count=1
module	of information ||| twitter	count=1
class	displaying the ||| parser	count=1
class	a token from the ||| shift reduce	count=1
arg	sole training text for ||| verbose	count=1
class	tagger uses to generate ||| based tagger	count=1
class	of this decision tree ||| decision tree classifier	count=1
function	node label ||| tgrep node label	count=2
arg	luname frameid and framename ||| luname frameid	count=1
class	words in alphabetical ||| corpus	count=1
arg	list of word tag ||| strip_space stem	count=1
function	translate one entity to ||| descape entity	count=1
arg	n-gram f-score described ||| hypothesis min_len max_len	count=1
class	text contents ||| senseval	count=1
arg	and punctuation ||| fileids speaker stem	count=1
class	[class_1] examples ||| [class_2] [class_1]	count=4
arg	can all appear ||| fail_on_unknown	count=1
module	of difference ||| metrics	count=1
arg	and print classifier performance ||| test_set classifier accuracy f_measure	count=1
arg	:type graph ||| graph	count=1
arg	if ||| bin	count=1
arg	a string of ||| s	count=1
function	chart's sentence ||| leaves	count=1
function	of speech [function_2] ||| [function_1] [function_2]	count=2
class	this tree [class_2] ||| [class_2] [class_1]	count=8
function	returns the probability of ||| probability	count=1
function	maps the tag ||| tag	count=1
class	generated when parsing a ||| parser	count=3
arg	pairs generated by ||| pairs window	count=1
function	left [function_2] ||| [function_1] [function_2]	count=1
arg	[arg] then ||| [arg]	count=6
arg	:param valuation_str str with ||| valuation_str	count=1
module_class	exists return its ||| core feat dict	count=1
function	the first pass of ||| annotate first pass	count=1
function	the fulltextindex ||| handle fulltextindex elt	count=1
class	this dependencygrammar ||| probabilistic dependency grammar	count=1
function_arg	in [arg_2] ||| [arg_2] [function_1]	count=6
arg	source-to-target ||| e2f	count=1
function	a first-order logic ||| fol	count=1
class	as sentence breaks ||| sentence	count=1
function	pointwise [function] ||| point [function]	count=3
class	tags ||| markov	count=1
arg	of child to ||| child	count=2
class	[class_1] in specified ||| [class_2] [class_1]	count=1
arg	creates the sentence alignment ||| source_blocks target_blocks params	count=1
class	[class_1] gzip ||| [class_2] [class_1]	count=1
function	the use of a ||| pred use	count=1
class	symbols in the corpus ||| corpus reader	count=1
function	to a local file ||| retrieve	count=1
arg	finds the reference that ||| references hyp_len	count=1
arg	a baseline ||| initial_tagger templates trace deterministic	count=1
function_arg	[function_1] n-gram f-score ||| [arg_2] [function_1]	count=2
arg	s as a ||| fileids strip_space	count=1
arg	string of bracketted tagged ||| s	count=1
class	instance's ||| instance	count=1
arg	a pretty-printed [arg_2] ||| [arg_1] [arg_2]	count=3
arg	[arg_1] with fstruct2, ||| [arg_2] [arg_1]	count=1
class	that reads the pickle ||| pickle	count=1
arg	in the base ||| tr nr n	count=1
function	chart into the ||| set	count=1
function_arg	[function_1] function ||| [arg_2] [function_1]	count=3
function	right-hand side length of ||| len	count=2
class	for the ||| corpus	count=1
function	add a multi-word expression ||| add	count=1
arg	train ||| trainer	count=1
class	[class_1] widget ||| [class_1] [class_2] tags	count=2
arg	[arg_1] drtindividualvariableexpression for ||| [arg_1] [arg_2]	count=2
function_arg	[function_1] [arg_2] ||| [function_1] sample [arg_2]	count=1
class	be called ||| chart parser app	count=1
arg	its id luname ||| ignorekeys luname	count=1
arg	of samples given ||| samples	count=1
class	the internal indexes ||| corpus	count=1
class	[class_1] as ||| [class_2] [class_1]	count=3
class	tags the sequence ||| model tagger	count=1
class	periods as sentence breaks ||| sentence	count=1
arg	variable ||| variable	count=5
class	of the frontier in ||| recursive	count=1
class	given bigram using ||| bigram collocation finder	count=1
function	[function_1] from ||| [function_1] [function_2]	count=4
function	chart to a ||| chart	count=1
class	[class_1] this rule ||| [class_2] [class_1] apply everywhere chart grammar	count=1
class	function must be ||| chart	count=1
arg	helper used to implement ||| bracket_sent tag strip_space	count=1
class	when ||| probabilistic	count=1
arg	frame object name or ||| frame frame2	count=1
arg	all possible ways ||| ancestors0 queue potential_labels0	count=1
arg	tags as a list ||| fileids	count=1
arg	a list of reference ||| reference	count=3
function	unigram [function_2] ||| [function_1] [function_2]	count=3
class	to the end of ||| reduce	count=1
arg	the remaining lines at ||| lines	count=1
function	various methods ||| drt	count=1
class	trigram using the ||| trigram	count=1
function	hole that ||| hole	count=1
arg	classifies the token ||| token	count=1
class	every feature ||| feat	count=1
function_arg	sentence [arg_2] ||| [arg_2] [function_1]	count=2
class	a single ||| parser	count=1
arg	freqdist ||| freqdist gamma bins	count=1
class	binder in the expression ||| lambda expression	count=1
module	remaining text to ||| parse	count=1
class	cmudict lexicon as ||| cmudict corpus reader	count=2
class	the first element ||| descent	count=1
function	iso 639-3 ||| iso	count=1
arg	int limit the ||| limit	count=1
class	a list of ||| reader	count=1
function	file for tadm based ||| tadm file	count=1
class	the frontier in ||| stepping recursive	count=1
function	of features ||| features	count=1
module	calculate ||| translate	count=1
arg	the word ||| word	count=2
function	the use of ||| pred use	count=1
class	a list concatenating ||| lazy iterator list	count=1
class	given underlying ||| lazy	count=1
arg	lines at exactly ||| lines	count=1
class	that this tagger ||| tagger	count=2
class	application ||| application	count=1
module_class	[module_1] [class_2] not including graphical ||| [module_1] [class_2] tags	count=4
function	custom ||| custom	count=1
arg	tagger must be trained ||| unk trained n	count=1
class	as ||| crubadan	count=1
class	in alphabetical ||| lexicon corpus reader	count=1
function	suffix-removal rule ||| rule	count=1
class	as ||| corpus reader	count=2
function	of words or ||| words	count=1
arg	of text ||| word_tokenizer	count=1
class	reader for a ||| reader	count=3
arg	of variable [arg_2] ||| [arg_2] [arg_1]	count=3
function	in that ||| from	count=1
arg	of the earley parsers ||| print_times print_grammar print_trees trace	count=1
module	to the ||| parse	count=1
arg	trees can be extracted ||| tokens trace	count=1
class	the remaining text ||| stepping shift	count=1
function	speech [function_2] ||| [function_2] [function_1]	count=2
arg	list of ||| fileids sent tag	count=1
arg	a string containing a ||| vnframe indent	count=1
function	readme txt or readme ||| readme	count=1
class	iso ||| reader	count=1
class	the feature [class] ||| feat [class]	count=2
class	of samples ||| good turing prob dist	count=1
class	best chunk [class] for ||| chunk parser [class]	count=1
arg	phrase_table table of translations ||| phrase_table	count=1
function	generates ||| generate	count=1
class	method ||| nertagger	count=1
function	to find ||| find room	count=1
arg	forward pointer to ||| forward fs_class visited	count=1
arg	expression to ||| expression command x	count=1
class	canvas [class] and all ||| canvas [class]	count=1
function	words/sentences ||| views	count=1
function	train a ||| train	count=1
class	probability state ||| model	count=1
arg	[arg_1] vectors to ||| [arg_2] [arg_1]	count=2
function	information ||| user info	count=1
arg	list of word ||| fileids speaker stem	count=1
class	dict with ||| dict	count=1
arg	child to not ||| child	count=1
function	edge's left-hand side which ||| lhs	count=1
class	of words for the ||| swadesh corpus	count=1
function_arg	[function_1] stream ||| [arg_2] [function_1]	count=2
class	based ||| based	count=1
arg	any [arg] has a ||| [arg] forward fs_class	count=1
module	convert a ||| twitter	count=1
module_class	return an ||| core abstract	count=2
arg	of data ||| data	count=1
function	static index ||| static index	count=2
class	[class_1] [class_2] cumulative displaying the most ||| [class_1] [class_2]	count=4
class	build the internal indexes ||| corpus	count=1
class	of this confusion ||| confusion	count=1
class	function must be called ||| drt glue	count=1
function	all sentences in the ||| sents	count=1
class	child's parent ||| sequence	count=1
class	sequence this ||| hidden markov model tagger	count=1
function_arg	children under the ||| children node_index	count=1
class	of ||| nombank	count=1
class	associated with ||| probabilistic mix in	count=1
function	bound node label ||| node label pred	count=2
arg	value ||| value	count=4
class	probability state sequence ||| hidden markov	count=1
class	index ||| i	count=1
class	counts from two counters ||| freq dist	count=1
function	in accordance to the ||| parse	count=1
function	[function_1] pass ||| [function_2] [function_1]	count=3
class	that ||| backoff	count=1
class	probability state sequence ||| tagger	count=1
function	computes the probability ||| prob	count=2
class	build a new classifier ||| classifier	count=1
class	resulting tree ||| tree	count=1
arg	input expression to ||| assumptions max_models	count=1
class	list of tweets ||| twitter corpus reader	count=1
arg	cached n ||| key	count=1
arg	:param data [arg_2] ||| [arg_2] [arg_1]	count=2
class	chunkstring ||| string	count=1
class	the frontier in particular ||| stepping recursive	count=1
class	a given bigram using ||| bigram collocation finder	count=1
class	in store ||| store	count=1
class	constructs a collocation finder ||| abstract collocation finder	count=1
function	sequence this ||| tag	count=1
class	:see ||| drt negated expression	count=1
function_arg	present document ||| extract features document	count=1
function	for the [function] ||| [function]	count=1
module	the internal ||| corpus	count=1
class	feature of ||| feature	count=2
class	to elements of ||| lazy map	count=1
class	inside probabilities ||| inside chart parser	count=1
arg	generic ||| generic word	count=1
module	big a unit needs ||| app	count=1
function	the cosine ||| cosine	count=1
arg	classifier performance on ||| test_set classifier accuracy f_measure	count=1
arg	if with_shutdown ||| with_shutdown	count=1
class	this alignedsent ||| aligned sent	count=2
class	this corpus ||| categorized corpus	count=1
arg	given file s as ||| fileids strip_space	count=1
module_class	[module_1] discourse ||| [module_1] [class_2]	count=2
class	return all ||| corpus	count=1
arg	to the word ||| word	count=1
arg	dictionary where keys are ||| stems	count=1
function_arg	was [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
class	bigram collocation ||| collocation finder	count=1
function	tgrep search string ||| tgrep tokenize	count=1
class	the ||| stepping recursive	count=2
arg	[arg_1] [arg_2] any sequence over a ||| [arg_2] [arg_1]	count=8
function	node label ||| label	count=2
arg	:param status_code the status ||| status_code	count=1
function	the tag ||| tag	count=1
arg	cls ||| cls	count=2
function_arg	[function_1] filtered by ||| [arg_2] [function_1]	count=2
function	regular expression for word ||| word	count=1
class	from a rte ||| rtecorpus	count=1
arg	information content ||| synset1 synset2 ic	count=1
class	enter the ||| regexp chunk	count=1
module	helper function -- return ||| core	count=1
function	get the static ||| get static	count=3
class	name of the ||| instance	count=1
class	utterances each [class] ||| [class]	count=3
function	userid to a screen ||| userid	count=1
function	binding to ||| bind to columns	count=2
function	for the fileids ||| fileids	count=1
class	when parsing a text ||| reduce parser	count=1
class	files ||| reviews	count=1
class	by this tagger to ||| tagger	count=1
class	a new iterator over ||| iterator	count=1
class	be ||| regexp	count=1
function	find ||| find room	count=1
function	test ||| extract test	count=1
module	this ||| app	count=2
function_arg	euclidean distance [arg_2] ||| [arg_2] [function_1]	count=5
arg	list of samples given ||| samples	count=1
function	convert a ||| from	count=1
class	for this corpus ||| chunked corpus	count=1
arg	on the node ||| node	count=1
class	of joint-feature values ||| maxent feature	count=1
function	right sibling of ||| right sibling	count=1
function	a lambda function ||| tgrep	count=3
function_arg	[function_1] [arg_2] ||| [function_1] fileids [arg_2]	count=47
class	the ||| app	count=2
class	text to the ||| parser	count=1
function	compiles ||| re	count=2
function	this edge's right-hand side ||| rhs	count=1
class	function must be ||| chart parser	count=1
class	first element of the ||| parser	count=1
class	to princeton wordnet ||| word net	count=1
function	parse multiple sentences ||| tagged parse	count=1
class	multi-column listbox ||| multi listbox	count=2
function	of chomsky [function_2] ||| [function_2] [function_1]	count=3
class	new classifier ||| classifier	count=1
arg	fval1 ||| fval1	count=1
function	index page ||| index page	count=2
function	abstractvariableexpression appropriate for ||| variable	count=1
function	rule ||| rule	count=4
function	of unigram [function_2] ||| [function_2] [function_1]	count=3
class	a source language phrase ||| phrase	count=1
arg	drawing ||| x y	count=2
module	tags the ||| tag	count=1
function	the mapping dictionary ||| tagset mapping	count=1
function_arg	:rtype [arg_2] ||| [arg_2] [function_1]	count=3
class	return all ||| corpus reader	count=1
arg	[arg] of the ||| [arg]	count=1
function	pop the [function_2] ||| [function_1] [function_2]	count=3
class	given ||| corpus reader	count=8
arg	of word tag tuples ||| fileids speaker stem relation	count=1
function	lowercase 'e' ||| eventvar	count=1
function	read a sequence ||| read	count=1
arg	use ||| assumptions verbose	count=1
class	a dictionary containing the ||| dictionary	count=1
function	[function_1] static ||| [function_1] [function_2]	count=1
arg	drawing the item ||| item x y	count=3
arg	should be [arg_2] ||| [arg_1] [arg_2]	count=1
arg	tab file containing ||| tab_file lang	count=1
class	the frequency ||| freq	count=1
function	trigrams generated from ||| trigrams	count=1
function_arg	train fit the ||| train labeled_featuresets	count=1
function	shortest ||| min	count=1
arg	child to not point ||| child index	count=1
class	sentence ||| chart	count=1
arg	specified xml ||| tagspec	count=1
function	about the ||| from	count=1
function	in the predicate-argument annotation ||| lines	count=2
function_arg	to configure [arg_2] ||| [arg_2] [function_1]	count=1
arg	variable v ||| variable	count=3
function	appropriate for the ||| variable	count=1
class	be generated ||| arff formatter	count=1
function_arg	[function_1] documents each ||| [arg_2] [function_1]	count=1
function	return the [function] ||| [function]	count=6
class	by this [class_2] ||| [class_2] [class_1] apply chart grammar	count=4
class	sequence with ||| tagger	count=1
function	md5 [function_2] ||| [function_1] [function_2]	count=3
class	the sequence with the ||| model	count=1
class	return the chart ||| stepping chart parser	count=1
function	create a ||| create	count=1
module	of the recursive ||| parse	count=1
class	[class_1] the pickle ||| [class_2] [class_1]	count=1
arg	documents ||| cls documents	count=1
function	probability distribution ||| prob	count=2
class	a dependency ||| dependency parser	count=1
class	interpretations ||| standard stemmer	count=1
function	about the ||| user	count=1
class	repp ||| repp	count=1
function_arg	tree positions [arg_2] ||| [function_1] pattern [arg_2]	count=5
function	extract the unique counter ||| unique counter	count=1
module	tag position mapping ||| tag	count=1
function	unique counter from the ||| unique counter from	count=1
function	adjust the [function_2] ||| [function_1] [function_2]	count=1
function	informative ||| informative	count=1
arg	a grammar ||| grammar trace	count=1
class	corpus ||| framenet corpus reader	count=1
function	instantiates and returns ||| variable expression	count=1
arg	the binary with ||| binary args	count=1
function	containing a pretty-printed representation ||| pprint	count=3
class	[class_1] tokenizer binary ||| [class_2] [class_1]	count=1
function_arg	beginning of [arg_2] ||| [arg_2] [function_1]	count=5
function	of the text ||| text	count=2
function	synset ||| get synset	count=1
class	feature ||| feature grammar	count=2
function	corpus of classified tokens ||| write	count=2
class	[class_1] binder in ||| [class_1] [class_2]	count=4
function	from a subcorpus ||| lusentence	count=1
module	abstractvariableexpression ||| sem	count=1
function_arg	train on sentence_aligned_corpus and [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
class	a ngramassocmeasures class ||| contingency measures	count=1
function	incoming [function_2] ||| [function_2] [function_1]	count=4
function	a table of ||| token table	count=1
module	aligned ||| corpus reader	count=1
function	[function_1] chart ||| [function_1] [function_2]	count=1
module	to ||| corpus	count=1
class	given the iso 639-3 ||| crubadan corpus reader	count=1
function	of bigram ||| extract bigram	count=1
module	sequence ||| tag	count=2
class	in alphabetical ||| reader	count=1
arg	context [arg_2] ||| [arg_2] [arg_1]	count=1
arg	a list of text ||| word_tokenizer	count=1
class	single [class_2] ||| [class_1] [class_2]	count=1
class	a token from ||| shift reduce	count=1
function	identifier of the ||| predid	count=1
class	:return the text contents ||| senseval corpus reader	count=1
function	[function_1] chart to ||| [function_1] [function_2]	count=1
class	version of the tree ||| tree	count=1
class	function must be ||| drt	count=1
function_arg	train on [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
function	for the ||| variable	count=1
function_arg	[function_1] all ||| [function_1] [arg_2]	count=3
function	of the conditions that ||| conditions	count=1
arg	penn treebank ||| nx	count=1
function	the score ||| score	count=4
function	a userid to ||| lookup by userid demo	count=1
class	logic parsers ||| logic	count=2
function	representation ||| repr	count=8
class	true if the graph ||| graph	count=1
class	to the chart ||| stepping chart	count=1
class	conditional [class_2] ||| [class_1] [class_2]	count=3
function	format("verbose") ||| verbose	count=1
function_arg	[function_1] document ||| [function_1] [arg_2]	count=4
class	the chart ||| chart	count=4
arg	frame object ||| frame frame2	count=1
function	a chart to a ||| chart	count=1
function	about the ||| user info from	count=1
function_arg	[function_1] labels ||| [function_1] [arg_2]	count=2
arg	[arg] to ||| [arg] beam_size	count=1
function	measure for all ||| measure	count=1
function	the columns ||| column	count=1
arg	perform the actual ||| intact_word	count=1
class	how ||| edge	count=1
function	[function_1] web ||| [function_1] [function_2]	count=3
arg	given colors ||| linecolor textcolor	count=1
function	the region [function] ||| [function]	count=3
function	the fulltextindex ||| handle fulltextindex	count=1
class	in the corpus ||| nombank corpus	count=1
arg	list of lists of ||| fileids	count=1
function	of fileids ||| fileids	count=1
class	[class_1] the expression ||| [class_1] [class_2]	count=5
function	table's ||| check table	count=1
function	[function_1] model ||| parse find [function_1] [function_2]	count=1
class	to figure out ||| chart view	count=1
function	the right [function_2] ||| [function_2] [function_1]	count=1
function	set of variables ||| variables	count=1
arg	production to combine ||| production	count=1
arg	from a ||| srctext trgtext alignment	count=1
class	iso 639-3 language ||| crubadan	count=1
arg	f-score it ||| max_len	count=1
class	must be ||| drt	count=1
function	str rule and rule ||| demo str rule format	count=1
class	move a token ||| shift reduce	count=1
class	function ||| demo	count=1
function	try some proofs and ||| model	count=1
class	transition ||| transition	count=1
module	to the end ||| parse	count=1
function	conditions that have been ||| conditions	count=1
function	[function_1] relations ||| [function_2] [function_1]	count=1
class	contents ||| category corpus reader	count=1
arg	the hunpos-tag ||| path_to_bin encoding	count=1
function	freqdist containing ||| freq	count=1
class	of the frontier ||| parser	count=1
function	demonstration of ||| malt demo	count=1
arg	[arg_1] xml file ||| [arg_2] [arg_1]	count=2
class	dependency ||| projective dependency	count=1
module	and ||| core	count=5
function	bound node label ||| node label	count=1
class	this corpus or for ||| corpus	count=2
class	:see expression ||| function variable expression	count=2
function	names of [function_2] ||| [function_2] [function_1]	count=4
class	for the given ||| corpus reader	count=1
function	compute ||| compute	count=1
function	index for a given ||| index	count=1
module	of [module] canvas widget ||| [module]	count=1
function	check to make sure ||| check grammar	count=1
function	word ||| word	count=4
class	set ||| segment widget	count=1
arg	the highest information content ||| ic verbose	count=1
class	save ||| parser app	count=1
class	dutch ||| dutch stemmer	count=1
class	must ||| drt glue demo	count=1
class	encoded as a ||| chunked corpus	count=2
function	entries in the table ||| size	count=1
function_arg	replace all [arg_2] ||| [arg_2] [function_1]	count=9
module	factory method ||| sem	count=1
class	the stack ||| shift reduce parser	count=1
module	this constructor should ||| draw	count=1
class	a french ||| french	count=1
class	[class] that are ||| [class] encoding	count=1
module	name of ||| corpus	count=1
function	arc to the ||| arc	count=1
arg	of a tree ||| tree	count=1
module	alphabetical order ||| reader	count=1
function	of abstractvariableexpression appropriate ||| variable	count=1
module	this function must ||| app	count=2
function	add a ||| add	count=1
class	[class_1] rule and ||| [class_2] [class_1]	count=1
function	get the [function_2] ||| [function_2] [function_1]	count=3
arg	bracketed tree string ||| s brackets read_node	count=3
arg	root directory ||| root fileids	count=1
arg	the given scoring function ||| score_fn w1 w2	count=2
function	:return the tree ||| tree	count=1
function	a custom ||| custom	count=1
function	uniform ||| uniform	count=1
function	a variety ||| from	count=1
function	rv that is used ||| rv	count=1
function_arg	[function_1] metric ||| [arg_2] [function_1]	count=1
arg	:param positive_featuresets a ||| positive_featuresets	count=1
function	convert ||| id	count=1
function_arg	[function_1] [arg_2] into account partial agreement ||| metrics masi [function_1] [arg_2]	count=1
class	of a dependency graph ||| projective dependency parser	count=1
function_arg	[function_1] [arg_2] leave the stream's file ||| [function_1] [arg_2] block_size comment_char	count=7
class	the frontier ||| stepping	count=1
module	and ||| parse	count=2
class	a pickle [class_2] ||| [class_2] [class_1]	count=4
class	this parser ||| chart parser	count=4
function_arg	which [arg_2] ||| [function_1] nodes pattern trees [arg_2]	count=3
module	the text widget used ||| draw	count=1
class	token from ||| stepping shift reduce parser	count=1
arg	if x ||| x	count=1
class	called ||| parser	count=1
class	probability ||| hidden markov model	count=1
arg	a sentence as a ||| sentence	count=1
arg	displaying ||| stack remaining_text	count=1
class	by this rule and ||| rule i	count=1
function	upper frame page ||| upper page	count=1
class	[class_1] distribution if ||| [class_2] [class_1]	count=1
arg	given item ||| item x y	count=1
class	a token from ||| stepping shift reduce parser	count=1
class	as iso ||| crubadan corpus	count=1
class	return ||| crubadan corpus	count=1
class	feature [class_2] ||| [class_1] [class_2]	count=3
module_class	[module_1] table's ||| [module_1] [class_2]	count=12
function	likelihood ratios as in ||| likelihood ratio	count=1
function	[function_1] index page ||| [function_1] [function_2]	count=3
function	[function] of the ||| [function]	count=23
function	of rules ||| rules	count=1
class	the name ||| nombank	count=1
function	the user ||| user	count=1
module	a previously opened ||| core	count=1
function	set the node ||| set	count=1
class	:param ||| chunk app	count=1
function	part of speech ||| pos	count=1
function	[function] character followed ||| [function]	count=1
class	expression for the ||| expression	count=2
function	tokenized list of ||| list	count=1
function	the hierarchical parent ||| parent	count=1
function_arg	[function_1] a word ||| [function_1] [arg_2]	count=2
class	feature of the ||| feature grammar	count=1
function	list ||| user info from	count=1
arg	is the minimum ||| other	count=2
arg	for a word ||| word	count=1
module	the cached n ||| core	count=1
function	step 1a ||| step1a	count=1
class	row into the table ||| table	count=1
function	currently recommended [function] ||| [function] chunk	count=3
class	nombankinstance objects one for ||| reader	count=1
function	sentences each [function_2] ||| [function_2] [function_1]	count=12
class	for this corpus ||| category corpus reader	count=1
class	element [class_2] ||| [class_1] [class_2]	count=2
class	this rule it has ||| chunk rule	count=1
class	much of the ||| edge i	count=1
class	first element of the ||| descent	count=1
class	that have been identified ||| probabilistic nonprojective parser	count=1
arg	with [arg] the twitter ||| [arg]	count=1
class	the corpus ||| categorized sentences corpus	count=1
function	pointer to preserve reentrancy ||| apply forwards to	count=1
function	configure ||| configure	count=2
module	of supported ||| corpus	count=1
arg	the remaining lines at ||| lines wrap_at	count=1
function_arg	[function_1] and relation ||| [function_1] synset [arg_2]	count=1
class	scores [class] ||| [class]	count=2
function_arg	[function_1] [arg_2] ||| [function_1] queue queue [arg_2]	count=1
class	positive examples ||| naive bayes dependency	count=1
module	recursive descent parser ||| parse	count=1
module_class	for the text that [module_1] [class_2] being parsed ||| [module_1] [class_2] recursive descent parser	count=1
class	name of the ||| nombank instance	count=1
arg	nonterminals ||| cat	count=1
function	[function_1] representing a ||| [function_2] [function_1]	count=2
function	for pretty-printing a list ||| pretty	count=2
class	of supported ||| corpus	count=1
arg	base_fdist ||| base_fdist heldout_fdist bins	count=1
module	this constructor ||| draw	count=1
function	truncation line ||| get truncation coordinates	count=1
function	analyze the sentence ||| analyze	count=1
class	function must be ||| parser app	count=1
function	a rare [function_2] ||| [function_1] [function_2]	count=2
function	of speech [function_2] ||| [function_2] [function_1]	count=2
function	tadm ||| tadm	count=1
arg	pair of segmentations a ||| k boundary	count=1
class	the parser ||| parser	count=1
function	initialize a new ||| init	count=1
class	each context to the ||| context index	count=1
function	approximate score ||| score	count=1
function	convert a userid ||| by userid demo	count=1
function	for the ||| get	count=1
function	repr ||| demo repr	count=1
arg	a list of word ||| stem	count=2
arg	lines at ||| lines wrap_at	count=1
function_arg	[function_1] synset note ||| [function_1] [arg_2]	count=4
arg	of word tag ||| c5 strip_space stem	count=1
arg	expression in cnf ||| expression	count=1
function	result of ||| result	count=1
function	a userid to a ||| lookup by userid	count=1
function	scores the score ||| score	count=1
function_arg	:param [arg_2] ||| [arg_2] [function_1]	count=49
arg	to size bytes ||| size	count=1
module	[module] on ||| [module]	count=1
arg	if self and other ||| other	count=1
module	structure is consistent with ||| parse	count=1
class	a tnt statistical tagger ||| tn t	count=1
class	a sentence ||| sentence tokenizer	count=2
class	structure is ||| edge	count=1
class	dependency graph based ||| dependency	count=1
arg	to the input string ||| input	count=1
class	if the underlying stream ||| seekable unicode stream reader	count=1
function	probability of the ||| probability	count=1
class	[class_1] format ||| [class_1] [class_2]	count=2
function	scrollregion ||| scrollregion	count=1
function	built ||| from reference	count=1
function	open a ||| open	count=1
class	probability state ||| markov model	count=1
module	the tree should ||| app	count=1
function	for past tweets by ||| tweets by	count=1
function_arg	[function_1] the symbol ||| [arg_2] [function_1]	count=2
class	wrapper ||| wrapper	count=2
function	[function_1] of clusters ||| [function_2] [function_1]	count=2
class	a given trigram using ||| trigram collocation finder	count=1
class	if a feature with ||| feat	count=1
class	stack ||| stepping shift	count=1
class	word ||| language vars	count=1
class	of the ||| stepping shift reduce parser	count=2
class	tree occurs ||| multi parented tree	count=2
function	[function_1] relations data ||| [function_1] [function_2]	count=1
function	bigram ||| bigram	count=2
function	list *tr*, where *tr[r]* ||| tr	count=1
function_arg	children [arg_2] ||| [function_1] [arg_2]	count=4
class	corpus or in ||| corpus reader	count=1
function	binary concept out ||| binary concept	count=2
function	longest ||| max	count=1
module	[module] a copy ||| [module]	count=3
arg	reading ids [arg_2] ||| [arg_2] [arg_1]	count=2
function	a string representation ||| repr	count=2
function	set [function_2] ||| [function_1] [function_2]	count=1
class	with the ||| hidden markov	count=1
function_arg	encoded as [arg_2] ||| [function_1] sents [arg_2]	count=2
module	about the ||| twitter	count=1
arg	synset and relation ||| synset relation	count=2
arg	context_to_tag a dictionary mapping ||| context_to_tag backoff	count=1
arg	id luname frameid ||| luname frameid	count=1
function	read a [function_2] ||| [function_1] [function_2]	count=3
function	encoded as a ||| tagged	count=3
class	a ||| crubadan	count=1
class	variable binder [class_2] ||| [class_2] [class_1]	count=2
class	two ||| lin thesaurus	count=1
class	tagger ||| tagger trainer	count=1
class	store [class_2] ||| [class_2] [class_1]	count=2
function_arg	button press [arg_2] ||| [function_1] [arg_2]	count=3
class	corpus if ||| corpus reader	count=1
arg	from consideration given the ||| test_sents	count=1
class	[class_1] stream ||| [class_2] [class_1]	count=6
function	the [function] ||| tgrep [function]	count=2
class	of this synset ||| synset	count=1
class	is consistent ||| edge i	count=1
arg	matching the specified criteria ||| exemplars full_text	count=1
arg	with the assumptions ||| goal assumptions	count=1
function	maltparser ||| malt	count=1
arg	pk metric for a [arg_1] [arg_2] vocabulary of two items ||| [arg_2] [arg_1]	count=4
arg	the given speaker dialect ||| dialect	count=1
function	pos tagged ||| tagged	count=1
function	of all roots of ||| roots	count=1
function	a demonstration showing ||| demo	count=3
function	with ||| tag	count=1
arg	fileids of ||| fileids	count=1
module	parser ||| parse	count=1
class	standard [class_2] ||| [class_1] [class_2]	count=1
arg	of text label tuples ||| label word_tokenizer	count=1
class	order ||| opinion	count=1
arg	a sequence of items ||| sequence	count=3
function	read up to ||| read	count=2
function_arg	[function_1] the word ||| [function_1] [arg_2]	count=1
arg	a feature is ||| feat	count=1
class	trigram using ||| trigram collocation finder	count=1
function_arg	[function_1] classifier ||| [arg_2] [function_1]	count=1
arg	new edge to the ||| edge	count=1
arg	divides the text ||| text	count=1
class	uses to ||| classifier based	count=1
arg	implement the view ||| fileid unit bracket_sent	count=1
class	corpus ||| timit corpus	count=1
class	the ||| dist	count=1
function	probability of ||| probability	count=1
module	is displayed by this ||| draw	count=2
module	element of the ||| parse	count=1
class	out how ||| chart view	count=1
class	element of ||| stepping recursive descent parser	count=1
function_arg	words [arg_2] ||| [function_1] fileids [arg_2]	count=4
class	corpus ||| reviews corpus reader	count=2
class	in a ||| tokenizer	count=1
class	of the stack ||| parser	count=1
class	:param ||| space clusterer	count=1
function	methods ||| drt	count=1
class	token from the ||| shift reduce	count=1
function_arg	[function_1] [arg_2] variable ||| sem variable [function_1] [arg_2]	count=1
function	and [function] lexical translation ||| [function]	count=1
arg	a temporary file as ||| delete_on_gc	count=1
function	readme ||| readme	count=1
class	parsing a text ||| descent parser	count=1
arg	to generate base_fdist ||| base_fdist heldout_fdist	count=1
class	[class_1] dependency parser ||| [class_2] [class_1]	count=4
function	a decorator ||| decorator	count=1
class	distribution of [class_2] ||| [class_2] [class_1]	count=2
function	parse ||| parse	count=10
class	frames ||| framenet corpus reader	count=1
class	the tree ||| chart view	count=1
class	a given bigram using ||| bigram	count=1
arg	refs list ||| refs conds	count=2
class	be etc ||| view	count=1
arg	the reflexive ||| reflexive	count=1
class	feature-based grammar from the ||| feature grammar	count=1
function	classifier ||| classifier	count=1
function	construct a ||| construct threads	count=1
class	parser ||| stepping recursive descent parser	count=1
module	parse texts ||| parse	count=5
function	that ||| expression	count=1
class	number of sample outcomes ||| freq dist	count=1
function_arg	string containing [arg_2] ||| [function_1] [arg_2]	count=4
function	likelihood ratios as ||| likelihood ratio	count=2
function	in the model ||| model var	count=1
class	that a ||| parser	count=1
class	similar to a list's ||| pretty list	count=1
module	this ||| reader	count=1
function	dictionary ||| dict	count=2
function	out a ||| show	count=1
function_arg	:param context_to_tag ||| init context_to_tag backoff	count=1
function	a projective dependency parser ||| projective	count=1
class	frontier in particular ||| stepping	count=1
function	head of the entire ||| head index	count=1
class	structure is consistent with ||| i	count=1
function	known abbreviation or ||| abbrev	count=1
class	the feature with the ||| feat	count=2
function	the next best rule ||| best rule	count=1
function	this function generates ||| generate	count=1
class	a single tree ||| shift reduce parser	count=1
arg	v ||| v	count=2
class	a token from ||| shift	count=1
function	for tadm ||| tadm	count=1
arg	train ||| trainer save_analyzer n_instances	count=1
function	factory ||| variable	count=1
class	tree or none if ||| parented tree	count=2
function	for megam ||| megam	count=1
function_arg	average [arg_2] ||| [function_1] [arg_2]	count=3
class	positive [class_2] ||| [class_2] [class_1]	count=2
function	delete all rows ||| clear	count=1
function_arg	[function_1] featureset ||| [arg_2] [function_1]	count=6
class	hypothesized structure is ||| edge i	count=1
function	about the ||| user info	count=1
function	demonstration showing how ||| demo	count=1
class	text for this sentence ||| sentence	count=1
function	[function_1] sentence and ||| [function_2] [function_1]	count=10
arg	dictionary from a corpus ||| corpus	count=1
module	this function ||| sem	count=1
function	all positive words in ||| positive	count=1
function_arg	[function_1] of tree ||| [function_1] [arg_2]	count=2
module	and used ||| core	count=1
function	rank alignment algorithm described ||| rank alignment	count=1
class	[class_1] file ||| core [class_1] [class_2]	count=1
arg	of tree cls ||| cls tree	count=1
class	for this corpus ||| propbank corpus reader	count=1
class	this corpus or ||| corpus	count=2
class	that have been ||| probabilistic nonprojective parser	count=1
function	transform the ||| test transform	count=1
function	past tweets by a ||| tweets by	count=1
function	check to make ||| check	count=1
function	least common subsumer that ||| lcs	count=1
class	[class_1] for ||| [class_2] [class_1]	count=1
function	[function_1] bound node ||| [function_2] label [function_1]	count=1
arg	of a single sentence ||| sentence threaded verbose	count=1
arg	is licensed by production ||| production	count=1
class	[class_1] listbox ||| [class_2] [class_1]	count=1
function	with the bigram ||| bigram	count=1
arg	appearances of words ||| word_fd	count=1
function	form s the grammar ||| grammar	count=1
function	the cache is ||| cache	count=1
class	[class_1] [class_2] not including graphical ||| [class_1] [class_2]	count=1
module	in wordnet ||| reader	count=1
class	remaining text to ||| reduce	count=1
arg	should be ||| tokens	count=1
arg	string of bracketted ||| s chunk_label root_label	count=1
function	table of ||| token table	count=1
function_arg	[function_1] fit ||| [function_1] [arg_2]	count=1
arg	from a word-aligned sentence ||| srctext trgtext alignment	count=1
class	of the files ||| reviews corpus	count=1
class	may cause the ||| mutable	count=1
class	each [class] ||| [class]	count=3
class	remaining text to ||| shift reduce	count=1
class	languages as iso 639-3 ||| crubadan corpus	count=1
arg	phrase_table table of ||| phrase_table	count=1
class	each context ||| context	count=1
class	the ||| chunk	count=1
class	decision [class_2] ||| [class_1] [class_2]	count=1
function	the upper frame ||| get static upper	count=1
arg	the top n ||| n	count=1
module	of a relation ||| sem	count=1
function	subcorpus ||| handle lusentence	count=1
class	associated with this object ||| probabilistic mix in	count=1
class	[class] its ||| [class]	count=2
arg	the specified criteria ||| exemplars full_text	count=1
class	the transformational ||| brill template	count=1
function	add a multi-word ||| add	count=1
function	a variety of ||| info from id	count=1
arg	if [arg] is ||| [arg]	count=1
class	words for ||| swadesh corpus reader	count=1
class	fixed-length [class] ||| [class] encoding	count=1
module	corpus ||| corpus	count=5
class	neural dependency parser and ||| neural dependency parser	count=1
function	the primitive ||| primitive	count=1
function	the conditions that ||| conditions	count=1
function	instantiates ||| variable	count=1
class	hypothesized structure is ||| edge	count=1
module	necessary ||| corpus reader	count=1
arg	line ||| linenum line	count=1
function	the indices where this ||| indices	count=1
function_arg	[function_1] initial_tagger ||| [arg_2] [function_1]	count=1
function_arg	[function_1] feature is ||| [arg_2] [function_1]	count=1
function	dictionary of ||| predicate dict	count=1
class	as a list ||| corpus reader	count=1
function_arg	[function_1] model_found() ||| [function_1] [arg_2]	count=1
class	iterator over ||| lazy iterator	count=1
function	each ||| span tokenize	count=1
class	map from contexts ||| context	count=1
module	unit ||| app	count=1
arg	modelbuilder the ||| modelbuilder goal	count=1
module	a token from the ||| parse	count=1
class	this dependencygrammar ||| dependency grammar	count=1
function_arg	[function_1] word of ||| [arg_2] [function_1]	count=1
class	mapping each context ||| context	count=1
class	its ||| dict	count=1
function	new ||| new	count=1
function	that the token is ||| is	count=1
class	must be ||| chart parser app	count=1
class	underlying stream ||| seekable unicode stream	count=3
class	e g tags=['subst', 'comp'] ||| nkjpcorpus	count=1
class	to ||| reduce parser	count=1
class	the remaining text ||| reduce	count=1
function	the clustering parameters ||| cluster	count=1
class	hypothesized ||| edge	count=1
function	sentence ||| sentences	count=1
arg	with_shutdown is true then ||| with_shutdown	count=1
class	the ||| hidden	count=2
class	[class_1] wrapper ||| [class_1] [class_2]	count=1
class	path [class_2] ||| core [class_1] [class_2]	count=4
function	a string containing a ||| format	count=1
class	as iso ||| reader	count=1
class	classifier ||| multi classifier	count=1
arg	words [arg_2] ||| [arg_1] [arg_2]	count=8
function	expected agreements ||| multi kappa	count=1
function	edge in ||| edge scores	count=1
class	in ||| opinion lexicon corpus reader	count=1
function	backward probability matrix ||| backward probability	count=1
function_arg	positions in [arg_2] ||| [arg_2] [function_1]	count=6
class	[class_1] [class_2] ||| [class_2] [class_1]	count=345
arg	list of text label ||| label word_tokenizer sent_tokenizer	count=1
class	elements into [class] ||| [class]	count=2
class	for the ||| reader	count=1
arg	word [arg_2] ||| [arg_1] [arg_2]	count=1
class	expression ||| drt lambda expression	count=2
function_arg	[function_1] of variable ||| [arg_2] [function_1]	count=3
arg	used to generate base_fdist ||| base_fdist heldout_fdist bins	count=1
function	methods of ||| drt discourse demo	count=1
function	the data [function_2] ||| [function_2] [function_1]	count=4
class	ipython ||| tree	count=1
class	this confusion ||| confusion	count=1
module	supported languages as ||| corpus	count=1
class	the internal indexes ||| framenet corpus reader	count=1
class	joint-feature ||| maxent feature encoding	count=1
class	remaining text ||| stepping	count=1
class	this function must be ||| regexp chunk app	count=1
function	information about the ||| user	count=1
function	is a factory method ||| expression	count=1
module_class	[module_1] this dependencygrammar ||| [module_1] [class_2]	count=2
function_arg	the present document ||| extract features document	count=1
function	list of tagged words ||| tagged words	count=2
class	the internal ||| reader	count=1
class	a proper [class_2] ||| [class_1] [class_2] renormalize r nr	count=1
arg	and returns a ||| line primitives families	count=1
function	for ||| variable	count=1
arg	head_address ||| head_address	count=1
arg	extracted ||| trace	count=1
module_class	this canvasframe ||| draw canvas frame	count=3
arg	its id luname frameid ||| fn_luid ignorekeys luname frameid	count=1
function	if an integer begins ||| read int	count=1
function	generates the [function_2] ||| [function_2] [function_1]	count=8
function	string representation of this ||| format	count=2
class	chart rule used ||| stepping chart	count=1
class	displaying the ||| recursive descent parser	count=1
class	text as ||| text	count=1
arg	[arg_1] tree string ||| [arg_2] [arg_1]	count=6
arg	file s as ||| fileids	count=18
module	a list of supported ||| corpus	count=1
class	boundary ||| punkt	count=1
function	of information about the ||| id	count=1
class	text contents of ||| senseval	count=1
arg	input expression ||| assumptions timeout	count=1
arg	function results ||| function	count=1
function	a userid to ||| lookup by userid	count=1
class	return a ||| corpus reader	count=1
class	of the remaining text ||| parser	count=1
class	the heldout estimate to ||| heldout	count=1
function	the hole ||| hole	count=1
class	binder in [class_2] ||| [class_1] [class_2]	count=2
class	[class_1] distribution ||| [class_1] [class_2] tabulate	count=4
class	given bigram ||| bigram	count=1
class	leaves [class] have ||| [class]	count=1
class	alphabetical ||| corpus	count=1
function	construct a value for ||| construct readings	count=1
arg	a string ||| string	count=1
class	frequency distribution if ||| freq dist	count=2
function	to ||| to	count=6
class	the tree in ||| tree	count=1
function	find [function_2] ||| [function_1] [function_2]	count=1
module	file [module] for the ||| [module]	count=1
class	dictionary containing the probdists ||| dictionary	count=1
arg	with first word key ||| key cache cachedepth	count=1
arg	[arg_1] and ranks2 ||| [arg_1] [arg_2]	count=1
module	count error-rate ||| metrics	count=1
function	set the log ||| set	count=1
function	status ||| status	count=1
class	as ||| measures	count=1
function_arg	[function_1] of function ||| [function_1] [arg_2]	count=3
function	megam based on the ||| megam	count=1
function	wu-palmer ||| wup	count=1
function_arg	fileids that [arg_2] ||| [function_1] [arg_2]	count=1
class	[class_1] from contexts ||| [class_2] [class_1]	count=4
arg	10000 ||| trainer n_instances output	count=1
function	top-lebel ||| exprs	count=1
module	consistent with ||| parse	count=1
function	the sentences in ||| sentences from	count=2
function	[function_1] concept ||| [function_1] [function_2]	count=1
function	the set of labels ||| labels	count=1
function	template [function_2] ||| [function_2] [function_1]	count=4
class	of predicates ||| closed world prover	count=1
function	a variety ||| user info	count=1
class	probability state ||| hidden markov model	count=1
class	of the remaining ||| stepping shift reduce parser	count=1
class	given the [class_2] ||| [class_2] [class_1]	count=6
function_arg	lin similarity [arg_2] ||| [function_1] [arg_2]	count=4
arg	given file ||| file	count=1
class	no additional ||| projective	count=1
function	tagged words ||| tagged words	count=2
function	a timer decorator to ||| timer	count=1
class	that ||| sequential backoff	count=1
class	return all ||| opinion lexicon corpus	count=1
class	the corpus ||| nombank corpus	count=1
arg	nodes in the originals ||| originals	count=1
function	variety of information about ||| id	count=1
class	of supported languages as ||| crubadan	count=1
function	train ||| train	count=3
class	this variable [class_2] ||| [class_1] [class_2]	count=5
function	a userid ||| lookup by userid demo	count=1
function	info from the fulltextindex ||| handle fulltextindex elt	count=1
function	[function_1] sets in ||| tag describe [function_1] [function_2]	count=1
arg	the rule data tables ||| rule	count=1
function	known abbreviation ||| abbrev	count=1
function	by a given ||| by	count=1
class	[class_1] frequency distribution ||| [class_2] [class_1]	count=2
arg	given item at the ||| item	count=1
function	containing the names ||| names	count=1
arg	a string of bracketted ||| s	count=1
function	rank [function_2] ||| [function_1] [function_2]	count=4
function	abstractvariableexpression appropriate ||| variable	count=1
function	string value of ||| value	count=1
class	element in a ||| framenet corpus reader	count=1
function	list of words or ||| words	count=1
function	dictionary ||| make predicate dict	count=1
function	to a uniform ||| uniform	count=1
class	path pointer pointing ||| zip file path pointer	count=1
module	internal indexes to ||| corpus	count=1
function	of the columns used ||| column	count=1
class	corpus or for ||| corpus	count=2
arg	frame object ||| frame	count=1
class	[class_1] the corpus ||| [class_2] [class_1]	count=4
function	word ||| head word	count=1
class	a single sentence ||| tn t	count=2
function	[function_1] for the ||| [function_2] [function_1]	count=4
class	number of samples ||| good turing prob dist	count=1
class	store if ||| store	count=1
function	representation of the ||| repr	count=1
module	tag dictionary ||| tag	count=1
arg	:param frame optional frame ||| frame frame2 type	count=1
function_arg	[function_1] probabilistic parsers ||| [arg_2] [function_1]	count=2
class	a text returns a ||| punkt sentence tokenizer	count=1
function	contexts where the specified ||| contexts	count=1
class	the first ||| stepping recursive	count=1
class	[class_1] uses ||| [class_2] [class_1]	count=8
function	targets and frame ||| frames	count=1
module	predicate ||| corpus reader	count=2
arg	the binary ||| binary args	count=1
class	indicates how ||| edge i	count=1
class	within zipfile ||| zip	count=1
arg	the index of the ||| index	count=1
arg	cached ||| key	count=1
class	probability state sequence ||| hidden	count=1
class	be how big the ||| view	count=1
arg	featureset label pair ||| featureset label	count=2
function	a variety ||| user	count=1
class	this rule it ||| rule with context	count=1
function	is a factory ||| expression	count=1
class	underlying [class] decode ||| seekable unicode [class]	count=1
function	the names of ||| names	count=2
function	about the users ||| user info from	count=1
class	two ngrams ||| lin thesaurus	count=1
function	the clustering ||| cluster	count=1
arg	text label tuples ||| label word_tokenizer	count=1
arg	the [arg] this ||| [arg]	count=1
function	right-hand side which ||| rhs	count=1
function	edge in the ||| edge	count=1
class	to ||| chart view	count=2
module_class	[module_1] [class_2] ||| [module_1] canvas [class_2]	count=3
function	words defined in ||| words	count=1
class	all parses that can ||| descent parser	count=2
module_class	any packages ||| core downloader	count=1
class	a feature ||| feat dict	count=1
function	demonstration showing ||| demo	count=3
arg	file s as a ||| fileids strip_space	count=1
function	of words or a ||| words	count=1
class	be how big ||| chart	count=1
function_arg	stem a word ||| stem word	count=2
function	all conditions ||| conditions	count=1
module	called after this ||| draw	count=1
function	nodes traversed on the ||| hypernym paths	count=1
class	supported ||| crubadan corpus	count=1
module	single corpus using ||| corpus reader	count=1
arg	new callback ||| callback	count=1
class	a finnish ||| finnish	count=1
arg	the given zipfile ||| zipfile	count=1
function	str [function_2] ||| [function_1] [function_2]	count=2
arg	the tree structures that ||| tree_class complete	count=1
function	sentence and a ||| of	count=1
arg	newvar ||| newvar	count=2
module	this feature [module] to ||| [module]	count=1
class	return the chart ||| chart parser	count=1
class	the remaining text ||| shift	count=1
class	of the remaining ||| shift reduce parser	count=1
function	a plot ||| plot	count=1
function	load ||| handle luannotationset elt	count=1
class	return the chart ||| stepping chart	count=1
function	crubadan ||| to crubadan	count=2
function_arg	alignments [arg_2] ||| [arg_2] [function_1]	count=6
class	etc ||| chart	count=1
class	the stack ||| parser	count=1
class	given bigram using ||| bigram collocation	count=1
function	by ||| by user demo	count=1
arg	other ||| other check_reentrance visited_self	count=1
function	left [function_2] ||| [function_2] [function_1]	count=1
arg	replace every [arg_1] [arg_2] across every atom ||| inference clause replace [arg_1] [arg_2]	count=1
class	may cause the ||| mutable prob	count=1
class	needs to be ||| chart view	count=1
class	in an subcorpus ||| corpus reader	count=1
module	tag for each ||| tag	count=1
class	function ||| chart parser	count=1
arg	if samples is ||| samples	count=1
function	list ||| user info from id	count=1
module	in this ||| sem	count=2
class	sequence with ||| model tagger	count=1
function	synset relations data ||| relations data	count=2
function	userid ||| userid	count=1
function	illustrate the various ||| drt discourse	count=1
class	zip [class_2] ||| core [class_1] [class_2]	count=1
function	used to resize ||| resize	count=1
arg	synset and the other ||| other	count=1
arg	use a grammar ||| grammar	count=1
class	a ||| reduce parser	count=2
function	measure for ||| measure	count=1
arg	a synset note that ||| synset	count=1
arg	target of its forward ||| forward bindings	count=1
class	the sequence with the ||| hidden markov model	count=1
class	the cached n ||| freq dist	count=1
arg	given ||| chart	count=1
function	update _tag_positions to ||| update tag positions	count=1
arg	be the sole training ||| verbose	count=1
class	rule it has the ||| rule with context	count=1
arg	q ||| q	count=2
class	as ||| crubadan corpus	count=1
function	_readings to construct ||| construct threads	count=1
function	the f-measure ||| f measure	count=1
function	features reflecting ||| feats	count=2
class	before ||| sequence	count=1
class	a german ||| german stemmer	count=1
arg	given resource to a ||| resource_url	count=1
function	convert ||| info from	count=1
function	calls java ||| java	count=1
arg	ranks2 for keys present ||| ranks2	count=1
function	left sibling of ||| left sibling	count=1
function_arg	[function_1] initial_tagger ||| [function_1] [arg_2]	count=1
class	to file or buffer ||| buffered gzip file	count=1
class	the files that have ||| reviews corpus reader	count=1
class	each context to ||| context	count=1
class	tags the sequence with ||| hidden markov model	count=1
module	which ||| core	count=1
arg	zipfile ||| zipfile	count=1
module	[module] a single ||| [module]	count=1
class	to the ||| parser	count=1
function	the topmost hypernyms of ||| root hypernyms	count=1
class	corpus or for the ||| categorized corpus	count=1
arg	of tree the ||| tree treeloc	count=1
arg	return a score denoting ||| other verbose	count=3
class	result to prevent unnecessary ||| resolution	count=1
class	this function must ||| regexp	count=1
function	the number of words ||| num	count=1
class	container [class_2] ||| [class_1] [class_2]	count=1
function	appropriate for the ||| variable expression	count=1
class	end of the ||| stepping shift	count=1
arg	new edge to ||| edge	count=1
function	implements step 3 from ||| step3	count=1
arg	by stems ||| cutlength	count=1
function	is in ||| in	count=1
function	list of the indices ||| parent indices	count=1
class	neural dependency parser ||| neural dependency parser	count=1
class	of ||| shift reduce	count=2
class	corpus ||| propbank corpus reader	count=2
module_class	if this canvas ||| draw canvas	count=1
function	add an [function_2] ||| [function_1] [function_2]	count=4
arg	gold standard ||| gold	count=1
arg	label ||| label	count=2
class	be how ||| chart	count=1
module	return a list of ||| corpus reader	count=1
arg	[arg] still ||| [arg]	count=3
function	condition *o from the ||| ends cvc	count=1
arg	trained ||| unk trained	count=1
function	information about the users ||| id	count=1
module	of the [module] ||| [module]	count=2
function	values for a contingency ||| values	count=1
class	[class_1] set ||| [class_2] [class_1]	count=4
function_arg	[function_1] empty ||| [arg_2] [function_1]	count=3
arg	of word tag tuples ||| c5 strip_space stem	count=1
function	the number [function_2] ||| [function_2] [function_1]	count=2
function	a subtype of abstractvariableexpression ||| expression	count=1
function	a friendly error ||| parse error	count=1
function	realign punctuation ||| realign	count=1
arg	list of word ||| speaker stem	count=1
class	sentence boundary detector or ||| punkt sentence	count=1
class	[class_1] tree ||| [class_1] [class_2]	count=3
arg	of its forward ||| forward bindings	count=1
class	that is licensed ||| recursive descent parser	count=1
function	upper frame [function_2] ||| [function_2] [function_1]	count=2
class	this sentence [class_2] ||| [class_2] [class_1]	count=8
class	corpus reader for a ||| corpus reader	count=3
function	self ||| add	count=1
function_arg	the average [arg_2] ||| [function_1] [arg_2]	count=3
module	entailment attribute [module] ||| [module]	count=3
class	of the moses tokenizer ||| moses tokenizer	count=1
class	this encoding ||| typed maxent feature encoding	count=1
function	the topmost hypernyms ||| root hypernyms	count=1
arg	given user ||| user	count=1
class	[class_1] parsing a ||| [class_1] [class_2]	count=4
class	likelihood ||| space clusterer	count=1
arg	tokenizes a ||| tgrep_string	count=1
function	from the beginning of ||| shift	count=2
arg	limit the number ||| limit	count=1
arg	the reference ||| references	count=1
class	function must ||| drt glue	count=1
class	maltparser ||| malt	count=2
class	to ||| stepping	count=1
class	this corpus ||| twitter corpus	count=1
class	how big a unit ||| chart view	count=1
class	called if ||| drt glue demo	count=1
class	this function must be ||| chart parser	count=1
class	:param ||| base theorem tool command	count=1
arg	on the input text ||| text	count=1
arg	following ||| format cache verbose	count=1
arg	fstruct1 and fstruct2 ||| fstruct1 fstruct2	count=1
function	creates a table ||| table	count=1
class	add all edges licensed [class_1] [class_2] are currently in the ||| [class_2] [class_1] apply everywhere chart grammar	count=2
function	and a list of ||| list	count=1
arg	from a word-aligned ||| srctext trgtext alignment max_phrase_length	count=1
arg	sure that s ||| s verify_tags	count=1
function	return a matrix ||| matrix	count=1
class	brill tagger on the ||| brill tagger trainer	count=1
class	enter ||| chunk	count=1
class	chart rule ||| chart parser	count=1
arg	to implement the view ||| fileid unit bracket_sent	count=1
function	counter from the url ||| counter from url	count=1
module	tweets ||| twitter	count=6
function	most ||| most	count=1
function	[function_1] pointer ||| [function_1] [function_2]	count=4
function	normalize ||| normalize	count=1
function	analyze ||| analyze	count=1
function	abstractvariableexpression appropriate for ||| expression	count=1
arg	of a single sentence ||| sentence threaded verbose filter	count=1
function_arg	[function_1] translating the ||| [arg_2] [function_1]	count=3
arg	in positions where it ||| positions	count=1
arg	the vectors to ||| vectors	count=1
class	by this variable binder ||| variable binder	count=1
function	variety of ||| info from	count=1
class	bigram collocation finder with ||| collocation finder	count=1
arg	should otherwise [arg] included ||| [arg]	count=1
function	a given training ||| train	count=2
class	simple [class_2] ||| [class_1] [class_2]	count=2
module_class	[module_1] corpus and ||| [module_1] pickle [class_2]	count=1
class	needs to be ||| view	count=1
function_arg	[function_1] [arg_2] underlying ||| [function_1] [arg_2]	count=2
arg	[arg_1] as tuples ||| [arg_2] [arg_1]	count=1
class	a [class_1] [class_2] ||| [class_2] [class_1]	count=2
function	arcs to ||| redirect arcs	count=1
arg	if no filename ||| filename verbose	count=1
function	rule [function_2] ||| [function_2] [function_1]	count=2
arg	:param positive_featuresets ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
function	head of the entire ||| head	count=1
class	state ||| hidden markov	count=1
function	standard interpretations of ||| r1r2 standard	count=2
arg	[arg_1] frameid ||| [arg_1] [arg_2]	count=4
class	verbnet class ||| verbnet	count=2
class	set to 0 75 ||| kneser ney prob dist	count=1
class	bigram collocation ||| trigram collocation	count=1
function_arg	phonetic segments [arg_2] ||| [arg_2] [function_1]	count=6
class	supported languages as ||| corpus	count=1
class	container [class_2] ||| [class_2] [class_1]	count=1
class	to file ||| file	count=1
class	to invalidate the cached ||| dist	count=1
class	frontier ||| recursive descent parser	count=1
function_arg	[function_1] print classifier ||| [function_1] test_set [arg_2]	count=1
arg	n-gram ||| min_len	count=2
class	given a ngramassocmeasures ||| contingency measures	count=1
function	deleting ||| remove variables	count=2
arg	given freqdists for appearances ||| word_fd bigram_fd	count=1
function	past tweets by a ||| tweets by user	count=1
arg	register a new callback ||| callback	count=1
function_arg	[function_1] [arg_2] ||| [function_1] s [arg_2]	count=4
function	unique counter [function_2] ||| [function_1] [function_2]	count=3
module	should be ||| app	count=1
class	rule that changes a ||| rule	count=1
function	pointer forward ||| forward	count=1
function	[function_1] clusters ||| [function_2] [function_1]	count=3
arg	data ||| data	count=6
function	descended from the ||| descendants	count=1
arg	frameid and framename ||| frameid	count=1
class	called ||| chunk	count=1
function	static web ||| get static web	count=2
class	for a given trigram ||| trigram collocation	count=1
function	chomsky normal [function_2] ||| [function_2] [function_1]	count=2
arg	frameid ||| frameid	count=1
function_arg	experiment _create_rand_fdist [arg_2] ||| [function_1] [arg_2]	count=2
function	iso 639-3 codes ||| langs	count=1
class	how much ||| edge i	count=1
function	already been [function] this ||| ensure [function]	count=1
function_arg	the beginning [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	list [arg_2] ||| [arg_2] [function_1]	count=1
class	the first ||| stepping	count=1
function	build a nltk ||| test build	count=1
arg	train and test a ||| trainer save_analyzer n_instances	count=1
function	*rule* applies at the ||| applies	count=1
function	words screenanames hashtags urls ||| tokenized	count=1
class	em clusterer ||| emclusterer	count=1
module	return true ||| core	count=8
arg	given the original text ||| text	count=1
class	grammar from the set ||| grammar	count=1
function	[function_1] chunk the ||| [function_2] [function_1]	count=2
arg	devset_name ||| devset_name devset grammar	count=1
function_arg	[function_1] labels a ||| [arg_2] [function_1]	count=2
module	tag for the specified ||| tag	count=1
arg	file s ||| fileids c5	count=2
function	out ||| show	count=1
class	the chart rule used ||| chart parser	count=1
arg	of children that cover ||| constituents	count=1
module	probability state ||| tag	count=1
arg	of tree [arg_2] ||| core tree convert [arg_2] [arg_1]	count=1
class	all verb ||| verbnet corpus reader	count=1
class	substitution corresponding to ||| ccgvar	count=1
class	this method serves ||| drt	count=1
class	parsing a text ||| parser	count=2
class	this ||| parser	count=1
class	called ||| regexp	count=1
function	string representing a ||| aug	count=1
module	a subtype of abstractvariableexpression ||| sem	count=1
arg	[arg_1] f ||| [arg_2] [arg_1]	count=3
function	a list ||| user info	count=1
arg	replace [arg_1] [arg_2] across every atom ||| [arg_1] [arg_2]	count=1
class	must be called if ||| chunk	count=1
class	single parsing ||| parser	count=1
class	licensed [class] ||| [class]	count=4
function	return internal crubadan ||| crubadan	count=1
function_arg	[function_1] word ||| [arg_2] [function_1]	count=4
class	relative to ||| paice	count=1
function	roleset used by this ||| roleset	count=1
arg	ngram ||| ngram	count=1
function_arg	lists for [arg_2] ||| [function_1] [arg_2]	count=1
class	grammar from ||| grammar	count=1
function	interpretations of the string ||| r1r2	count=1
class	state sequence this ||| model tagger	count=1
arg	of samples ||| samples	count=1
function	illustrate the various ||| discourse	count=2
class	confusion matrix ||| confusion matrix	count=4
class	the perl unicode properties ||| unichars	count=1
function	with the given ||| by	count=1
class	of the moses ||| moses	count=2
arg	a quadgramcollocationfinder [arg_2] ||| [arg_2] [arg_1]	count=2
arg	return ||| other ic verbose	count=1
module_class	of this feature ||| core feature	count=1
class	this function ||| regexp chunk	count=1
function	some proofs and ||| model	count=1
function	that are immediately before ||| immediately before	count=1
module_class	[module_1] parser ||| [module_1] [class_2]	count=2
function	encoded as a ||| chunked	count=1
function	a new [function_2] ||| [function_1] [function_2]	count=4
class	the parser uses ||| parser	count=1
function	a list of ||| info	count=1
arg	repeatedly taking ||| train_sents test_sents min_score min_acc	count=1
function	the table's _rows variable ||| check table	count=1
function	are ||| find top	count=1
arg	trees [arg_2] ||| [arg_1] [arg_2]	count=3
function	an integer or float ||| number	count=1
class	function must be called ||| regexp	count=1
arg	by stems defined ||| cutlength	count=1
function	closest length to the ||| closest ref length	count=1
class	[class_1] a quadgram ||| [class_2] [class_1]	count=2
function	a demonstration ||| malt demo	count=1
arg	the highest information content ||| ic	count=1
function	[function_1] alignment ||| [function_1] model2 [function_2]	count=2
class	the stack ||| stepping	count=1
arg	format ||| format	count=1
function	[function_1] tree ||| [function_1] [function_2]	count=1
class	the chart rule used ||| stepping chart parser	count=1
class	state sequence this ||| hidden	count=1
class	the text contents ||| senseval corpus	count=1
module	return an ||| core	count=2
class	a ||| chart view	count=1
class	counts ||| conditional freq dist	count=2
class	of ||| stepping recursive descent	count=1
function	file and ||| file	count=1
arg	print classifier performance ||| test_set classifier accuracy f_measure	count=1
class	to the end ||| shift	count=1
function	the grammar is ||| calculate grammar	count=2
function_arg	approximate score [arg_2] ||| [function_1] [arg_2]	count=2
arg	the words through ||| words	count=1
class	error-rate relative to ||| paice	count=1
arg	[arg] and ||| [arg]	count=1
arg	document of each of ||| document	count=2
class	starting at the path ||| path	count=1
module	predicate ||| corpus	count=1
function_arg	stem a [arg_2] ||| [function_1] [arg_2]	count=3
class	of this alignedsent ||| aligned sent	count=1
arg	frame object name ||| frame	count=1
arg	should be used ||| tokens index	count=2
class	contexts ||| minimal set	count=1
function	to ||| to parse	count=1
class	hypothesized ||| i	count=1
function	pretty-printing a frame ||| pretty	count=1
class	enter the ||| chunk	count=1
arg	unigrams ||| unigrams handle_negation	count=1
function	to each tkinter label ||| to columns	count=1
class	list of all verb ||| verbnet corpus	count=1
function	static ||| static	count=1
module_class	[module_1] [class_2] graphical ||| [module_1] [class_2] tags	count=4
arg	ngram is in ||| ngram	count=1
function	a dictionary ||| predicate dict	count=1
function	illustrate the ||| drt discourse demo	count=1
class	tags ||| markov model tagger	count=2
function	is ||| variable	count=1
function_arg	indent an ||| indent elem level	count=1
function	used ||| find	count=1
class	be called ||| regexp chunk	count=1
function_arg	[function_1] filename ||| [arg_2] [function_1]	count=1
class	called if ||| parser	count=1
class	this encoding ||| feature encoding	count=2
function	of variables [function_2] ||| [function_2] [function_1]	count=4
arg	the input ||| input	count=1
class	words in alphabetical ||| lexicon corpus	count=1
class	remaining text to the ||| stepping shift	count=1
function	str rule and rule ||| demo str rule	count=1
arg	initial_tagger the ||| initial_tagger rules training_stats	count=1
function	and a list ||| list	count=1
function_arg	categories for [arg_2] ||| [arg_2] [function_1]	count=1
class	given bigram using ||| bigram	count=1
arg	a string of bracketted ||| s chunk_label	count=1
function	lemmas in ||| lemmas	count=1
arg	segmentation [arg_2] ||| [arg_2] [arg_1]	count=1
function	level chrf character ||| chrf	count=1
arg	reference ||| references hyp_len	count=1
function	the euclidean [function_2] ||| [function_1] [function_2]	count=1
function	of all [function_2] ||| [function_2] [function_1]	count=2
class	uses to generate featuresets ||| based	count=1
function	topmost hypernyms ||| root hypernyms	count=1
class	internal indexes to ||| framenet corpus	count=1
module	tree ||| app	count=1
function	perform the first pass ||| annotate first pass	count=1
module	state sequence ||| tag	count=1
arg	function finds the reference ||| references hyp_len	count=1
class	token from ||| stepping shift reduce	count=1
class	this function ||| parser	count=1
class	[class_1] parser ||| [class_1] [class_2]	count=7
arg	s as a list ||| fileids tagset	count=2
function	illustrate the ||| demo	count=2
module	of the hypothesized structure ||| parse	count=1
arg	alignment ||| alignment_info	count=2
arg	be [arg_2] ||| [arg_1] [arg_2]	count=1
arg	given file s as ||| fileids c5	count=2
class	a list of supported ||| corpus	count=1
function	unique counter from ||| unique counter from	count=1
function	adjust the scrollregion ||| adjust scrollregion	count=1
class	probability state ||| hidden markov	count=1
function	closest ||| closest	count=1
arg	given a featureset label ||| featureset label	count=1
function	all frames that contain ||| frames	count=1
class	for this corpus or ||| categorized corpus reader	count=1
arg	data ||| data start	count=1
function	hole that will be ||| hole	count=1
function_arg	[function_1] an ||| [function_1] [arg_2]	count=4
class	the internal indexes to ||| corpus reader	count=1
function	right ||| right	count=1
class	tweets as as a ||| twitter corpus reader	count=1
class	all parses that ||| descent parser	count=2
function	returns the number of ||| num	count=1
function	arc ||| add arc	count=1
function	hole that [function_2] ||| [function_2] [function_1]	count=2
function	a single ||| raw	count=1
function	[function_1] used ||| [function_2] [function_1]	count=11
arg	of the regular expression ||| regexp	count=2
function	abstractvariableexpression appropriate ||| variable expression	count=1
function	of this chart's leaves ||| leaves	count=1
function	list of ||| id	count=1
class	all ||| comparative	count=1
class	much of the hypothesized ||| edge i	count=1
arg	a punktparameters object ||| lang_vars token_cls	count=1
function	parse ||| tagged parse	count=2
class	feature-based grammar from ||| feature grammar	count=1
class	dictionary containing the ||| dictionary conditional prob	count=1
function	[function_1] counter ||| [function_1] [function_2]	count=3
class	rule and the ||| chart rule	count=1
class	tree ||| tree pretty	count=1
function	mappings of lemmas ||| lemmas	count=1
class	as positive examples (i ||| positive naive bayes classifier	count=1
function	lookup 'key' ||| lookup	count=1
function	_sentences to construct a ||| construct readings	count=1
class	a ||| reduce	count=1
class	a variety of ||| query	count=1
class	generated ||| arff formatter	count=1
arg	starting at [arg_1] [arg_2] ||| metrics retrieve [arg_1] [arg_2]	count=1
function	build a ||| test build	count=1
module	and set ||| core	count=1
function	the word ||| is head word	count=1
function	a string ||| format	count=1
function	disable warnings ||| warnings	count=1
arg	rows and columns ||| rows cols attempts	count=1
class	how much ||| i	count=1
class	repp [class_2] ||| [class_2] [class_1]	count=3
function	maltparser [function_2] ||| parse find [function_1] [function_2]	count=1
class	enter ||| drt	count=1
function	2 retrieve an access ||| access	count=1
arg	distortion [arg] ||| sentence_aligned_corpus iterations [arg]	count=3
class	identifiers for ||| ycoecorpus reader	count=1
arg	the trees ||| trees	count=2
class	the conditional frequency ||| core conditional freq	count=1
module	corpus or that ||| corpus reader	count=1
arg	produce the *worder* ||| hypothesis character_based	count=1
class	the ||| reader	count=1
function	score ||| future score	count=1
function	create a dictionary of ||| dict	count=1
function	_tag_positions to reflect ||| positions	count=1
class	the frontier in particular ||| recursive descent parser	count=1
arg	production to combine the ||| production	count=1
function	with the ||| tag	count=1
function	rare ||| rare	count=1
function	the primitive is the ||| primitive	count=1
function_arg	[function_1] boxer_drs_interpreter a ||| [function_1] [arg_2]	count=1
class	parser and the stanfordcorenlp ||| parser	count=1
function	set the node label ||| set label	count=1
function	six patterns ||| pro w64	count=2
class	transformational ||| brill template	count=1
arg	:param show all neg ||| show	count=1
class	in ||| stepping recursive descent parser	count=1
function	of clusters ||| clusters	count=1
arg	reference ||| reference	count=7
function	initialize ||| init	count=5
function_arg	demonstration of [arg_2] ||| [function_1] [arg_2]	count=4
module	corpus or that ||| corpus	count=1
function	instantiates and returns a ||| expression	count=1
function	show the readings ||| readings	count=1
class	the remaining ||| stepping	count=1
arg	starts the hunpos-tag ||| path_to_bin encoding	count=1
function	ratios as in ||| ratio	count=1
function	of modifiers is listed ||| arity parse	count=1
arg	appear in the reference ||| reference	count=1
class	in particular ||| parser	count=1
arg	in the document ||| document	count=2
function	path ||| path	count=3
arg	cluster ||| cluster	count=1
class	compute ||| corpus reader	count=1
module	the end of ||| parse	count=1
arg	row to ||| rowvalue	count=1
function	assumes ||| read tweets	count=1
class	supported languages as ||| crubadan corpus reader	count=1
arg	information content value ||| synset1 synset2 ic verbose	count=1
class	the path [class_2] ||| [class_2] [class_1]	count=1
function	pass of annotation ||| pass	count=1
class	list of file identifiers ||| ycoecorpus reader	count=1
arg	element that matches tagspec, ||| tagspec elt_handler	count=1
function	hole ||| hole	count=1
arg	return a score ||| other ic verbose	count=1
function	return a string ||| format	count=1
class	if ||| regexp chunk app	count=1
class	the fixed-length [class] that are ||| [class] encoding	count=1
arg	given file s as ||| fileids	count=18
class	of this confusion matrix ||| confusion matrix	count=1
function	literal predicates ||| literal	count=1
arg	iter tree :return an ||| rtext tree frontier	count=1
arg	id luname ||| fn_luid ignorekeys luname	count=1
function	the fulltextindex xml ||| fulltextindex elt	count=1
function_arg	given training [arg_2] ||| [function_1] [arg_2]	count=2
class	the tree should ||| chart view	count=1
function	contains a [function_2] ||| [function_1] [function_2]	count=1
arg	be trained ||| trained	count=1
function	button press ||| press cb	count=1
arg	bindings with the ||| fstruct bindings	count=1
arg	highest information content ||| synset1 synset2 ic verbose	count=1
function	true if the given ||| in range	count=1
class	projective dependency ||| projective dependency	count=1
class	a corpus ||| propbank corpus	count=1
function	web ||| web	count=1
function_arg	given location ||| in range location	count=1
function	tweets tokenized ||| demo tweets	count=1
arg	original text and ||| text	count=1
module_class	over this [class_2] ||| [module_1] [class_2]	count=1
function	dictionary of bigram ||| bigram	count=1
function_arg	[function_1] document ||| [arg_2] [function_1]	count=4
class	the remaining text ||| reduce parser	count=1
class	binder in the ||| binder	count=1
arg	of a single sentence ||| sentence threaded	count=1
function	top of ||| find top	count=1
arg	tokenizes ||| tgrep_string	count=1
function	user ||| user demo	count=1
class	from contexts to ||| context	count=1
function	all possible [function_2] ||| [function_2] [function_1]	count=2
function	only relations involving ||| relations	count=1
arg	helper for [arg] ||| [arg]	count=1
class	projective dependency ||| projective dependency parser	count=2
function	to invalidate the ||| setitem	count=1
arg	a line ||| line	count=1
class	a bigram ||| bigram	count=1
module	list of supported languages ||| reader	count=1
arg	fstruct1 with fstruct2, ||| fstruct1 fstruct2 bindings trace	count=1
class	expression for ||| imp expression	count=1
module_class	return all [class_2] ||| [module_1] [class_2]	count=2
class	neural dependency [class_2] ||| [class_2] [class_1]	count=4
class	a feature with ||| feat	count=2
function	the indices ||| indices	count=1
arg	[arg] function ||| [arg]	count=3
arg	helper used to implement ||| bracket_sent	count=1
class	the file ||| file	count=1
class	state sequence this ||| tagger	count=1
function	[function_1] sets in ||| [function_2] [function_1]	count=1
class	distribution if ||| dist	count=1
function_arg	root counting [arg_2] ||| [function_1] [arg_2]	count=3
class	return ||| edge	count=1
arg	for one [arg] ||| [arg]	count=6
module	this corpus or that ||| corpus reader	count=1
class	the ||| shift reduce	count=4
arg	can be extracted ||| tokens trace	count=2
class	exemplar ||| corpus reader	count=1
function	probability state ||| tag	count=1
function	arc from the ||| add arc	count=1
class	words in alphabetical order ||| opinion lexicon	count=1
arg	string containing a ||| vnframe	count=1
function	find all [function_2] ||| [function_1] [function_2]	count=1
arg	collection of documents each ||| cls documents	count=1
class	with the ||| hidden markov model tagger	count=1
function	all variables in this ||| variables	count=1
class	of the inside probabilities ||| inside	count=1
function	factory method that ||| expression	count=1
arg	symbol being observed in ||| state symbol	count=1
module	list ||| corpus	count=1
arg	"known labels" for ||| mapping unseen_features alwayson_features	count=2
class	the iso 639-3 ||| crubadan	count=1
class	must be ||| glue	count=1
arg	to implement ||| bracket_sent	count=1
function	stop bounds ||| bounds	count=1
arg	function ||| function	count=1
function	return the start ||| start	count=1
arg	return a score denoting ||| other	count=4
class	best ||| probabilistic nonprojective parser	count=1
arg	b is [arg] ||| [arg]	count=1
class	state sequence ||| markov model tagger	count=1
class	lemma ||| word net corpus reader	count=1
function	step 5a ||| step5b	count=1
function	binary concept ||| binary concept	count=2
class	[class_1] stream ||| core [class_1] [class_2]	count=1
function	of information about the ||| from id	count=1
function_arg	[function_1] of tree ||| [arg_2] [function_1]	count=2
function	single-line [function] of ||| [function]	count=1
arg	positions where it ||| tokens positions	count=1
class	encoded as ||| chunked corpus reader	count=3
function	unique [function_2] ||| [function_2] [function_1]	count=4
function	determine an appropriate ||| one	count=1
function_arg	[function_1] string ||| [function_1] [arg_2]	count=1
class	a token from the ||| reduce parser	count=1
class	called if ||| demo	count=1
function	the various methods ||| drt	count=1
class	to file ||| buffered gzip file	count=1
function_arg	[function_1] [arg_2] the ||| [function_1] [arg_2]	count=4
class	the bounding boxes of ||| scroll watcher widget	count=1
function	return a string containing ||| pretty format	count=1
arg	that matches tagspec, ||| tagspec elt_handler	count=1
class	tree or ||| tree	count=2
class	of the frontier ||| stepping recursive descent parser	count=1
module	return an iterator that ||| core	count=1
function	two sentences ||| align	count=1
function	s-expressions from ||| sexpr	count=1
class	languages as ||| reader	count=1
arg	the left-hand side ||| lhs rhs	count=2
arg	[arg] decode ||| [arg]	count=3
class	encoding ||| binary maxent feature encoding	count=1
arg	can be [arg_2] ||| [arg_2] [arg_1]	count=1
function	- record the button ||| cb	count=1
class	that the parser ||| parser	count=1
class	calculates values of a ||| assoc measures	count=2
arg	v this is equivalent ||| v	count=1
module_class	this parser ||| parse parser	count=1
class	tree should be etc ||| chart	count=1
class	chart rule ||| stepping chart	count=1
function	clustering parameters from the ||| cluster	count=1
class	pointer ||| tree pointer	count=2
function	the ||| discourse	count=2
arg	any word between them ||| wildcard_fd trigram_fd	count=1
function	chunk the given list ||| chunk	count=2
arg	frame optional frame ||| frame frame2 type	count=1
class	probability state ||| hidden	count=1
arg	child to ||| child	count=2
class	sentence string ||| chart view	count=1
function	the height ||| height	count=2
class	must be ||| parser app	count=1
class	the frontier in ||| descent parser	count=1
class	tree or none if ||| tree	count=2
function	to be overridden ||| get all symbols	count=1
class	encoded as ||| tagged corpus reader	count=2
class	first element ||| stepping recursive descent	count=1
class	as a list ||| corpus	count=1
class	discourse ||| discourse tester	count=1
class	this rule ||| chunk rule with	count=1
arg	[arg] starting ||| i j [arg]	count=3
class	expression for the ||| application expression	count=1
class	639-3 ||| crubadan corpus reader	count=1
class	the expression ||| drt lambda expression	count=1
function	the fulltextindex xml ||| handle fulltextindex elt	count=1
function	was [function] ||| trace [function]	count=1
arg	left-hand side ||| lhs rhs	count=2
class	this function must be ||| chart parser app	count=1
function	users ||| user	count=1
function	a subcorpus ||| handle lusentence	count=1
class	a list of supported ||| crubadan	count=1
arg	:param index the index ||| index depth	count=1
class	over sets of ||| classifier i	count=1
function	the first pass ||| annotate first pass	count=2
function	a binding ||| bind	count=3
class	the sequence ||| hidden markov model	count=1
module	conjunctive normal form ||| sem	count=1
function	convert ||| from	count=1
module	from nltk corpus import ||| corpus reader	count=1
function	output [function] produces ||| grow diag final [function]	count=1
class	necessary ||| nkjpcorpus reader	count=1
function_arg	entity to [arg_2] ||| [arg_2] [function_1]	count=1
function	subcorpus of an ||| lusentence	count=1
class	of words for ||| swadesh corpus reader	count=2
function	the kendall's [function] correlation ||| kendall [function]	count=1
module	method that instantiates ||| sem	count=1
class	a list ||| crubadan	count=1
function	sentence ||| of fes	count=2
function	of lemmas in the ||| lemmas	count=1
function	verbose string representation of ||| str	count=1
function	set the value by ||| set	count=1
function_arg	[function_1] expressed as ||| [function_1] [arg_2]	count=16
class	mtecorpusreader ||| mtecorpus	count=1
arg	in positions where ||| positions	count=1
function	one entity ||| entity	count=1
arg	modelbuildercommand modelbuildercommand to decorate ||| modelbuildercommand	count=1
arg	list [arg_2] ||| [arg_2] [arg_1]	count=2
class	the frontier in ||| recursive descent parser	count=1
function	the block comparison method ||| block comparison	count=1
arg	of its forward ||| forward	count=2
arg	override counter __setitem__() ||| key val	count=1
function_arg	[function_1] word ||| [function_1] [arg_2]	count=4
function	first pass of annotation ||| annotate first pass	count=1
class	the ||| hidden markov	count=2
class	count error-rate ||| paice	count=1
class	for ||| lin thesaurus corpus reader	count=1
function	userid ||| lookup by userid demo	count=1
function	relation to ||| tgrep relation	count=1
class	[class_1] corpus and ||| [class_2] [class_1]	count=2
function	modify ||| modify	count=1
class	must ||| chunk	count=1
module	for this corpus view ||| corpus reader	count=4
arg	tweet ids ||| ids_f	count=1
class	if the token's ||| token	count=1
function	the node label ||| tgrep node label	count=2
arg	context_to_tag a dictionary ||| context_to_tag backoff	count=1
class	dictionary containing ||| dictionary	count=1
function	information about the ||| user info from id	count=1
module	opened ||| core	count=1
class	from ||| stepping	count=1
function	read a ||| read	count=2
class	a list of ||| crubadan	count=1
arg	and ranks2 ||| ranks2	count=1
module	relative ||| metrics	count=1
class	cmudict lexicon as a ||| cmudict corpus reader	count=1
arg	with the [arg] ||| words [arg]	count=1
class	the corpus or in ||| corpus reader	count=1
arg	returns a list of ||| fileids	count=1
function_arg	skolemize the [arg_2] ||| [arg_2] [function_1]	count=5
arg	for cls ||| cls	count=1
class	return ||| opinion lexicon	count=1
arg	used to generate freqdist ||| freqdist gamma bins	count=1
function_arg	[function_1] of strings ||| [function_1] [arg_2]	count=3
class	probability distribution for the ||| prob dist	count=3
class	joint-feature vectors [class_2] ||| classify [class_1] [class_2]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] word [arg_2]	count=9
class	[class_1] a bigram ||| [class_2] [class_1]	count=2
arg	true if stem ||| stem	count=1
arg	sentence into ||| sentence	count=1
function	using the [function] node ||| [function] node literal	count=1
class	needs to ||| view	count=1
class	of the remaining text ||| stepping shift reduce	count=1
arg	documents each ||| cls documents	count=1
function	a list of chunks ||| chunk	count=1
class	trigram using ||| trigram	count=1
function	returns the names ||| names	count=1
module	return a list of ||| corpus	count=1
function	a list of fileids ||| fileids	count=1
function	md5 [function_2] ||| [function_2] [function_1]	count=3
function	method that ||| variable	count=1
module	file [module] for ||| [module]	count=1
function	obtained by deleting ||| remove variables	count=1
function	[function_1] data for ||| [function_2] [function_1]	count=3
function	all frames ||| frames	count=1
function	creates a new ||| add	count=1
class	widget ||| widget	count=15
module	tweets are coming ||| twitter	count=1
class	canvas widget's bounding box ||| canvas	count=2
class	a standard format ||| standard format	count=2
function_arg	add hypothesis to ||| push hypothesis	count=1
class	change ||| descent parser	count=1
arg	that these ||| fileids	count=1
class	[class_1] grammar ||| [class_1] [class_2]	count=1
class	return a list of ||| corpus	count=1
function_arg	a custom [arg_2] ||| [arg_2] [function_1]	count=3
function	replacing each feature ||| retract bindings	count=1
arg	the xml description ||| roleset_id	count=1
function	get synset [function_2] ||| [function_1] [function_2]	count=4
function	be ||| file	count=1
arg	[arg_1] extracted ||| [arg_1] [arg_2]	count=3
function	all possible ||| all	count=2
function	[function_1] normal ||| [function_2] [function_1]	count=3
function	a projective dependency ||| projective rule	count=1
function	variety of ||| user	count=1
arg	into a ||| read	count=1
function	number of rows ||| len	count=1
class	frontier in particular ||| recursive	count=1
function	citation bib file ||| citation	count=1
function	list of all frames ||| frames	count=1
function_arg	distance [arg_2] ||| [arg_2] [function_1]	count=9
function_arg	[function_1] variable v ||| [arg_2] [function_1]	count=3
class	box ||| box	count=1
class	function must be called ||| glue demo	count=1
class	grammar can ||| cfg	count=1
class	sequence ||| markov model tagger	count=4
function	labels for the given ||| classify	count=3
arg	expressed as a ||| src_sentence trg_sentence	count=2
class	context-free grammar ||| cfg	count=1
class	new feature ||| feature	count=2
function	the errors ||| error	count=1
class	in ||| opinion lexicon corpus	count=1
class	this confusion [class_2] ||| [class_1] [class_2]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] a given s [arg_2]	count=6
class	text ||| shift reduce parser	count=1
class	to 0 75 ||| kneser ney prob	count=1
class	import the module ||| module	count=1
function_arg	[function_1] and ||| [function_1] [arg_2]	count=11
arg	s as a list ||| fileids strip_space	count=1
function	sort the ||| sort	count=2
function	of left [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] page ||| [function_1] [function_2]	count=12
arg	the chart parsers ||| choice print_times print_grammar print_trees	count=1
module_class	aligned [class_2] ||| [module_1] [class_2]	count=5
function	returns a freqdist ||| freq threshold	count=1
arg	vectors ||| vectors	count=1
class	dict of (corpus_property_key value) ||| childescorpus reader	count=1
function	[function_1] distance ||| [function_1] [function_2]	count=4
module	recursive descent ||| parse	count=1
arg	all nonterminals ||| cat	count=1
function	the similarity score ||| similarity	count=1
module	representation for this corpus ||| corpus	count=4
function	[function_1] [function_2] ||| [function_2] tokenizer [function_1]	count=1
class	:param ||| dependency evaluator	count=1
arg	false otherwise ||| node_address	count=1
function	:return whether the word ||| is head word	count=1
function_arg	the given [arg_2] ||| [arg_2] [function_1]	count=5
class	end of the stack ||| shift reduce	count=1
class	the same sentence ||| sentence tokenizer	count=1
arg	sentence pair from ||| sentence_pair	count=2
class	text to ||| stepping shift reduce parser	count=1
arg	lists frame ||| frame	count=1
class	text to the end ||| shift reduce parser	count=1
class	bigram collocation ||| collocation	count=1
class	a dictionary containing ||| dictionary conditional prob dist	count=1
class	text ||| stepping shift reduce parser	count=1
arg	of segmentations [arg_2] ||| [arg_2] [arg_1]	count=4
arg	appearances ||| word_fd bigram_fd	count=1
function	maltparser command use at ||| malt command	count=1
function	subtype of abstractvariableexpression ||| expression	count=1
function_arg	[function_1] variable ||| [arg_2] [function_1]	count=3
module	some full [module] in json ||| [module]	count=1
arg	sequence of ||| sequence	count=3
module	indexes to ||| corpus	count=1
class	this function must be ||| demo	count=1
class	end ||| parser	count=1
class	text to the end ||| stepping	count=1
class	constructs a collocation finder ||| collocation finder	count=1
arg	a bracketed tree ||| brackets read_node	count=1
function	[function_1] alignment algorithm ||| [function_1] [function_2]	count=1
function	[function] should be ||| demo multiposition [function]	count=3
function	[function_1] label ||| [function_1] [function_2]	count=7
class	[class_1] [class_2] results ||| [class_1] [class_2] renormalize r nr	count=9
function	given an exemplar sentence ||| exemplar of	count=1
class	order ||| reader	count=1
arg	counted as ||| cur_tok next_tok	count=1
arg	containing a pretty-printed ||| width	count=1
class	table's main ||| table	count=1
class	[class_1] sentence ||| [class_2] [class_1]	count=10
class	standard format marker ||| standard format	count=1
module	into ||| parse	count=1
function	3 from "an ||| step3	count=1
module	and whose root ||| parse	count=1
class	cmudict lexicon [class_2] ||| [class_1] [class_2]	count=4
class	by this [class_2] ||| [class_2] [class_1]	count=10
function	the fulltextindex xml file ||| fulltextindex	count=1
class	this decision ||| decision	count=1
arg	and an alignment ||| alignment_info	count=2
arg	frame optional frame object ||| frame	count=1
function	nltk's recommended word tokenizer ||| word	count=1
class	buffered gzip ||| buffered gzip	count=1
arg	metric ||| label1 label2	count=1
class	of the ||| stepping shift reduce	count=2
module	return ||| reader	count=2
class	internal indexes ||| corpus	count=1
class	pointer ||| nombank tree pointer	count=1
module	of ||| corpus reader	count=4
arg	given text if ||| text verbose	count=2
class	of the frontier ||| recursive	count=1
class	[class_1] sentences in ||| [class_1] [class_2]	count=1
class	total mass of probability ||| prob	count=1
class	read ||| stream reader	count=1
function	and returns ||| variable expression	count=1
class	binder in ||| binder	count=1
arg	the list of samples ||| samples store_logs	count=1
function	assumes that each ||| tweets	count=1
arg	filtered by ||| rhs empty	count=2
function	frame xml ||| frame	count=1
class	[class_1] encoding ||| [class_2] [class_1]	count=1
class	string to figure ||| chart view	count=1
function	the root counting the ||| hypernym distances	count=1
function	friendly error message when ||| parse error	count=1
class	be called if ||| glue	count=1
class	from the frequency ||| freq	count=1
function	returns a subtype ||| variable	count=1
function	demonstration showing the creation ||| parse demo	count=1
function	corresponding string ||| tuple2str	count=1
arg	the given file s ||| fileids strip_space	count=1
module_class	[module_1] feature dictionary ||| [module_1] [class_2]	count=2
arg	return a ||| other	count=4
arg	words by stems ||| words cutlength	count=2
class	are generated [class] ||| maxent feature [class]	count=1
class	list specifying ||| mtecorpus	count=1
class	punkt ||| punkt	count=1
module	count ||| metrics	count=1
class	of the frontier ||| descent	count=1
function	evaluate ||| evaluate	count=1
function	print the available [function_1] [function_2] ||| tag describe [function_1] [function_2]	count=4
function	returns the likelihood a ||| likelihood	count=1
class	this corpus ||| chunked corpus reader	count=1
class	new classifier based on ||| classifier based tagger	count=1
function	experiment _create_rand_fdist ||| create sum pdist	count=1
function	the sequence with ||| tag	count=1
arg	[arg_1] string ||| [arg_2] [arg_1]	count=6
function_arg	:param int [arg_2] ||| [arg_2] [function_1]	count=4
class	of words [class_2] ||| [class_2] [class_1]	count=3
function_arg	wu-palmer similarity [arg_2] ||| [function_1] [arg_2]	count=4
class	of a dependency ||| projective dependency parser	count=1
function	list of all words ||| words	count=1
arg	child ||| child index dry_run	count=1
function	first pass of ||| first pass	count=1
function	of information ||| user	count=1
function	subtype of abstractvariableexpression appropriate ||| variable	count=1
function	conditions that have ||| conditions	count=1
function	chart ||| chart	count=2
function	make sure that a ||| check	count=1
arg	text [arg_2] ||| [arg_2] [arg_1]	count=9
function_arg	less [arg_2] ||| [arg_2] [function_1]	count=1
function	the various methods ||| discourse demo	count=2
class	offset ||| timezone offset	count=1
class	samples with frequency ||| freq dist	count=1
function	search for past tweets ||| search	count=1
function_arg	[function_1] hypothesis ||| [function_1] [arg_2]	count=1
function	load a ||| load	count=1
arg	appearances of ||| word_fd	count=1
class	first element of ||| recursive descent	count=1
arg	variable is already bound ||| variable binding	count=1
arg	identifiers for the ||| filetype	count=1
arg	from ||| srctext trgtext alignment max_phrase_length	count=1
arg	item is ||| item	count=1
function	perform a projective dependency ||| projective rule	count=1
function	probability of target ||| prob t a	count=4
function	tweet ids fetch ||| expand tweetids demo	count=1
class	corpus ||| categorized sentences corpus reader	count=2
class	show ||| tester	count=1
function	construct a bigramcollocationfinder given ||| init	count=1
module	figure out ||| app	count=1
function	return the static ||| get static	count=1
arg	from ||| srctext trgtext	count=1
arg	all nonterminals for which ||| cat	count=1
function	arcs to ||| arcs	count=1
function_arg	[function_1] p ||| [arg_2] [function_1]	count=3
function	for the data file ||| data file	count=1
function	length six patterns ||| pro w6	count=2
class	[class_1] rule ||| [class_2] [class_1] apply everywhere chart grammar	count=1
function	the block [function_2] ||| [function_2] [function_1]	count=2
class	dictionary ||| dictionary conditional prob	count=1
class	must be called if ||| regexp chunk app	count=1
arg	source-to-target [arg_2] ||| [arg_1] [arg_2]	count=1
function_arg	[function_1] false otherwise ||| [arg_2] [function_1]	count=3
module	of the ||| corpus reader	count=1
function	the ||| user info from	count=1
function	find a ||| find room	count=1
class	a list of ||| corpus	count=1
module	[module] concept objects ||| [module]	count=1
arg	the set of productions ||| productions	count=1
arg	files in paths where ||| paths	count=1
module	to this ||| draw	count=1
class	rule it has the ||| chunk rule	count=1
arg	or in the ||| fileids	count=1
class	similar to a list's ||| pretty lazy	count=1
function	show_column() ||| show column	count=1
arg	symbol when entering ||| symbol	count=1
module	cached ||| core	count=1
class	reader with ||| reader	count=1
function	file position [function] by ||| char seek [function]	count=1
class	parser uses to decide ||| parser	count=1
function	convert a list of ||| user info from id	count=1
arg	'head' to ||| mod	count=2
class	the chart ||| stepping chart	count=3
function	[function_1] data for ||| [function_1] [function_2]	count=3
function	to realign ||| realign	count=1
class	by this pointer ||| pointer	count=1
function	the ||| drt	count=1
class	inside probabilities of ||| inside chart	count=1
class	reader using data from ||| reader	count=1
function	and returns a subtype ||| variable expression	count=1
function	standard [function_2] ||| [function_2] [function_1]	count=6
arg	to size bytes from ||| size	count=1
function_arg	string [arg_2] ||| [function_1] [arg_2]	count=4
function	a known abbreviation ||| abbrev	count=1
function	returns only ||| strings	count=1
function	[function_1] latex qtree ||| [function_1] [function_2]	count=1
class	sentence string to figure ||| view	count=1
function	leaves ||| drag leaves	count=1
class	dependency [class_2] ||| [class_2] [class_1]	count=8
function	load an information content ||| ic	count=1
class	corpus view that acts ||| nombank corpus reader	count=1
function	to construct a ||| construct threads	count=1
arg	every instance [arg] ||| [arg]	count=1
function	also str [function_2] ||| [function_2] [function_1]	count=2
arg	and returns ||| line primitives	count=1
function	each element of ||| tokenize sents	count=1
class	[class] cumulative ||| [class]	count=3
class	instance's ||| nombank instance	count=1
arg	return a ||| other ic verbose	count=1
module	invalidate ||| core	count=1
arg	a sentence as ||| sentence verbose	count=1
class	a standard ||| standard	count=1
function_arg	[function_1] [arg_2] ||| [function_1] lhs [arg_2]	count=4
arg	[arg_1] look up ||| [arg_1] index [arg_2]	count=1
class	a pickle ||| chart parser app	count=2
function	[function_1] ratios as ||| [function_2] [function_1]	count=1
class	use maltparser ||| malt	count=2
class	method serves ||| drt	count=1
arg	string representation ||| format	count=3
class	tree that ||| tree	count=1
arg	expression and convert to ||| expression	count=1
class	meaning's ||| meaning	count=4
class	[class_1] reader using ||| [class_2] [class_1]	count=1
class	the sequence with the ||| hidden	count=1
function	with the highest score ||| best	count=1
function	[function] human-readable strings ||| error [function]	count=3
arg	input expression ||| assumptions max_models model_builder	count=1
class	a ||| descent parser	count=1
arg	the stemming ||| remove_total append_string	count=1
function	of variables ||| variables	count=1
class	state sequence ||| hidden	count=1
arg	specified features ||| features	count=1
class	in the ||| reader	count=1
class	for this corpus or ||| categorized corpus	count=1
class	be called ||| glue	count=1
arg	finds the reference ||| references hyp_len	count=1
arg	as determined [arg] ||| [arg]	count=1
class	move a ||| parser	count=1
class	[class_1] [class_2] including ||| [class_1] [class_2]	count=1
arg	based on the node ||| node	count=1
module_class	this container ||| draw abstract container	count=1
class	return a list of ||| crubadan corpus reader	count=1
class	the ||| glue	count=1
function_arg	lists [arg_2] ||| [function_1] [arg_2]	count=1
function	truncation errt ||| errt	count=1
class	invalidate the cached n ||| freq dist	count=1
class	for this corpus ||| categorized corpus reader	count=1
class	of this semantics ||| semantics	count=1
module	as an integer ||| corpus	count=1
function	add an ||| add	count=1
function_arg	[function_1] a feature ||| [function_1] informative [arg_2]	count=1
function	length six [function_2] ||| [function_2] [function_1]	count=16
function	height of a ||| height	count=1
arg	n ||| key	count=1
arg	file s as a ||| fileids c5 strip_space	count=2
class	of the remaining ||| reduce	count=1
class	listbox widget ||| listbox	count=1
function_arg	sort the [arg_2] ||| [function_1] queue queue [arg_2]	count=1
module_class	[module_1] list ||| [module_1] colorized [class_2]	count=1
class	a projective ||| projective	count=1
function_arg	rules [arg_2] ||| [arg_2] [function_1]	count=2
class	the feature with ||| feat	count=2
function	the sequence ||| tag	count=1
function	a dictionary of unigram ||| extract unigram	count=1
module	the ||| sem	count=2
function	register it's json tag ||| register tag	count=1
arg	the expression and convert ||| expression	count=1
class	indicates how ||| i	count=1
function	load full annotation ||| fulltextannotation	count=1
function	java binary and what ||| java	count=1
module	this widget use label_* ||| draw	count=1
class	a text returns ||| punkt sentence	count=1
class	that a token ||| shift reduce parser	count=1
function	all possible [function_2] ||| [function_1] [function_2]	count=2
function	words chunks or sentences ||| words	count=1
function	xml index ||| build index	count=1
class	collocation finder ||| trigram collocation	count=1
arg	rule ||| rule	count=1
arg	a string of ||| s chunk_label root_label sep	count=1
module_class	[module_1] discourse or ||| [module_1] [class_2]	count=2
function_arg	self [arg_2] ||| [function_1] [arg_2]	count=1
function	[function_1] token ||| [function_1] [function_2] creds_file	count=1
function	fvm ||| str	count=1
arg	[arg] preserve reentrancy ||| fstruct [arg]	count=2
function	its relation to ||| tgrep relation	count=1
function	string representing [function_2] ||| [function_2] [function_1]	count=1
class	encoding ||| maxent feature encoding	count=2
function	next best rule ||| best rule	count=2
class	for this corpus ||| corpus	count=5
function	tree positions ||| positions	count=1
arg	proof string ||| format	count=1
function	unification of the ||| unification	count=1
arg	documents each of ||| documents	count=1
function	of entries containing word ||| entries	count=1
function_arg	[function_1] tree the ||| [function_1] [arg_2]	count=2
function	rule ||| apply rule	count=1
function	userid to ||| by userid demo	count=1
function	gets the string value ||| value	count=1
class	that a token has ||| parser	count=1
class	representation of the tree ||| tree	count=1
class	the ||| freq	count=1
class	with the ||| edge i	count=1
function	unique [function_2] ||| [function_1] [function_2]	count=4
function	"preterminals", [function] unary rules ||| [function]	count=1
function	create a ||| init	count=9
function	the users ||| user	count=1
function	a frame ||| frame	count=2
arg	potential_labels' ||| potential_labels plug_acc record	count=1
class	the table so ||| table	count=1
arg	given variable ||| variable	count=1
class	the moses tokenizer ||| moses tokenizer	count=2
arg	collection of documents ||| documents	count=1
function	[function_1] s-expressions from ||| [function_2] [function_1]	count=1
class	encoded as a list ||| chunked corpus reader	count=2
arg	replace any [arg] has ||| [arg] forward fs_class	count=1
arg	segmentations a [arg_2] ||| [arg_2] [arg_1]	count=4
function	[function_1] [function_2] ||| [function_2] with [function_1]	count=2
class	to the end ||| stepping shift	count=1
class	standard [class_2] ||| [class_2] [class_1]	count=1
class	to the end of ||| stepping shift reduce	count=1
function	of information about ||| id	count=1
arg	in the document of ||| document	count=2
class	by this rule given ||| rule i	count=1
function	overall score ||| score	count=1
class	method ||| drt	count=1
arg	in breadth-first order ||| children maxdepth	count=1
function	the start ||| start	count=1
module	in ||| sem	count=3
function	only relations involving ||| frame relations	count=1
function	lambda function ||| tgrep	count=3
function	convert ||| user info from id	count=1
function	convert ||| user info from	count=1
class	to file or ||| gzip file	count=1
function	a [function] ||| [function]	count=18
arg	generate base_fdist ||| base_fdist heldout_fdist bins	count=1
function	arrange the ||| manage	count=1
function	convert a list of ||| from	count=1
arg	a tree [arg_2] ||| [arg_1] [arg_2]	count=1
class	sentence breaks yielding ||| punkt sentence	count=1
function	leacock chodorow ||| lch	count=1
arg	input expression to ||| assumptions prover	count=2
function	[function_1] abbreviation if ||| [function_1] [function_2]	count=2
function	tags the sequence with ||| tag	count=1
class	parsing a ||| shift reduce parser	count=1
function	of unigram [function_2] ||| [function_1] [function_2]	count=3
module	appropriate ||| sem	count=1
function_arg	[function_1] of tokens ||| [arg_2] [function_1]	count=1
module	count error-rate relative to ||| metrics	count=1
function	the unique counter from ||| unique counter from	count=1
function	if an integer ||| read int	count=2
arg	given resource ||| resource_url	count=2
function	'lines' with textwrap and ||| mimic	count=1
class	for ||| corpus reader	count=4
function	variety of ||| user info	count=1
function	convert a userid to ||| userid demo	count=1
class	tree ||| multi parented tree	count=1
module	the list ||| inference	count=1
class	the tree in three ||| tree	count=1
function_arg	[function_1] a sentence ||| [function_1] [arg_2]	count=1
function	distance of the ||| distance	count=1
class	the probability ||| prob	count=1
arg	tokens construct and ||| tokens	count=1
function	of variables used ||| find variables	count=2
class	smoothing method 4 shorter ||| smoothing	count=1
function	the cached n ||| setitem	count=1
function	rule this is ||| rule	count=1
class	[class_1] expression to ||| [class_1] [class_2]	count=5
class	the name of the ||| instance	count=1
function	tables to a uniform ||| set uniform	count=1
module	sentence string to ||| app	count=1
class	tags the sequence ||| markov model	count=1
module	which indicates how ||| parse	count=1
class	may cause the object ||| mutable prob dist	count=1
class	if ||| demo	count=1
class	remaining ||| parser	count=1
function_arg	[function_1] [arg_2] decode them using this ||| [function_1] [arg_2]	count=4
function	a subtype of ||| expression	count=1
arg	j of the ||| j	count=1
arg	positive_featuresets a list ||| positive_featuresets unlabeled_featuresets	count=1
function	krippendorff's interval distance metric ||| interval distance	count=1
module_class	to [module_1] [class_2] ||| [module_1] [class_2]	count=2
arg	target tagset ||| target source_tag	count=2
class	projective [class_2] ||| [class_2] [class_1]	count=1
class	to the end ||| stepping	count=1
class	the text contents of ||| senseval corpus reader	count=1
function	python [function_2] ||| [function_2] [function_1]	count=1
class	corpus or in the ||| corpus	count=2
function	use of [function_2] ||| [function_2] label [function_1]	count=1
class	dependency grammar ||| dependency grammar	count=2
class	the chart ||| stepping chart parser	count=2
arg	given prob_dist ||| prob_dist	count=1
class	best ||| tagger trainer	count=1
function	list of entries ||| entries	count=1
class	rule that changes ||| rule	count=1
class	if the underlying stream ||| seekable unicode stream	count=1
class	big a ||| chart view	count=1
class	this ||| hidden	count=1
class	list ||| crubadan corpus	count=1
class	return new feature encoding ||| maxent feature encoding	count=2
arg	of rows and columns ||| rows	count=1
class	parsing ||| parser	count=1
module	a ||| app	count=1
class	to be ||| chart	count=1
module	invalidate the cached n ||| core	count=1
arg	a subprocess that ||| cmd classpath stdin stdout	count=1
function	regions ||| regions	count=1
function	variety of information ||| info from	count=1
arg	word tag tuples ||| stem	count=1
function	[function_1] alignments ||| [function_1] [function_2]	count=10
function_arg	first-order logic [arg_2] ||| [arg_2] [function_1]	count=1
class	indexes ||| framenet corpus	count=1
module	string to figure out ||| app	count=1
class	alphabetical ||| opinion lexicon corpus	count=1
function	use label_* to configure ||| configure	count=1
arg	given item at ||| item	count=1
function_arg	each element [arg_2] ||| [function_1] [arg_2]	count=1
class	for ||| tree	count=1
function	the log probability ||| logprob	count=1
class	function ||| parser app	count=1
function	latex [function_2] ||| [function_1] [function_2]	count=2
arg	a temporary file ||| delete_on_gc	count=1
arg	the alignment in alignment_info, ||| alignment_info	count=1
class	that have been identified ||| nonprojective parser	count=1
function	replacing each feature ||| retract	count=1
function	location of an error ||| error	count=1
function	information about the ||| info from id	count=1
class	french ||| french stemmer	count=1
arg	nonterminals for which ||| cat	count=1
function	rank alignment algorithm ||| rank alignment	count=2
function_arg	[function_1] temporary file ||| [arg_2] [function_1]	count=1
class	be returned ||| comparative sentences	count=1
class	canvasframe ||| frame	count=3
function	_sentences to construct ||| construct	count=1
function	[function_1] of text ||| [function_2] [function_1]	count=2
arg	pairs is a list ||| pairs	count=1
function_arg	less than min_freq ||| filter min_freq	count=1
function	[function] displaying ||| [function]	count=2
class	all ||| lexicon corpus reader	count=1
function	return all sentences ||| sents	count=2
class	remaining ||| shift reduce parser	count=1
function	view ||| view	count=1
class	corpus and then ||| corpus	count=1
class	file within zipfile that ||| zip file	count=1
arg	child to ||| child index dry_run	count=1
class	tagger on ||| tagger trainer	count=1
class	aligned corpus reader ||| aligned corpus reader	count=1
function	counter from the ||| counter from	count=2
class	probability state sequence ||| markov model	count=1
arg	featureset label ||| featureset label	count=2
function	returns the score for ||| score	count=2
function	remove ||| remove	count=3
module_class	[module_1] corpus ||| [module_1] plaintext [class_2]	count=1
function	1c from "an algorithm ||| step1c	count=1
class	supported ||| crubadan corpus reader	count=1
class	of ||| edge i	count=1
class	:return a list of ||| corpus reader	count=1
class	use the cross-validation estimate ||| cross validation	count=1
arg	takes a sentence as ||| sentence	count=1
function	of child ||| child	count=1
function	list of ||| list	count=3
class	sentence in an ||| reader	count=1
arg	specified criteria ||| exemplars full_text	count=1
module	return true if all ||| core	count=1
function	paragraphs each ||| paras	count=5
class	an xml element in ||| corpus reader	count=1
class	repp tokenizer ||| repp tokenizer	count=2
function_arg	[function_1] [arg_2] stream's file position at ||| [function_1] [arg_2] comment_char	count=7
arg	the left-hand side or ||| lhs rhs	count=2
arg	rows and columns ||| rows	count=1
function	various methods ||| drt discourse demo	count=1
function	the truncation line ||| get truncation coordinates	count=1
arg	the expression and ||| expression	count=1
class	sentence breaks ||| sentence	count=1
class	in the chart ||| stepping chart	count=1
class	this rule ||| rule	count=3
function	the block ||| block	count=1
arg	of model_found() ||| found	count=1
function	macro name [function_2] ||| [function_2] [function_1]	count=1
function	a dictionary of ||| predicate dict	count=1
module	of ||| metrics	count=6
function	input file for ||| file	count=2
class	this chart ||| chart	count=4
class	minimal set having ||| minimal set add	count=1
class	function must be called ||| chunk app	count=1
class	the remaining ||| stepping shift	count=1
arg	if [arg] terminal which ||| [arg]	count=1
class	in alphabetical order ||| opinion lexicon corpus	count=1
arg	the fileids that have ||| fileids	count=1
class	of ||| edge	count=1
function	of abstractvariableexpression appropriate ||| expression	count=1
class	in this [class_1] [class_2] ||| core [class_1] [class_2]	count=1
class	in particular if ||| descent parser	count=1
arg	n-gram ||| hypothesis min_len	count=1
arg	[arg_1] expression ||| [arg_1] [arg_2]	count=6
class	corpus or ||| corpus	count=4
function	a variety of ||| user	count=1
function	error message ||| parse error	count=1
function	about ||| id	count=1
class	function must be called ||| glue	count=1
function	convert a list ||| info from id	count=1
function	search for ||| search	count=1
class	variable binder in the ||| variable binder	count=1
function	[function_1] for all ||| [function_2] [function_1]	count=2
function_arg	belonging [arg_2] ||| [arg_2] [function_1]	count=1
arg	sentnum ||| sentnum	count=1
function_arg	reduce [arg_2] ||| [arg_2] [function_1]	count=1
function	have equal values ||| equal	count=1
function	whether the word ||| is head word	count=1
class	[class_1] detokenizer ||| [class_2] [class_1]	count=3
class	to figure ||| view	count=1
class	canvasframe to ||| canvas frame	count=1
function	of bigram ||| bigram	count=1
arg	should [arg_2] ||| [arg_2] [arg_1]	count=6
class	moses [class_2] ||| [class_2] [class_1]	count=2
arg	utterance identifiers for ||| sex spkrid sent_type	count=1
class	first element ||| descent	count=1
class	element of the frontier ||| stepping	count=1
function	next complete expression from ||| process next expression	count=1
class	in the cmudict lexicon ||| cmudict	count=1
arg	variable v with expression ||| variable expression	count=3
function	for the ||| variable expression	count=1
class	this rule it has ||| rule	count=1
class	end of the ||| shift reduce parser	count=1
function	a ||| user info from id	count=2
function	a factory method that ||| variable	count=1
function	a given chart into ||| set	count=1
arg	a segmentation [arg_2] ||| [arg_2] [arg_1]	count=1
function	that instantiates ||| expression	count=1
function	page if ||| page	count=1
class	tweet ||| tweet	count=1
class	dependency ||| dependency	count=4
class	tagger on ||| tagger	count=1
class	tree in three ways ||| tree	count=1
class	must be ||| chart parser	count=1
arg	offset ||| offset est_bytes	count=1
arg	of tagged data to ||| data	count=1
class	the corpus file underlying ||| lazy sequence	count=1
module	indexes ||| corpus	count=1
function	average of ||| average	count=1
arg	[arg] if specified ||| [arg] include_encoding	count=3
arg	baseline ||| initial_tagger templates trace deterministic	count=1
class	of the stack ||| reduce	count=1
class	classifier object ||| classifier	count=1
function	[function_1] alignment algorithm ||| [function_2] [function_1]	count=1
function	the ||| setitem	count=1
arg	with_shutdown is ||| with_shutdown	count=1
arg	production to ||| production	count=1
arg	relation ||| relation	count=1
function	the url for ||| get url	count=2
class	in the corpus ||| corpus reader	count=7
class	from the ||| shift reduce parser	count=1
module_class	this [class_2] ||| [module_1] [class_2] tags	count=4
function	the least common subsumer ||| lcs ic	count=1
function	names [function_2] ||| [function_2] [function_1]	count=4
function	[function_1] sentence ||| [function_2] [function_1]	count=17
class	is consistent with the ||| i	count=1
module	variety of information ||| twitter	count=1
class	prevent unnecessary ||| resolution	count=1
arg	tree in breadth-first order ||| tree children maxdepth	count=1
module	re-download any ||| core	count=1
function	a subtype of abstractvariableexpression ||| variable	count=1
arg	for one [arg] corpus ||| [arg]	count=2
class	be called if ||| regexp chunk app	count=1
function	[function_1] distance metric ||| [function_1] [function_2]	count=1
arg	a release callback ||| event	count=1
function_arg	skolemize the expression ||| skolemize expression	count=2
class	must ||| demo	count=1
function	the likelihood a ||| likelihood	count=1
function	been recorded by ||| n	count=1
arg	ranks1 and [arg_2] ||| [arg_1] [arg_2]	count=4
class	space [class_2] ||| [class_2] [class_1]	count=1
class	a ||| stepping shift reduce parser	count=2
class	path pointer pointing at ||| path pointer	count=1
function	the sentences in ||| sentences	count=1
arg	or in ||| fileids categories	count=1
function	rank ||| rank	count=1
function	make sure that ||| sanity check	count=1
function	which ||| tgrep	count=1
class	from this synset to ||| synset	count=1
class	change ||| recursive descent parser	count=1
function	sentences in that ||| sentences	count=1
module	:return true if this ||| draw	count=1
class	distribution for the ||| dist	count=3
function	first [function_2] ||| [function_1] [function_2]	count=4
function	[function_1] tree ||| [function_2] [function_1]	count=1
class	in alphabetical order ||| corpus	count=1
class	must be called ||| glue	count=1
class	with the ||| markov model	count=1
function	latex qtree ||| latex qtree	count=2
arg	positive_featuresets a list of ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
arg	whether a feature is ||| feat	count=1
function_arg	from stream ||| block stream	count=1
function	the underlying byte ||| tell	count=1
class	corpus [class_2] ||| [class_2] [class_1]	count=22
function	upper frame ||| get static upper	count=1
function_arg	edge in [arg_2] ||| [function_1] [arg_2]	count=1
class	the remaining ||| shift reduce	count=1
arg	[arg_1] given pattern ||| [arg_2] [arg_1]	count=9
class	read ||| backed corpus view	count=1
class	sequence this ||| hidden markov	count=1
function	of all conditions ||| conditions	count=1
arg	with the assumptions ||| assumptions	count=1
class	name ||| nombank instance	count=1
arg	of a given sample ||| sample	count=1
class	:see expression ||| variable expression	count=3
function	[function_1] comparison method ||| [function_1] [function_2]	count=1
arg	[arg] decode them ||| [arg]	count=3
module_class	[module_1] tree ||| [module_1] [class_2] subtrees	count=1
function	tadm based on ||| tadm	count=1
class	about the ||| query	count=1
function	text generates the ||| from	count=1
function	uppercase ||| funcvar	count=1
function	to each tkinter label ||| to	count=1
class	called ||| chart	count=1
function	of plausible semtypes in ||| get semtypes	count=1
arg	string at ||| s	count=1
arg	starts the hunpos-tag ||| path_to_bin encoding verbose	count=1
function	condition *o from ||| ends cvc	count=1
class	the text [class] ||| string [class]	count=3
arg	the new edge ||| edge	count=2
arg	t ||| t	count=1
class	the sequence with the ||| tagger	count=1
function	of ||| from	count=2
class	with ||| token	count=1
class	if the feature ||| feat	count=2
class	should ||| view	count=1
arg	function the function ||| function	count=1
class	this function ||| app	count=2
function	[function_1] pointer lists ||| [function_2] [function_1]	count=4
function	realign punctuation that ||| realign boundaries	count=1
class	path identified by ||| path	count=1
function	the approximate score for ||| future score	count=1
function	of all conditions for ||| conditions	count=1
class	the sequence with the ||| hidden markov	count=1
class	element [class_2] ||| [class_2] [class_1]	count=2
class	a lexical translation ||| ibmmodel2	count=1
function	precision ||| precision	count=2
module	iso 639-3 ||| corpus reader	count=1
arg	read a bracketed tree ||| brackets read_node	count=1
arg	train and ||| trainer	count=1
arg	convert this split disjunction ||| first second	count=1
arg	a string containing ||| vnframe indent	count=1
module	build ||| corpus reader	count=2
function	a concise string ||| repr	count=1
arg	:param other ||| other	count=1
class	token ||| shift reduce	count=1
class	invalidate the cached ||| dist	count=1
class	[class_1] based on ||| [class_2] [class_1]	count=4
class	enter the ||| chart parser	count=1
arg	to generate freqdist ||| freqdist gamma bins	count=1
class	return all ||| opinion lexicon corpus reader	count=1
arg	the tuple representation ||| tagged_token sep	count=1
function	various methods of ||| drt	count=1
function_arg	distance similarity [arg_2] ||| [arg_2] [function_1]	count=4
class	must ||| regexp	count=1
arg	[arg_1] v ||| [arg_1] [arg_2]	count=1
arg	list of ||| fileids	count=4
class	is different ||| transition	count=1
class	mapping contexts to tags ||| context tagger	count=1
class	tags ||| model	count=1
function_arg	[function_1] from ||| [arg_2] [function_1]	count=3
function	annotated sentences matching the ||| sents	count=1
arg	website ||| fileid urlbase	count=1
function	the right [function_2] ||| [function_1] [function_2]	count=1
function	paragraphs each [function_2] ||| [function_2] [function_1]	count=12
arg	or the list ||| fileids sent	count=1
class	encoding ||| typed maxent feature encoding	count=1
function_arg	normalize the [arg_2] ||| [function_1] [arg_2]	count=1
module_class	that this [class_2] ||| [module_1] [class_2]	count=2
function	friendly error ||| parse error	count=1
class	as iso 639-3 ||| crubadan corpus reader	count=1
function_arg	skolemize the [arg_2] ||| [function_1] [arg_2]	count=5
function	translate one entity ||| descape entity	count=1
class	:return a corpus ||| propbank corpus reader	count=1
function	convert a userid to ||| by userid	count=1
function	for pretty-printing ||| pretty	count=2
function_arg	[function_1] of model_found() ||| [function_1] [arg_2]	count=1
arg	data returned ||| data	count=1
function	an exemplar sentence and ||| exemplar of	count=1
arg	tagset to the target ||| target	count=1
class	[class_1] distribution for ||| [class_2] [class_1]	count=6
function	cache is a tuple ||| cache	count=1
class	text to the ||| stepping shift	count=1
function	the log [function_2] ||| [function_2] [function_1]	count=1
module	create and return ||| core	count=1
function	[function_1] max ||| [function_2] [function_1]	count=1
arg	ranks1 [arg_2] ||| [arg_2] [arg_1]	count=3
class	sentences ||| punkt sentence tokenizer	count=1
class	true if the rule ||| rule	count=1
module_class	pickle [class_2] ||| [module_1] [class_2]	count=4
class	editing the ||| cfgeditor	count=1
function	pop ||| pop	count=1
arg	[arg_1] tuples ||| [arg_1] [arg_2]	count=3
function	about the users ||| id	count=1
function	[function] to ||| [function]	count=1
function	[function] feature ||| [function]	count=2
class	the sentence string ||| chart view	count=1
class	using the lancaster stemmer ||| lancaster stemmer	count=1
class	probability state sequence this ||| hidden markov model tagger	count=1
arg	the expression to ||| expression command	count=1
class	occurs as a ||| multi parented	count=1
module_class	[module_1] agenda ||| [module_1] [class_2]	count=4
function_arg	[function_1] rule data ||| [function_1] applies [arg_2]	count=1
arg	input string ||| input	count=1
arg	raw_score likelihood ||| raw_score src_phrase_span trg_phrase	count=1
class	the brill tagger ||| brill tagger	count=1
module_class	[module_1] path pointer ||| [module_1] zip file [class_2]	count=2
module	the alignments ||| translate	count=2
arg	information content value ||| synset2 ic verbose	count=1
class	text contents of the ||| senseval corpus	count=1
arg	the correction ||| labels mapping unseen_features alwayson_features	count=1
arg	file s as ||| fileids speaker stem relation	count=1
function	creates a new index ||| add index	count=1
function	a chart to ||| chart	count=1
function	a [function] of this ||| [function]	count=1
function	a ||| user	count=2
arg	the highest information content ||| synset2 ic	count=1
class	the corpus or ||| corpus	count=2
module_class	return [class_2] ||| [module_1] feat [class_2]	count=1
class	a unit needs to ||| chart view	count=1
class	as sentence ||| sentence	count=1
arg	variable v [arg_2] ||| [arg_2] [arg_1]	count=3
arg	the assumptions ||| assumptions	count=2
function	tweets and output data ||| tweets	count=1
class	add all edges licensed [class_1] [class_2] ||| [class_2] [class_1]	count=4
class	probability ||| tagger	count=1
function	of plausible semtypes ||| get semtypes	count=1
function	determines the approximate score ||| future score	count=1
class	a single ||| shift reduce parser	count=1
function	alpha ||| alpha	count=1
module	times this ||| core	count=1
function	color in ||| color	count=1
class	dict with which to ||| dict	count=1
module	how much of the ||| parse	count=1
function	of sentence strings ||| build sentence	count=1
class	:param ||| prob dist	count=1
class	return a ||| reader	count=1
class	positive ||| lexicon corpus reader	count=1
arg	in the ||| tr	count=1
module	tag for each word ||| tag	count=1
function	representation ||| item repr	count=1
class	objects one for ||| reader	count=1
class	this rule it has ||| rule with context	count=1
class	the moses [class_2] ||| [class_1] [class_2]	count=2
arg	[arg_1] label ||| [arg_2] [arg_1]	count=11
arg	[arg_1] appearances of ||| [arg_2] [arg_1]	count=2
function	containing [function] of the ||| [function]	count=2
module_class	[module_1] [class_2] including graphical ||| [module_1] [class_2] tags	count=4
arg	with [arg] the ||| [arg]	count=1
arg	[arg] parser's ||| [arg]	count=1
class	a list of text ||| list	count=1
function_arg	[function_1] other ||| [arg_2] [function_1]	count=1
arg	etree ||| etree	count=1
arg	sequence of data ||| data start	count=1
module_class	by this [class_2] ||| [module_1] [class_2]	count=25
function	a freqdist containing ||| freq threshold	count=1
class	boxer to ||| boxer	count=2
function_arg	[function_1] and returns ||| [function_1] [arg_2]	count=6
class	the frontier ||| parser	count=1
class	leaves [class] have not ||| [class]	count=1
function	of information ||| user info	count=1
arg	string of bracketted tagged ||| s chunk_label root_label	count=1
class	be called ||| app	count=2
module	error-rate ||| metrics	count=1
function	classify a ||| classify	count=1
arg	rows ||| rows cols	count=1
function	normal [function_2] ||| [function_2] [function_1]	count=2
module	of the text widget ||| draw	count=1
class	list of supported ||| corpus reader	count=1
function	the ||| from	count=1
function_arg	adds an [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
class	particular ||| recursive	count=1
function	[function_1] pass of ||| [function_2] [function_1]	count=3
function	most frequent [function] contexts ||| [function]	count=1
class	the underlying stream ||| seekable unicode stream reader	count=1
function	information about the ||| id	count=1
function	clustering parameters from ||| cluster	count=1
function_arg	[function_1] estimator ||| [function_1] [arg_2]	count=1
class	unicode ||| unicode	count=1
module	calculates the ||| translate	count=2
arg	models ||| source_word_classes target_word_classes	count=2
module	clustering ||| cluster	count=1
class	remaining text to ||| stepping shift	count=1
function_arg	synset [arg_2] ||| [function_1] synset [arg_2]	count=2
function	variety of information ||| user	count=1
class	called ||| drt glue	count=1
module	be called ||| sem	count=1
function	of information about the ||| info from	count=1
arg	can be [arg_2] ||| [arg_1] [arg_2]	count=1
arg	in unigrams ||| unigrams handle_negation	count=1
module	set of ||| sem	count=1
function	the static [function_2] ||| [function_1] [function_2]	count=5
function_arg	[function_1] context_to_tag a ||| [function_1] [arg_2]	count=1
arg	a string of ||| s chunk_label root_label	count=1
arg	[arg_1] list ||| [arg_2] [arg_1]	count=1
class	[class] on ||| function [class]	count=1
function	of the names ||| names	count=1
arg	which match the ||| search_leaves	count=1
function	tree :return the tree ||| production to tree	count=1
class	of the remaining text ||| stepping shift reduce parser	count=1
class	in store if hack=true ||| cooper store	count=1
arg	trees which match ||| trees search_leaves	count=3
function	checksum for ||| hexdigest	count=1
class	this sentence boundary detector ||| punkt sentence	count=1
function	recommended word ||| word	count=1
class	if ||| descent parser	count=1
function_arg	table of [arg_2] ||| [arg_2] [function_1]	count=1
function	the [function] to ||| [function]	count=1
function	a userid to a ||| userid	count=1
class	rule and the given ||| rule	count=1
arg	list of text ||| word_tokenizer	count=1
class	of ||| descent	count=1
function	a frame xml ||| frame	count=1
class	of the production ||| production	count=1
function	extract the unique ||| unique	count=1
class	creates the mutable probdist ||| mutable prob dist	count=1
class	handle ||| drs drawer	count=1
class	into [class] ||| [class]	count=2
arg	the sequence ||| sequence	count=1
class	in this corpus or ||| corpus	count=1
class	structure ||| edge	count=1
function	of the table's ||| check table	count=1
arg	or the list ||| fileids sent tag	count=1
function	given a text generates ||| from	count=1
function	each successive ||| tokenize	count=1
class	[class] edges ||| [class]	count=2
class	dependency grammar from ||| dependency grammar	count=2
class	predicates ||| closed world prover	count=2
class	[class_1] as as ||| [class_1] [class_2]	count=3
arg	count ||| count	count=1
module	hypothesized structure ||| parse	count=1
arg	substrings ||| string left right	count=1
function	:see ||| visit	count=1
module	to ||| metrics	count=1
function_arg	[function_1] child ||| [function_1] [arg_2]	count=1
function_arg	a new empty ||| init cond_samples	count=1
module	to invalidate the cached ||| core	count=1
function	table's _rows ||| table	count=1
class	all parses ||| recursive descent	count=2
arg	[arg_1] drtindividualvariableexpression for ||| [arg_2] [arg_1]	count=2
class	the hypothesized ||| edge	count=1
module	build the internal indexes ||| reader	count=1
class	how ||| view	count=2
function_arg	[function_1] a line ||| [function_1] [arg_2]	count=2
class	of the frontier ||| recursive descent parser	count=1
function_arg	pcfg grammar from ||| pcfg start	count=1
arg	takes a sentence ||| sentence verbose	count=1
class	a dictionary ||| dictionary conditional	count=1
class	a probability distribution ||| prob dist	count=6
class	the same sentence ||| punkt sentence	count=1
arg	stream until we find ||| stream	count=1
function	tree nodes in the ||| nodes	count=1
class	structure is ||| edge i	count=1
function	dictionary of unigram ||| unigram	count=1
function	unigram ||| extract unigram	count=1
function_arg	the eval [arg_2] ||| [function_1] [arg_2]	count=1
function	list of words ||| words	count=4
class	the inside probabilities ||| inside chart	count=1
class	as iso 639-3 ||| crubadan corpus	count=1
arg	the vectors ||| vectors	count=1
arg	by its id luname ||| fn_luid ignorekeys luname	count=1
class	the frequency distribution in ||| simple good turing prob dist	count=1
class	the underlying ||| seekable unicode	count=1
function	a subtype ||| variable expression	count=1
class	how big ||| view	count=2
class	feature identifiers ||| feat	count=1
function_arg	present [arg_2] ||| [function_1] [arg_2]	count=1
class	of a ||| parser	count=1
module	corpus or that store ||| corpus reader	count=1
function	output [function] produces aka ||| grow diag final [function]	count=1
function	result ||| result	count=1
arg	from a ||| srctext	count=1
class	text to ||| shift reduce	count=1
function	of information about ||| info	count=1
function	concise representation of this ||| repr	count=1
arg	variable-value pair ||| var val	count=1
class	in this corpus or ||| corpus reader	count=1
class	if ||| canvas	count=2
function	a variety of information ||| from id	count=1
arg	[arg_1] [arg_2] determines ||| core tree convert [arg_2] [arg_1]	count=4
module	this ||| core	count=35
class	relative ||| paice	count=1
arg	of 'variable' with 'expression' ||| variable expression replace_bound alpha_convert	count=1
function	list of plausible semtypes ||| semtypes	count=1
class	comparing ||| variable binder expression	count=1
class	tags the ||| model	count=1
function	static web help ||| get static web help	count=1
class	the stack ||| reduce	count=1
class	that ||| tagger	count=1
function	annotates all ||| legacy	count=1
class	pointer ||| pointer	count=8
arg	freqdists for appearances ||| word_fd	count=1
class	a ||| shift reduce	count=1
function	top-lebel node in ||| tgrep exprs	count=1
function	that the eval ||| eval chunk	count=1
class	underlying this corpus ||| lazy	count=2
class	corpus ||| comparative sentences corpus reader	count=1
class	child's parent will ||| sequence	count=1
class	first element of ||| stepping recursive descent	count=1
arg	the gold standard ||| gold	count=1
class	the neural dependency ||| stanford neural dependency	count=2
arg	use the rest ||| keywords	count=1
class	given ||| framenet corpus reader	count=2
class	this rule ||| chart rule	count=2
function	tagged chunks represented ||| tagged chunks	count=1
arg	[arg_1] cls ||| core tree convert [arg_2] [arg_1]	count=4
class	predicates from the ||| closed world prover	count=1
arg	highest information content value ||| ic	count=1
class	the [class] lists ||| [class]	count=1
class	in specified ||| reader	count=3
function	[function] values ||| [function]	count=1
class	this tagger ||| tagger	count=3
arg	if [arg] terminal ||| [arg]	count=1
class	that have been identified ||| parser	count=1
module	for the [module] ||| [module]	count=1
arg	stream is a json-serialised ||| stream	count=1
module	the name of ||| corpus	count=1
function	appropriate for ||| variable	count=1
class	this object ||| substitute	count=1
function	information about the ||| info	count=1
function_arg	parse a [arg_2] ||| [function_1] [arg_2]	count=1
class	expression for ||| expression	count=2
class	in ||| recursive descent parser	count=1
class	given ||| stream reader	count=1
function	pearson's chi-square as ||| chi sq	count=1
class	convert a list ||| query	count=1
function_arg	[function_1] an ||| [arg_2] [function_1]	count=4
arg	into a ||| read lexicon	count=1
arg	'variable' with 'expression' ||| variable expression replace_bound alpha_convert	count=1
arg	[arg] if ||| [arg]	count=3
module_class	to this table's ||| draw table	count=1
class	classifier based on the ||| classifier based	count=1
class	the cached n ||| freq	count=1
function_arg	[function_1] and punctuation ||| [arg_2] [function_1]	count=13
arg	the given index ||| index	count=1
arg	readings ||| readings	count=1
function_arg	lemma objects [arg_2] ||| [arg_2] [function_1]	count=1
arg	distance ||| distance	count=1
module	string then return ||| core	count=1
function	the list of sentences ||| sentences	count=1
arg	int limit the number ||| limit	count=1
class	alphabetical order ||| opinion lexicon corpus	count=1
class	that this tagger uses ||| based tagger	count=2
class	given element ||| framenet corpus reader	count=1
class	state sequence ||| model	count=1
arg	tagger must be trained ||| trained n c	count=1
class	use simple [class_2] ||| [class_2] [class_1]	count=2
module_class	[module_1] grammar ||| [module_1] [class_2]	count=2
function	the latex [function_2] ||| [function_2] [function_1]	count=2
class	clustering ||| cluster i	count=1
class	the ||| framenet corpus	count=1
function	[function_1] concept ||| [function_2] [function_1]	count=1
arg	goal sem ||| goal assumptions verbose	count=1
function	the highest score ||| best	count=1
function	[function_1] of clusters ||| [function_1] [function_2]	count=2
function	edges contained in ||| edges	count=1
class	[class] not including ||| [class]	count=1
class	proper probability ||| simple good turing prob	count=1
class	bigram using the ||| bigram	count=1
class	:return a corpus view ||| nombank corpus	count=1
arg	of variable [arg_2] ||| [arg_1] [arg_2]	count=3
function	backward probability matrix a ||| backward probability	count=1
class	parsing a ||| parser	count=4
class	as in manning ||| ngram assoc measures	count=1
function_arg	to reduce stack ||| reduce stack	count=1
arg	as determined [arg] provided ||| [arg]	count=1
arg	word and part of ||| word	count=1
class	fixed-length [class] that ||| [class] encoding	count=1
class	zip ||| zip	count=1
arg	probability distributions ||| numsamples numoutcomes	count=1
class	order ||| opinion lexicon corpus	count=1
class	positive examples the ||| naive bayes dependency	count=1
arg	into ||| read lexicon	count=1
function	a dictionary ||| make	count=1
class	sequence ||| hidden markov	count=2
function	first pass of ||| annotate first pass	count=2
class	corpus ||| pros cons corpus reader	count=1
class	the inside probabilities ||| inside	count=1
arg	node return a list ||| node	count=1
arg	s ||| s	count=1
module_class	[module_1] canvas widget ||| [module_1] [class_2]	count=26
class	parses that can ||| recursive descent parser	count=4
function	translate one entity to ||| entity	count=1
function_arg	[function_1] event ||| [arg_2] [function_1]	count=3
class	exemplar ||| framenet corpus reader	count=1
arg	the highest information content ||| synset2 ic verbose	count=1
arg	in the ||| tr nr	count=1
function_arg	[function_1] a line ||| [arg_2] [function_1]	count=2
function	[function_1] tags ||| [function_2] [function_1]	count=1
function	override counter __delitem__() ||| delitem	count=1
function	variables [function_2] ||| [function_2] [function_1]	count=4
function_arg	[function_1] strings ||| [function_1] [arg_2]	count=2
function	learning curve -- ||| learning curve	count=1
arg	[arg_1] specified xml ||| [arg_2] [arg_1]	count=2
function	the standard ||| standard	count=1
class	rule ||| rule with	count=1
function	illustrate ||| drt discourse demo	count=1
class	this tree ||| multi parented tree	count=1
function	the distance of ||| distance	count=1
module	and using the list ||| core	count=1
class	a token from ||| stepping	count=1
class	path pointer in ||| path pointer	count=1
class	be how big the ||| chart view	count=1
class	if ||| chunk app	count=1
class	given element ||| corpus reader	count=1
function	arcs ||| arcs	count=1
class	a projective dependency ||| projective dependency	count=1
function	load a valuation from ||| load	count=1
function	sentence and ||| t	count=2
function_arg	[function_1] [arg_2] ||| [function_1] sents [arg_2]	count=8
class	build the internal indexes ||| corpus reader	count=1
class	of the remaining ||| parser	count=1
function	[function_1] index ||| [function_1] [function_2]	count=6
class	tree ||| parented tree	count=3
function	f [function_2] ||| [function_2] [function_1]	count=4
function_arg	corpus [arg_2] ||| [function_1] [arg_2]	count=4
arg	if [arg_2] ||| [arg_1] [arg_2]	count=4
class	as iso ||| crubadan corpus reader	count=1
function	timer decorator to measure ||| timer	count=1
arg	implement the view ||| bracket_sent	count=1
arg	remaining lines ||| lines wrap_at	count=1
arg	regular expression ||| regexp	count=2
class	this synset to the ||| synset	count=1
function	userid to a screen ||| by userid demo	count=1
function	index ||| build index	count=1
function	the conditions that have ||| conditions	count=1
module	state ||| tag	count=1
class	the associated menu ||| mutable option menu	count=1
class	table's main frame ||| table	count=1
function	implements step 3 ||| step3	count=1
module	text to ||| parse	count=1
module	the [module] a single ||| [module]	count=1
function	padded ||| pad	count=1
arg	frame optional frame ||| frame frame2	count=1
class	text contents of the ||| senseval corpus reader	count=1
class	this [class_2] ||| [class_2] [class_1]	count=2
arg	estimator ||| estimator	count=1
arg	sentence as a ||| sentence verbose	count=1
function_arg	[function_1] under ||| [arg_2] [function_1]	count=5
arg	the given prob_dist ||| prob_dist	count=1
arg	a sequence of ||| sequence n k	count=1
class	languages as iso ||| crubadan	count=1
arg	s ||| fileids tagset	count=2
class	languages ||| crubadan	count=1
arg	for the given edge ||| edge	count=1
class	element of ||| stepping recursive descent	count=1
function	concept out of ||| concept	count=1
class	to file or buffer ||| gzip file	count=1
module	order ||| corpus reader	count=2
class	probability state sequence ||| markov	count=1
function	a factory method ||| variable	count=1
class	a single tree ||| stepping shift reduce parser	count=1
function	graph represented as ||| transclose	count=1
class	the remaining ||| stepping shift reduce	count=1
function_arg	[function_1] expression and ||| [arg_2] [function_1]	count=1
function	is a factory ||| variable	count=1
module	words ||| corpus	count=1
arg	for [arg] ||| [arg]	count=1
arg	appearances of ||| word_fd bigram_fd	count=1
module	ignoring stopwords ||| core	count=1
class	sequence this ||| model	count=1
class	dependency [class_2] ||| [class_1] [class_2]	count=8
class	uses a set of ||| tn t	count=1
class	the name of the ||| nombank	count=1
function	the given node address ||| address	count=1
function	by a ||| by user demo	count=1
function	[function_1] s-expressions from ||| [function_1] [function_2]	count=1
class	alphabetical order ||| lexicon corpus reader	count=1
function	function generates [function_2] ||| [function_1] [function_2]	count=1
module	string to figure ||| app	count=1
function	set the node label ||| set	count=1
function	the ||| tag	count=2
function	to [function_1] [function_2] ||| [function_1] [function_2]	count=6
function	applies at the ||| applies	count=1
class	dict ||| dict	count=1
class	proper [class_2] ||| [class_2] [class_1]	count=3
module	full tweets ||| twitter	count=1
arg	j ||| j	count=3
class	a token ||| stepping	count=1
class	be how big the ||| chart	count=1
arg	t in the ||| t	count=1
class	from ||| reduce	count=1
arg	several other such ||| join_char	count=1
function	the model ||| model var	count=1
arg	suffix-removal rules represented as ||| rules	count=1
arg	trees can be ||| tokens	count=1
function	demo showing ||| prob parse demo	count=1
module_class	[module_1] currently ||| [module_1] [class_2] recursive descent parser	count=1
arg	positions where ||| positions	count=1
arg	of child to ||| child index	count=2
class	for this sentence ||| sentence	count=1
function	extract ||| valid	count=1
arg	pair of segmentations ||| seg1 seg2 k boundary	count=1
function	string ||| pretty format	count=1
arg	aka system-level ||| list_of_references hypotheses weights smoothing_function	count=1
arg	multiple ||| verbose top_relation_label	count=1
class	a ||| query	count=2
function	describes the use ||| pred use	count=1
function	callback ||| bind drag	count=1
class	end of the ||| stepping	count=1
arg	and ||| speaker stem	count=1
class	probdist ||| simple good turing prob dist	count=1
class	tokenizer ||| tokenizer	count=3
class	given corpus ||| corpus	count=1
class	dependency graph ||| probabilistic projective dependency	count=1
arg	given string ||| s	count=2
function	have frequency [function_2] ||| [function_2] [function_1]	count=1
function_arg	[function_1] the item ||| [function_1] [arg_2]	count=1
class	this sentence ||| sentence tokenizer	count=1
function	the approximate score ||| future score	count=1
function	[function_1] measure for ||| [function_1] [function_2]	count=1
function	[function_1] first expression ||| [function_1] [function_2]	count=1
arg	a list of productions ||| productions	count=1
class	binder ||| binder	count=1
function	hole ||| plug hole	count=1
arg	file ||| file	count=1
function	through left branches ||| leftmost	count=1
function	creates a table of ||| table	count=1
class	return ||| opinion lexicon corpus reader	count=1
class	danish ||| danish	count=1
function	exemplar sentence ||| exemplar of fes	count=1
class	[class_1] tokenizer binary ||| [class_1] [class_2]	count=1
arg	index the index ||| index	count=1
function_arg	[function_1] of remaining_text ||| [function_1] stack [arg_2]	count=3
function	relations ||| relations	count=1
class	lu ||| framenet corpus	count=1
module_class	[module_1] edge ||| [module_1] [class_2]	count=16
function_arg	[function_1] a pretty-printed ||| [arg_2] [function_1]	count=3
function	string ||| format	count=1
arg	the tuple representation ||| tagged_token	count=1
class	tagged ||| bnccorpus reader	count=1
class	list ||| crubadan corpus reader	count=1
function	the score of ||| score	count=2
class	make up this corpus ||| timit corpus	count=1
class	in alphabetical ||| opinion lexicon corpus	count=1
class	bigram collocation finder with ||| trigram collocation finder	count=1
module	ignoring ||| core	count=1
function	implements step 1a ||| step1a	count=1
class	state sequence this ||| markov	count=1
arg	search ||| env_vars searchpath	count=1
module	and returns a subtype ||| sem	count=1
class	returns a list ||| punkt sentence	count=1
class	must ||| glue	count=1
class	dependency grammar from the ||| dependency grammar	count=1
function_arg	tag [arg_2] ||| [arg_2] [function_1]	count=4
class	the overall ||| score	count=2
module	returns a subtype of ||| sem	count=1
arg	in that thread ||| thread_id	count=1
module	internal ||| corpus	count=1
class	:param ||| conditional prob dist	count=1
arg	the string for the ||| string	count=1
arg	implement the ||| fileid unit bracket_sent	count=1
class	the neural dependency parser ||| neural dependency parser	count=1
function	length to the ||| ref length	count=1
function	as a single string ||| raw	count=1
function	the primitive is ||| primitive	count=1
class	holes of this semantics ||| semantics	count=1
arg	freqdists for appearances of ||| word_fd bigram_fd	count=1
function	filter ||| filter	count=1
class	encoded ||| chunked	count=1
arg	add a ||| func add	count=1
function	save a [function_2] ||| [function_2] [function_1]	count=4
arg	add a new edge ||| edge	count=1
function	a subtype of ||| variable	count=1
module	probability state sequence this ||| tag	count=1
class	this object ||| substitute bindings	count=1
class	for the current ||| corpus reader	count=1
function	find contexts including possible ||| period context	count=1
class	the corpus ||| framenet corpus reader	count=1
function	remove all tags ||| clear tags	count=2
arg	word back into the ||| word	count=1
arg	implement ||| bracket_sent	count=1
arg	is ||| other	count=4
arg	[arg] takes into ||| [arg]	count=1
class	return a list ||| crubadan corpus reader	count=1
class	internal indexes to ||| framenet	count=1
function	length six patterns and ||| pro w6	count=1
function	file to its web ||| file	count=1
class	[class_1] wrapper ||| [class_2] [class_1]	count=1
arg	list ||| a	count=1
module	to ||| parse	count=1
function	table of ||| create token table	count=1
function	past tweets ||| tweets	count=1
function_arg	adds [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
arg	list of characters ||| fileids	count=1
function_arg	[function_1] remaining_text ||| [arg_2] [function_1]	count=3
function	the probability of all ||| prob all	count=2
arg	the given ||| chart	count=1
module	as an integer 1 ||| corpus	count=1
arg	metric that ||| label1 label2	count=1
arg	print classifier performance on ||| test_set classifier accuracy f_measure	count=1
class	must be called ||| regexp	count=1
class	indicates how much ||| edge	count=1
arg	t in ||| t	count=1
arg	initial_tagger the initial ||| initial_tagger rules training_stats	count=1
function	factory ||| expression	count=1
function	redirects arcs to ||| redirect arcs	count=1
module	must be called ||| sem	count=1
arg	it precedes [arg] ||| [arg]	count=1
module_class	the [module_1] [class_2] ||| [module_1] [class_2]	count=4
class	gzip file ||| gzip file	count=2
arg	given item at the ||| item x	count=1
function	a list ||| info from	count=1
arg	train and ||| trainer save_analyzer n_instances output	count=1
arg	invalidate ||| key	count=1
function_arg	[function_1] [arg_2] ||| [function_1] sents fileids [arg_2]	count=6
class	enter ||| chart parser app	count=1
function	save a chart to ||| save chart	count=1
class	be called if ||| regexp	count=1
function	information ||| user info from id	count=1
arg	samples given ||| samples	count=1
function	chapters each encoded as ||| chapters	count=1
function	located at a specific ||| nltk	count=1
class	stack ||| stepping	count=1
function	variety of ||| from id	count=1
function	of nodes ||| nodes	count=1
function	exemplar sentence and ||| exemplar of	count=1
class	bigram using ||| bigram	count=1
function	flatten ||| flatten	count=1
class	called if ||| drt glue	count=1
function	obtained by [function] ||| [function]	count=3
function_arg	replace all [arg_2] ||| [function_1] [arg_2]	count=9
module	first element ||| parse	count=1
function	the truncation line ||| get truncation	count=1
arg	posted by ||| screen_name limit include_rts	count=1
module_class	re-download any [class_2] ||| [module_1] [class_2]	count=2
class	a probabilisticdependencygrammar based ||| projective dependency parser	count=1
class	the pickled model weights ||| averaged perceptron	count=2
arg	bayes classifier on 10000 ||| n_instances output	count=1
class	this ||| shift reduce app	count=1
function	to a new ||| init	count=1
arg	in the given tree ||| tree	count=1
class	sort ||| chart parser	count=1
function	[function_1] a dictionary ||| [function_2] [function_1]	count=2
arg	:param positive_featuresets a ||| positive_featuresets unlabeled_featuresets	count=1
function	list ||| user info	count=1
arg	remaining lines at exactly ||| lines wrap_at	count=1
class	called if ||| regexp	count=1
arg	be trained ||| unk trained n	count=1
function	returns the log ||| log	count=1
class	probability state sequence this ||| markov	count=1
class	the files ||| reviews corpus reader	count=1
function	demonstration of the recursive ||| demo	count=1
function_arg	stem [arg_2] ||| [arg_2] [function_1]	count=3
function	[function_1] by ||| [function_2] [function_1]	count=4
module	is ||| parse	count=2
function	relations [function_2] ||| [function_1] [function_2]	count=3
function	that the eval ||| eval	count=1
class	sentence string to ||| view	count=1
module	then [module] a ||| [module]	count=2
class	move a token from ||| shift reduce parser	count=1
function	nltk's recommended word ||| word	count=1
module	called ||| sem	count=1
function	the most recent tweets ||| tweets	count=1
arg	input expression to ||| assumptions timeout prover	count=1
arg	expression the expression ||| expression	count=1
class	[class_1] matrix from ||| [class_1] [class_2]	count=1
arg	string containing ||| vnframe indent	count=1
arg	by repeatedly taking a ||| train_sents test_sents min_score min_acc	count=1
class	the hmm ||| hidden markov model	count=1
class	how much of the ||| i	count=1
class	this ||| parser app	count=1
class	defined for this corpus ||| categorized corpus reader	count=1
class	a probabilisticdependencygrammar based on ||| parser	count=1
function	create a dictionary ||| make predicate dict	count=1
arg	the item is a ||| item	count=1
class	probability state ||| model tagger	count=1
class	convert a list of ||| query	count=1
class	childes ||| childescorpus	count=2
class	of the dependencygrammar ||| dependency grammar	count=1
function	add [function_2] ||| [function_1] [function_2]	count=5
class	data ||| data	count=1
arg	distance ||| distance simulate_root	count=1
class	this corpus ||| category corpus	count=1
class	operators in store ||| store	count=1
arg	[arg_1] and ranks2 ||| [arg_2] [arg_1]	count=1
function_arg	a category [arg_2] ||| [function_1] [arg_2]	count=4
class	the test ||| test	count=1
function	illustrate the ||| discourse	count=2
class	list of ||| list	count=1
class	the internal ||| corpus reader	count=1
function	eval ||| eval chunk	count=1
class	all parses [class_2] ||| [class_2] [class_1]	count=8
class	set ||| tree segment widget	count=1
class	the ||| query	count=1
function	help [function_2] ||| [function_1] [function_2]	count=1
function	process length six ||| w6	count=1
arg	in an ||| limit	count=1
function	lists for the given ||| lists	count=1
class	the files that have ||| reviews	count=1
class	the files that have ||| reviews corpus	count=1
arg	match of *regexp* ||| regexp	count=1
function_arg	[function_1] words can ||| [function_1] [arg_2]	count=2
function	apply self prob_classify() to ||| prob classify many	count=2
module	chunk parser using ||| chunk	count=1
class	be ||| chunk	count=1
class	contents of the ||| category corpus	count=1
function	to realign punctuation that ||| realign boundaries	count=1
module_class	this table's main ||| draw table	count=1
function	chunks represented ||| chunks	count=1
class	function ||| regexp chunk app	count=1
arg	:return the xml description ||| roleset_id	count=1
module	the sentence string to ||| app	count=1
function	fulltextindex ||| fulltextindex elt	count=2
function	of entries in the ||| size	count=1
arg	tree ||| tree	count=6
class	probability [class_2] ||| [class_1] [class_2]	count=12
arg	the given root directory ||| root fileids	count=1
arg	the binary with ||| binary	count=1
arg	of documents ||| documents	count=1
class	unit needs to be ||| chart	count=1
function_arg	[function_1] grammar ||| [arg_2] [function_1]	count=3
function	plausible semtypes in ||| semtypes	count=1
class	a list specifying ||| mtecorpus	count=1
function_arg	recent tweets [arg_2] ||| [function_1] [arg_2]	count=2
class	wordnet corpus reader with ||| word net corpus reader	count=1
class	tags the sequence ||| hidden markov model tagger	count=1
class	to the ||| stepping shift	count=1
arg	from a word-aligned ||| srctext trgtext	count=1
class	chart ||| chart	count=6
class	header_mode ||| nkjpcorpus header	count=1
arg	tree structures ||| tree_class complete	count=1
function	invalidate the cached n ||| setitem	count=1
arg	the utterance identifiers ||| sex spkrid sent_type	count=1
class	with eval(), [class] lists ||| [class]	count=1
class	end of the ||| parser	count=1
function	information about ||| info from	count=1
class	the ||| instance	count=2
class	the ||| drt glue demo	count=1
arg	luname frameid ||| fn_luid ignorekeys luname frameid	count=1
class	of this tree ||| parented tree	count=1
class	overall ||| score	count=2
function	web help [function_2] ||| [function_1] [function_2]	count=1
class	normalize ||| text tiling tokenizer	count=1
class	words in ||| opinion lexicon corpus	count=1
class	graph in ||| graph	count=1
function	a tgrep search string ||| tgrep tokenize	count=1
arg	status_code the status code ||| status_code	count=1
function	representation of the ||| item repr	count=1
class	to be how ||| chart view	count=1
module	method function return ||| core	count=1
function	chunk ||| chunk parse	count=1
function	the fileids ||| fileids	count=1
class	state sequence this ||| hidden markov	count=1
function	[function_1] bound node ||| [function_2] [function_1]	count=1
function_arg	read up [arg_2] ||| [arg_2] [function_1]	count=4
arg	*text* see :class regexptokenizer ||| text pattern gaps discard_empty	count=1
function	override counter __delitem__() to ||| delitem	count=1
function	with ||| with	count=3
class	the remaining text to ||| shift reduce parser	count=1
class	conditional ||| conditional	count=2
arg	of word ||| strip_space stem	count=1
arg	:param positive_featuresets ||| positive_featuresets unlabeled_featuresets	count=1
class	[class_1] probability distribution ||| [class_2] [class_1]	count=4
class	bigram using ||| bigram collocation finder	count=1
arg	and returns a tuple ||| line primitives	count=1
module	be etc ||| app	count=1
function_arg	[function_1] given user ||| [function_1] [arg_2]	count=5
class	:return ||| corpus reader	count=1
class	this rule given the ||| rule	count=1
arg	a given sample the ||| sample	count=1
class	binder in the expression ||| binder expression	count=1
module	build the ||| corpus	count=1
function	[function_1] the url ||| [function_1] [function_2]	count=5
function_arg	[function_1] *regexp* ||| [arg_2] [function_1]	count=1
class	may cause the ||| mutable prob dist	count=1
class	0 75 ||| kneser ney prob	count=1
module	on whether tweets ||| twitter	count=1
function_arg	tags [arg_2] ||| [function_1] [arg_2]	count=1
function	a demonstration showing ||| parse demo	count=1
class	generates ||| malt parser	count=1
class	tags the sequence with ||| markov model tagger	count=1
module	[module] that ||| [module]	count=1
arg	highest information content ||| synset1 synset2 ic	count=1
class	may cause ||| mutable prob dist	count=1
function	methods ||| drt discourse demo	count=1
module	function ||| sem	count=1
class	file within zipfile ||| zip file	count=2
class	encoded ||| chunked corpus reader	count=1
class	alphabetical ||| opinion lexicon corpus reader	count=1
function	the productions ||| productions	count=2
class	feature identifiers used ||| feat	count=1
function	that *rule* applies at ||| rule applies	count=1
class	sequence this ||| tagger	count=1
class	function must be ||| regexp chunk app	count=1
class	this function must be ||| drt	count=1
class	frontier ||| descent	count=1
class	rule it has the ||| rule	count=1
arg	be [arg_2] ||| [arg_2] [arg_1]	count=2
function	unique ||| get unique	count=1
function	is the special category ||| category	count=1
arg	if ||| verbose	count=1
arg	configure the ||| cnf	count=1
function	the various methods of ||| discourse demo	count=2
function	from a frame xml ||| frame	count=1
function	search for past ||| search	count=1
function	string representation of this ||| repr	count=8
module	639-3 ||| corpus reader	count=3
class	must be called if ||| demo	count=1
class	parsing a text ||| recursive descent parser	count=1
function	bigrams generated from a ||| bigrams	count=1
arg	to value ||| value	count=2
module	which looks up the ||| core	count=1
class	[class_1] encoding ||| [class_2] [class_1] length	count=1
arg	devset_name the name ||| devset_name devset grammar chunk_label	count=1
arg	string ||| s chunk_label	count=1
arg	override counter __setitem__() to ||| val	count=1
class	unicode encoding [class] ||| [class]	count=1
arg	rows and ||| rows cols attempts	count=1
class	words in alphabetical order ||| lexicon	count=1
class	of the frontier in ||| stepping	count=1
class	[class] not ||| [class]	count=1
function	of information ||| info from id	count=1
function	file for tadm ||| tadm file	count=3
class	tags the ||| hidden markov	count=1
class	probability state ||| markov	count=1
class	feature structures assign ||| feat struct	count=1
function	the fulltextindex xml file ||| handle fulltextindex	count=1
class	the base frequency ||| dist	count=1
class	trigram using the ||| trigram collocation finder	count=1
class	introduced by this variable ||| variable	count=1
function	userid to ||| lookup by userid	count=1
class	identifiers for ||| ycoecorpus	count=1
arg	size bytes ||| size	count=1
function	in accordance ||| parse	count=1
class	the chart rule used ||| stepping chart	count=1
class	a list ||| list	count=1
arg	i j ||| i j	count=1
class	return lemmas ||| word net	count=1
arg	paths where ||| paths	count=1
class	text returns a ||| punkt sentence tokenizer	count=1
function	known abbreviation ||| reclassify abbrev	count=1
arg	objects if [arg] is ||| [arg]	count=1
function	of child pointer ||| child pointer	count=2
module	remaining text to the ||| parse	count=1
function	each successive match ||| regexp span tokenize	count=1
function	unigram features reflecting the ||| extract unigram feats	count=1
arg	[arg_1] [arg_2] the ||| [arg_1] [arg_2]	count=9
class	the brill [class_2] ||| [class_1] [class_2]	count=3
class	a list of supported ||| reader	count=1
class	of ||| recursive descent	count=1
class	pickle ||| pickle	count=2
function	chunker to chunk the ||| chunk	count=2
arg	the distance of each ||| distance simulate_root	count=1
function_arg	[function_1] [arg_2] leave the stream's file ||| [function_1] [arg_2]	count=7
function	bigrams generated from ||| bigrams	count=1
class	of the remaining ||| shift reduce	count=1
class	alphabetical order ||| corpus	count=1
class	:param ||| tool command	count=1
function	list ||| tagged words	count=1
function	the number of left ||| left	count=1
module	the canvas that this ||| draw	count=1
function	from the [function_2] ||| [function_2] [function_1]	count=1
class	this function must ||| glue demo	count=1
function	license file if ||| license	count=1
class	encoded as a ||| tagged	count=2
function	[function_1] megam based ||| [function_2] [function_1]	count=6
function	exemplar ||| exemplar	count=1
function	ratios ||| ratio	count=1
module	exemplify repr rule (see ||| tbl	count=1
module_class	[module_1] packages ||| [module_1] [class_2]	count=4
module_class	[module_1] associated menu ||| [module_1] [class_2]	count=2
function	trace output ||| trace	count=5
function_arg	fringe [arg_2] ||| [function_1] [arg_2]	count=2
class	parses ||| recursive descent	count=2
function_arg	[function_1] offset ||| [function_1] [arg_2]	count=2
module	with ||| parse	count=1
function	likelihood [function_2] ||| [function_2] [function_1]	count=4
arg	bracketed ||| brackets read_node	count=1
function	of tagged ||| tagged	count=6
class	that is ||| descent parser	count=1
function	entries containing word ||| entries	count=1
function	the probability of ||| probability	count=1
arg	a segmentation is ||| ref hyp	count=1
class	eval(), [class] lists ||| [class]	count=1
class	[class_1] expression ||| [class_2] [class_1]	count=8
arg	a quadgramcollocationfinder given ||| quadgram_fd ii iii	count=1
arg	all nonterminals for ||| cat	count=1
class	feature ||| feature	count=7
class	error-rate ||| paice	count=1
function	:return the input string ||| input	count=1
module	recursive ||| parse	count=1
class	function must be called ||| parser	count=1
class	the ||| recursive	count=2
class	chunks ||| corpus reader	count=1
function	sequence ||| tag	count=2
function	learning curve -- the ||| demo learning curve	count=1
function	friendly error message ||| parse error	count=1
class	with the ||| edge	count=1
class	how much of ||| i	count=1
module	of ||| twitter	count=2
arg	used to generate freqdist ||| freqdist	count=1
function	vector ||| vector	count=1
function	relation [function_2] ||| [function_2] [function_1]	count=2
function	the strategy used ||| strategy	count=1
class	probability state sequence ||| hidden markov model tagger	count=1
function_arg	[function_1] a sequence ||| [function_1] [arg_2]	count=4
function	a variety ||| info from id	count=1
arg	target [arg_2] ||| [arg_1] [arg_2]	count=1
module	a method function return ||| core	count=1
function	number of [function_2] ||| [function_2] [function_1]	count=2
class	out how big a ||| chart view	count=1
class	defined for this corpus ||| corpus	count=1
arg	specified by [arg] ||| [arg]	count=3
class	uses to choose ||| classifier based	count=1
function	discoursetester ||| discourse demo	count=2
class	the childes ||| childescorpus	count=1
class	of information ||| query	count=1
class	[class_1] that can ||| [class_1] [class_2]	count=8
function	create a dictionary ||| predicate dict	count=1
arg	repeatedly taking a ||| train_sents test_sents min_score min_acc	count=1
class	the end of ||| stepping shift reduce	count=1
arg	a featureset label pair ||| featureset label	count=1
arg	reference ||| references	count=1
class	of the moses detokenizer ||| moses detokenizer	count=1
module	a list of ||| sem	count=2
class	probability ||| markov model tagger	count=3
class	tags the sequence with ||| model	count=1
function	close a ||| close	count=1
function	a list of words ||| words	count=3
arg	word using ||| word	count=1
arg	method ||| handler	count=2
function	normalize the ||| normalize	count=1
class	the corpus ||| pros cons corpus reader	count=1
module	be how ||| app	count=1
class	of the files that ||| reviews corpus	count=1
module	the internal indexes to ||| corpus	count=1
function	the output of ||| output	count=1
function	given node address ||| address	count=1
function_arg	the [function_1] [arg_2] ||| [function_1] [arg_2]	count=55
function	form cnf ||| cnf	count=1
class	the ||| regexp	count=1
function	function for pretty-printing a ||| pretty	count=2
arg	refs list of ||| refs conds	count=2
function	about the users ||| info from	count=1
module_class	probability this [class_2] ||| [module_1] [class_2]	count=2
function	of information ||| user info from id	count=1
function_arg	sentences matching [arg_2] ||| [arg_2] [function_1]	count=1
class	of tweets ||| twitter	count=2
class	remaining text to the ||| reduce	count=1
function	assumes that each ||| read tweets	count=1
class	alphabetical ||| opinion lexicon	count=1
arg	:param expression the expression ||| expression command x y	count=1
arg	a list of ||| fileids	count=3
arg	children that cover span ||| span constituents	count=1
class	file underlying this ||| lazy	count=2
module	list of supported languages ||| corpus reader	count=1
module	of abstractvariableexpression appropriate for ||| sem	count=1
function_arg	[function_1] translating ||| [arg_2] [function_1]	count=3
function	average ||| average	count=1
arg	in a simple manner ||| follow to_screen stream	count=1
module	how big a unit ||| app	count=1
arg	of tree ||| tree treeloc	count=1
function	that is ||| is	count=1
arg	the remaining lines ||| lines	count=1
class	child's ||| sequence	count=1
arg	the following ||| format cache verbose	count=1
arg	synset note that this ||| synset	count=1
arg	the vector to unit ||| vector	count=1
module	return true iff self ||| core	count=1
class	words in alphabetical order ||| corpus reader	count=1
class	inside probabilities ||| inside	count=1
arg	:param positive_featuresets a list ||| positive_featuresets unlabeled_featuresets	count=1
class	given trigram using the ||| trigram collocation	count=1
function	-- i e ||| mro	count=1
class	set ||| kneser ney prob dist	count=1
class	supported languages ||| crubadan corpus reader	count=1
class	is the same for ||| transition	count=1
function	have been recorded by ||| n	count=1
class	a bigram collocation finder ||| trigram collocation finder	count=1
function	to build a nltk ||| build	count=1
module	invalidate the ||| core	count=1
class	the production ||| production	count=1
function	concepts indexed by the ||| process bundle	count=1
class	by this rule ||| chart rule i	count=2
class	text to ||| stepping shift	count=1
arg	[arg_1] j ||| metrics retrieve [arg_1] [arg_2]	count=1
function	string representation of ||| format	count=2
class	out how ||| view	count=1
module	must ||| sem	count=1
function_arg	[function_1] location is ||| [function_1] [arg_2]	count=4
arg	for a [arg] ||| ref hyp [arg]	count=2
arg	p [arg_2] ||| [arg_2] [arg_1]	count=4
function	exemplar sentences ||| exemplars	count=1
class	prevent unnecessary ||| resolution prover	count=1
class	name of ||| nombank	count=1
function	a list of ||| user info from	count=1
class	token from the ||| shift reduce parser	count=1
module_class	[module_1] dependencygrammar ||| [module_1] [class_2]	count=4
class	function must be ||| chunk	count=1
function	concept ||| concept	count=1
function_arg	[function_1] and punctuation ||| [function_1] [arg_2]	count=5
class	model ||| model builder command decorator	count=1
function	string representing [function_2] ||| [function_1] parse [function_2]	count=1
function_arg	each [arg_2] ||| [arg_2] [function_1]	count=1
function	target sentence and an ||| t a	count=2
function	returns the node ||| tgrep node	count=1
class	stream ||| unicode stream	count=1
class	:rtype str :return ||| laplace prob	count=1
function	the token is beginning ||| is	count=1
function	write out ||| show	count=1
function	that instantiates and ||| variable	count=1
function_arg	[function_1] from a ||| [function_1] [arg_2]	count=3
function	token is beginning a ||| is	count=1
function	returns a subtype of ||| expression	count=1
class	to every feature ||| feat	count=1
module_class	[module_1] colorized list ||| [module_1] [class_2]	count=2
arg	:param index the index ||| index	count=1
function	freqdist containing only data ||| freq threshold	count=1
function	a string containing ||| format	count=1
class	a rte ||| rtecorpus	count=1
function	of all tags and ||| tags	count=1
class	proper probability [class_2] ||| [class_2] [class_1]	count=1
arg	the given edge ||| edge	count=1
function_arg	[function_1] numsamples x ||| [function_1] [arg_2]	count=3
class	of tweets [class_2] ||| [class_1] [class_2]	count=3
class	be ||| drt glue demo	count=1
module_class	[module_1] space widget ||| [module_1] [class_2]	count=2
class	of supported ||| crubadan	count=1
function	data for ||| data	count=1
function	enable or disable warnings ||| warnings	count=1
class	tags the ||| markov	count=1
function	file for megam based ||| megam file	count=1
function	convert a ||| from id	count=1
function	modify and ||| decorate	count=1
arg	s as a ||| fileids c5	count=2
module	much of the ||| parse	count=1
function	as derived ||| get params	count=1
function	that ||| variable	count=1
function	features each feature is ||| features	count=1
function_arg	[function_1] empty ||| [function_1] [arg_2]	count=3
module	of supported languages as ||| corpus	count=1
class	parser ||| parser	count=7
arg	initialize a discoursetester ||| input reading_command background	count=1
class	the sentence ||| chart view	count=1
class	a feature with ||| feat dict	count=1
function_arg	tweets [arg_2] ||| [function_1] [arg_2]	count=2
class	:rtype str :return a ||| laplace prob dist	count=1
function	contains a node ||| contains	count=1
function	a padded ||| pad	count=1
class	a brill ||| brill	count=1
class	languages as ||| corpus	count=1
class	a ||| reader	count=1
function	table ||| table	count=1
class	element of ||| descent	count=1
class	is consistent with ||| edge i	count=1
function	for the experiment _create_rand_fdist ||| create sum pdist	count=1
arg	tokens in bigrams ||| bigrams	count=1
arg	no filename ||| filename	count=1
class	sequence with ||| markov model tagger	count=1
class	supported languages as iso ||| reader	count=1
module	hypothesized ||| parse	count=1
function	an information content lookup ||| ic	count=1
arg	and consequent of 'self' ||| other	count=1
module	corpus ||| corpus reader	count=11
class	probability ||| prob	count=10
class	this function ||| regexp chunk app	count=1
module_class	[module_1] corpus reader ||| [module_1] tagged [class_2]	count=1
class	the internal ||| framenet	count=1
class	end of the ||| shift	count=1
class	from a sentence in ||| reader	count=1
function_arg	[function_1] than min_freq ||| [arg_2] [function_1]	count=3
class	tree should be ||| chart	count=1
function	by a given ||| by user	count=1
module_class	if this canvasframe ||| draw canvas frame	count=1
function_arg	[function_1] boxer_drs_interpreter ||| [arg_2] [function_1]	count=1
class	freqdist ||| freq	count=1
arg	distribution of the words ||| words	count=1
class	the name of ||| nombank	count=1
class	distribution of ||| dist	count=1
function	is ||| expression	count=1
class	feature with the given ||| feat	count=1
function	of words ||| words	count=4
module	of file [module] for ||| [module]	count=1
function_arg	[function_1] sequence of ||| [arg_2] [function_1]	count=4
class	list ||| crubadan	count=1
function	each successive match of ||| span tokenize	count=1
class	enter ||| chart parser	count=1
class	the rule ||| rule	count=1
class	a substitution corresponding ||| ccgvar	count=1
function	subcorpus ||| lusubcorpus	count=1
class	cumulative ||| freq dist	count=1
class	representing the current ||| gaaclusterer	count=1
function_arg	[function_1] refs list ||| [function_1] [arg_2]	count=1
function_arg	score for [arg_2] ||| [function_1] [arg_2]	count=2
arg	:param positive_featuresets ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
class	a single ||| stepping shift reduce parser	count=1
function	help ||| help	count=1
arg	f-score it is ||| max_len	count=1
arg	variables in univ_scope ||| univ_scope	count=1
class	on the childes ||| childescorpus reader	count=1
class	normalises ||| vector space clusterer	count=1
function	value ||| value	count=1
arg	[arg] next portion ||| [arg]	count=2
class	this rule given ||| rule	count=1
function	and returns a decorator ||| decorator	count=1
function	a dictionary of bigram ||| bigram	count=1
function	abstractvariableexpression appropriate for the ||| variable	count=1
function	learning curve -- the ||| learning curve	count=1
module_class	[module_1] tree or ||| [module_1] [class_2]	count=4
function	formed from the given ||| from	count=1
class	the stack ||| reduce parser	count=1
class	the cmudict lexicon ||| cmudict	count=2
class	indicates how much of ||| i	count=1
arg	i [arg_2] ||| [arg_2] [arg_1]	count=1
arg	the given item ||| item	count=1
function	about ||| info from	count=1
class	with ||| markov model tagger	count=2
module	corresponding full tweets if ||| twitter	count=1
function_arg	[function_1] probability ||| [arg_2] [function_1]	count=1
function	match the first element ||| match	count=1
function	assumes that each line ||| tweets	count=1
class	using the punkt word ||| punkt	count=1
arg	a segmentation ||| hyp	count=1
arg	hunpos-tag ||| path_to_bin	count=1
arg	and punctuation symbols encoded ||| strip_space stem	count=1
function	tokenized list [function_2] ||| [function_2] [function_1]	count=4
class	sentences in the corpus ||| sentences corpus reader	count=1
function	n ||| setitem	count=1
function	web [function_2] ||| [function_1] [function_2]	count=2
function	characters ||| char	count=2
function	binding to each ||| bind to	count=1
arg	list of samples ||| samples store_logs	count=1
function	tokenize() to each element ||| sents	count=1
module	first element of the ||| parse	count=1
arg	word tag tuples ||| strip_space stem	count=1
class	representation for this alignedsent ||| aligned	count=1
function	truncation line ||| get truncation	count=1
function	the top ||| find top	count=1
function	latex qtree package ||| latex qtree	count=2
function	construct a new ||| init	count=27
arg	:rtype ||| production	count=1
module	the childes corpus ||| corpus reader	count=1
function	a chart ||| chart	count=2
arg	location ||| location	count=1
function	of all variables in ||| variables	count=1
class	[class_1] examples (i ||| [class_1] [class_2]	count=4
function	the truncation line ||| truncation coordinates	count=1
arg	finalize is true ||| finalize	count=1
class	be called ||| parser	count=1
class	finnish ||| finnish	count=1
function_arg	read from [arg_2] ||| [function_1] [arg_2]	count=4
class	frequency distribution in two ||| turing prob dist	count=1
function	number of [function_2] ||| [function_1] [function_2]	count=2
arg	word back into ||| word	count=1
class	enter the ||| parser app	count=1
function	to a dictionary ||| dict	count=1
function	positions in ||| positions	count=1
function_arg	[function_1] each rule ||| [function_1] [arg_2]	count=1
function	type ||| get type	count=2
arg	the given resource to ||| resource_url	count=1
class	build the internal ||| framenet corpus reader	count=1
arg	implement the view methods ||| bracket_sent tag strip_space	count=1
class	based on ||| based	count=1
class	lidstone estimate ||| lidstone	count=1
class	mapping each context to ||| context	count=1
arg	numsamples x ||| numsamples	count=1
arg	the node return a ||| node	count=1
class	the remaining text to ||| shift reduce	count=1
function	[function] in ||| [function]	count=2
function	error message when parsing ||| parse error	count=1
function	used ||| use	count=1
module_class	exists return [class_2] ||| [module_1] [class_2]	count=1
function	factory method that instantiates ||| variable expression	count=1
class	underlying this corpus ||| lazy sequence	count=1
arg	with the highest ||| unlabeled_sequence	count=1
class	corpus and then return ||| corpus	count=1
arg	"known labels" for this ||| mapping unseen_features alwayson_features	count=2
function	scores the score of ||| score	count=1
function	fval2, ||| feature values	count=1
function	rule and rule ||| rule	count=1
arg	the reference that is ||| references hyp_len	count=1
function	ending step ||| end w5	count=1
function	all possible word ||| all	count=2
function	of ||| discourse	count=2
class	a new maxent classifier ||| maxent classifier	count=1
arg	the index of the ||| index depth	count=1
arg	[arg_1] with edge ||| [arg_2] [arg_1]	count=2
arg	optional frame object name ||| frame	count=1
class	a corpus view ||| nombank corpus	count=1
class	this function must be ||| glue	count=1
arg	highest information content value ||| ic verbose	count=1
function_arg	[function_1] classifier performance ||| [function_1] [arg_2]	count=1
class	a new classifier based ||| classifier based	count=1
class	remaining text ||| shift reduce parser	count=1
arg	directory ||| root encoding	count=1
class	this rule it ||| chunk rule with context	count=1
class	the lancaster ||| lancaster	count=2
class	in ||| lexicon corpus	count=1
arg	file s as ||| fileids tag	count=1
function	names of the columns ||| column names	count=1
module	of this chunk ||| chunk	count=1
function_arg	eval [arg_2] ||| [arg_2] [function_1]	count=1
module	full [module] in json ||| [module]	count=1
function_arg	[function_1] [arg_2] account partial agreement when ||| [function_1] [arg_2]	count=1
arg	[arg] parser's tree ||| [arg]	count=1
arg	p and q ||| p q	count=3
arg	the tree structures ||| tree_class complete	count=1
function	subtype of ||| variable	count=1
function	the users ||| from id	count=1
function	for tadm based ||| tadm	count=1
class	stack ||| stack	count=3
module	of the stack ||| parse	count=1
arg	the input stream ||| stream	count=1
function	chunk ||| chunk	count=3
class	tagged corpus reader for ||| tagged corpus reader	count=1
function	applies at the ||| rule applies	count=1
function_arg	relations data [arg_2] ||| [function_1] [arg_2]	count=2
function	a variety of ||| from	count=1
arg	binary with ||| binary	count=1
class	words in ||| lexicon corpus reader	count=1
function	information about ||| from id	count=1
function	[function_1] target ||| [function_1] t [function_2]	count=2
arg	provercommand provercommand ||| provercommand	count=1
class	of supported languages ||| crubadan corpus	count=1
class	of a dependency graph ||| probabilistic projective dependency parser	count=1
function_arg	annotated sentences [arg_2] ||| [arg_2] [function_1]	count=1
class	conditional frequency [class_2] ||| [class_2] [class_1]	count=3
class	frequency distribution in two ||| prob dist	count=1
class	single ||| tn	count=1
arg	a pretty-printed version ||| width prefix depth	count=2
function	tadm based ||| tadm	count=1
function	size of ||| size	count=1
class	for the ||| thesaurus corpus reader	count=1
arg	string of bracketted ||| s chunk_label root_label sep	count=1
class	collocation finder with the ||| trigram collocation finder	count=1
function	given a collection ||| from documents	count=1
function_arg	the chunk [arg_2] ||| [function_1] [arg_2]	count=1
function	[function] info for ||| handle [function]	count=2
class	a given trigram ||| trigram collocation finder	count=1
arg	word tag tuples ||| c5 strip_space stem	count=1
function	unique counter from the ||| get unique counter from	count=1
class	a sentence in an ||| reader	count=1
function	the names of the ||| names	count=2
class	a set of all ||| comparative	count=1
function	frame from a frame ||| frame	count=1
arg	forward ||| forward fs_class visited	count=1
function	plausible semtypes ||| semtypes	count=1
module	alignment ||| translate	count=1
function	list of ||| info	count=1
class	order ||| lexicon corpus	count=1
class	this function must ||| demo	count=1
class	remaining ||| shift	count=1
class	neural dependency [class_2] ||| [class_1] [class_2]	count=4
function	an epytext @field ||| epytext	count=1
function	best incoming [function_2] ||| [function_1] [function_2]	count=4
function	a string ||| pretty format	count=1
class	returns a ||| punkt sentence tokenizer	count=1
function	common top_n [function] features ||| unigram [function]	count=1
class	in ||| opinion	count=1
function	construct a ||| init	count=5
module	to [module] ||| [module]	count=6
arg	some ||| keywords	count=1
class	for this alignedsent ||| aligned	count=1
function	into pseudosentences of ||| divide to tokensequences	count=1
class	the ||| framenet	count=1
function	two sentences c{source_sents[i]}, c{target_sents[j]} ||| align	count=1
arg	sentence pair from the ||| sentence_pair	count=2
class	function must be ||| regexp chunk	count=1
class	each line in ||| corpus reader	count=1
class	a pickle ||| parser app	count=1
function_arg	tagged [arg_2] ||| [function_1] to parse [arg_2]	count=1
class	conditional [class_2] ||| [class_2] [class_1]	count=5
function	a string representing ||| aug	count=1
arg	[arg] corpus ||| [arg]	count=2
class	from the given ||| framenet corpus reader	count=1
module	words in alphabetical order ||| corpus	count=1
class	function must ||| regexp	count=1
arg	symbol [arg_2] ||| [arg_2] [arg_1]	count=4
class	make ||| perceptron tagger	count=1
function	[function_1] the sentences ||| [function_2] [function_1]	count=8
function	word alignments ||| alignments	count=2
function	leaf nodes ||| leaves	count=1
class	encoded as a ||| chunked corpus reader	count=2
function	max ||| max	count=1
function	use of ||| use	count=1
class	of the remaining text ||| shift reduce parser	count=1
function	find all [function_2] ||| [function_2] [function_1]	count=1
class	in ||| descent parser	count=1
function	stem a ||| stem	count=1
function	3 from ||| step3	count=1
module	this is ||| core	count=1
function	into pseudosentences of fixed ||| divide to tokensequences	count=1
class	creates a distribution of ||| dist	count=1
arg	insert a [arg] canvas widget ||| index [arg]	count=2
module	of ||| inference	count=2
module	languages as iso 639-3 ||| reader	count=1
function	observed and expected agreements ||| multi kappa	count=1
class	contingencymeasures given a ngramassocmeasures ||| contingency measures	count=1
class	context to the ||| context index	count=1
function	dependencygraph as the training ||| train	count=1
class	first ||| parser	count=1
class	big a ||| chart	count=1
function	find ||| common	count=1
class	this encoding ||| binary maxent feature encoding	count=1
function	arc from ||| arc	count=1
function	unigram features reflecting ||| unigram feats	count=1
class	parsers that ||| parser	count=2
module	corresponding full tweets ||| twitter	count=1
class	examples ||| naive bayes	count=1
function	binding ||| bind	count=3
function	of s-expressions from ||| sexpr block	count=1
module	internal indexes ||| reader	count=1
class	big a unit ||| chart	count=1
function	parse a [function_2] ||| [function_2] [function_1]	count=4
arg	version ||| prefix depth	count=1
class	to be how big ||| view	count=1
arg	new callback that will ||| callback	count=1
function_arg	[function_1] displaying ||| [arg_2] [function_1]	count=2
class	as in ||| measures	count=1
arg	list of lists of ||| fileids tagset	count=1
function	subtype of abstractvariableexpression appropriate ||| expression	count=1
function	check ||| check grammar	count=1
function	beginning of ||| shift	count=2
class	line in ||| corpus reader	count=1
class	639-3 ||| crubadan corpus	count=1
class	words ||| corpus	count=1
function	node with the given ||| remove by	count=1
function	the tree ||| to tree	count=1
arg	if the sequence ||| sequence	count=1
class	encoding [class] file if ||| [class]	count=1
function	[function] is ||| calculate [function]	count=1
arg	paths where a ||| paths	count=1
class	big a ||| view	count=1
function_arg	fringe of [arg_2] ||| [function_1] [arg_2]	count=2
class	list of supported ||| crubadan	count=1
function	the sentences [function_2] ||| [function_1] [function_2]	count=2
arg	to csv ||| outfile fields encoding	count=1
function	distance similarity ||| similarity	count=1
arg	the *worder* list i ||| reference hypothesis character_based	count=1
class	bigram ||| bigram	count=2
function_arg	evaluate and [arg_2] ||| [arg_2] [function_1]	count=3
class	necessary ||| nkjpcorpus	count=1
class	[class_1] examples ||| [class_1] [class_2]	count=4
function	a freqdist containing only ||| freq threshold	count=1
function	its multi-listbox (_mlb) ||| vs mlb	count=1
function	start stop bounds ||| bounds	count=1
module	corpus or that store ||| corpus	count=1
class	the frontier in particular ||| descent	count=1
class	be called if ||| chunk	count=1
function_arg	[function_1] strings ||| [arg_2] [function_1]	count=2
function	to build a ||| build	count=1
module	of abstractvariableexpression ||| sem	count=1
class	returns words [class_2] ||| [class_2] [class_1]	count=1
module	to be ||| app	count=1
arg	of tokens using ||| tokens	count=1
class	rte ||| rtecorpus	count=1
arg	a sequence of ||| sequence	count=3
function	unification of ||| unification	count=1
function_arg	[function_1] and ||| [function_1] fileids [arg_2]	count=8
function	train a new ||| train	count=1
class	list of text colortag ||| list	count=1
class	words in ||| lexicon	count=1
class	to ||| view	count=2
arg	s ||| fileids c5	count=2
class	the dict with which ||| dict	count=1
function	_tag_positions ||| tag positions	count=2
class	path identified ||| path	count=1
class	classifier ||| naive bayes classifier	count=1
function	status of the ||| status	count=1
function	a pcfg grammar ||| pcfg	count=1
arg	and other ||| other check_reentrance visited_self	count=1
function_arg	which [arg_2] ||| [function_1] nodes [arg_2]	count=1
class	of ||| parser	count=3
arg	[arg] terminal which ||| [arg]	count=2
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2] mod_address	count=6
function_arg	[function_1] of tokentablefields ||| [arg_2] [function_1]	count=3
function	the table's _rows ||| table	count=1
class	[class_1] in specified ||| [class_1] [class_2]	count=1
class	brill tagger on the ||| brill tagger	count=1
class	configure ||| multi listbox	count=2
module_class	this [class_2] ||| [module_1] colorized [class_2]	count=1
module	end ||| parse	count=1
arg	positions where it applies ||| tokens positions	count=1
arg	must be trained ||| unk trained n	count=1
function	the roleset used by ||| roleset	count=1
class	if ||| chart parser app	count=1
function	[function_1] rule this ||| [function_1] [function_2]	count=3
arg	t ||| s t	count=1
class	resize ||| multi listbox	count=1
class	ngram [class] pairs as ||| [class]	count=1
function	all nodes [function] ||| [function]	count=4
function	equal to ||| eq	count=2
arg	translating ||| hypothesis future_score_table sentence_length	count=1
class	text to ||| parser	count=1
module	the ||| corpus	count=3
class	this rule ||| rule with	count=1
arg	given synset and relation ||| synset relation	count=1
arg	a string of bracketted ||| s chunk_label root_label sep	count=1
arg	text ||| word_tokenizer sent_tokenizer	count=1
class	corpus view ||| corpus	count=2
function	url [function_2] ||| [function_2] [function_1]	count=8
function	[function] node ||| [function]	count=1
function	file [function_2] ||| [function_2] [function_1]	count=12
function	return internal crubadan ||| to crubadan	count=1
class	supported languages as ||| reader	count=1
function	get the ||| get	count=1
class	add all edges licensed [class_1] [class_2] ||| [class_2] [class_1] apply everywhere chart grammar	count=4
function	pop [function_2] ||| [function_1] [function_2]	count=3
function	to chunk the ||| chunk	count=2
arg	show all neg or ||| show	count=1
function_arg	an error [arg_2] ||| [arg_2] [function_1]	count=1
class	[class_1] stream ||| core [class_1] [class_2] reader	count=1
function	the sequence with the ||| tag	count=1
function	from [function_2] ||| [function_2] [function_1]	count=1
function	static web [function_2] ||| [function_2] [function_1]	count=2
class	the transition ||| transition	count=1
function_arg	[function_1] [arg_2] the variable ||| sem variable [function_1] [arg_2]	count=1
arg	csv ||| outfile fields encoding	count=1
arg	given [arg] parser's tree ||| [arg]	count=1
arg	return ||| other verbose simulate_root	count=3
function	expressions as a ||| expressions	count=1
function	[function_1] epytext @field ||| [function_1] [function_2]	count=1
function	pointer of ||| delparent	count=1
function	the pointwise [function] ||| point [function]	count=3
function	absolute [function] that ||| [function]	count=1
class	corresponding vector of joint-feature ||| maxent feature encoding	count=1
function	return a [function] ||| [function]	count=1
arg	id luname ||| ignorekeys luname	count=1
class	[class_1] contexts to ||| [class_2] [class_1]	count=2
class	to ||| shift reduce parser	count=1
function	which have frequency ||| freq	count=1
function	function provides a demonstration ||| demo	count=1
class	generated when parsing a ||| reduce parser	count=1
class	the hypothesized structure ||| i	count=1
function	[function_1] an integer ||| [function_1] [function_2]	count=1
function	edge ||| edge scores	count=1
class	of information about the ||| query	count=1
class	the internal ||| corpus	count=1
class	files that have to ||| reviews corpus	count=1
function	information about the users ||| info from	count=1
class	true if a feature ||| feat	count=1
arg	an ||| elem	count=1
class	of the ||| edge i	count=1
function	2 ||| 2	count=1
function	cosine of ||| cosine	count=1
class	the underlying [class_2] ||| [class_2] [class_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2]	count=2196
class	return a list of ||| crubadan	count=1
module	which looks up ||| core	count=1
class	to a list's ||| abstract lazy sequence	count=1
module	639-3 ||| reader	count=1
arg	structures that are ||| tree_class complete	count=1
arg	[arg_1] label pair ||| [arg_1] [arg_2]	count=3
function	the top of ||| top	count=1
class	a new classifier ||| classifier	count=1
class	[class_1] the pickle ||| [class_2] corpus [class_1]	count=1
arg	string of bracketted ||| s chunk_label	count=1
arg	the [arg] in half ||| [arg]	count=1
class	corpus view ||| corpus reader	count=2
function	the ||| user	count=1
function_arg	page if [arg_2] ||| [arg_2] [function_1]	count=4
function_arg	chunk [arg_2] ||| [arg_2] [function_1]	count=1
class	indexes to ||| framenet	count=1
arg	the "known labels" for ||| mapping unseen_features alwayson_features	count=2
arg	discoursetester ||| reading_command	count=2
module_class	for the text that [module_1] [class_2] being parsed ||| [module_1] [class_2]	count=1
class	internal ||| reader	count=1
class	translation model and ||| ibmmodel2	count=1
class	tree ||| view	count=1
function	[function_1] an epytext ||| [function_1] [function_2]	count=1
function	tagged [function] consisting ||| ne chunk [function]	count=1
class	the tree should be ||| view	count=1
function	1a ||| step1a	count=1
class	scores [class] ngram ||| [class]	count=1
arg	filtered by the ||| empty	count=2
function	of nodes ||| collapse nodes	count=1
class	of this rule it ||| rule	count=1
class	frequency distribution ||| turing prob dist	count=1
function	instantiates and returns ||| expression	count=1
arg	q for feature f ||| q f	count=1
class	the remaining ||| stepping shift reduce parser	count=1
function	on its relation ||| relation	count=1
arg	binary with the ||| binary args	count=1
arg	from the source ||| source	count=1
module	values as its arguments ||| metrics	count=1
class	file ||| file	count=4
function_arg	[function_1] expression ||| [function_1] [arg_2]	count=5
class	the tag of ||| tag	count=1
module	frontier in particular if ||| parse	count=1
module	corpus import wordnet as ||| corpus reader	count=1
class	must be called if ||| chart	count=1
module	name of the ||| reader	count=1
class	result to prevent unnecessary ||| resolution prover	count=1
module	a ||| sem	count=10
class	remaining text to ||| stepping shift reduce parser	count=1
arg	tree the ||| tree	count=1
class	sentences in the test ||| test	count=1
class	bigrams in the ||| bigram	count=1
module	the stack ||| parse	count=1
function	the best incoming arc ||| best incoming arc	count=1
function	of ||| discourse demo	count=2
module	function must be ||| app	count=2
class	bigrams ||| bigram	count=3
arg	for rhs ||| rhs	count=1
function_arg	left children under ||| left children node_index	count=1
class	dependency graph ||| projective dependency	count=1
class	tagged ||| tagged	count=1
arg	of drtindividualvariableexpression for ||| consequent	count=1
function	and __str__ methods under [function_1] [function_2] ||| [function_1] [function_2] unicode compatible klass	count=1
function	the readings ||| readings	count=1
function	and [function_2] ||| [function_2] [function_1]	count=1
class	of the feature identifiers ||| feat	count=1
function	the first ||| annotate first	count=1
function	contents of the table's ||| check table	count=1
function	a factory method ||| variable expression	count=1
class	the predicate ||| propbank instance	count=1
function	relative to truncation errt ||| errt	count=1
function	and returns a ||| expression	count=1
function	file to its ||| webview file	count=1
class	of *sentences* [class] ||| tagger [class]	count=2
class	feature-based grammar ||| feature grammar	count=1
class	variety ||| query	count=1
function	minus the cosine ||| cosine	count=1
function	frequent [function] contexts first ||| [function]	count=1
function	to reduce ||| reduce	count=1
class	much ||| edge i	count=1
function	the tkinter mainloop ||| mainloop	count=6
arg	and returns ||| line	count=1
module	widget in this ||| draw	count=1
class	of the ||| stepping recursive descent	count=1
arg	:param status_code ||| status_code	count=1
class	make up this corpus ||| corpus	count=2
function	node ||| tgrep node	count=1
function	the data ||| data	count=1
function	about ||| user info from	count=1
function	the macro name used ||| macro use	count=1
function	trains ||| train	count=4
class	the inside probabilities of ||| inside chart	count=1
class	rule and ||| rule	count=1
function	likelihood ratios ||| likelihood ratio	count=2
class	[class_1] given corpus ||| [class_2] [class_1] encoding file	count=1
class	underlying this ||| lazy	count=2
class	lexical translation ||| ibmmodel2	count=1
arg	of text label tuples ||| label word_tokenizer sent_tokenizer	count=1
class	stack ||| reduce	count=1
class	remove ||| canvas widget	count=1
class	the name ||| nombank instance	count=1
arg	tuple representation of ||| tagged_token	count=1
function	abbreviation or ||| abbrev	count=1
class	file or ||| buffered gzip file	count=1
function	rules that would ||| rules	count=1
function	categories for a ||| categories	count=1
class	this corpus or for ||| corpus reader	count=2
function	of word/tag/iob tuples ||| iob sents	count=1
function	set of pairs ||| pairs	count=1
module	for this corpus ||| corpus	count=4
module	contained by this ||| draw	count=1
class	to ||| shift	count=1
class	if ||| regexp chunk	count=1
function	[function_1] chunks represented ||| [function_2] [function_1]	count=3
function	type ||| type	count=4
function	convert a ||| user info	count=1
arg	creates ||| source_blocks target_blocks params	count=1
class	corpus reader with the ||| corpus reader	count=1
function	illustrate the various methods ||| demo	count=2
function	the alignment [function] rate aer ||| alignment [function]	count=1
function	the set of variables ||| variables	count=1
class	have to be returned ||| comparative sentences	count=1
arg	sequence of data ||| data start end	count=1
function_arg	average of [arg_2] ||| [function_1] [arg_2]	count=4
class	path ||| file path	count=1
function	node into the tgrep2 ||| node label	count=1
class	tree [class_2] ||| [class_2] [class_1]	count=8
class	the colorized ||| colorized	count=1
function_arg	[function_1] remaining_text ||| [function_1] stack [arg_2]	count=3
class	table's main frame that ||| table	count=1
function	to parse a ||| parse	count=1
function	set [function_2] ||| [function_2] [function_1]	count=1
function	which describes the use ||| use	count=1
class	the ||| recursive descent parser	count=2
class	in particular if ||| recursive	count=1
class	the ||| i	count=2
function	true if the given ||| range	count=1
class	scores ngrams using ||| ngram assoc measures	count=6
arg	the input string ||| input	count=1
function	file ||| search file	count=1
function	stream ||| parse token stream	count=1
function_arg	[function_1] line ||| [function_1] [arg_2]	count=1
arg	count times ||| count	count=1
arg	for a synset ||| word synset	count=1
class	sentence string to ||| chart view	count=1
module	returns ||| sem	count=1
class	positive examples the edges ||| naive bayes dependency	count=1
function	to parse ||| tagged parse	count=2
function_arg	[function_1] of tokens ||| [function_1] [arg_2]	count=1
function	closest length to ||| closest ref length	count=1
class	to invalidate the cached ||| freq dist	count=1
arg	containing ||| vnframe indent	count=1
function	tuple ||| entries	count=1
function	that instantiates and ||| expression	count=1
class	i e ||| tokenizer i	count=1
class	token from the ||| shift	count=1
function	classify ||| classify	count=1
arg	univ_scope ||| univ_scope	count=1
function	the block comparison ||| block comparison	count=2
module	state sequence this ||| tag	count=1
class	this corpus ||| corpus reader	count=10
function_arg	update the [arg_2] ||| [function_1] applies [arg_2]	count=4
function_arg	left children [arg_2] ||| [function_1] [arg_2]	count=4
function	values for ||| values	count=1
class	picklecorpusview [class] ||| pickle corpus [class]	count=2
class	the corpus file underlying ||| abstract lazy	count=1
function	convert a userid ||| userid	count=1
module_class	[module_1] feature ||| [module_1] [class_2]	count=9
arg	specified [arg_1] [arg_2] ||| add [arg_1] [arg_2]	count=1
function	dominating the ||| ancestors	count=1
class	remaining text to the ||| shift reduce parser	count=1
class	returns ||| punkt sentence	count=1
function	and ||| model	count=1
class	actions when the tweet ||| tweet	count=1
module	lu ||| corpus reader	count=1
function	fe coreset ||| fecoreset	count=1
function_arg	likelihood of [arg_2] ||| [function_1] vectorspace [arg_2]	count=1
module	this corpus or ||| corpus reader	count=1
function	indices where ||| indices	count=1
class	change ||| stepping recursive descent parser	count=1
class	encoded as a list ||| chunked	count=2
class	positive examples ||| positive naive bayes classifier	count=1
class	iso ||| corpus	count=1
function	the approximate score for ||| score	count=1
class	figure ||| view	count=1
function	apply ||| apply	count=3
arg	segmentations a segmentation is ||| ref hyp k boundary	count=1
module	the end of the ||| parse	count=1
class	[class_1] probability distribution ||| [class_1] [class_2] renormalize r nr	count=4
function	:return the tree ||| to tree	count=1
function	userid to a ||| lookup by userid	count=1
function	the ||| discourse demo	count=2
function_arg	to reduce [arg_2] ||| [arg_2] [function_1]	count=1
class	as in ||| ngram assoc measures	count=1
function_arg	[function_1] numsamples ||| [function_1] [arg_2]	count=3
function	less ||| filter	count=1
function	pcfg grammar ||| pcfg	count=1
function	whether the word ||| word	count=1
class	languages ||| corpus reader	count=1
class	:param ||| resolution prover command	count=1
function	to invalidate ||| setitem	count=1
class	in ||| reader	count=4
function	get synset [function_2] ||| [function_2] [function_1]	count=4
arg	of child ||| child index	count=2
function	information about ||| info from id	count=1
arg	search ||| searchpath	count=1
class	may cause the object ||| mutable prob	count=1
arg	given span ||| span	count=1
class	evaluate ||| sentiment analyzer	count=1
function	tweets by ||| tweets by user	count=1
function	convert a userid ||| lookup by userid demo	count=1
function	top of the ||| find top	count=1
arg	uses [arg_2] ||| [arg_2] [arg_1]	count=2
arg	expression the expression to ||| expression command	count=1
class	build ||| framenet corpus	count=1
module	build the internal ||| reader	count=1
function	tweets by ||| tweets by user demo	count=1
class	corpus file underlying this ||| abstract lazy	count=1
function	best [function_2] ||| [function_2] [function_1]	count=1
module	the name ||| corpus reader	count=1
function	wu-palmer similarity ||| wup similarity	count=2
class	returns ||| nkjpcorpus reader	count=1
function_arg	[function_1] documents ||| [arg_2] [function_1]	count=1
class	this instance's predicate ||| nombank	count=1
function_arg	[function_1] demon ||| [function_1] [arg_2]	count=4
arg	stream until we ||| stream	count=1
function	[function_1] tadm ||| [function_2] [function_1]	count=6
module	valuation from a ||| sem	count=1
function	megam ||| megam	count=1
arg	tree [arg_2] ||| core tree convert [arg_2] [arg_1]	count=1
class	:return a corpus view ||| corpus	count=2
class	sequence with ||| hidden	count=1
function	table's _rows variable ||| table	count=1
module	function return ||| core	count=1
arg	expression ||| expression command x y	count=1
function	[function_1] probability ||| [function_2] [function_1]	count=3
class	neural ||| neural	count=1
class	edge if the edge ||| edge	count=1
class	remaining text to the ||| reduce parser	count=1
class	weights ||| averaged	count=2
class	contexts to tags ||| tagger	count=1
class	should be provided ||| prover9parent	count=1
arg	compute the [arg_1] [arg_2] any sequence over a ||| metrics pk [arg_2] [arg_1]	count=1
function	[function_1] by a ||| [function_1] [function_2]	count=4
function	fact that *rule* applies ||| applies	count=1
class	sentence in ||| corpus reader	count=1
module	tags the sequence ||| tag	count=1
class	corpus ||| cons corpus reader	count=1
class	convert ||| reading command	count=1
function_arg	parse on [arg_2] ||| [arg_2] [function_1]	count=1
function	difference between phonetic segments ||| diff	count=1
class	sequence ||| markov	count=2
class	sequence this ||| model tagger	count=1
function	create a dictionary ||| dict	count=1
module	supported languages as iso ||| reader	count=1
arg	quadgramcollocationfinder given [arg_2] ||| [arg_2] [arg_1]	count=4
function	binding [function_2] ||| [function_1] [function_2]	count=5
arg	n-gram f-score it is ||| min_len max_len	count=1
class	test ||| test	count=1
function	of labels ||| labels	count=1
function	of tagged words ||| tagged words	count=4
function	codes ||| langs	count=1
class	collocation finder with the ||| collocation	count=1
module	this function returns ||| core	count=1
class	the end of the ||| stepping shift reduce	count=1
function_arg	[function_1] iter tree ||| [arg_2] [function_1]	count=1
arg	root directory ||| root fileids encoding	count=1
function	a pretty-printed representation ||| pprint	count=6
class	that have ||| probabilistic nonprojective parser	count=1
class	constructs a bigram collocation ||| trigram collocation finder	count=1
class	the cached n ||| dist	count=1
function	the beginning of ||| shift	count=2
class	freqdist ||| punkt trainer	count=1
arg	must be trained ||| trained	count=1
class	agenda ||| agenda	count=1
class	contexts to tags ||| context tagger	count=1
arg	train_text can either ||| train_text	count=1
module	to invalidate the ||| core	count=1
class	be more ||| map	count=1
class	[class_1] 639-3 language ||| [class_2] [class_1]	count=2
class	is ||| transition	count=2
class	categorization arguments ||| categorized plaintext	count=1
function	forward ||| forward	count=1
function	bigram features reflecting ||| extract bigram feats	count=2
function	print the ||| print	count=1
arg	of rows and columns ||| rows cols	count=1
module	a ||| twitter	count=2
class	the ||| recursive descent	count=2
function	text generates the sentences ||| sentences	count=1
class	new classifier based ||| classifier based tagger	count=2
function	each successive match ||| tokenize	count=1
arg	with ||| other	count=1
function	if the primitive is ||| primitive	count=1
module	[module] on a ||| [module]	count=1
arg	id luname frameid ||| ignorekeys luname frameid	count=1
arg	modelbuilder the theorem ||| modelbuilder goal	count=1
arg	source-to-target [arg_2] ||| [arg_2] [arg_1]	count=1
function	cache is a ||| cache	count=1
function	containing mappings of lemmas ||| lemmas	count=1
arg	given index ||| index	count=1
arg	given sample the ||| sample	count=1
function	wu-palmer [function_2] ||| [function_1] [function_2]	count=1
function	for all ||| corpus	count=1
function	of unigram features reflecting ||| unigram feats	count=1
function	average log likelihood ||| log likelihood	count=1
class	text to ||| shift reduce parser	count=1
class	identifiers for the ||| ycoecorpus reader	count=1
class	generated when [class_2] ||| [class_2] [class_1]	count=2
class	the end ||| reduce	count=1
class	from the ||| reduce	count=1
arg	text label ||| label word_tokenizer sent_tokenizer	count=2
class	distribution that this probability ||| prob	count=1
function	:return a [function] for the ||| [function]	count=1
arg	and punctuation ||| stem	count=3
function	various methods of ||| discourse demo	count=2
function	alignment [function] rate aer ||| alignment [function]	count=1
class	this corpus ||| string category corpus	count=1
class	translation ||| ibmmodel2	count=1
function	static index page ||| static index page	count=3
function	update the graphical ||| update	count=1
class	when parsing a text ||| shift reduce parser	count=1
arg	userids into a variety ||| userids	count=1
arg	finalize ||| finalize	count=1
class	[class_1] boundary detector ||| [class_2] [class_1]	count=8
function	expected agreements for each ||| multi kappa	count=1
module_class	[module_1] api ||| [module_1] [class_2]	count=4
class	tweets ||| twitter corpus reader	count=1
class	return the overall ||| chunk score	count=2
class	that are generated [class_1] [class_2] ||| [class_2] [class_1]	count=2
class	as in manning ||| measures	count=1
module_class	[module_1] container widget ||| [module_1] [class_2]	count=8
class	sentence ||| stack decoder	count=1
function	[function_1] data ||| [function_1] [function_2]	count=3
class	in a [class_2] ||| [class_2] [class_1]	count=2
class	languages ||| reader	count=1
class	proper probability [class_2] ||| [class_1] [class_2] renormalize r nr	count=1
function	1c from ||| step1c	count=1
function	[function_1] qtree package ||| [function_2] [function_1]	count=3
class	tags the sequence with ||| markov model	count=1
arg	n-gram [arg_2] ||| [arg_1] [arg_2]	count=4
arg	determined [arg] ||| [arg]	count=1
function	of chapters each encoded ||| chapters	count=1
arg	python port ||| tokens return_str	count=1
function_arg	distance similarity [arg_2] ||| [function_1] [arg_2]	count=4
class	of the corpus ||| categorized sentences corpus reader	count=1
function	index for ||| index	count=1
function	a dictionary of bigram ||| extract bigram	count=1
arg	pretty-printed [arg_2] ||| [arg_2] [arg_1]	count=3
function	left-hand side ||| lhs	count=2
function	fulltextindex xml ||| handle fulltextindex elt	count=1
arg	release callback ||| event	count=1
function	collocations derived from the ||| collocations	count=1
class	[class_1] as a ||| [class_1] [class_2]	count=3
function	induce a [function_2] ||| [function_2] [function_1]	count=1
class	this ||| tag	count=1
function_arg	data [arg_2] ||| [arg_2] [function_1]	count=2
module	in alphabetical order ||| reader	count=1
class	the stack ||| shift	count=1
class	list ||| colorized list	count=1
function	appropriate ||| variable expression	count=1
function	[function] of ||| [function]	count=45
function	that ||| variable expression	count=1
arg	generate base_fdist ||| base_fdist heldout_fdist	count=1
function	tree ||| tree pos	count=1
arg	a grammar ||| grammar	count=1
function	a list of ||| from	count=1
arg	distance of ||| distance	count=1
class	a given bigram ||| bigram collocation finder	count=1
arg	implement the view ||| unit bracket_sent	count=1
class	matrix from a ||| matrix	count=1
module	that appears in the ||| inference	count=1
class	update ||| prob dist	count=1
function_arg	[function_1] int limit ||| [arg_2] [function_1]	count=1
module	parse ||| parse	count=8
class	unicode ||| unicode stream	count=1
arg	whether a feature ||| feat flag	count=1
function_arg	categories [arg_2] ||| [function_1] [arg_2]	count=1
class	if the grammar ||| cfg	count=1
class	xml element in a ||| framenet corpus reader	count=1
function	positive words in ||| positive	count=1
function	and __str__ methods under [function_1] [function_2] ||| [function_1] [function_2]	count=1
function	of paragraphs each ||| paras	count=5
module_class	this list ||| draw colorized list	count=1
arg	the binary with the ||| binary args	count=1
module	with ||| tag	count=1
class	[class_1] princeton wordnet ||| [class_2] [class_1]	count=4
function	tabulate ||| tabulate	count=1
class	to the ||| stepping shift reduce parser	count=1
function	nodes [function] ||| [function]	count=4
class	indexes to ||| corpus	count=1
arg	[arg_1] frameid and ||| [arg_2] [arg_1]	count=4
function	create a dictionary of ||| predicate dict	count=1
class	path identified [class_2] ||| [class_1] [class_2]	count=1
arg	the terminal ||| inputfilename outputfilename mode	count=1
function_arg	page [arg_2] ||| [arg_2] [function_1]	count=3
function	tag ||| map tag	count=1
arg	n-gram f-score it ||| min_len max_len	count=1
class	return all ||| reader	count=1
arg	given file s ||| fileids tag	count=1
arg	vectors to clusters ||| vectors	count=1
arg	input ||| assumptions max_models model_builder	count=1
class	text returns a list ||| punkt sentence	count=1
class	this ||| drt	count=1
arg	text nodes [arg] ||| [arg]	count=3
arg	predicate ||| predicate	count=1
arg	[arg_1] vectors ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] string to ||| [function_1] [arg_2]	count=1
function	[function_1] epytext ||| [function_1] [function_2]	count=1
class	confusion [class_2] ||| [class_2] [class_1]	count=5
function	[function_1] first ||| [function_1] [function_2]	count=1
module	this widget and ||| draw	count=1
function	interpretations of ||| r1r2	count=1
class	build the ||| corpus reader	count=1
module	returns a ||| sem	count=1
arg	features one [arg] each start ||| cls starts [arg]	count=1
class	instance of the lancaster ||| lancaster	count=1
arg	filtered by ||| empty	count=2
class	should ||| chart view	count=1
function	given a sequence ||| sequence	count=1
class	big a unit ||| chart view	count=1
class	of the ||| shift	count=2
module_class	to the stack ||| translate stack	count=1
arg	specific c{alignment} ||| i j source_sents target_sents	count=1
function	[function_1] block from ||| [function_2] [function_1]	count=1
arg	fileids that ||| fileids	count=1
function	information about the ||| info from	count=1
function	the [function] ||| max [function]	count=2
arg	marker file ||| sfm_file	count=1
module_class	return [class_2] ||| [module_1] [class_2]	count=37
class	of ngram [class] pairs ||| [class]	count=1
function	entries in ||| size	count=1
class	this semantics ||| semantics	count=1
function	userid to a ||| by userid	count=1
function_arg	[function_1] [arg_2] ||| [function_1] informative [arg_2]	count=6
function	a left corner ||| leftcorner parents	count=1
module	then return ||| core	count=1
function	distance metric ||| distance	count=1
class	of this rule it ||| chunk rule	count=1
function	cached ||| setitem	count=1
function_arg	the likelihood [arg_2] ||| [arg_2] [function_1]	count=1
function	to train the ||| train	count=1
arg	is [arg] ||| [arg]	count=1
arg	implements ||| tokseqs token_table	count=1
function	change the ||| set	count=6
module	and values are ||| metrics	count=1
class	[class_1] detokenizer ||| [class_1] [class_2]	count=3
function	probability ||| probability	count=2
arg	given part of speech ||| pos	count=1
module	widget used ||| draw	count=1
function	[function_1] chunk ||| [function_2] [function_1]	count=2
arg	and possibly non-contiguous ||| bigram_fd window_size	count=1
class	return a list of ||| reader	count=1
function	alignment algorithm described ||| alignment	count=1
module	internal indexes ||| corpus reader	count=1
arg	the classid if specified ||| classid	count=1
class	the files ||| reviews	count=1
arg	cover span ||| span constituents	count=2
arg	train on sentence_aligned_corpus and ||| sentence_aligned_corpus iterations	count=4
arg	a string containing a ||| vnframe	count=1
class	cached ||| dist	count=1
class	colorized list ||| colorized list	count=2
function	binding operators ||| bindops	count=1
function	and [function] lexical ||| [function]	count=1
function	with binding operators ||| with bindops	count=2
function	sentence [function_2] ||| [function_1] [function_2]	count=1
module	the first element ||| parse	count=1
function	rules that ||| rules	count=1
class	in the same sentence ||| sentence	count=1
class	tags the sequence ||| hidden	count=1
function	a ||| variable expression	count=2
class	:param ||| builder command	count=1
class	constructs a collocation ||| abstract collocation	count=1
class	return lemmas of the ||| word net	count=1
class	element of ||| recursive descent	count=1
arg	[arg] if it ||| [arg]	count=3
class	when parsing a ||| parser	count=3
function	illustrate the ||| drt discourse	count=1
function	two ||| align	count=3
function_arg	the tag [arg_2] ||| [arg_2] [function_1]	count=4
function	this is ||| expression	count=1
class	enter ||| demo	count=1
function	length six ||| w64	count=1
function	code based on iso ||| iso	count=1
class	the token's ||| token	count=1
arg	the actual word ||| word intact_word	count=2
function	a tuple of ||| entries	count=1
class	the moses machine translation ||| moses	count=1
class	use the lidstone estimate ||| lidstone	count=1
class	[class_1] frequency ||| [class_2] [class_1]	count=2
arg	with edge ||| edge	count=1
function	maltparser model ||| malt model	count=1
class	for editing ||| cfgeditor	count=1
class	of joint-feature values ||| maxent feature encoding	count=1
function_arg	:param labels ||| init labels	count=2
class	big a unit needs ||| chart view	count=1
arg	fileid ||| fileid delete_on_gc	count=1
arg	function finds the reference ||| references	count=1
class	be called ||| chart	count=1
class	encoded as ||| chunked corpus	count=3
arg	'predicate' as the predicate ||| predicate	count=1
function	word/tag/iob tuples ||| iob sents	count=1
arg	luname frameid ||| luname frameid	count=1
function	the height of ||| height	count=1
module	of the remaining text ||| parse	count=1
class	unit ||| view	count=1
class	to file or ||| file	count=1
class	sentences ||| framenet corpus reader	count=1
function	convert a list ||| id	count=1
function	have frequency less ||| freq filter	count=2
class	with the ||| model tagger	count=1
class	over sets of ||| multi classifier i	count=1
function	replacing each ||| retract bindings	count=1
function	subtype ||| variable expression	count=1
class	words ||| opinion lexicon corpus reader	count=1
arg	of the given fileids ||| fileids	count=2
function	illustrate the ||| discourse demo	count=2
function	bound node [function_2] ||| [function_2] [function_1]	count=1
module	an ||| sem	count=1
function_arg	update the [arg_2] ||| [arg_2] [function_1]	count=6
arg	given file s as ||| fileids tag	count=1
class	a bigram collocation finder ||| collocation	count=1
function	to_fol() ||| to fol	count=2
function	concept out of the ||| concept	count=1
arg	sentence pair ||| sentence_pair	count=2
class	probability [class_2] ||| [class_2] [class_1]	count=14
function	the conjunction ||| conjunction	count=1
class	[class_1] list ||| [class_2] [class_1]	count=2
function	a demonstration of ||| malt demo	count=1
function_arg	[function_1] a synset ||| [arg_2] [function_1]	count=4
arg	a sentence ||| sentence	count=2
arg	match [arg_2] ||| [arg_2] trees [arg_1]	count=2
function	static web help page ||| get static web help page	count=1
arg	userids into a ||| userids	count=1
class	phrase ||| phrase	count=1
arg	classifier ||| classifier	count=1
class	contents of the given ||| category corpus	count=1
arg	divide a string ||| s chunk_label	count=1
class	languages as iso 639-3 ||| crubadan	count=1
function	function "calculates ribes ||| ribes	count=1
function	defaultdict dict s ||| defaultdict	count=1
function	of sentence ||| sentence	count=1
class	this corpus or ||| timit corpus	count=1
function	[function_1] sentence strings ||| [function_2] [function_1]	count=6
class	expression ||| imp expression	count=1
arg	sentence ||| sentence verbose	count=1
arg	fstruct1 ||| fstruct1	count=3
function	find a space ||| find	count=1
class	with the ||| hidden	count=1
arg	the list of ||| fileids sent tag	count=1
arg	number of rows ||| rows cols	count=1
module_class	over this [class_2] ||| [module_1] lazy iterator [class_2]	count=1
arg	implement ||| bracket_sent tag strip_space	count=1
function	is of [function_2] ||| [function_1] [function_2]	count=4
module	representation for this corpus ||| corpus reader	count=4
arg	train ||| trainer save_analyzer	count=1
arg	hypothesis with ||| hypothesis	count=1
function	given ||| classify	count=1
function	[function_1] relations data ||| [function_2] [function_1]	count=1
class	enter the ||| drt	count=1
function	str [function_2] ||| [function_2] [function_1]	count=2
function_arg	[function_1] [arg_2] ||| [function_1] to parse [arg_2]	count=4
arg	n-gram f-score ||| reference hypothesis min_len max_len	count=1
function	wrap the first of ||| wrap	count=1
module_class	[module_1] corpus reader ||| [module_1] aligned [class_2]	count=1
function	to the ||| add	count=1
class	all bigrams in ||| bigram	count=1
arg	list of word tag ||| speaker stem	count=1
function	a list of entries ||| entries	count=1
arg	coming in an ||| limit	count=1
function	compatible with the latex ||| pformat latex	count=1
function	translate one entity ||| entity	count=1
function_arg	similarity [arg_2] ||| [arg_2] [function_1]	count=16
function	alignment algorithm described in ||| alignment	count=1
arg	input expression to ||| assumptions	count=5
module	about the users ||| twitter	count=1
arg	word tag ||| stem	count=2
function	paragraphs each encoded as ||| chunked paras	count=1
arg	and target-to-source word alignment ||| f2e	count=1
function	tags the sequence ||| tag	count=1
arg	specifying the fileids that ||| fileids	count=1
module	supported ||| reader	count=1
function	of information ||| from id	count=1
module	token from the ||| parse	count=1
arg	value of the correction ||| labels mapping unseen_features alwayson_features	count=1
class	the sequence ||| tagger	count=1
class	single [class_2] ||| [class_2] [class_1]	count=1
class	tagged ||| corpus reader	count=2
class	move ||| shift reduce	count=1
class	register ||| canvas widget	count=1
function	table's _rows variable ||| check table	count=1
function	[function_1] to ||| [function_1] [function_2]	count=4
function	[function_1] node label ||| [function_1] [function_2]	count=1
function_arg	file [arg_2] ||| [arg_2] [function_1]	count=1
function	table of ||| table	count=1
class	corpus view that ||| corpus	count=2
class	called if ||| chart parser app	count=1
function	local file if no ||| retrieve	count=1
module	string to ||| app	count=1
class	a corpus view that ||| corpus	count=2
class	how big a unit ||| chart	count=1
class	new maxent classifier ||| maxent classifier	count=2
class	of the ||| parser	count=3
class	language to princeton wordnet ||| word net	count=1
function	step 1a from "an ||| step1a	count=1
function_arg	positions in [arg_2] ||| [function_1] pattern [arg_2]	count=5
module	with ||| core	count=5
function_arg	score [arg_2] ||| [arg_2] [function_1]	count=2
class	true if this dependencygrammar ||| dependency grammar	count=1
class	the ||| regexp chunk app	count=1
module	synset ||| corpus reader	count=4
arg	'var', replace it with ||| chunks primitives families var	count=1
arg	hypothesis ||| hypothesis	count=2
class	end of the stack ||| stepping	count=1
function	the node [function_2] ||| [function_1] [function_2]	count=1
function	t ||| t	count=1
class	of the remaining ||| shift	count=1
arg	a given length this ||| length	count=1
arg	build a ||| synset_relations	count=1
function	new data xml index ||| build index	count=1
function	a rare abbreviation if ||| rare abbrev	count=1
class	internal indexes ||| corpus reader	count=1
class	ibm model ||| ibmmodel	count=1
class	buffered gzip [class_2] ||| [class_1] [class_2]	count=1
function	[function_1] chomsky normal ||| [function_1] [function_2]	count=1
class	hypernyms of the synset ||| synset	count=1
class	a probability ||| prob	count=3
arg	tagging ||| train_sents	count=1
class	path [class_2] ||| [class_2] [class_1]	count=10
class	frequency [class_2] ||| [class_2] [class_1]	count=8
function	krippendorff's interval [function_2] ||| [function_1] [function_2]	count=4
class	of supported languages ||| corpus reader	count=1
class	the frequency [class_2] ||| [class_2] [class_1]	count=1
function	a list of nodes ||| collapse nodes	count=1
arg	child to not ||| child index	count=1
function	the longest ||| max	count=1
class	add all edges licensed [class_1] [class_2] that are currently in ||| [class_2] [class_1] apply everywhere chart grammar	count=2
function	past tweets by a ||| tweets by user demo	count=1
function	positions in the ||| tgrep positions	count=1
class	frontier in particular ||| descent parser	count=1
function	normal form cnf ||| cnf	count=1
class	feature structure is ||| feat struct	count=2
function	in ||| rank dists	count=1
class	plaintext corpus reader ||| plaintext corpus reader	count=1
function	file to ||| webview file	count=1
function	the best ||| best	count=2
arg	[arg_1] f-score ||| [arg_1] [arg_2]	count=1
function	top-lebel node in a ||| exprs	count=1
function	tweets ||| demo tweets	count=2
arg	to the reading ids ||| threads	count=1
function	parse a primitive ||| parse	count=1
module_class	[module_1] its ||| [module_1] [class_2]	count=4
arg	optional frame object ||| frame	count=1
module_class	[module_1] this expression ||| [module_1] [class_2]	count=2
class	in particular if ||| parser	count=1
module	of supported languages as ||| corpus reader	count=1
function	in this chart's sentence ||| leaves	count=1
arg	word ||| strip_space stem	count=1
class	[class_1] parser ||| [class_2] [class_1]	count=7
module	big the tree should ||| app	count=1
class	within zipfile that ||| zip	count=1
class	by this [class] ||| [class]	count=1
arg	the symbol for rhs ||| rhs	count=1
module	that ||| classify	count=1
arg	vector to unit ||| vector	count=1
class	[class] suite are ||| [class]	count=3
class	called if ||| chunk	count=1
function	to the list of ||| add	count=1
module	the ||| tag	count=2
module	languages as iso ||| reader	count=1
function	[function_1] static index ||| [function_2] [function_1]	count=1
function	a table of ||| create token table	count=1
arg	bracketed tree ||| brackets read_node	count=1
function	method that instantiates ||| variable	count=1
class	as a ||| tagged	count=1
arg	of the item ||| item	count=1
class	iterator of all parses ||| recursive descent	count=2
function_arg	[function_1] context_to_tag ||| [function_1] [arg_2]	count=1
class	for its classifier ||| classifier	count=1
function	the node ||| node	count=1
class	of the synset ||| synset	count=2
class	frontier in particular if ||| recursive	count=1
module_class	[module_1] beginning ||| [module_1] [class_2]	count=8
class	this function must be ||| app	count=2
function	list of ||| user info	count=1
arg	should be ||| tokens index	count=2
arg	and punctuation [arg_2] ||| [arg_1] [arg_2]	count=1
arg	instance [arg] ||| [arg]	count=1
function	there ||| unique	count=1
class	of file identifiers ||| ycoecorpus	count=1
class	dependency parser and ||| dependency parser	count=2
module_class	[module_1] table's main ||| [module_1] [class_2]	count=4
function	to build a nltk ||| test build	count=1
class	return the unicode encoding [class_1] [class_2] known ||| [class_2] [class_1] encoding file	count=2
class	a list of ||| corpus reader	count=1
module	a list ||| corpus reader	count=1
function	encoded as ||| chunked	count=1
class	collocation [class_2] ||| [class_2] [class_1]	count=1
arg	tagger must be trained ||| trained	count=1
arg	source-to-target ||| trglen e2f	count=1
class	of this rule it ||| chunk rule with context	count=1
function	in ||| parse	count=1
function	of child [function_2] ||| [function_1] [function_2]	count=5
arg	given fileids as ||| fileids	count=2
arg	return most ||| words	count=1
function	variety of ||| from	count=1
class	sentence ||| sentence	count=6
arg	[arg] terminal ||| [arg]	count=2
class	:return a list ||| corpus reader	count=1
arg	trained ||| unk trained n	count=1
function	all the productions ||| productions	count=1
module	cached n ||| core	count=1
class	tags the sequence with ||| hidden	count=1
arg	relation metadata bundles make ||| rels	count=1
function	rule and rule format("verbose")) ||| rule format	count=1
class	a dependency graph ||| dependency parser	count=1
arg	the ||| key	count=1
function	each successive ||| regexp span tokenize	count=1
arg	[arg] node ||| new_node cycle_path [arg]	count=3
function	table's _rows ||| check table	count=1
class	of the ||| recursive descent parser	count=1
arg	of its forward pointer ||| forward	count=1
function	a tgrep search ||| tgrep tokenize	count=1
class	of the ||| i	count=1
module	single corpus ||| corpus reader	count=1
class	to self ||| abstract	count=2
class	must be called if ||| glue demo	count=1
class	dependency graph based on ||| dependency	count=1
function	top-lebel node ||| tgrep exprs action	count=1
function	identifies [function] at the ||| identify [function]	count=1
class	frontier in particular ||| descent	count=1
arg	luname frameid and framename ||| ignorekeys luname frameid	count=1
function	the [function] ||| clear [function]	count=1
arg	in the given string ||| s	count=2
function	perform the first ||| first	count=1
class	packages ||| downloader	count=1
arg	highest information content value ||| synset1 synset2 ic verbose	count=1
class	[class_1] rule and ||| [class_2] [class_1] apply chart grammar	count=1
class	of the frontier in ||| recursive descent	count=1
function	rule this ||| rule	count=1
function	tgrep search ||| tgrep tokenize	count=1
class	state ||| model	count=1
function	the grammar ||| grammar	count=1
function	information about ||| user	count=1
function	[function_1] incoming arc ||| [function_1] [function_2]	count=3
class	of this decision ||| decision	count=1
module_class	of the discourse ||| inference discourse tester	count=1
arg	grammar ||| grammar trace	count=2
class	chart rule ||| chart	count=1
class	text to the ||| stepping shift reduce	count=1
function	[function_1] web help ||| [function_2] [function_1]	count=3
function	convert ||| info	count=1
module	this function must ||| draw	count=2
function	variety of information ||| from id	count=1
arg	t in the target ||| s t	count=1
function	[function_1] by a ||| [function_2] [function_1]	count=4
arg	word with their ||| word	count=1
class	iterator ||| iterator	count=1
function	of classified tokens ||| write	count=2
function	of all frames ||| frames	count=1
arg	look up ||| history	count=1
class	collocation finder ||| trigram collocation finder	count=1
function	representation of ||| item repr	count=1
function	[function_1] to chunk ||| [function_1] [function_2]	count=2
class	alphabetical order ||| opinion lexicon corpus reader	count=1
function	helper function for pretty-printing ||| pretty	count=2
function	removes ||| apply	count=2
class	the corpus ||| comparative sentences corpus reader	count=1
arg	of child ||| child index dry_run	count=1
class	a unit ||| chart	count=1
class	element of the ||| stepping	count=1
function	previously bound node label ||| node label pred	count=1
arg	baseline ||| initial_tagger	count=1
arg	a line ||| linenum line	count=1
class	unit ||| chart	count=1
class	[class_1] wrapper for ||| [class_2] [class_1]	count=1
function_arg	[function_1] word using ||| [function_1] [arg_2]	count=1
function_arg	check [arg_2] ||| [function_1] informative [arg_2]	count=2
arg	csv ||| outfile fields	count=1
class	that ||| reduce parser	count=1
arg	with [arg] across every ||| variable [arg]	count=1
class	tree occurs as ||| multi parented tree	count=2
class	collocation ||| collocation	count=2
arg	the list of ||| fileids sent tag strip_space	count=1
arg	and returns a ||| line primitives	count=1
arg	list of userids into ||| userids	count=1
class	the minimal [class_2] ||| [class_2] [class_1]	count=3
function	variety of information ||| id	count=1
class	first element ||| stepping recursive descent parser	count=1
function	retrieve the mapping dictionary ||| tagset mapping	count=1
class	the ||| regexp chunk	count=1
arg	f-score ||| max_len	count=2
function	pass of annotation which ||| pass	count=1
class	text ||| parser	count=1
arg	a list of word ||| strip_space stem	count=1
function	abstractvariableexpression appropriate for the ||| expression	count=1
arg	graphs list ||| graphs	count=1
function	of abstractvariableexpression ||| variable	count=1
class	:param ||| variable expression	count=1
function_arg	apply the [arg_2] ||| [arg_2] [function_1]	count=1
function	realign punctuation ||| realign boundaries	count=1
class	cmudict lexicon as a ||| cmudict corpus	count=1
class	opinion lexicon note ||| opinion lexicon	count=1
arg	which are preceded ||| stream	count=1
arg	[arg_1] index ||| [arg_2] [arg_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] given s [arg_2]	count=18
class	underlying this corpus view ||| lazy	count=2
class	indexes ||| framenet corpus reader	count=1
function	of the model ||| model	count=1
function	the use ||| use	count=1
class	occurs ||| multi parented	count=1
function	"preterminals", [function] unary ||| [function]	count=1
function	child ||| child	count=1
class	the assignment ||| assignment	count=1
class	when parsing a text ||| viterbi parser	count=1
function	provides a demonstration ||| demo	count=1
class	the name ||| instance	count=1
class	calculates values [class_2] ||| [class_2] [class_1]	count=4
class	name of ||| nombank instance	count=1
function	crosses the truncation line ||| get truncation coordinates	count=1
arg	quadgramcollocationfinder ||| quadgram_fd ii iii	count=1
class	in alphabetical order ||| opinion	count=1
arg	given pattern ||| pattern	count=2
module	this is ||| sem	count=1
class	tnt statistical tagger tagger ||| tn t	count=1
class	[class_1] list ||| [class_1] [class_2]	count=2
module	order ||| reader	count=1
function	fringe of ||| fringe	count=1
class	the stack ||| stepping shift reduce	count=2
arg	-- ie tags ||| fileid	count=1
arg	[arg_1] is ||| metrics pk [arg_2] [arg_1]	count=5
class	of ||| shift reduce parser	count=2
class	canvas widget ||| canvas widget	count=16
arg	by save_classifier ||| training_set save_classifier	count=1
class	used for editing the ||| cfgeditor	count=1
class	tags ||| context tagger	count=1
function	[function] tag ||| [function]	count=1
class	sentence in ||| reader	count=1
function	induce [function_2] ||| [function_2] [function_1]	count=1
function	of chunks ||| chunk	count=1
module	whether tweets ||| twitter	count=1
class	perform a single parsing ||| descent parser	count=1
class	over sets of ||| i	count=1
arg	a given subcorpus ||| subcorpus	count=1
function_arg	sentence [arg_2] ||| [function_1] a given s [arg_2]	count=2
arg	highest information content value ||| synset1 synset2 ic	count=1
function_arg	xml index [arg_2] ||| [arg_2] [function_1]	count=2
arg	all ||| callback button	count=3
function	the number of rows ||| len	count=1
class	a list of supported ||| crubadan corpus reader	count=1
module	instance's ||| corpus reader	count=2
arg	a string ||| s chunk_label root_label sep	count=1
class	state sequence this ||| markov model tagger	count=1
function_arg	train [arg_2] ||| [function_1] [arg_2]	count=1
arg	index of the ||| index depth	count=1
class	a list ||| crubadan corpus	count=1
arg	the penn treebank ||| nx	count=1
module_class	[module_1] container ||| [module_1] [class_2]	count=8
class	is consistent with the ||| edge	count=1
function	kendall's [function] correlation ||| kendall [function]	count=1
module	tagged ||| corpus reader	count=1
function	to realign punctuation ||| realign	count=1
class	of the stack ||| stepping shift reduce	count=1
arg	under ||| node_index	count=1
arg	its forward ||| forward fs_class visited	count=1
arg	to the input ||| input	count=1
arg	its forward pointer ||| forward fs_class	count=1
arg	data ||| data start end	count=1
class	this tree occurs ||| multi parented tree	count=2
arg	of segmentations a ||| k boundary	count=1
function	condition *d from ||| ends double consonant	count=1
function	all tags and ||| tags	count=1
class	pl196x ||| pl196x	count=1
function_arg	[function_1] of word ||| [function_1] fileids [arg_2]	count=3
function	the sentences [function_2] ||| [function_2] [function_1]	count=2
class	a ||| recursive descent parser	count=1
module	this feature [module] to the ||| [module]	count=1
class	of the transformational ||| brill template	count=1
module_class	of this feature ||| core feat	count=1
class	a unit needs ||| view	count=1
arg	stream until ||| stream	count=1
function_arg	training data [arg_2] ||| [function_1] [arg_2]	count=6
function	best ||| best	count=3
class	out how big ||| chart view	count=1
arg	f-score described in - ||| max_len	count=1
arg	used to implement ||| bracket_sent	count=1
class	similar to a list's ||| abstract lazy sequence	count=1
function	the use of a ||| use	count=1
arg	given widget ||| widget	count=1
class	feature encoding ||| maxent feature encoding i	count=1
class	variety of information ||| query	count=1
class	based ||| based tagger	count=1
class	end of ||| parser	count=1
function	the table's _rows ||| check table	count=1
class	[class_1] this encoding ||| [class_2] [class_1] length	count=1
function	fact that *rule* applies ||| rule applies	count=1
class	as a list of ||| corpus reader	count=1
class	a dictionary containing the ||| dictionary conditional	count=1
class	value for the feature ||| feat	count=2
class	construct ||| trigram collocation finder	count=1
function	in the model ||| model	count=1
function	patterns and extract length ||| pro	count=2
module_class	by this multi-column ||| draw multi	count=1
class	figure out how big ||| chart view	count=1
class	data ||| corpus reader	count=1
function	sequence yields each element ||| sequence	count=1
module	this function must be ||| app	count=2
function	exemplar sentence and ||| exemplar of fes	count=1
function	of its multi-listbox (_mlb) ||| vs mlb	count=1
function	edge's right-hand side ||| rhs	count=1
class	predicates from ||| closed world prover	count=1
arg	[arg_1] file ||| [arg_2] [arg_1]	count=8
function	the ||| user info from id	count=1
function	command line help message ||| usage	count=1
function	features reflecting the ||| feats	count=2
class	an iterator that ||| abstract	count=1
class	639-3 language ||| crubadan	count=1
class	a ||| corpus	count=1
class	be ||| drt glue	count=1
function	the left [function_2] ||| [function_2] [function_1]	count=1
arg	which match ||| search_leaves	count=1
function	internal crubadan ||| crubadan	count=1
function	to each tkinter ||| to columns	count=1
class	name ||| instance	count=1
class	element of ||| recursive descent parser	count=1
class	feature of ||| feature grammar	count=1
class	corpus ||| categorized sentences corpus	count=1
arg	list ||| fileids tagset	count=1
class	may cause ||| mutable prob	count=1
function	of ||| drt discourse	count=1
class	function must ||| glue demo	count=1
arg	list of productions ||| productions	count=1
class	that a ||| shift reduce parser	count=1
function	freqdist containing only data ||| freq	count=1
class	update ||| tagger trainer	count=2
function	data ||| data	count=2
class	particular ||| stepping recursive descent	count=1
class	that ||| template	count=1
function_arg	in ranks1 ||| rank dists ranks1	count=1
class	utterances in this corpus ||| corpus	count=1
class	of ||| stepping recursive	count=1
arg	nodes of a tree ||| tree	count=1
function_arg	beginning of remaining_text ||| shift stack remaining_text	count=1
function	tokenized list of sentence ||| sentence list	count=1
class	tags ||| hidden markov model tagger	count=2
arg	the binary with the ||| binary	count=1
module	predicate ||| reader	count=1
class	for this encoding ||| maxent feature encoding	count=2
arg	a list of characters ||| fileids	count=1
function	entity in the model ||| model	count=1
arg	:param status_code the ||| status_code	count=1
class	a list of ||| list	count=1
function	is ||| is	count=10
arg	left-hand side ||| lhs	count=2
function	into conll ||| conll	count=1
function	algorithm ||| parse	count=1
function_arg	by [arg_2] ||| [arg_2] [function_1]	count=1
class	indicates how much ||| i	count=1
function	remove entities ||| entities	count=1
class	frontier in particular if ||| parser	count=1
arg	a list of lists ||| fileids	count=1
function_arg	to [arg_2] ||| [arg_2] [function_1]	count=2
function_arg	[function_1] the trees ||| [function_1] pattern [arg_2]	count=6
class	this function ||| glue	count=1
module_class	widget used [class_2] ||| [module_1] [class_2]	count=6
module	porter stemmer ||| stem	count=1
function	epytext ||| epytext	count=1
module	name of the ||| corpus	count=1
class	the assignment and ||| assignment	count=1
function	users ||| info from	count=1
class	generate the resulting list ||| base class	count=1
arg	used to generate freqdist ||| freqdist gamma	count=1
class	first element of the ||| recursive descent	count=1
class	the users ||| query	count=1
arg	with expression ||| expression	count=3
class	sentence boundary detector ||| punkt sentence tokenizer	count=2
function	learning the clustering ||| cluster	count=1
function	a grammar ||| grammar	count=1
arg	n-gram f-score described in ||| min_len max_len	count=1
function	userid to a screen ||| lookup by userid demo	count=1
function	parameters to the present ||| extract	count=1
class	must ||| regexp chunk app	count=1
function	krippendorff's interval ||| interval	count=1
class	the frontier in ||| recursive	count=1
class	translation model ||| ibmmodel2	count=1
arg	i ||| i	count=1
function_arg	reduce [arg_2] ||| [function_1] [arg_2]	count=1
class	which ||| edge	count=1
function_arg	[function_1] n-gram ||| [function_1] [arg_2]	count=2
class	a token from the ||| shift reduce parser	count=1
function	bound node [function_2] ||| [function_1] [function_2]	count=1
class	the thesaurus ||| lin thesaurus	count=1
function	[function_1] checksum for ||| [function_2] [function_1]	count=1
function_arg	from [arg_2] ||| [arg_2] [function_1]	count=4
function	qtree package ||| qtree	count=1
function	demonstration ||| malt demo	count=1
function	suffix-removal rule to the ||| rule	count=1
class	supported ||| corpus	count=1
function	match ||| match	count=2
arg	iter tree :return ||| rtext tree frontier	count=1
class	iso ||| crubadan corpus reader	count=1
function	the logged values returning ||| log add	count=1
function	userid to a screen ||| userid demo	count=1
function	corresponding ||| tuple2str	count=1
arg	used to implement ||| unit bracket_sent	count=1
arg	[arg_1] by stems ||| [arg_2] [arg_1]	count=1
arg	status_code the status ||| status_code	count=1
class	the ||| markov model	count=2
arg	userids into ||| userids	count=1
function	build ||| test build	count=1
arg	given a featureset ||| featureset	count=1
class	an iterator that generates ||| abstract	count=1
class	a unit needs ||| chart	count=1
function	uncurry ||| uncurry	count=1
function	demonstration of the result ||| malt demo	count=1
arg	list of word tag ||| stem	count=2
class	by ||| i	count=4
module_class	[module_1] [class_2] not including graphical ||| [module_1] [class_2]	count=4
class	a ||| chart	count=1
class	[class_1] the given ||| [class_1] [class_2]	count=1
arg	and punctuation symbols ||| fileids speaker stem	count=1
class	for ||| timit corpus reader	count=1
module	must be called if ||| sem	count=1
function	list of sentence strings ||| build sentence list	count=1
function	byte ||| tell	count=1
class	minimal [class_2] ||| [class_1] [class_2] add	count=3
arg	search for ||| searchpath	count=1
arg	file s ||| fileids	count=21
function	1c from "an ||| step1c	count=1
class	when the tweet ||| tweet	count=1
module	the internal ||| corpus reader	count=1
arg	*regexp* ||| regexp	count=1
function	[function_1] first ||| [function_2] [function_1]	count=1
arg	precedes [arg] beginning ||| [arg]	count=1
arg	s as a list ||| fileids speaker stem relation	count=1
function	of an initial ||| initial	count=1
arg	between them ||| wildcard_fd trigram_fd	count=1
class	alphabetical ||| lexicon corpus reader	count=1
function	length ||| ref length	count=1
arg	return a score denoting ||| other ic verbose	count=1
function	upon collapse ||| compute	count=1
function_arg	word alignments [arg_2] ||| [function_1] [arg_2]	count=6
function	a rare [function_2] ||| [function_2] [function_1]	count=2
class	editing the productions ||| cfgeditor	count=1
function	lemmas that ||| lemmas	count=1
arg	and punctuation ||| speaker stem	count=1
class	handling ||| query	count=1
function	file for the ||| file	count=1
function	analyze the ||| analyze	count=1
arg	match ||| search_leaves	count=2
module	in alphabetical ||| corpus	count=1
function	full annotation ||| fulltextannotation	count=1
function_arg	positions [arg_2] ||| [function_1] pattern [arg_2]	count=5
arg	length ||| length	count=1
class	words in alphabetical ||| opinion	count=1
function	[function_1] special category ||| [function_1] [function_2]	count=2
function	are "preterminals", [function] unary rules ||| [function]	count=1
class	a list of supported ||| corpus reader	count=1
function	[function_1] target ||| [function_2] [function_1]	count=2
arg	filter function ||| filter	count=1
class	frontier ||| parser	count=1
function	rules from ||| rules	count=1
class	perform a single parsing ||| stepping recursive descent parser	count=1
function	learning the clustering parameters ||| cluster	count=1
function	information ||| from id	count=1
function	md5 ||| md5	count=1
function	step 1c from "an ||| step1c	count=1
class	values of a bigram ||| bigram	count=1
class	plaintext corpus reader for ||| plaintext corpus reader	count=1
class	document ||| corpus reader	count=1
function	pointer [function_2] ||| [function_2] [function_1]	count=4
function	a dictionary ||| make predicate dict	count=1
class	cached n ||| freq dist	count=1
function	the static ||| get static	count=1
class	read-only ||| open	count=1
module_class	639-3 [class_2] ||| [module_1] [class_2]	count=2
class	freqdist ||| freq dist	count=1
arg	giza-formatted string and return ||| cls s	count=1
class	of sample outcomes ||| freq dist	count=1
function	words defined in the ||| words	count=1
class	feature encoding based on ||| maxent feature encoding i	count=1
class	invalidate ||| freq dist	count=2
function	top ||| find top	count=1
class	use stanfordparser to ||| generic stanford parser	count=2
class	this corpus or for ||| categorized corpus reader	count=1
class	tagger ||| brill tagger	count=2
arg	forward ||| forward bindings	count=1
arg	file s ||| fileids tag	count=1
class	of supported languages as ||| corpus reader	count=1
function	matrix ||| matrix	count=1
class	positive examples the ||| naive bayes dependency scorer	count=1
class	this ||| recursive descent app	count=1
class	element of the ||| parser	count=1
function	write to ||| write	count=1
function	each successive match ||| span tokenize	count=1
arg	[arg_1] word ||| [arg_2] [arg_1]	count=6
arg	input ||| input	count=1
class	the first element of ||| recursive	count=1
class	in alphabetical order ||| corpus reader	count=1
class	internal indexes to ||| corpus	count=1
function	a factory ||| variable	count=1
arg	and punctuation symbols ||| c5 strip_space stem	count=1
function	open ||| open	count=1
function	find [function_2] ||| [function_2] [function_1]	count=1
function	as iso 639-3 codes ||| langs	count=1
arg	a specific c{alignment} ||| i j source_sents target_sents	count=1
arg	the trees which ||| trees	count=1
function	with binding operators to ||| with bindops	count=1
function	minus the cosine of ||| cosine	count=1
module_class	[module_1] codes ||| [module_1] [class_2]	count=8
module_class	[module_1] editing the ||| [module_1] [class_2]	count=4
module_class	[module_1] an ||| [module_1] [class_2]	count=4
class	[class_1] reader with ||| [class_2] [class_1]	count=2
class	the remaining ||| reduce parser	count=1
function	check to ||| check	count=1
arg	[arg_1] q for ||| [arg_1] [arg_2]	count=1
class	of the ||| descent	count=1
function	the next field in ||| raw fields	count=1
class	true if the grammar ||| cfg	count=1
class	supported languages as iso ||| crubadan corpus	count=1
arg	stemming ||| remove_total append_string	count=1
class	of the given element ||| framenet corpus reader	count=1
class	if the token's ||| punkt token	count=1
function_arg	list of [arg_2] ||| [function_1] word [arg_2]	count=2
arg	[arg] any sequence ||| [arg]	count=1
class	boundary detector or can ||| punkt	count=1
module	for the ||| corpus reader	count=1
class	a ||| crubadan corpus	count=1
arg	given sample ||| sample	count=1
class	the name of ||| nombank instance	count=1
function	variety of information about ||| user info from	count=1
class	distribution ||| dist	count=13
function	to the root counting ||| hypernym distances	count=1
class	this rule it ||| chunk rule	count=1
class	how big a ||| chart	count=1
module	that [module] model was ||| [module]	count=2
class	corpus ||| chunked corpus	count=1
arg	given length ||| length	count=1
arg	word with their non-accented ||| word	count=1
function	the button press ||| press cb	count=1
class	offset ||| offset	count=1
function	and ||| variable	count=1
function	a learning curve -- ||| demo learning curve	count=1
function	the cyrillic ||| cyrillic	count=1
class	conditional frequency [class_2] ||| core [class_1] [class_2]	count=1
function	from the fulltextindex xml ||| handle fulltextindex elt	count=1
class	for the ||| lin thesaurus corpus reader	count=1
class	of ||| shift	count=2
class	this decision [class_2] ||| [class_1] [class_2]	count=1
arg	its variable [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] stack ||| [arg_2] [function_1]	count=4
function	for megam based on ||| megam	count=1
class	the internal indexes ||| reader	count=1
function	a single-line [function] of ||| [function]	count=1
function	userid ||| by userid demo	count=1
class	given language ||| corpus reader	count=1
class	constructs a bigram collocation ||| trigram collocation	count=1
class	internal indexes ||| framenet corpus reader	count=1
class	to a list's ||| pretty lazy concatenation	count=1
function	instantiates and returns ||| variable	count=1
class	[class] its row ||| [class]	count=2
class	hack=true ||| cooper	count=1
class	invalidate the ||| dist	count=1
function	recorded by ||| n	count=1
arg	[arg_1] finalize is ||| [arg_2] [arg_1]	count=5
arg	word and part ||| word	count=1
class	:see [class_2] ||| [class_2] [class_1]	count=3
class	the given element ||| framenet corpus reader	count=1
arg	by its id luname ||| luname	count=1
class	rule it ||| chunk rule	count=1
class	probability ||| heldout prob	count=2
arg	information content ||| ic	count=1
class	return a list of ||| list	count=1
arg	number of rows ||| rows cols attempts	count=1
arg	matrix s [arg_2] ||| [arg_1] [arg_2]	count=1
class	if this dependencygrammar ||| dependency grammar	count=1
class	parsing ||| descent parser	count=1
function_arg	[function_1] cluster ||| [function_1] vector [arg_2]	count=1
class	the sequence ||| markov	count=1
module	the [module] on a ||| [module]	count=1
class	encoding ||| encoding	count=3
function_arg	[function_1] tokentablefields ||| [function_1] [arg_2]	count=3
class	the table so that ||| table	count=1
module	tags ||| tag	count=1
arg	-- ||| fileid	count=1
class	as as ||| corpus	count=1
module	the rest api ||| twitter	count=2
class	dictionary containing the ||| dictionary conditional prob dist	count=1
arg	tokens in unigrams ||| unigrams	count=1
arg	list ||| fileids sent	count=1
function	text ||| text	count=3
function_arg	[function_1] [arg_2] ||| [function_1] set filename label [arg_2]	count=1
class	a list of tweets ||| twitter corpus	count=1
function	[function] which ||| find top most [function]	count=3
arg	of documents located at ||| fileids sep word_tokenizer	count=2
function	lookup 'key' there ||| lookup unique	count=2
function_arg	[function_1] for translating ||| [arg_2] [function_1]	count=4
class	a danish ||| danish	count=1
function	[function_1] distance similarity ||| [function_1] [function_2]	count=1
class	the initial tagger ||| tagger	count=1
class	aligned corpus ||| aligned corpus	count=1
arg	positive_featuresets a list ||| positive_featuresets unlabeled_featuresets positive_prob_prior estimator	count=1
class	stack ||| shift	count=1
arg	fstruct1 [arg_2] ||| [arg_2] [arg_1]	count=2
class	spans representing the chart ||| chart	count=1
function	sentence ||| translate	count=1
function	score of ||| score	count=2
function	also str ||| demo str	count=1
function	userid to ||| userid	count=1
function	rule this is done ||| rule	count=1
class	add to the chart ||| chart	count=1
function	[function_1] the scrollregion ||| [function_1] [function_2]	count=1
function	lexicographic exemplar sentences optionally ||| exemplars	count=1
arg	helper used to implement ||| fileid unit bracket_sent	count=1
class	as a ||| corpus reader	count=1
class	token from the ||| parser	count=1
arg	feature is ||| feat	count=1
class	distribution for the experiment ||| dist	count=3
class	if ||| descent	count=1
class	token from the ||| reduce	count=1
class	by this [class_2] ||| [class_2] [class_1] length	count=1
function	a variety of information ||| info	count=1
class	:rtype str :return ||| laplace	count=1
class	a dependency graph ||| projective dependency parser	count=1
function	module [function_2] ||| [function_1] [function_2]	count=3
function_arg	a demonstration [arg_2] ||| [arg_2] [function_1]	count=3
class	feature encoding based ||| maxent feature encoding i	count=1
arg	featureset ||| featureset	count=5
function	nodes ||| collapse nodes	count=2
function	primitive is [function_2] ||| [function_1] [function_2]	count=1
function	variety of information about ||| user info from id	count=1
arg	given fileids as a ||| fileids	count=2
class	the sequence ||| model tagger	count=1
function	timer decorator ||| timer	count=1
class	return a list of ||| crubadan corpus	count=1
class	text returns a ||| punkt	count=1
class	is the probability ||| prob	count=1
class	a collocation [class_2] ||| [class_2] [class_1]	count=1
arg	is the ||| other	count=4
function	representation but ||| repr	count=5
module	list of supported ||| corpus	count=1
class	particular if ||| descent parser	count=1
class	absolute path identified ||| file system	count=1
class	encoded as ||| tagged	count=2
function	a verbose string representation ||| str	count=1
class	sequence with ||| hidden markov	count=1
function	apply self classify() to ||| classify many	count=2
arg	in paths where a ||| paths	count=1
function	to chunk ||| chunk	count=2
class	text to the end ||| reduce	count=1
class	samples ||| simple good turing prob dist	count=1
class	of file identifiers for ||| ycoecorpus	count=1
function	binding [function_2] ||| [function_2] [function_1]	count=5
arg	or the list of ||| fileids sent tag strip_space	count=1
function	reflect ||| update	count=1
function	a list of ||| user info from id	count=1
class	categorization arguments ||| categorized tagged	count=1
class	feature of the ||| feature	count=2
function	the width ||| width	count=1
class	a [class_2] ||| [class_2] [class_1]	count=11
class	particular ||| stepping recursive	count=1
arg	item ||| item	count=4
class	parses that can be ||| recursive descent parser	count=2
function	fulltextindex xml file ||| handle fulltextindex elt	count=1
function	find a space ||| find room	count=1
arg	encodes the chunking ||| chunk_struct debug_level	count=1
class	words ||| swadesh	count=1
function	of the best ||| best	count=1
class	examples (i ||| naive bayes classifier	count=1
arg	given file s ||| fileids speaker stem relation	count=1
arg	tree string [arg_2] ||| [arg_2] [arg_1]	count=2
function	a variety of ||| info	count=1
class	as a ||| corpus	count=1
class	internal indexes to ||| corpus reader	count=1
class	end of ||| stepping shift reduce parser	count=1
function_arg	pcfg grammar [arg_2] ||| [function_1] [arg_2]	count=5
class	unimplemented because the neural ||| stanford neural	count=1
class	enter ||| regexp chunk app	count=1
function	a table ||| token table	count=1
class	if ||| stepping recursive	count=1
function	self _sentences to construct ||| construct	count=1
function	about ||| from	count=1
class	neural [class_2] ||| [class_2] [class_1]	count=5
function	instantiates and ||| variable expression	count=1
class	this instance's predicate ||| instance	count=1
function	returns the node ||| node	count=1
module_class	this [class_2] ||| [module_1] canvas [class_2]	count=2
arg	context_to_tag a ||| context_to_tag backoff	count=1
arg	positive_featuresets a list ||| positive_featuresets unlabeled_featuresets positive_prob_prior	count=1
module_class	[module_1] colorized ||| [module_1] [class_2]	count=2
class	affixes from ||| stemmer i	count=1
class	or ||| timit	count=1
class	figure ||| chart	count=1
class	[class_1] this rule ||| [class_2] [class_1] apply chart grammar	count=1
class	linear regression to ||| good turing prob dist	count=1
arg	id luname frameid and ||| luname frameid	count=1
class	remaining text ||| parser	count=1
function	pre-calculate of ||| forms	count=1
class	tree or none ||| parented tree	count=2
module_class	[module_1] [class_2] ||| [module_1] pickle [class_2]	count=4
function	the learned [function] ||| demo serialize [function]	count=3
class	enter ||| app	count=2
class	the remaining text ||| stepping	count=1
arg	possible ways of ||| ancestors0 queue potential_labels0	count=1
function	variety of information ||| user info from id	count=1
class	the remaining ||| parser	count=1
arg	a quadgramcollocationfinder ||| quadgram_fd ii iii	count=1
function	f measure for all ||| f measure	count=1
arg	modelbuilder the theorem ||| modelbuilder	count=1
function	command ||| command	count=1
function	next best [function_2] ||| [function_2] [function_1]	count=4
class	end ||| shift reduce parser	count=1
class	of the frontier in ||| descent parser	count=1
arg	its id luname frameid ||| ignorekeys luname frameid	count=1
class	repp tokenizer binary ||| repp tokenizer	count=2
function	topmost hypernyms of this ||| root hypernyms	count=1
module	review ||| corpus reader	count=1
class	a corpus view that ||| propbank corpus reader	count=1
function	chomsky [function_2] ||| [function_1] [function_2]	count=3
module	is a factory ||| sem	count=1
function	the depth ||| depth	count=1
class	the tree ||| view	count=1
arg	module returns a list ||| fileids	count=1
function	indent ||| indent	count=1
class	from the ||| stepping shift	count=1
class	this synset ||| synset	count=2
arg	window_size ||| window_size pad_left	count=1
class	space ||| space	count=2
function_arg	[function_1] words ||| [function_1] [arg_2]	count=2
function	table into a dictionary ||| make	count=1
class	use stanfordparser to ||| generic stanford	count=3
function	into the cyrillic alphabet ||| cyrillic	count=1
arg	instances of variable ||| variable	count=3
function	cached n ||| setitem	count=1
function	a frame xml file ||| frame	count=1
class	one for ||| reader	count=1
arg	a given file ||| file	count=1
arg	luname [arg_2] ||| [arg_1] [arg_2]	count=4
class	hypothesized structure is ||| i	count=1
arg	temporary file ||| delete_on_gc	count=1
arg	[arg_1] productions ||| [arg_1] [arg_2]	count=1
function	meaning ||| meaning	count=1
class	[class_1] dependency parser ||| [class_1] [class_2]	count=4
arg	new callback that ||| callback	count=1
arg	expression the expression to ||| expression command x	count=1
function	fulltextindex ||| fulltextindex	count=1
arg	is incomplete (i ||| span lhs rhs dot	count=1
function	the tree ||| production to tree	count=1
class	tnt statistical ||| tn t	count=1
arg	from a list ||| start	count=1
function	get synset ||| get	count=1
function_arg	result of [arg_2] ||| [arg_2] [function_1]	count=1
class	of tweets ||| twitter corpus	count=1
function	1 minus the cosine ||| cosine	count=1
class	figure out how ||| chart	count=1
class	model vacancy ||| ibmmodel5	count=1
function	(from ||| nouns	count=1
arg	if strings is ||| strings	count=1
class	periods as sentence breaks ||| punkt sentence	count=1
arg	optional frame ||| frame frame2 type	count=1
function	about ||| from id	count=1
class	perl unicode properties ||| unichars	count=1
function	to ||| add	count=1
function_arg	[function_1] if with_shutdown ||| [arg_2] [function_1]	count=4
function	relations involving ||| frame relations	count=1
class	of the stack ||| stepping shift reduce parser	count=1
function	an input file for ||| file	count=2
function	of information about the ||| user info from	count=1
class	structure is ||| struct	count=2
module	this function must be ||| sem	count=1
arg	feature ||| feat	count=1
function	implements step 5a from ||| step5b	count=1
function	:return a concise string ||| repr	count=1
arg	forward pointer to ||| forward fs_class	count=1
class	probability state sequence ||| markov model tagger	count=1
class	[class_1] tagger on ||| [class_1] [class_2]	count=2
function_arg	block from [arg_2] ||| [arg_2] [function_1]	count=1
class	to file ||| gzip file	count=1
class	parses that can ||| descent parser	count=2
class	this alignedsent ||| aligned	count=2
arg	sentence_aligned_corpus ||| sentence_aligned_corpus	count=4
arg	[arg_1] f-score ||| chrf list_of_references hypotheses [arg_1] [arg_2]	count=1
function	the lemma objects ||| lemmas	count=1
class	this ||| hidden markov model tagger	count=2
function	named [function_2] ||| [function_2] [function_1]	count=2
class	use simple [class_2] ||| [class_1] [class_2]	count=2
function	data file ||| data file	count=1
arg	single sentence ||| sentence threaded verbose	count=1
function	[function_1] synset relations ||| [function_2] [function_1]	count=1
class	the path ||| path	count=1
class	element of the frontier ||| recursive descent	count=1
function	of abstractvariableexpression ||| variable expression	count=1
arg	[arg_1] bytes to ||| [arg_2] [arg_1]	count=2
arg	draw the given item ||| item x y	count=1
function_arg	[function_1] tab file ||| [function_1] lemmas [arg_2]	count=3
function	resize a ||| resize	count=1
class	defined for this corpus ||| corpus reader	count=1
class	in alphabetical ||| lexicon corpus	count=1
module_class	by this edge ||| parse edge i	count=2
arg	add ||| func add	count=1
class	the frontier in particular ||| recursive descent	count=1
function_arg	[function_1] a given ||| [function_1] plugging plugging [arg_2]	count=1
function	generates the sentences in ||| sentences from	count=2
class	this rule it has ||| rule with	count=1
function	past tweets by ||| tweets by	count=1
function	token is beginning ||| is	count=1
function	pairs ||| pairs	count=1
function	child [function_2] ||| [function_2] [function_1]	count=5
function	data xml index ||| index	count=1
class	of the ||| corpus reader	count=1
function	the indices where ||| parent indices	count=1
arg	productions ||| productions	count=2
arg	the expression to ||| expression command x y	count=1
function	[function_1] by ||| [function_1] [function_2]	count=4
function	best rule ||| best rule	count=1
arg	frame optional frame object ||| frame frame2	count=1
function	create a new ||| init	count=9
function	returns ||| variable expression	count=1
arg	[arg] any ||| [arg]	count=1
function	applicable suffix-removal rule to ||| apply rule	count=1
function	file for ||| file	count=3
class	a single tree ||| parser	count=1
arg	a string of ||| s chunk_label	count=1
arg	earley parsers ||| print_times print_grammar print_trees trace	count=1
function	various ||| demo	count=2
class	the end of the ||| stepping shift reduce parser	count=1
class	as a pickle ||| pickle	count=1
function	return the corresponding ||| tuple2str	count=1
arg	train on sentence_aligned_corpus and ||| sentence_aligned_corpus iterations probability_tables	count=3
function	six patterns ||| pro w6	count=2
arg	actual [arg_2] ||| [arg_2] [arg_1]	count=2
function	score for ||| future score	count=1
class	the dict ||| dict	count=1
function	[function_1] [function_2] ||| [function_1] parse [function_2]	count=6
arg	the *worder* list i ||| hypothesis character_based	count=1
function	expected agreements for ||| multi kappa	count=1
arg	n ||| n	count=2
class	if ||| chunk	count=1
class	languages as iso ||| reader	count=1
module_class	in the [class_2] ||| [module_1] [class_2]	count=2
module_class	tagged [class_2] ||| [module_1] tagged [class_2]	count=5
function	least common subsumer ||| lcs	count=1
function	a projective dependency ||| projective	count=1
class	in the expression ||| expression	count=2
arg	a string containing ||| vnframe	count=1
function	test sentence ||| test sentences	count=1
arg	used to generate base_fdist ||| base_fdist heldout_fdist	count=1
class	[class_1] widget ||| [class_2] [class_1]	count=11
class	ngramassocmeasures ||| contingency measures	count=2
function	to convert a ||| to	count=1
class	as as a list ||| corpus	count=1
class	to the end ||| reduce parser	count=1
function	sentence alignment of two ||| align	count=2
arg	forward pointer to ||| forward	count=1
class	when parsing a ||| bottom up probabilistic chart parser	count=1
arg	[arg_1] for appearances ||| [arg_2] [arg_1]	count=4
class	return the unicode encoding [class_1] [class_2] if known ||| [class_2] [class_1] encoding file	count=2
class	tree ||| chart	count=1
arg	context ||| context	count=1
class	[class_1] tokenizer ||| [class_2] [class_1]	count=4
arg	a synset ||| synset	count=1
function	the score ||| score ngram	count=2
function	set of child pointer ||| child pointer	count=1
function	to parse ||| parse	count=3
function_arg	[function_1] given edge ||| [function_1] [arg_2]	count=6
class	frequency [class_2] ||| [class_1] [class_2]	count=6
arg	[arg] underlying ||| [arg]	count=1
function	[function_1] the scrollregion ||| [function_2] [function_1]	count=1
function	pretty-printing ||| pretty	count=4
function	[function_1] pass of ||| [function_1] [function_2]	count=3
function	reads a custom ||| custom	count=1
arg	ranks1 and ranks2 for ||| ranks1 ranks2	count=1
function	replacing each feature structure ||| retract bindings	count=1
class	feature dictionary ||| feat dict	count=2
module_class	[module_1] freqdist ||| [module_1] [class_2]	count=2
class	feature structures assign the ||| feat struct	count=1
function	block from the ||| block	count=1
arg	used to implement the ||| bracket_sent tag strip_space	count=1
arg	event in ||| event	count=1
arg	[arg] has ||| [arg] forward fs_class	count=1
arg	from consideration given ||| test_sents	count=1
arg	[arg] rightmost ||| [arg]	count=1
function	given a ||| from	count=1
function	of the indices ||| indices	count=1
module	this ||| corpus reader	count=2
arg	given file s ||| fileids c5 strip_space	count=2
arg	and punctuation symbols ||| speaker stem	count=1
arg	to newvar ||| newvar	count=2
class	first ||| recursive descent parser	count=1
class	this instance's ||| instance	count=1
class	this corpus ||| propbank corpus	count=1
function_arg	[function_1] a string ||| [function_1] [arg_2]	count=1
function	convert a list of ||| from id	count=1
arg	utterance identifiers ||| sex spkrid sent_type	count=1
module	the internal indexes ||| corpus reader	count=1
function	source group id ||| source group	count=1
function	of productions ||| productions	count=1
function	to train ||| train	count=1
function	:return the previous ||| previous	count=1
class	attributes of the given ||| framenet corpus reader	count=1
arg	match [arg_2] ||| [arg_2] [arg_1]	count=2
function	the status ||| status	count=1
class	canvas [class_2] ||| [class_2] [class_1]	count=9
function	build a model store ||| build model	count=1
function	[function_1] an epytext ||| [function_2] [function_1]	count=1
class	a given underlying ||| lazy	count=1
arg	the list ||| fileids sent tag	count=1
function	[function] of ||| adjust [function]	count=1
arg	p and ||| p	count=1
function	retrieve the mapping dictionary ||| mapping	count=1
module	display the ||| app	count=1
function	clusters ||| clusters	count=1
arg	given synset ||| synset	count=1
module	[module] feature ||| [module]	count=1
class	grammar ||| cfg	count=4
class	punkt word ||| punkt	count=1
function	path distance [function_2] ||| [function_2] [function_1]	count=1
class	check ||| shift reduce parser	count=1
class	a ||| chart parser	count=1
class	[class_1] corpus ||| [class_1] [class_2]	count=5
function	to a local ||| retrieve	count=1
class	end of ||| shift reduce parser	count=1
function	main frame widget ||| pack	count=1
arg	[arg_1] which match ||| [arg_2] [arg_1]	count=3
module_class	[module_1] wrapper ||| [module_1] [class_2]	count=2
function	[function_1] [function_2] referenced directly as part ||| [function_2] [function_1]	count=8
class	sequence this ||| hidden markov model	count=1
class	a ||| tokenizer	count=1
class	positive examples ||| positive naive bayes	count=1
arg	[arg_1] v ||| [arg_2] [arg_1]	count=1
arg	them into on larger ||| g_graph b_graph	count=1
arg	its forward pointer ||| forward	count=1
function	skolemize the ||| skolemize	count=1
class	the ||| reduce	count=4
function_arg	[function_1] match the ||| [arg_2] [function_1]	count=1
function	log p ||| logprob	count=1
function	load a subcorpus of ||| lusubcorpus	count=1
function	returns the type ||| type	count=2
arg	list of word tag ||| fileids speaker stem	count=1
module	move a token ||| parse	count=1
function	length ||| length	count=1
class	remaining text ||| shift	count=1
class	a list of tweets ||| twitter	count=1
function	[function_1] tokenization ||| [function_1] [function_2]	count=3
function	qtree ||| qtree	count=1
arg	pairs generated by ||| pairs	count=1
class	function ||| drt glue demo	count=1
function	sentence and a set ||| of fes	count=1
function	arcs to any of ||| arcs	count=1
module_class	words [class_2] ||| [module_1] swadesh [class_2]	count=3
class	file identified by this [class_1] [class_2] ||| core [class_1] [class_2]	count=1
arg	list of drtindividualvariableexpression for ||| conds consequent	count=1
class	words ||| opinion lexicon corpus	count=1
function	edge's dot position ||| dot	count=1
function	id only relations involving ||| frame relations	count=1
arg	at the specified entry ||| entry	count=1
arg	status_code the ||| status_code data	count=1
class	be generated when ||| probabilistic	count=1
function	of the shortest ||| min	count=1
class	[class_1] concatenating ||| [class_2] [class_1]	count=2
function	base ||| base	count=1
function	convert ||| user	count=1
function	size of ||| file size	count=1
class	of the stack ||| reduce parser	count=1
class	element of the frontier ||| descent	count=1
class	called ||| demo	count=1
function	is specified then select ||| select	count=1
module	corpus or ||| corpus	count=1
function	subcorpus of a ||| lusubcorpus	count=1
function	the best [function_2] ||| [function_1] [function_2]	count=5
arg	nonterminals for which the ||| cat	count=1
class	reader with the given ||| reader	count=1
arg	build_index(): perform some checks ||| pkg_xml zipfilename zf	count=1
class	this corpus ||| nombank corpus	count=1
class	the underlying [class_2] ||| [class_1] [class_2]	count=1
module	feature [module] the ||| [module]	count=1
function_arg	beginning of [arg_2] ||| [function_1] stack [arg_2]	count=4
class	big the tree ||| view	count=1
module_class	[module_1] canvas ||| [module_1] [class_2]	count=34
function	time that the eval ||| eval chunk	count=1
arg	s as a ||| fileids c5 strip_space	count=2
module	words in alphabetical order ||| reader	count=1
function_arg	[function_1] stream until ||| [function_1] [arg_2]	count=2
function	counter [function_2] ||| [function_1] [function_2]	count=3
arg	takes multiple ||| top_relation_label	count=1
function	given ||| in range	count=1
function	a single [function] character ||| [function]	count=2
function	decode the ||| decode	count=1
function	decorator ||| decorator	count=2
arg	a pretty-printed ||| width	count=1
arg	[arg] tree2semi_rel ||| [arg]	count=2
class	the ||| stepping recursive descent parser	count=2
arg	if [arg] ||| [arg]	count=3
arg	sure that s ||| s	count=1
class	in particular ||| recursive descent	count=1
class	module ||| module	count=1
function	perform a projective dependency ||| projective rule parse	count=1
class	of tweets [class_2] ||| [class_2] [class_1]	count=3
class	consistent with ||| edge	count=2
class	buffered gzip file ||| buffered gzip file	count=1
function	pretty-printing a list of ||| pretty	count=2
function_arg	a list [arg_2] ||| [function_1] word [arg_2]	count=1
function	web help [function_2] ||| [function_2] [function_1]	count=1
function	transform ||| transform	count=1
module	the sentence string ||| app	count=1
class	sentence string ||| chart	count=1
function	rule to the word ||| apply rule	count=1
function	the unique counter from ||| get unique counter from	count=1
class	element of the frontier ||| descent parser	count=1
function	alignment ||| alignment	count=2
function	labels [function_2] ||| [function_2] [function_1]	count=4
class	positive examples (i ||| positive naive bayes	count=1
class	similar to a list's ||| pretty lazy concatenation	count=1
module	must ||| app	count=2
class	[class_1] stemmer ||| [class_2] [class_1]	count=3
class	the stack ||| stepping shift reduce parser	count=1
function	[function_1] all ||| [function_1] [function_2]	count=6
function	change ||| set	count=6
function_arg	a local [arg_2] ||| [arg_2] [function_1]	count=1
class	[class_1] structure is ||| [class_2] [class_1]	count=1
class	the ||| chart view	count=2
function	header as ||| header section	count=1
function	the users ||| user info	count=1
class	the corpus ||| propbank corpus	count=1
module	this widget this ||| draw	count=1
module	and values are sets ||| metrics	count=1
function	first applicable suffix-removal rule ||| rule	count=1
class	with ||| punkt token	count=1
arg	to the [arg] this ||| [arg]	count=1
class	tags the ||| hidden markov model tagger	count=1
class	a given bigram ||| bigram	count=1
class	for this corpus ||| nombank corpus reader	count=1
class	a single ||| reduce parser	count=1
class	translation model vacancy ||| ibmmodel5	count=1
function_arg	children under ||| children node_index	count=1
class	[class_1] [class_2] ||| [class_1] [class_2]	count=744
class	of the ||| reduce	count=2
function	a demonstration showing how ||| demo	count=1
class	words in alphabetical ||| opinion lexicon corpus reader	count=1
class	will add edges licensed [class_1] [class_2] ||| [class_2] [class_1]	count=7
function	a single [function] ||| [function]	count=1
arg	for translating the ||| hypothesis future_score_table sentence_length	count=1
class	probdist ||| witten bell prob dist	count=1
function	create a lexical ||| init	count=4
class	:return a corpus ||| propbank corpus	count=1
function	entities ||| html entities	count=1
function	convert a userid to ||| lookup by userid	count=1
class	by this [class_2] ||| [class_2] [class_1] apply everywhere chart grammar	count=5
arg	uses grammar ||| grammar strategy trace trace_chart_width	count=1
class	by this encoding ||| encoding i	count=1
function	in a valuation file ||| valuation	count=1
module	the name of the ||| corpus	count=1
class	a romanian ||| romanian	count=1
function_arg	[function_1] alignment ||| [arg_2] [function_1]	count=8
arg	of discoursetester ||| reading_command	count=2
function	[function_1] root ||| [function_2] [function_1]	count=1
function	convert a userid ||| lookup by userid	count=1
arg	tree structures that are ||| tree_class complete	count=1
class	of the ||| stepping	count=3
function	source of the best ||| best	count=1
class	element in ||| framenet corpus reader	count=1
function	tweets [function_2] ||| [function_2] [function_1]	count=3
function	a table ||| table	count=1
class	with the ||| model	count=1
class	feature with the ||| feat dict	count=2
function	create ||| init	count=10
class	to elements ||| lazy map	count=1
class	dictionary ||| dictionary conditional prob dist	count=1
function	set ||| set	count=9
arg	iff self and other ||| other	count=1
arg	make up this ||| vnclass_ids	count=1
arg	distance of each ||| distance simulate_root	count=1
arg	a list of lists ||| fileids tagset	count=1
function	primitive [function_2] ||| [function_1] [function_2]	count=1
class	frequency distribution ||| prob dist	count=1
function	a list ||| from	count=1
function	[function] the given ||| [function]	count=2
arg	its forward ||| forward	count=2
function	unique counter [function_2] ||| [function_2] [function_1]	count=3
class	tagged ||| semcor corpus reader	count=1
arg	arrange [arg] into a ||| [arg] rows cols	count=1
function	to remove ||| remove	count=1
function_arg	[function_1] edge ||| [function_1] [arg_2]	count=6
function_arg	[function_1] stream and ||| [arg_2] [function_1]	count=3
class	a dictionary ||| dictionary conditional prob	count=1
function_arg	[function_1] [arg_2] ||| [function_1] list [arg_2]	count=4
arg	invalidate the cached ||| key	count=1
function	of left ||| left	count=1
function_arg	[function_1] child to ||| [function_1] [arg_2]	count=1
class	this tagger ||| brill tagger	count=1
class	of ||| stepping	count=3
class	this path pointer ||| core path pointer	count=1
arg	a feature ||| feat flag	count=1
class	be ||| parser	count=1
function	[function_1] static index ||| [function_1] [function_2]	count=1
class	must be ||| glue demo	count=1
function_arg	likelihood of [arg_2] ||| [arg_2] [function_1]	count=1
function	also str [function_2] ||| [function_1] [function_2]	count=2
arg	a valuation ||| valuation	count=1
class	is different for ||| transition	count=1
arg	by save_classifier ||| save_classifier	count=1
class	api ||| query	count=1
function_arg	[function_1] between tagsets ||| [function_1] [arg_2]	count=3
function	file ||| binary search file	count=1
arg	and q [arg_2] ||| [arg_1] [arg_2]	count=1
arg	10000 ||| n_instances output	count=2
function	depth ||| depth	count=1
function	sentences each encoded ||| sents	count=2
class	file underlying this ||| lazy sequence	count=1
function	node [function_2] ||| [function_1] [function_2]	count=2
function_arg	and [arg_2] ||| [function_1] [arg_2]	count=1
class	list of tweets ||| twitter corpus	count=1
class	distribution mapping each context ||| context	count=1
class	defined for this corpus ||| categorized corpus	count=1
class	invalidate ||| dist	count=1
module	big a ||| app	count=1
function	the ||| id	count=1
class	for this corpus or ||| corpus	count=1
module	list ||| reader	count=1
function_arg	[function_1] a feature ||| [arg_2] [function_1]	count=1
class	return all sentences ||| comparative sentences	count=2
function	back into the cyrillic ||| cyrillic	count=1
class	generated when [class_2] ||| [class_1] [class_2]	count=2
class	enter ||| regexp chunk	count=1
class	the end of the ||| shift	count=1
function	the probability of ||| prob	count=2
class	is consistent ||| edge	count=1
class	vector of joint-feature values ||| maxent feature encoding i	count=1
arg	a sentence ||| sentence verbose	count=1
class	pointer pointing ||| pointer	count=1
class	[class] structure it ||| [class]	count=3
function_arg	[function_1] of function ||| [arg_2] [function_1]	count=3
arg	the cached ||| key	count=1
function	replace all instances of ||| replace	count=3
module	words in alphabetical order ||| corpus reader	count=1
arg	language as list ||| lang	count=1
function	file to its web ||| webview file	count=1
class	the [class_1] [class_2] ||| core [class_1] [class_2]	count=5
arg	being observed in the ||| state	count=1
arg	remaining_text to ||| remaining_text	count=1
module	structure hypothesized by this ||| parse	count=1
function	f measure for ||| f measure	count=2
class	this canvas [class] and ||| canvas [class]	count=1
function	convert a ||| info from	count=1
class	probability distribution for ||| prob dist	count=6
class	in alphabetical ||| corpus reader	count=1
arg	structures that ||| tree_class complete	count=1
function	list of ||| from id	count=1
class	corpus or for ||| corpus reader	count=2
function	logged values returning the ||| log add	count=1
class	to be ||| view	count=1
arg	tuple (val end_position) ||| start_position	count=1
function	edge in the dependencygraph ||| edge scores	count=1
class	token from the ||| reduce parser	count=1
function_arg	representation of [arg_2] ||| [function_1] [arg_2]	count=1
class	binder in [class_2] ||| [class_2] [class_1]	count=2
class	if ||| glue demo	count=1
arg	trees which match the ||| trees search_leaves	count=1
module	a subtype ||| sem	count=1
class	maltparser to ||| malt	count=2
function	crubadan ||| crubadan	count=1
arg	of word tag ||| stem	count=2
arg	string representation of the ||| format	count=1
module	this chunk ||| chunk	count=1
class	lemma ||| net corpus reader	count=1
class	sequence ||| hidden markov model tagger	count=4
class	the bounding boxes ||| scroll watcher widget	count=1
class	indicates ||| edge	count=1
class	licensed [class] ||| chart rule [class]	count=2
class	[class_1] linear regression ||| [class_1] [class_2]	count=2
class	scroll-watcher the ||| scroll watcher	count=1
class	enter the ||| regexp	count=1
function	sentence ||| of	count=1
class	token ||| shift	count=1
module	of supported languages as ||| reader	count=1
function	:return a [function] ||| [function]	count=4
arg	function results for ||| function	count=1
class	tagger uses ||| based tagger	count=2
module	that [module] model ||| [module]	count=2
class	if ||| stepping recursive descent	count=1
function	of ||| drt	count=1
function	top of ||| top	count=1
function	variety of information ||| info from id	count=1
arg	'expression' ||| variable expression replace_bound alpha_convert	count=1
class	corpus ||| propbank corpus	count=3
arg	regexp specifying the fileids ||| fileids	count=2
class	this ||| model	count=1
function	is a factory ||| variable expression	count=1
arg	given tokens ||| tokens	count=1
class	of the file ||| file	count=1
arg	samples ||| samples	count=2
arg	the variables in univ_scope ||| univ_scope	count=1
module	variety of ||| twitter	count=1
class	words in alphabetical order ||| opinion lexicon corpus reader	count=1
function	of all the productions ||| productions	count=1
class	end of the ||| stepping shift reduce	count=1
class	text to the end ||| stepping shift	count=1
class	[class_1] pickle ||| [class_1] [class_2]	count=1
function	list of tagged ||| tagged	count=6
class	corpus ||| string category corpus	count=1
class	to princeton wordnet 3 ||| word net	count=1
function	a list of nodes ||| nodes	count=1
function	arc from the ||| arc	count=1
arg	for appearances of ||| word_fd bigram_fd	count=1
module	sequence with the ||| tag	count=1
class	this function must be ||| chart	count=1
class	edge ||| edge	count=2
function	width ||| width	count=1
class	element of ||| stepping	count=1
module	for the given ||| reader	count=1
function	height of a line ||| height	count=1
module	in ||| parse	count=1
module	in alphabetical ||| reader	count=1
arg	samples ||| samples store_logs	count=1
function	variety ||| user info from id	count=1
arg	n-gram f-score described ||| reference hypothesis min_len max_len	count=1
arg	the fileids ||| fileids	count=2
class	gzip ||| gzip	count=1
module	instance's predicate ||| corpus reader	count=1
function	a string representing a ||| aug	count=1
function	a known abbreviation or ||| abbrev	count=1
function	relations data for ||| relations data	count=2
class	supported languages as iso ||| crubadan corpus reader	count=1
class	feature structures ||| feat	count=1
function_arg	and [arg_2] ||| [arg_2] [function_1]	count=1
function	a view ||| view	count=1
class	alphabetical ||| reader	count=1
class	hypothesized structure ||| i	count=1
class	the frontier in ||| descent	count=1
class	conditionalprobdist ||| conditional prob dist i	count=1
class	this ||| reduce app	count=1
arg	and punctuation symbols encoded ||| stem	count=2
class	this chart ||| feature chart	count=1
arg	part of speech ||| pos	count=1
module_class	this [class_2] ||| [module_1] [class_2] subtrees	count=1
function	to parse multiple sentences ||| tagged parse	count=1
arg	segmentation ||| hyp	count=1
arg	frame object name or ||| frame frame2 type	count=1
class	a probabilisticdependencygrammar ||| dependency parser	count=1
arg	draw the given item ||| item	count=1
function	tagged words and chunks ||| chunked words	count=1
class	parser state ||| recursive descent parser	count=1
class	canvas widget including ||| canvas widget tags	count=1
module	function must be ||| sem	count=1
arg	implements the ||| tokseqs token_table	count=1
module	state [module] ||| [module]	count=2
function_arg	[function_1] return a ||| [arg_2] [function_1]	count=9
arg	documents each ||| documents	count=1
function	[function_1] index for ||| [function_1] [function_2]	count=3
arg	input string s ||| input	count=1
class	wordnet ||| word net	count=2
class	matrix from ||| matrix	count=1
class	be called if ||| drt	count=1
function_arg	training [arg_2] ||| [function_1] [arg_2]	count=2
arg	an association measure ||| measures	count=1
function	probability [function_2] ||| [function_1] t [function_2]	count=2
class	string to ||| chart	count=1
class	corpus or ||| corpus reader	count=3
arg	tab file containing ||| tab_file	count=1
arg	a single sentence ||| sentence threaded verbose filter	count=1
class	this function must be ||| drt glue demo	count=1
function	node label ||| node label pred	count=2
function	generates the [function_2] ||| [function_1] [function_2]	count=2
class	moses [class_2] ||| [class_1] [class_2]	count=2
arg	expression the expression ||| expression command x y	count=1
arg	is the maximum ||| other	count=2
arg	finds the reference ||| references	count=1
arg	lines at exactly the ||| lines	count=1
class	of (corpus_property_key value) ||| childescorpus	count=1
class	[class_1] frequency distribution ||| [class_1] [class_2]	count=1
class	:return a corpus ||| corpus reader	count=2
function	the first ||| first	count=2
function	[function_1] nodes ||| [function_1] [function_2]	count=1
class	is ||| porter stemmer	count=1
function	response ||| on success	count=1
function	number [function_2] ||| [function_2] [function_1]	count=1
class	identifiers for the files ||| ycoecorpus	count=1
class	to be ||| chart view	count=1
arg	the pairs generated by ||| pairs window	count=1
arg	for the given sample ||| sample	count=1
function	named entity [function_2] ||| [function_2] [function_1]	count=4
function	words or ||| words	count=1
function	arcs to any ||| arcs	count=1
arg	of variable v ||| variable	count=3
class	remaining text to the ||| stepping	count=1
module	appear and return ||| core	count=1
function	given ||| given s	count=2
arg	with_shutdown ||| with_shutdown	count=1
function	list of ||| info from	count=1
arg	frameid and framename are ||| frameid	count=1
function	[function_1] resource cache ||| [function_2] [function_1]	count=1
class	the expression to ||| expression	count=2
arg	classifies the token into ||| token	count=1
function	and ||| variable expression	count=1
class	internal ||| corpus reader	count=1
arg	source-to-target and ||| srclen trglen e2f	count=1
function	a subtype of abstractvariableexpression ||| variable expression	count=1
function	wrap the ||| wrap	count=1
arg	in the originals ||| originals	count=1
class	[class_1] [class_2] results ||| [class_1] [class_2]	count=9
function	for ||| for	count=1
class	all leaves [class] have ||| [class]	count=1
arg	a string ||| s chunk_label	count=1
arg	remaining lines at ||| lines wrap_at	count=1
arg	in paths where ||| paths	count=1
class	to the ||| stepping shift reduce	count=1
class	if ||| regexp	count=1
function	token ||| token	count=1
arg	takes a word and ||| word	count=1
class	iso ||| crubadan corpus	count=1
function_arg	[function_1] corpus train_toks ||| [function_1] [arg_2]	count=8
function	update the ||| update	count=3
class	to all tree ||| tree	count=2
class	value for the feature ||| feat list	count=1
arg	marker file for ||| sfm_file	count=1
class	a tnt statistical ||| tn t	count=1
class	first element ||| parser	count=1
module	indexes ||| corpus reader	count=2
arg	remaining lines at ||| lines	count=1
function	about the ||| info from id	count=1
arg	as tuples ||| relation	count=1
module	this corpus or that ||| corpus	count=1
arg	the tokens in unigrams ||| unigrams handle_negation	count=1
arg	train ||| trainer save_analyzer n_instances output	count=1
function	[function_1] special category ||| [function_2] [function_1]	count=2
arg	root the root directory ||| root fileids extension str2chunktree	count=1
class	in the corpus ||| corpus	count=3
function	record the button press ||| press cb	count=1
class	probability of a dependency ||| dependency parser	count=1
module	big a unit ||| app	count=1
arg	[arg] as ||| [arg]	count=3
class	modify ||| prover command	count=1
class	string to ||| view	count=1
class	tags ||| markov model	count=1
class	of the hypothesized ||| i	count=1
class	[class] file ||| [class]	count=3
class	apply ||| lancaster stemmer	count=1
function	convert a list of ||| id	count=1
function	matrix of ||| matrix	count=1
function	demo showing the ||| prob parse demo	count=1
function	if the primitive ||| primitive	count=1
function_arg	productions [arg_2] ||| [function_1] lhs [arg_2]	count=4
function	log probability of the ||| output logprob	count=1
class	count ||| paice	count=1
class	of this rule ||| chunk rule	count=1
class	sentence ||| tn t	count=1
function_arg	[function_1] ranks1 and ||| [function_1] [arg_2]	count=1
function_arg	[function_1] synset ||| [function_1] [arg_2]	count=4
function	number of words in ||| num	count=1
class	move a token ||| reduce parser	count=1
function	list of sentences ||| sentences	count=1
class	create a new iterator ||| iterator	count=1
function	[function_1] chunk the ||| [function_1] [function_2]	count=2
class	identifiers for the ||| ycoecorpus	count=1
arg	token into a ||| token	count=1
class	words for the specified ||| swadesh corpus reader	count=1
function	[function_1] to each ||| [function_2] [function_1]	count=2
function	replacing each ||| retract	count=1
class	[class_1] text ||| [class_2] [class_1]	count=6
class	new iterator over ||| iterator	count=1
arg	into on larger ||| g_graph b_graph	count=1
class	return new feature encoding ||| maxent feature encoding i	count=1
class	the ||| stepping shift	count=4
arg	[arg_1] that thread ||| [arg_2] [arg_1]	count=4
function_arg	representation [arg_2] ||| [function_1] [arg_2]	count=1
arg	implement the ||| bracket_sent tag strip_space	count=1
class	a token from the ||| reduce	count=1
function	of left [function_2] ||| [function_1] [function_2]	count=1
function	contains a node with ||| contains	count=1
function	chomsky normal [function_2] ||| [function_1] [function_2]	count=2
arg	for appearances ||| word_fd	count=1
function	a list ||| user	count=1
class	that a token ||| parser	count=1
module	the ||| app	count=5
class	with ||| i	count=1
class	corpus reader with ||| corpus reader	count=2
class	that ||| stepping recursive descent parser	count=2
class	analyze ||| chart view	count=1
class	sequence with ||| model	count=1
arg	given root directory ||| root fileids encoding	count=1
function	names of the ||| names	count=2
arg	the [arg] in ||| [arg]	count=1
class	a standard [class_2] ||| [class_2] [class_1]	count=1
function	predicate-argument annotation file ||| lines	count=2
function	arrange the child widgets ||| manage	count=1
arg	:param data [arg_2] ||| [arg_1] [arg_2]	count=2
function	a userid ||| by userid demo	count=1
class	a list's ||| pretty lazy iterator list	count=1
function	of information about ||| info from id	count=1
module	is consistent with the ||| parse	count=1
arg	remaining_text to the end ||| remaining_text	count=1
class	of joint-feature ||| maxent feature encoding i	count=1
class	rule and the given ||| chart rule	count=1
function	tree positions in ||| tgrep positions	count=1
function_arg	[function_1] raw_score likelihood ||| [arg_2] [function_1]	count=1
function	from ||| block	count=1
arg	the given colors ||| linecolor textcolor	count=1
class	sentence string to figure ||| chart	count=1
function	tagged chunks represented in ||| tagged chunks	count=1
module	[module] to ||| [module]	count=6
function_arg	relations data [arg_2] ||| [arg_2] [function_1]	count=2
function	is a ||| variable expression	count=1
function	convert this expression into ||| to	count=1
arg	tokentablefields ||| token_sequences par_breaks	count=1
function	of variables used by ||| find variables	count=1
module	for this corpus ||| corpus reader	count=4
class	hypothesized structure ||| edge	count=1
arg	and ranks2 for ||| ranks2	count=1
class	element of ||| stepping recursive	count=1
function_arg	[function_1] specified criteria ||| [arg_2] [function_1]	count=2
class	in alphabetical ||| opinion lexicon corpus reader	count=1
function_arg	[function_1] distance of ||| [arg_2] [function_1]	count=2
module	tree should ||| app	count=1
function	length to ||| ref length	count=1
module	languages as iso 639-3 ||| corpus	count=1
function_arg	nodes in [arg_2] ||| [arg_2] [function_1]	count=1
function	pretty-printing a frame element ||| pretty	count=1
arg	[arg_1] q ||| [arg_2] [arg_1]	count=1
class	the remaining text to ||| stepping shift	count=1
arg	binary with the given ||| binary args	count=1
arg	which match [arg_2] ||| [arg_2] [arg_1]	count=1
arg	information content ||| ic verbose	count=1
function	synsets that are hypernyms ||| hypernyms	count=1
function_arg	header [arg_2] ||| [arg_2] [function_1]	count=1
class	[class_1] distribution for ||| [class_1] [class_2]	count=6
class	multi-column [class_2] ||| [class_1] [class_2]	count=1
class	left ||| dependency graph	count=1
function_arg	construct a [arg_2] ||| [function_1] [arg_2]	count=4
function	given an exemplar ||| exemplar	count=1
class	the frontier ||| recursive	count=1
function	[function_1] chomsky ||| [function_1] [function_2]	count=1
arg	by its id luname ||| ignorekeys luname	count=1
module_class	[module_1] canvasframe ||| [module_1] canvas [class_2]	count=2
class	structure and ||| struct	count=1
class	the internal indexes ||| corpus reader	count=1
class	sentence [class_2] ||| [class_2] [class_1]	count=8
function	adjust the ||| adjust	count=1
function	illustrate the various methods ||| drt discourse demo	count=1
arg	read a bracketed ||| brackets read_node	count=1
class	the corpus ||| corpus reader	count=10
function	the various methods ||| drt discourse	count=1
function	(from the ||| nouns	count=1
function	test sentence ||| extract test sentences	count=2
class	normalize ||| tiling tokenizer	count=1
class	list's ||| pretty list	count=1
class	edges licensed [class] ||| chart rule [class]	count=2
function	to find a space ||| find room	count=1
function	annotated sentences matching ||| sents	count=1
class	this ||| drt glue	count=1
function	java binary ||| java	count=1
class	tagged corpus reader ||| tagged corpus reader	count=1
arg	devset_name the name of ||| devset_name devset	count=1
arg	are coming in an ||| limit	count=1
class	function must be ||| glue demo	count=1
function	into the ||| set	count=1
arg	a word and a ||| word	count=1
function_arg	by a [arg_2] ||| [function_1] [arg_2]	count=1
module_class	[module_1] a feature ||| [module_1] [class_2]	count=2
function	default value ||| default	count=1
function	[function_1] the url ||| [function_2] [function_1]	count=5
arg	*worder* ||| hypothesis character_based	count=1
function	the likelihood a float ||| likelihood	count=1
function	the various methods ||| demo	count=2
class	before ||| stack	count=1
function	an input file ||| file	count=2
class	that a token ||| reduce parser	count=1
function	write the output ||| output	count=1
class	edges in this chart ||| chart	count=1
class	files that have ||| reviews corpus reader	count=1
function	a list of ||| user	count=1
class	vector of joint-feature ||| maxent feature encoding	count=1
arg	matched substrings ||| string left	count=1
function	top-lebel node ||| tgrep exprs	count=1
class	the corpus or ||| corpus reader	count=1
arg	its id luname ||| luname	count=1
function	[function_1] node label ||| [function_2] [function_1]	count=1
function	_tag_positions to reflect the ||| tag positions	count=1
class	this ||| chart parser	count=1
module_class	[module_1] true ||| [module_1] [class_2]	count=2
function	calculate the score of ||| score	count=1
class	internal indexes ||| reader	count=1
arg	[arg_1] and q ||| [arg_2] [arg_1]	count=1
class	of the frontier ||| stepping	count=1
module	of the [module] on ||| [module]	count=1
function	remove entities ||| replace html entities	count=1
arg	:rtype bool ||| rightmost_stack	count=1
class	move a token from ||| parser	count=1
function	[function] unary ||| [function]	count=1
arg	documents located at the ||| fileids word_tokenizer sent_tokenizer	count=1
function	child pointer lists ||| child pointer lists	count=3
class	identified by this pointer ||| pointer	count=1
function	corpus ||| corpus	count=1
function_arg	[function_1] of word ||| [function_1] sents fileids [arg_2]	count=1
class	this function ||| chart	count=1
function	is of ||| is	count=1
function_arg	the given location ||| in range location	count=1
class	the first element of ||| stepping recursive descent parser	count=1
function	make sure that ||| check	count=1
module_class	iso 639-3 [class_2] ||| [module_1] [class_2]	count=2
function	[function_1] resource cache ||| core [function_1] [function_2]	count=1
module	this function ||| app	count=2
class	build the ||| framenet	count=1
class	figure out how ||| view	count=1
class	move a ||| stepping shift	count=1
arg	return a score ||| other verbose simulate_root	count=3
module	name of ||| corpus reader	count=1
arg	of text label ||| label word_tokenizer sent_tokenizer	count=2
class	a token from ||| reduce	count=1
module_class	of [module_1] [class_2] structure suitable for embedding ||| [module_1] [class_2]	count=1
arg	sentence as a ||| sentence	count=1
module	corpus view that ||| corpus reader	count=4
class	this ||| app	count=4
class	*estimate[r]* is the probability ||| prob	count=1
class	framenet ||| framenet	count=2
class	a sentence in an ||| corpus reader	count=1
arg	raw_score likelihood ||| raw_score src_phrase_span trg_phrase previous	count=1
function	of abstractvariableexpression appropriate for ||| variable	count=1
function_arg	classify a [arg_2] ||| [arg_2] [function_1]	count=2
class	of the hypothesized structure ||| edge	count=1
arg	list of samples ||| samples	count=1
function	the corresponding string representation ||| tuple2str	count=1
module	for ||| sem	count=1
class	of joint-feature ||| maxent feature encoding	count=1
class	corresponding vector of joint-feature ||| maxent feature encoding i	count=1
class	corpus view that acts ||| corpus reader	count=2
class	this classifier ||| naive bayes classifier	count=1
function	transform ||| test transform	count=1
class	given trigram ||| trigram	count=1
module	calculate and return ||| core	count=1
arg	from a word-aligned ||| srctext trgtext alignment	count=1
arg	and display ||| display	count=1
class	first element of the ||| stepping recursive descent	count=1
class	be ||| drt	count=1
arg	word tag [arg_2] ||| [arg_2] [arg_1]	count=1
module	supported languages ||| corpus reader	count=1
arg	segmentation is ||| ref hyp	count=1
class	and scores [class] ||| [class]	count=2
arg	self and other ||| other check_reentrance visited_self	count=1
arg	match the [arg_2] ||| [arg_2] trees [arg_1]	count=2
arg	features one [arg] each ||| cls starts [arg]	count=1
class	union ||| conditional freq dist	count=1
function	training ||| train	count=4
class	creating ||| lin thesaurus	count=1
function	fileids ||| fileids	count=2
function	for ipython ||| repr	count=1
arg	length this ||| length	count=1
function_arg	[function_1] print classifier ||| [arg_2] [function_1]	count=1
arg	[arg] if ||| [arg] include_encoding	count=3
function	variety ||| info from id	count=1
function	[function_1] ratios ||| [function_1] [function_2]	count=1
class	bigram collocation finder with ||| trigram collocation	count=1
function	factory method that ||| variable	count=1
arg	single sentence ||| sentence	count=2
arg	*text* see :class regexptokenizer ||| pattern gaps discard_empty	count=1
function	create a dictionary of ||| make predicate dict	count=1
function	local file ||| retrieve	count=1
class	to the ||| shift reduce parser	count=1
class	pickled model [class_2] ||| [class_2] [class_1]	count=4
function	includes ||| contains sentbreak	count=1
arg	reading ids ||| threads	count=1
class	build the internal ||| framenet corpus	count=1
function	demonstration of the result ||| demo	count=1
class	string to figure out ||| chart	count=1
module	the list of ||| inference	count=1
class	stack ||| stepping shift reduce	count=2
arg	string of ||| s	count=1
function	frequencies of the specified ||| frequencies	count=1
module	return ||| tag	count=1
arg	the alignment in alignment_info, ||| alignment_info j_pegged	count=1
function	to parse a sentence ||| tagged parse	count=1
function	parse a sentence ||| parse	count=1
class	a ||| shift reduce parser	count=2
function	about ||| info	count=1
module	that instantiates and returns ||| sem	count=1
class	corpus ||| cons corpus	count=1
arg	forward pointer ||| forward	count=1
function	the feature ||| feature	count=2
function	[function_1] page ||| [function_2] [function_1]	count=12
class	in ||| recursive descent	count=1
class	characters ||| unicode stream reader	count=2
class	of supported languages ||| reader	count=1
function	users ||| info from id	count=1
function	nodes in ||| nodes	count=1
module	the first ||| parse	count=1
function	restore selection ||| restore	count=1
class	corpus or ||| timit corpus reader	count=2
function	abbc ||| abbc	count=1
class	in the pl196x ||| pl196x	count=1
arg	for appearances of ||| word_fd	count=1
class	the end ||| stepping shift reduce parser	count=1
arg	the highest ||| unlabeled_sequence	count=1
class	to ibm model 2 ||| ibmmodel	count=1
arg	devset_name the name ||| devset_name devset	count=1
function	to create ||| init	count=3
arg	generate freqdist ||| freqdist	count=1
class	grammar ||| grammar	count=2
function	calculates the depth ||| depth	count=1
class	words in alphabetical ||| opinion lexicon	count=1
function_arg	tweets by [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	[function_1] given ||| [arg_2] [function_1]	count=2
function_arg	tagged [arg_2] ||| [arg_2] [function_1]	count=1
class	the end of ||| shift reduce parser	count=1
arg	:param expression the expression ||| expression command	count=1
class	variety of information about ||| query	count=1
arg	fstruct2 ||| fstruct2	count=1
function	that *rule* applies at ||| applies	count=1
class	of ||| i	count=1
class	canvasframe ||| canvas frame	count=3
arg	pretty-printed version of this ||| width prefix depth	count=1
function	the ||| variable expression	count=1
class	a ||| projective dependency parser	count=1
class	build the ||| reader	count=1
class	[class_1] grammar from ||| [class_1] [class_2]	count=1
function_arg	log probability [arg_2] ||| [arg_2] [function_1]	count=3
function	convert a list ||| user	count=1
function	methods under [function] ||| [function] unicode	count=1
class	this [class_1] [class_2] ||| core [class_1] [class_2]	count=4
module	from a ||| sem	count=1
class	variable binder in ||| variable binder	count=2
function	positive ||| positive	count=1
function	entropy over the possible ||| entropy	count=1
class	feature ||| feat list	count=1
arg	n-gram f-score ||| min_len max_len	count=2
class	of joint-feature ||| maxent feature	count=1
function	clusters learning the clustering ||| cluster	count=1
class	the sequence with ||| hidden markov model tagger	count=1
class	dict if its ||| binding dict	count=1
function	conditions that ||| conditions	count=1
arg	luname ||| fn_luid ignorekeys luname	count=1
function_arg	[function_1] with other ||| [arg_2] [function_1]	count=2
module_class	of this canvas ||| draw canvas	count=2
arg	grammar ||| grammar root_label trace	count=1
class	the ||| corpus	count=1
function	lambda ||| tgrep	count=1
arg	or in the ||| fileids categories	count=1
arg	implement ||| fileid bracket_sent tag strip_space	count=1
function	information ||| info	count=1
class	639-3 ||| reader	count=1
arg	the string ||| string	count=1
module	a primitive category ||| ccg	count=1
function_arg	result [arg_2] ||| [function_1] [arg_2]	count=1
arg	the tuple representation of ||| tagged_token sep	count=1
class	if the graph ||| graph	count=1
function	list of ||| info from id	count=1
class	corpus view that ||| propbank corpus	count=1
arg	of a valuation ||| valuation	count=1
class	order ||| opinion lexicon	count=1
class	a token ||| stepping shift reduce	count=1
class	a list of ||| query	count=1
class	a corpus view that ||| propbank corpus	count=1
function	illustrate the ||| drt	count=1
module	this ||| draw	count=44
class	review ||| review	count=1
function	userid ||| by userid	count=1
function	method that instantiates ||| expression	count=1
function	file to its ||| file	count=1
class	collocation finder with ||| trigram collocation finder	count=1
class	be generated when ||| up probabilistic	count=1
module	corpus import wordnet ||| corpus reader	count=1
arg	given item at the ||| item x y	count=1
function	demonstration showing ||| parse demo	count=1
function	demonstration of the ||| demo	count=5
function	right sibling ||| right sibling	count=1
class	predicate ||| nombank	count=1
class	a token from the ||| stepping shift reduce parser	count=1
class	framenet ||| framenet corpus	count=1
function	cumulative ||| cumulative	count=1
class	generated when ||| bottom up probabilistic	count=1
class	create a new iterator ||| lazy iterator	count=1
function	[function_1] a category ||| [function_1] [function_2]	count=1
function	parse multiple sentences ||| parse	count=1
arg	information content ||| synset1 synset2 ic verbose	count=1
arg	the given fileids as ||| fileids	count=2
arg	text label tuples ||| label word_tokenizer sent_tokenizer	count=2
class	:return a ||| corpus reader	count=1
arg	is the minimum of ||| other	count=2
function	[function] object ||| make [function]	count=2
function	match the ||| match	count=1
function	update ||| update rule	count=1
function	the given ||| by	count=1
arg	these ||| fileids	count=1
function	of target sentence ||| t a	count=4
function	probability ||| prob alignment point	count=2
function	[function_1] chart's leaves ||| [function_1] [function_2]	count=1
function	replace all ||| replace	count=3
function	a demonstration showing ||| rule parse demo	count=1
class	tree should be etc ||| view	count=1
module	sequence with ||| tag	count=1
function_arg	local file [arg_2] ||| [arg_2] [function_1]	count=1
arg	single sentence ||| sentence threaded	count=1
function	top_n [function] features ||| unigram [function]	count=1
class	n ||| freq dist	count=2
class	attributes of the given ||| corpus reader	count=1
function	[function] for which ||| reducible [function]	count=3
arg	vector ||| vector	count=2
arg	more [arg] to the ||| [arg]	count=1
class	of ||| stepping shift reduce parser	count=2
function	if ||| read	count=2
class	state sequence ||| hidden markov model tagger	count=1
arg	used to implement ||| fileid bracket_sent tag strip_space	count=1
function	the first [function_2] ||| [function_1] [function_2]	count=4
function	of left children ||| left children	count=2
arg	pair of segmentations a ||| seg1 seg2 k boundary	count=1
class	the minimal ||| minimal	count=1
arg	[arg_1] finalize ||| [arg_2] [arg_1]	count=5
module	a list of ||| twitter	count=1
arg	finds the reference that ||| references	count=1
class	move a token from ||| stepping	count=1
function	[function_1] patterns ||| [function_2] [function_1]	count=12
arg	feature is ||| feat flag	count=1
function	users ||| info	count=1
function_arg	[function_1] graph ||| [function_1] [arg_2]	count=1
function	and [function] ||| [function]	count=1
class	pointer in bytes ||| pointer	count=1
arg	insert a [arg] canvas ||| index [arg]	count=2
arg	[arg_1] match the ||| [arg_1] [arg_2]	count=3
class	called ||| chart parser app	count=1
class	[class_1] for the ||| [class_1] [class_2]	count=1
function	ratios as in manning ||| ratio	count=1
class	text returns a list ||| punkt	count=1
function	a module [function_2] ||| [function_2] [function_1]	count=3
arg	based on a ||| elt_handler	count=1
module_class	[module_1] corpus and ||| [module_1] [class_2]	count=1
function	display a friendly error ||| parse error	count=1
function	plug ||| plug	count=1
function	present ||| extract features	count=1
class	return all ||| comparative	count=2
function	background assumptions ||| background	count=1
class	dictionary ||| dictionary conditional	count=1
module_class	[module_1] corpus reader ||| [module_1] [class_2]	count=3
arg	[arg_1] a segmentation ||| [arg_2] [arg_1]	count=6
class	files that have to ||| reviews corpus reader	count=1
class	should be etc ||| chart	count=1
arg	[arg_1] expression ||| inference clause replace [arg_1] [arg_2]	count=3
class	the sequence with the ||| markov	count=1
class	[class_1] dependency graph ||| [class_2] [class_1]	count=8
module	for ipython ||| core	count=1
class	iterator ||| lazy iterator	count=1
function	a variety of ||| user info	count=1
class	use repp ||| repp	count=1
class	mass of probability ||| prob dist	count=1
function_arg	a table [arg_2] ||| [arg_2] [function_1]	count=1
class	parser ||| descent parser	count=1
class	much ||| i	count=1
arg	a featureset label ||| featureset label	count=2
class	a list ||| reader	count=1
function	assumes ||| tweets	count=1
arg	train and ||| trainer save_analyzer n_instances	count=1
function	[function_1] epytext ||| [function_2] [function_1]	count=1
class	first ||| stepping recursive descent	count=1
function	tagger to a ||| tagger	count=1
class	a token ||| reduce	count=1
class	candidate ngrams w1 w2 ||| abstract collocation finder	count=1
class	dict if its variable ||| dict	count=1
class	position' [class] given ||| [class]	count=2
function	of ||| variable expression	count=1
arg	multi-word tokenizer with ||| mwes separator	count=1
arg	freqdists for appearances ||| word_fd bigram_fd	count=1
arg	input ||| assumptions prover	count=2
function	[function_1] representing ||| [function_2] [function_1]	count=2
function	[function_1] all alphabetic ||| [function_1] [function_2]	count=1
class	chunks ||| semcor corpus reader	count=1
function_arg	[function_1] the distance ||| [arg_2] [function_1]	count=3
arg	samples given ||| samples store_logs	count=1
class	vector of joint-feature values ||| maxent feature encoding	count=1
class	sentence breaks yielding a ||| punkt sentence	count=1
class	new feature encoding ||| maxent feature encoding	count=2
function	[function_1] the latex ||| [function_1] [function_2]	count=1
module_class	plaintext [class_2] ||| [module_1] [class_2]	count=5
arg	phrase_table table ||| phrase_table	count=1
class	[class_1] pointer pointing ||| [class_2] [class_1]	count=1
function	a subcorpus of a ||| lusubcorpus	count=1
class	if ||| drt	count=1
function_arg	[function_1] p and ||| [arg_2] [function_1]	count=3
class	to the end ||| reduce	count=1
class	words in ||| corpus	count=1
arg	which ||| stream	count=1
class	function must be ||| demo	count=1
function	record the button ||| cb	count=1
arg	string fails ||| cls s match expecting	count=1
class	path pointer ||| zip file path pointer	count=1
function	convert ||| from id	count=1
class	score ||| collocation finder	count=3
class	etc ||| view	count=1
function_arg	productions [arg_2] ||| [arg_2] [function_1]	count=4
function_arg	table [arg_2] ||| [function_1] [arg_2]	count=1
module	[module] text ||| [module]	count=3
class	for ||| reader	count=2
class	[class_1] [class_2] including ||| [class_1] [class_2] tags	count=1
arg	root the root directory ||| root fileids delimiter encoding	count=1
module	true if this ||| draw	count=1
arg	t in the ||| s t	count=1
arg	s ||| fileids	count=22
function	skolemize ||| skolemize	count=1
function	a [function] for ||| [function]	count=1
module	the ||| reader	count=4
function	the upper frame page ||| upper page	count=1
class	a collocation finder ||| abstract collocation finder	count=2
arg	at [arg] ||| [arg] s	count=1
class	rule and ||| chart rule	count=1
function	the users ||| from	count=1
class	lancaster stemmer ||| lancaster stemmer	count=2
arg	a sequence of items ||| sequence n	count=1
class	the feature ||| feat	count=5
class	smoothing ||| smoothing	count=2
class	i e : ||| tokenizer i	count=1
arg	:param [arg] value ||| [arg]	count=1
class	of file identifiers ||| ycoecorpus reader	count=1
class	confusion ||| confusion	count=2
class	parsing ||| stepping recursive descent parser	count=1
class	a given bigram using ||| bigram collocation	count=1
function	the distance ||| distance	count=1
class	for ipython ||| tree	count=1
function	add ||| add	count=6
function	of entries in ||| size	count=1
module	that this ||| core	count=1
arg	number of rows ||| rows	count=1
class	return that ||| sequential backoff	count=1
function	to [function] ||| [function]	count=10
arg	displaying ||| remaining_text	count=1
function	comparison method ||| comparison	count=1
function	upper frame page ||| static upper page	count=1
arg	in bigrams ||| bigrams	count=1
arg	add a ||| sequence func add	count=1
class	of ngram [class] pairs as ||| [class]	count=1
class	list of ||| corpus	count=1
class	constructs a bigram collocation ||| collocation	count=1
function	[function] node specified ||| [function]	count=1
function	description ||| description	count=1
function_arg	[function_1] match ||| [function_1] nodes pattern trees [arg_2]	count=1
function	[function_1] abbreviation ||| [function_1] [function_2]	count=2
arg	specified entry in the ||| entry	count=1
arg	possibly non-contiguous ||| bigram_fd window_size	count=1
arg	of fileids ||| fileids	count=1
class	split the frequency distribution ||| simple good turing prob dist	count=1
class	invalidate the cached ||| freq dist	count=1
function	[function_1] megam ||| [function_2] [function_1]	count=6
class	be ||| glue demo	count=1
class	moses detokenizer ||| moses detokenizer	count=2
class	the childes ||| childescorpus reader	count=1
class	alignedsent ||| aligned	count=2
function	log p , where ||| logprob	count=1
function	attempts to realign punctuation ||| realign boundaries	count=1
class	return a ||| crubadan corpus reader	count=1
arg	of userids into a ||| userids	count=1
class	are not ||| corpus reader	count=1
class	called if ||| glue	count=1
class	that this tagger uses ||| classifier based tagger	count=1
module	much of the hypothesized ||| parse	count=1
function_arg	the chunk [arg_2] ||| [arg_2] [function_1]	count=1
function	target sentence ||| t a	count=4
class	return all ||| lexicon corpus reader	count=1
arg	index the index of ||| index depth	count=1
class	collocation finder with the ||| trigram collocation	count=1
class	sequence with the ||| hidden markov model tagger	count=1
class	sample outcomes ||| freq dist	count=1
arg	occurrence of the word ||| word	count=1
arg	:param frame optional frame ||| frame frame2	count=1
module	return all ||| reader	count=1
function_arg	demonstration [arg_2] ||| [function_1] [arg_2]	count=3
function_arg	[function_1] input stream ||| [arg_2] [function_1]	count=3
function	the euclidean ||| euclidean	count=1
class	end of the stack ||| stepping shift	count=1
arg	of samples given ||| samples store_logs	count=1
function_arg	[function_1] samples ||| [function_1] [arg_2]	count=1
class	sequence with the ||| hidden markov model	count=1
class	function must be called ||| drt glue demo	count=1
class	number of samples ||| turing prob dist	count=1
arg	root node is root ||| root	count=1
class	as iso 639-3 ||| reader	count=1
function	from ||| from stdlib	count=2
class	should be generated when ||| up probabilistic	count=1
arg	if the item ||| item	count=1
function	[function_1] arc to ||| [function_1] [function_2]	count=5
class	the given language to ||| corpus reader	count=1
function_arg	[function_1] associated with ||| [arg_2] [function_1]	count=3
function	all roots of this ||| roots	count=1
module	a variety ||| twitter	count=1
class	string ||| chart	count=1
function	the latex [function_2] ||| [function_1] [function_2]	count=2
function	parse on the list ||| parse	count=1
arg	and punctuation symbols ||| stem	count=3
function_arg	[function_1] [arg_2] the stream's file position ||| [function_1] [arg_2] comment_char	count=7
class	this function ||| regexp	count=1
class	:see ||| variable	count=3
class	as positive [class_2] ||| [class_1] [class_2]	count=2
class	a token from ||| reduce parser	count=1
function	precision for ||| precision	count=1
class	decision tree ||| decision tree	count=1
function	construct ||| init	count=5
function_arg	[function_1] of word ||| [function_1] [arg_2]	count=3
function	is a factory method ||| variable expression	count=1
class	a dictionary containing ||| dictionary conditional	count=1
module	of supported languages ||| corpus reader	count=1
class	this tree ||| parented tree	count=1
class	object ||| substitute	count=1
function	static web [function_2] ||| [function_1] [function_2]	count=2
class	cmudict lexicon ||| cmudict	count=2
class	much of ||| i	count=1
class	read ||| corpus view	count=1
function_arg	new empty ||| init cond_samples	count=1
class	languages ||| corpus	count=1
module	particular if ||| parse	count=1
class	featuresets [class] ||| classifier [class]	count=4
class	etc ||| chart view	count=1
function	a userid ||| userid	count=1
class	the punkt word segmentation ||| punkt	count=1
class	uses ||| classifier based	count=1
arg	[arg] output ||| srclen trglen e2f [arg]	count=2
class	build the internal ||| reader	count=1
arg	the probability [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] given text ||| [function_1] [arg_2]	count=1
function	a comparison (from listofkeywords ||| keywords readme	count=1
function	the node label ||| label	count=1
class	known as positive examples ||| positive naive bayes	count=1
class	where this tree occurs ||| multi parented tree	count=1
class	assignment ||| assignment	count=1
function	each successive match of ||| regexp span tokenize	count=1
class	to figure out how ||| chart view	count=1
function_arg	[function_1] initial_tagger the ||| [arg_2] [function_1]	count=1
function	all possible word alignments ||| all alignments	count=2
function	lin [function_2] ||| [function_1] [function_2]	count=1
class	[class_1] the corpus ||| [class_1] [class_2]	count=2
class	necessary to specified ||| nkjpcorpus	count=1
function	[function] chunkrulewithcontext ||| [function]	count=2
class	proper ||| simple good turing	count=1
arg	text and ||| text	count=1
function	lists ||| lists	count=1
class	in the corpus or ||| corpus reader	count=2
function	all words defined in ||| words	count=1
arg	tuple representation ||| tagged_token sep	count=1
function	the users ||| info	count=1
function	of tagged [function_2] ||| [function_2] [function_1]	count=6
function	points ||| entry	count=1
function	create a new frequency ||| create	count=1
class	feature encoding ||| maxent feature encoding	count=2
function	time that the eval ||| eval	count=1
function	return the strategy used ||| strategy	count=1
function	users ||| user info from id	count=1
class	the first ||| recursive	count=1
module	with the ||| parse	count=1
function	be the top of ||| top	count=1
rep	[module_class_1] [function_arg_2] ||| [module_class_1] [function_arg_2]	count=2
arg	subtypes of tree ||| tree	count=1
arg	text ||| word_tokenizer	count=1
arg	consideration given the ||| train_sents test_sents	count=1
function	resize ||| resize	count=1
class	the corpus file underlying ||| lazy	count=2
function	destroy ||| destroy	count=1
function	a variety of information ||| info from	count=1
class	tags the ||| tagger	count=1
arg	given resource to ||| resource_url	count=1
arg	speech ||| pos simulate_root	count=1
class	first element ||| recursive descent	count=1
function	tag ||| tag	count=2
class	tags the sequence with ||| hidden markov	count=1
class	sentences in the ||| sentences	count=1
class	item to the minimal ||| minimal	count=1
function	the backward probability matrix ||| backward probability	count=1
class	element of the frontier ||| stepping recursive descent parser	count=1
class	this ||| descent app	count=1
class	is the same ||| transition	count=1
class	of the remaining text ||| reduce parser	count=1
class	corpus view that ||| view	count=1
function	abstractvariableexpression appropriate ||| expression	count=1
class	the lidstone estimate to ||| lidstone	count=1
class	applied to elements of ||| lazy map	count=1
class	returns ||| punkt	count=1
function_arg	[function_1] sequence ||| [function_1] [arg_2]	count=4
arg	corpus ||| corpus	count=1
module	string ||| app	count=1
class	[class_1] ngrams using ||| [class_2] [class_1]	count=6
class	unit needs to be ||| view	count=1
class	first element of the ||| recursive descent parser	count=1
class	context-free grammar from ||| cfg	count=1
function_arg	[function_1] an alignment ||| [arg_2] [function_1]	count=8
module	internal indexes ||| corpus	count=1
class	return all ||| lexicon	count=1
class	[class_1] gzip file ||| [class_2] [class_1]	count=1
class	stream ||| stream reader	count=3
class	figure out ||| view	count=1
class	positive examples the ||| naive bayes	count=1
function	is all alphabetic ||| is alpha	count=2
arg	tokens using a chart-based ||| tokens	count=1
module	a variety of ||| twitter	count=1
class	the end of ||| stepping shift	count=1
module	this canvasframe if this ||| draw	count=1
class	feature structures assign ||| feat	count=1
class	all ||| lexicon	count=1
class	list's ||| pretty lazy concatenation	count=1
arg	"known labels" ||| mapping unseen_features alwayson_features	count=2
function	the chunk ||| chunk parse	count=1
arg	sample ||| sample	count=1
class	how big ||| chart	count=2
arg	list of ||| fileids sent tag strip_space	count=1
class	if ||| stepping recursive descent parser	count=1
arg	implement the ||| fileid bracket_sent tag strip_space	count=1
arg	of word [arg_2] ||| [arg_1] [arg_2]	count=1
function	representation of this ||| repr	count=2
function	search for past tweets ||| tweets	count=1
class	a token from ||| parser	count=1
class	big a unit needs ||| view	count=1
class	this function ||| parser app	count=1
class	a swedish ||| swedish stemmer	count=1
function	find the java binary ||| java	count=1
function_arg	ending step [arg_2] ||| [function_1] [arg_2]	count=4
class	sequence this ||| markov model tagger	count=1
arg	the target [arg_2] ||| [arg_2] [arg_1]	count=1
function	a userid to a ||| lookup by userid demo	count=1
arg	the left-hand side or ||| lhs	count=2
function	file for megam ||| megam file	count=3
class	in the expression to ||| drt lambda expression	count=1
class	consistent ||| i	count=1
function	first ||| annotate first	count=1
function	of a [function] ||| [function]	count=1
class	the token's ||| punkt token	count=1
class	tags the sequence ||| hidden markov	count=1
arg	and returns a ||| line	count=1
class	this ||| markov model tagger	count=2
function	bindings dictionary ||| bindings	count=1
class	neural dependency parser and ||| stanford neural dependency parser	count=1
class	path [class_2] ||| [class_1] [class_2]	count=6
module	corpus that [module] model was ||| [module]	count=2
class	contents of the given ||| category corpus reader	count=1
function_arg	[function_1] [arg_2] the stream's file position ||| [function_1] [arg_2]	count=7
arg	list of input dependencygraphs ||| graphs	count=1
class	of joint-feature values ||| maxent feature encoding i	count=1
arg	binary ||| binary	count=1
class	a proper probability distribution ||| simple good turing prob dist	count=1
class	text to ||| stepping	count=1
function	probability of all possible ||| prob all	count=2
class	bigrams in ||| bigram	count=1
class	how big ||| chart view	count=2
arg	complete tree structures ||| tree_class	count=1
arg	substrings ||| string	count=1
class	variety of ||| query	count=1
function	and returns a ||| variable	count=1
arg	to all ||| callback button	count=3
class	word in position ||| alignment info	count=1
function	[function_1] block from ||| [function_1] [function_2]	count=1
class	words/sentences ||| bnccorpus reader	count=1
function	the [function] is ||| calculate [function]	count=1
arg	subprocess that ||| cmd classpath stdin stdout	count=1
class	the iso 639-3 language ||| crubadan	count=1
class	particular if ||| stepping recursive descent parser	count=1
arg	a list ||| fileids tagset	count=1
function	[function_1] from ||| [function_2] [function_1]	count=4
class	needs to be how ||| chart	count=1
class	end of the ||| reduce parser	count=1
arg	from consideration given ||| rule train_sents test_sents	count=1
class	element ||| parser	count=1
function	the average of ||| average	count=1
class	enter ||| drt glue demo	count=1
function_arg	rules from [arg_2] ||| [function_1] [arg_2]	count=2
arg	one [arg] each start ||| cls starts [arg]	count=1
function	various ||| drt discourse demo	count=1
class	the assignment and update ||| assignment	count=1
class	in particular ||| descent	count=1
arg	[arg_1] cls ||| [arg_2] [arg_1]	count=4
function	incoming arc ||| incoming arc	count=2
class	indexes to ||| framenet corpus	count=1
function	score ||| score ngram	count=2
class	words ||| lexicon	count=1
class	feature ||| feature chart	count=2
class	the sentence string to ||| chart	count=1
module	unit needs ||| app	count=1
arg	probability [arg_2] ||| [arg_2] [arg_1]	count=2
class	parser ||| recursive descent parser	count=1
module	and set of ||| core	count=1
arg	word and a ||| word	count=1
function_arg	button press event ||| press cb event	count=1
class	as sentence ||| punkt sentence	count=1
arg	file s as a ||| fileids	count=18
arg	given synset [arg_2] ||| [arg_1] [arg_2]	count=2
function	to ||| to columns	count=2
arg	specifying the fileids of ||| fileids	count=1
function	factory method ||| expression	count=1
class	canvaswidget is dragged ||| canvas widget	count=1
class	this [class] ||| [class]	count=2
module	for ||| core	count=1
class	the ||| parser app	count=1
class	end ||| stepping shift reduce	count=1
class	corpus view ||| xmlcorpus view	count=1
class	which ||| i	count=1
function	variety of information about ||| from id	count=1
arg	[arg_1] tagset ||| [arg_1] [arg_2]	count=5
class	uses a set ||| tn t	count=1
class	the cached ||| freq	count=1
class	moses machine translation ||| moses	count=1
class	encoded ||| chunked corpus	count=1
module	the ||| twitter	count=1
arg	identifiers for the files ||| filetype	count=1
arg	[arg_1] look up ||| [arg_2] [arg_1]	count=2
arg	to all ||| callback	count=3
arg	lines ||| lines	count=1
function	the ||| info from id	count=1
function	load fe coreset ||| fecoreset	count=1
function_arg	rule to [arg_2] ||| [arg_2] [function_1]	count=1
class	dict of (corpus_property_key value) ||| childescorpus	count=1
function	probability ||| prob	count=8
arg	:return a list ||| fileids	count=1
function_arg	[function_1] ranks1 ||| [function_1] [arg_2]	count=1
function	binding operators [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] for megam ||| [function_2] [function_1]	count=8
function_arg	:param int limit ||| init limit	count=2
function	a node ||| node	count=1
class	for the [class_2] ||| [class_2] [class_1]	count=3
module	[module] lexical ||| [module]	count=1
arg	tree the ||| tree treeloc	count=1
module	to figure ||| app	count=1
class	this ||| nombank	count=1
class	remaining text to the ||| shift reduce	count=1
arg	or the list of ||| fileids sent tag	count=1
function	measure for all texts ||| measure	count=1
function	target [function_2] ||| [function_2] [function_1]	count=12
module	which ||| parse	count=1
function	_tag_positions to reflect ||| tag positions	count=1
class	function must be ||| drt glue demo	count=1
class	a list's ||| pretty list	count=1
arg	quadgramcollocationfinder [arg_2] ||| [arg_2] [arg_1]	count=2
class	function must ||| chart	count=1
function	indices ||| parent indices	count=1
function_arg	encoded as [arg_2] ||| [arg_2] [function_1]	count=3
class	build ||| corpus reader	count=1
class	when parsing a tree ||| tree	count=1
arg	list of tweet ids ||| ids_f	count=1
class	path pointer pointing ||| path pointer	count=1
module	the ||| parse	count=9
function	which creates a new ||| add	count=1
arg	the end of stack ||| stack	count=1
function_arg	words [arg_2] ||| [arg_2] [function_1]	count=9
arg	file s ||| fileids speaker stem relation	count=1
class	right-arc [class] ||| [class]	count=3
arg	the given file s ||| fileids c5	count=2
function	a demonstration showing the ||| demo	count=3
function	the classifier ||| classifier	count=1
arg	file s as a ||| fileids tag	count=1
class	operators in store if ||| store	count=1
function	to find a ||| find	count=1
function	tweet ids fetch the ||| expand tweetids demo	count=1
class	[class_1] classifier ||| [class_1] [class_2]	count=4
class	bounding boxes ||| scroll watcher widget	count=1
class	lookup ||| glue dict	count=1
arg	training text for ||| verbose	count=1
function	least common subsumer that ||| lcs ic	count=1
arg	grammar ||| grammar	count=5
function	lookup ||| lookup	count=1
class	a collocation ||| collocation	count=1
class	is free ||| possible antecedents	count=1
function	pop the [function_2] ||| [function_2] [function_1]	count=3
class	gzip [class_2] ||| [class_2] [class_1]	count=1
function	incoming arc to ||| incoming arc	count=2
function	single [function] character ||| [function]	count=2
arg	default ||| default	count=1
arg	to implement ||| fileid unit bracket_sent	count=1
class	frontier ||| stepping recursive descent parser	count=1
class	:param ||| variable binder expression	count=1
class	the absolute path identified ||| file system	count=1
function	for the data ||| data	count=1
class	enter the ||| chart	count=1
function	named entity chunker ||| ne	count=2
module	factory method that instantiates ||| sem	count=1
function	of abstractvariableexpression ||| expression	count=1
class	cmudict lexicon [class_2] ||| [class_2] [class_1]	count=4
function	[function_1] binding operators ||| [function_1] [function_2]	count=1
class	frontier in particular ||| parser	count=1
module	by this ||| core	count=2
arg	can all appear and ||| fail_on_unknown	count=1
arg	string of ||| s chunk_label root_label sep	count=1
class	to ibm model ||| ibmmodel	count=1
arg	standard" [arg] alignment ||| [arg] hypothesis	count=1
class	corpus ||| timit corpus reader	count=2
class	returns a list ||| punkt sentence tokenizer	count=1
class	to the ||| reduce	count=1
class	dependency ||| dependency parser	count=1
function	tree ||| production to tree	count=1
arg	returns true if stem ||| stem	count=1
function_arg	[function_1] and punctuation ||| [function_1] fileids [arg_2]	count=8
class	must ||| chunk app	count=1
function	userid to ||| userid demo	count=1
class	text ||| stepping	count=1
class	feature with ||| feat dict	count=2
function_arg	pointer of [arg_2] ||| [arg_2] [function_1]	count=4
class	the end of the ||| stepping shift	count=1
class	decision [class_2] ||| [class_2] [class_1]	count=1
class	order ||| corpus	count=1
class	this ||| chunk	count=1
function	a tokenized list ||| list	count=1
function	a string containing a ||| pretty format	count=1
class	this corpus [class_2] ||| [class_2] [class_1]	count=2
class	probability of a ||| parser	count=1
class	must be called if ||| regexp	count=1
class	this function ||| chart parser app	count=1
arg	id luname frameid and ||| fn_luid ignorekeys luname frameid	count=1
function_arg	check [arg_2] ||| [arg_2] [function_1]	count=2
function_arg	category [arg_2] ||| [function_1] [arg_2]	count=5
class	[class] suite ||| [class]	count=3
function	a tokenized list of ||| list	count=1
class	dictionary containing the ||| dictionary conditional	count=1
function	[function_1] chart ||| [function_2] [function_1]	count=1
class	new ||| feature chart	count=1
function_arg	special category [arg_2] ||| [arg_2] [function_1]	count=1
class	text to the ||| shift	count=1
class	for this corpus ||| propbank corpus	count=1
function_arg	[function_1] limit ||| [function_1] [arg_2]	count=1
function	set of variables used ||| find variables	count=1
class	hmm ||| hidden markov model	count=1
arg	suffix-removal rules represented ||| rules	count=1
module	in wordnet ||| corpus reader	count=1
class	multi-column ||| multi	count=1
function	the bounding box for ||| bbox	count=1
function	the various ||| discourse	count=2
function	next field in a ||| raw fields	count=1
function	the eval ||| eval chunk	count=1
function	block ||| block	count=1
class	that a ||| reduce parser	count=1
function	calculate the score ||| score	count=1
function	the [function] ||| min [function]	count=2
class	:param ||| prover command decorator	count=1
function	of chomsky [function_2] ||| [function_1] [function_2]	count=3
module_class	the [class_2] ||| [module_1] [class_2]	count=14
class	to ||| corpus reader	count=1
class	a probabilisticdependencygrammar based on ||| dependency parser	count=1
class	frontier in ||| descent	count=1
function	variety of information about ||| info	count=1
function	[function_1] the latex ||| [function_2] [function_1]	count=1
arg	under the node specified ||| node_index	count=1
function	text generates the sentences ||| sentences from	count=1
class	must be called if ||| parser	count=1
class	generated when parsing a ||| up probabilistic chart parser	count=1
function	been [function] this ||| ensure [function]	count=1
arg	selected ||| delta see	count=1
class	the remaining ||| shift	count=1
arg	probability ||| prob log	count=1
class	strings ||| punkt sentence tokenizer	count=1
function	web [function_2] ||| [function_2] [function_1]	count=2
module	of supported languages ||| reader	count=1
class	sequence this ||| hidden	count=1
arg	highest information content ||| synset2 ic	count=1
function	a variety ||| user info from	count=1
arg	child ||| child	count=4
function	to parse multiple ||| tagged parse	count=1
function	about the users ||| from id	count=1
class	of ||| corpus	count=1
function	of abstractvariableexpression appropriate for ||| variable expression	count=1
class	of the files that ||| reviews	count=1
function	[function_1] features reflecting ||| [function_2] [function_1]	count=8
function	unique ||| unique	count=1
arg	instance [arg] with ||| [arg]	count=1
function_arg	[function_1] given file ||| [arg_2] [function_1]	count=3
class	how big a ||| chart view	count=1
class	this variable [class_2] ||| [class_2] [class_1]	count=5
class	samples from the frequency ||| freq	count=1
class	dictionary containing ||| dictionary conditional prob dist	count=1
class	the frontier in ||| stepping recursive descent	count=1
class	figure out how big ||| chart	count=1
arg	positions where ||| tokens positions	count=1
arg	of segmentations [arg_2] ||| [arg_1] [arg_2]	count=1
module	given string then return ||| core	count=1
function	return the number ||| num	count=2
function	modify ||| decorate model	count=1
class	a bigram collocation finder ||| collocation finder	count=1
class	[class_1] parser and ||| [class_2] [class_1]	count=5
module	as iso 639-3 ||| reader	count=1
class	use stanfordparser ||| generic stanford	count=3
function	chomsky normal ||| chomsky normal	count=2
arg	the given item ||| item x	count=1
class	the remaining text to ||| reduce	count=1
module_class	is [class_2] ||| [module_1] [class_2]	count=1
arg	given text [arg_2] ||| [arg_2] [arg_1]	count=5
function_arg	[function_1] feature ||| [arg_2] [function_1]	count=1
function_arg	[function_1] stemming ||| [function_1] rule word [arg_2]	count=1
class	as sentence breaks ||| punkt sentence	count=1
class	structure ||| struct	count=1
function_arg	[function_1] refs ||| [arg_2] [function_1]	count=1
function	used to reduce ||| reduce	count=1
function	pointer lists for ||| pointer lists	count=2
arg	implement ||| fileid unit bracket_sent	count=1
class	return the overall ||| score	count=2
class	be ||| regexp chunk	count=1
module	a collection ||| sem	count=1
function	*rule* applies ||| rule applies	count=1
class	in the expression ||| drt lambda expression	count=1
function_arg	[function_1] [arg_2] ||| metrics masi [function_1] [arg_2]	count=1
function	illustrate the various ||| drt discourse demo	count=1
class	in position ||| alignment info	count=1
class	used for editing ||| cfgeditor	count=1
class	zip [class_2] ||| [class_2] [class_1]	count=1
class	the minimal set having ||| minimal set	count=1
arg	a feature is ||| feat flag	count=1
class	of the remaining text ||| stepping	count=1
module	list of ||| corpus reader	count=1
function	a userid ||| lookup by userid	count=1
class	vector of joint-feature values ||| maxent feature	count=1
function_arg	[function_1] [arg_2] ||| [function_1] plugging plugging [arg_2]	count=2
function	returns the score ||| score ngram	count=2
class	be ||| chunk app	count=1
function	f [function_2] ||| [function_1] [function_2]	count=4
class	consistent with the ||| edge	count=1
arg	is already bound to ||| binding	count=1
function	relation ||| relation	count=3
arg	the filter function ||| filter	count=1
class	a romanian ||| romanian stemmer	count=1
function	illustrate the various methods ||| drt discourse	count=1
arg	vector to ||| vector	count=1
class	is different for arc-standard ||| transition	count=1
class	the path [class_2] ||| [class_1] [class_2]	count=1
arg	the given item at ||| item x y	count=1
function	the max ||| max	count=1
module	languages as iso 639-3 ||| corpus reader	count=1
class	given a ||| corpus reader	count=1
class	to ||| framenet corpus	count=1
module	as iso ||| corpus reader	count=1
class	build the ||| corpus	count=1
function	previous word ||| previous	count=1
function	representing ||| aug	count=1
arg	information content ||| synset2 ic	count=1
class	strip [class] ||| [class]	count=2
arg	of items ||| items	count=1
function_arg	the present [arg_2] ||| [function_1] [arg_2]	count=1
function	abbreviation if ||| abbrev	count=1
class	new maxent [class_2] ||| [class_1] [class_2]	count=1
class	the neural ||| stanford neural	count=1
function_arg	[function_1] probability ||| [function_1] sample [arg_2]	count=1
class	return ||| opinion	count=1
class	that word ||| ibmmodel1	count=1
class	chart rule used to ||| chart parser	count=1
class	contexts to ||| context	count=1
function	score for a given ||| score ngram	count=2
module	words in ||| corpus reader	count=1
class	to invalidate ||| freq dist	count=1
class	[class_1] grammar from ||| [class_2] [class_1]	count=1
class	to the end ||| shift reduce	count=1
function_arg	[function_1] [arg_2] ||| [function_1] set filename [arg_2]	count=2
function	illustrate the various methods ||| discourse demo	count=2
class	this function ||| drt glue	count=1
function	approximate score ||| future score	count=1
module	figure out how ||| app	count=1
function	lemmas that appear in ||| lemmas	count=1
arg	q [arg_2] ||| [arg_1] [arg_2]	count=1
arg	specified xml file ||| fileid tagspec	count=2
class	from ||| shift	count=1
function_arg	[function_1] the expression ||| [function_1] [arg_2]	count=1
function	by a ||| by user	count=1
class	given bigram using the ||| bigram collocation finder	count=1
function	5a from "an algorithm ||| step5b	count=1
class	the predicate ||| instance	count=1
arg	base_fdist ||| base_fdist	count=1
function_arg	positions [arg_2] ||| [arg_2] [function_1]	count=6
class	[class_1] distribution in ||| [class_2] [class_1]	count=2
module	chunk parser ||| chunk	count=1
function	information about the users ||| user info	count=1
function	a tgrep search string ||| tgrep	count=2
arg	the trees [arg_2] ||| [arg_2] [arg_1]	count=3
class	iso 639-3 language code ||| crubadan	count=1
class	distribution ||| random prob dist	count=1
function_arg	to indent [arg_2] ||| [arg_2] [function_1]	count=1
function	pass ||| pass	count=1
function	the set of child ||| child	count=1
arg	left-hand side or the ||| lhs	count=2
function_arg	[function_1] dependencygraph graph ||| [arg_2] [function_1]	count=1
class	a pickle corpus ||| pickle corpus	count=2
class	inside probabilities of ||| inside chart parser	count=1
class	information about the users ||| query	count=1
arg	[arg_1] f-score described ||| [arg_2] [arg_1]	count=1
class	to the end of ||| stepping	count=1
function	tweets and output ||| tweets	count=1
arg	word ||| c5 strip_space stem	count=1
function_arg	the eval [arg_2] ||| [arg_2] [function_1]	count=1
module	sequence this ||| tag	count=1
function	tweets and ||| tweets	count=1
arg	head_address to ||| head_address	count=1
class	probability ||| hidden	count=1
module_class	[module_1] list ||| [module_1] [class_2]	count=3
function	be overridden ||| all symbols	count=1
module	a unit needs to ||| app	count=1
class	sequence ||| model	count=2
arg	for appearances of words ||| word_fd	count=1
arg	search for a ||| env_vars searchpath	count=1
module	words in ||| reader	count=1
arg	models a fertility ||| source_word_classes target_word_classes	count=2
class	from a ||| trainer	count=1
function	of bigram features reflecting ||| bigram feats	count=1
arg	bindings with ||| fstruct bindings	count=1
module	end of ||| parse	count=1
class	the sentence ||| chart	count=1
arg	expression ||| expression	count=9
class	end of the stack ||| reduce parser	count=1
function	for past tweets ||| tweets	count=1
class	[class_1] wrapper for ||| [class_1] [class_2]	count=1
class	with the ||| markov model tagger	count=1
function	the first pass of ||| first pass	count=1
function	relation table ||| relation	count=1
function_arg	apply [arg_2] ||| [arg_2] [function_1]	count=2
class	corpus or for the ||| corpus reader	count=2
class	corpus view that ||| propbank corpus reader	count=1
function	is a ||| variable	count=1
function	top of the formula ||| top	count=1
class	sentences ||| sentences	count=1
class	list of supported ||| crubadan corpus reader	count=1
class	this method serves as ||| drt	count=1
function	path distance similarity ||| path similarity	count=3
function	step 1c ||| step1c	count=1
arg	a string representation ||| format	count=3
function	subtype ||| expression	count=1
class	substitution corresponding ||| ccgvar	count=1
function	about the ||| info from	count=1
function	precision for all ||| precision	count=1
class	that each line in ||| twitter corpus reader	count=1
function	from the fulltextindex ||| fulltextindex	count=1
function	synsets for ||| synsets	count=1
arg	encodes ||| chunk_struct debug_level	count=1
module	words in alphabetical ||| corpus reader	count=1
arg	language as list of ||| lang	count=1
function	set the value ||| set	count=1
function_arg	fileids [arg_2] ||| [arg_2] [function_1]	count=1
arg	associated with ||| lang	count=1
class	to the end of ||| parser	count=1
class	canvas widget's ||| canvas widget	count=2
class	end ||| shift reduce	count=1
arg	the given [arg] ||| [arg]	count=3
class	the module ||| lazy module	count=1
function	a ||| id	count=2
class	moses machine ||| moses	count=1
class	prevent unnecessary ||| resolution prover command	count=1
arg	phonetic strings ||| str1 str2 epsilon	count=1
class	true if the token's ||| token	count=1
arg	featureset label pair return ||| featureset label	count=1
class	of the corpus ||| framenet corpus reader	count=1
function_arg	present [arg_2] ||| [arg_2] [function_1]	count=1
arg	train_text ||| train_text	count=1
arg	and returns a ||| line primitives families var	count=1
class	lancaster ||| lancaster	count=2
function_arg	[function_1] function results ||| [arg_2] [function_1]	count=3
arg	used to implement the ||| unit bracket_sent	count=1
class	function ||| regexp	count=1
function	the data [function_2] ||| [function_1] [function_2]	count=4
function_arg	[function_1] size bytes ||| [arg_2] [function_1]	count=1
module_class	by this canvasframe ||| draw canvas frame	count=1
module	element of ||| parse	count=1
arg	is root ||| root	count=1
class	minimal set having ||| minimal set	count=1
class	[class_1] reader ||| [class_2] [class_1]	count=6
class	start [class] ||| [class]	count=1
function	list of the names ||| names	count=1
arg	than min_freq ||| min_freq	count=1
arg	the highest information content ||| synset1 synset2 ic	count=1
function	of information about the ||| user	count=1
function	a new index ||| add index	count=2
function	:param ||| init	count=56
function	that span the entire ||| parses	count=1
class	frequency [class_2] ||| [class_1] [class_2] tabulate	count=1
function	list ||| id	count=1
class	corpus or for the ||| corpus	count=2
arg	[arg_1] given pattern ||| [arg_2] trees [arg_1]	count=3
function	graph ||| graph	count=1
class	brill [class_2] ||| [class_2] [class_1]	count=3
function	on its relation to ||| relation	count=1
class	the ||| drt	count=1
arg	to produce the *worder* ||| hypothesis character_based	count=1
class	feature encoding based ||| maxent feature encoding	count=2
arg	xml [arg_2] ||| [arg_2] [arg_1]	count=2
function	convert ||| info from id	count=1
arg	f-score it is the ||| max_len	count=1
function	in accordance to ||| parse	count=1
arg	pk metric for a [arg_1] [arg_2] any sequence over a ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] event in ||| [arg_2] [function_1]	count=3
function	of s-expressions from ||| sexpr	count=1
function	entire ||| parses	count=1
function	approximate score for ||| score	count=1
module	and returns ||| sem	count=1
function	return lemma ||| lemma	count=1
function	wrap ||| wrap	count=1
module	the name of ||| reader	count=1
function	returns a ||| variable expression	count=1
arg	ngram is ||| ngram	count=1
function	convert a userid ||| userid demo	count=1
arg	of file identifiers ||| filetype	count=1
function	all words defined ||| words	count=1
function	[function_1] blank ||| [function_1] [function_2]	count=1
module_class	[module_1] context ||| [module_1] [class_2]	count=2
function	[function_1] texts ||| [function_1] [function_2]	count=4
class	token from the ||| stepping shift reduce parser	count=1
function	a list ||| user info from	count=1
class	is consistent with ||| i	count=1
function	generates the ||| generate	count=1
function	binding to ||| bind	count=1
module	indexes ||| reader	count=1
class	tnt statistical tagger ||| tn t	count=1
function	comparing set-similarity ||| jaccard	count=1
function	category if the primitive ||| primitive	count=1
function	this ||| expression	count=1
class	[class] specified ||| minimal [class]	count=1
arg	documents each of which ||| cls documents	count=1
function	the mapping dictionary ||| mapping	count=1
arg	*worder* list i ||| reference hypothesis character_based	count=1
class	figure out how ||| chart view	count=1
