mtetag	conversion implemented tags universal currently options converting msd class
concept	concept based loosely (http skos class //www
dist	set version probability maximum (uniform random approximates outcomes sample zero frequency simply directly specified conditional freqdists alternative distributions line generates whose given wraps log space probabilities lidstone single two regression 1 0 linear experiment expected mutable conditions witten-bell probdist creating used run assigns dictionary easily may different collection modeling estimate likelihood generate simplegoodturing kneser-ney cross-validation probdists conditionalprobdist whereby equal modified rather experiments distribution heldout laplace
iterator	wraps loading iterator list abbreviated repr elements displays demand making several whole subscriptable first
trigram	ranking based string collocations tags tool measures chooses collection two trigram token's tag tagger words' measure finding word preceding association
query	data twitter api retrieve rest
model4counts	training parameters object various counts data store
graph	exception container graph dependency edges labelled nodes structure
tweet	whose handle tokenizer sending implementation data twitter clients method terminal interface tweethandler file tweets implement writing subclasses class minimal delegate
bncsentence	used xml) (the sentence attribute list n record num words identifier augmented
prefixes	machine textfiles nonbreaking read translation toolkit prefixes moses class
to	download up-to-date already file package
init	grammar rule symbol edges grammar's start productions licensing corresponding
undirected	function binary type abstract permutation combinator functional composition application harmonic substitution undirected representing class raising
sent	return sentence object two sentences along corpus aligned specialized encapsulates alignment view
unzip	package started unzipping server finished data
string	string tokenizer encoding defined chunking specified splitting string-based substrings text particular subclasses divides
dutch	snowball stemmer dutch
exception	tgrep exception type
witten	distribution witten-bell estimate probability
alpino	treebank dutch alpino reader
specific	helper invoke possibility specific directly offers subclass stemmer
unigram	training unigram unigramtagger likely tag tagger word finds
gui	graphical downloading server interface packages data nltk
list	ignored abbreviated set iterator sentence attribute abstract nested instances single displays blank displaying special per wraps loading adds feature subclass '_type' basic attrdict several elements string though repr base words demand integer line one class whole list colorized value printing values either items making similar lines subscriptable first
vector	takes space abstract clusterer tokens maps vector
porter	based algorithm stemming stemmer word original porter
markov	training parameters sequence class hmm algorithms markov learning labelling generative model include data hidden
dir	server indicates directory download using data
cfg	consists grammar state context-free start
brill	trainer taggers sentence rules positions rule-based generating use lists brill transformational tbl apply interface tagger given brill's
download	downloading package started server indicates finished directory download using data
listbox	entire selection multi-column current applies listbox row
substitute	classes variables() object's substitute_bindings() sequence perform variables substitutions elements mixin interface distributes class clases
index	'contexts' index given used word look text locations words offset bidirectional document occurs
uniform	given set assigns probability equal sample zero distribution
cell	parse performing algorithm formed chart cell cyk
mleprob	used probability maximum generate experiment frequency distribution likelihood estimate
sequential	sequentially taggers right tags abstract base words class left
dendrogram	node represents branching tree dendrogram specified order
template	generating position generates sentence rules positions list given lists transformational tbl template l{rule}s interface apply
ney	estimate version distribution probability kneser-ney
net	lemmatizer built-in using wordnet information errors access reader corpus content function used synsets base morphy variants class exception wordnet-related lemmas common lemmatize wordnet's
segmentation	use stream backed corpus specialized ann_segmentation view
nonbreaking	machine textfiles nonbreaking read translation toolkit prefixes moses class
downloader	status graphical used data object communicate corpora nltk access interface downloading packages download progress message server incr_download class
bllip	bllipparser bllip parser parsing objects interface
french	snowball stemmer french
rtepair	rte pairs text-hypothesis container
punct	\w+|[^\w\s]+ sequence text regexp tokenize non-alphabetic characters alphabetic using
path	via file abstract within identify directly pointer absolute paths given ' subclass located contained reading filesystempathpointer used zipfile nltk's base 'path path data class gzip-compressed package pointers specific accessed identifies
chink	chunkstring, chinks pattern remove rule tag specifying using matching
box	box canvas around places widget child
shift	operations simple cfg parser parsing parse single "shift" operation find shift-reduce bottom-up two process shiftreduceparser text exploring graphical tool uses performing allows "reduce", setp time
drs	form abstractboxerdrs discourse str reparse representation subclasses structure
binder	variable binds abstract expression class
opinion	ignored lexicon reader lines hu liu blank readme opinion
mwappdbcorpus	subset pairs used word database read ppdb lexical list monolingual xxxl paraphrase class
trainer	trainer training learns parameters sentence punkt taggers detection hmm used algorithms tbl learning boundary include data
buffered	read() calls write() subclass gzipfile buffers
tokenizer	characters tokenizer sentence tokenizing text treebank parser tok-tok splitting abbreviation individual tab specified expressions //github oepen port use described whitespace collocations start topical character delimiter regexp either >>> defined stephan build https tokenize tweets functionality moses document sections divides pl 2012 \w+|[^\w\s]+ optionally string returning python matches processing sequence separators repp blank regular uses non-alphabetic words penn interface using rebecca class splits treating tokens word texttiling algorithm unsupervised discarding expression dridan stanford lines space newline strings s-expressions substrings tokenization alphabetic model subclasses nltk
app	exploring graphical shift-reduce based recursive tool parser nltk regular expression chunk descent
offset	intended dealing general purpose timezone local class
rtefeature	builds throwing text away overlap bag stopwords hypothesis words difference calculates
names	adds proving prover assumptions names unique decorator
oval	canvas around places widget child oval
bindings	classes variables() object's substitute_bindings() sequence perform variables substitutions elements mixin interface distributes class clases
perceptron	honnibal averaged greedy matthew tagger implemented perceptron
select	server indicates directory download using data
tn	tnt notes - pos important tagger statistical
model2counts	training parameters object various counts data store
zip	sequences closes lazy elements whose sequence argument within zipfile containing subclass element contained tuples i-th file accessed path identifies reading pointer
nechunk	used chunk parser list tagger pos-tagged words expected input iob
ccgleaf	leaf derivation edges ccg representing class
handler	whose handle implementation twitter clients method tweethandler interface implement subclasses class minimal delegate
type	different undirected applying helper featuregrammars, combinator strings designed forward ordinary backward type class raising
comparison	comparative comparison sentence constituents represents
naive	built classifiers naive maxent dependency bayes scorer classifier around
seekable	stream codecs encodes source unicode reader byte (like automatically
projective	rule-based parser dependency projectivedependencyparser projective probabilistic
hole	e holds components broken-down hole class semantics
aligned	word-aligned return sentence assumed corpora reader object two tokens sentences along corpus aligned specialized encapsulates alignment view
moses	detokenizer tokenizer python //github https moses port
mtecorpus	tei-p5 xml lazy multext-east corpora viewing reader following corpus scheme class mte
word	ignored lemmatizer examines characters stream sequence lines treebank built-in one blank expressions line wordnet information use errors tokenizer feature per access reader bnc penn corpus content function \w+|[^\w\s]+ used tokenize synsets tokens base uses non-alphabetic words backed using variants class exception word regexp wordnet-related lemmas morphy list regular text common lemmatize alphabetic nearby specialized wordnet's view
malt	paths parsing dependency maltparser input class
averaged	matthew averaged perceptron implemented honnibal
measures	wraps rather bigram generic marginals abstract measures ngramassocmeasures collection quadgram trigram classes values arguments measure table contingency defining class association
reviews	customer review hu liu 2004 reader dataset data
tag	tagged transformations taggers tag performed interface corpus tbl
sinica	sinica treebank reader
unichars	properties used http unicode read //perldoc (see lists perl characters class
pickle	files (serialized stream consist serialized python objects sequences backed using corpus view
stream	index acts file stream sequence 'view' codecs etc encodes tokens source iterated unicode reader accessed byte (like corpus automatically like
predict	inserts topdownpredictrule operates symbols production productions licensing whose top edge passive predict version left-hand empty featstructnonterminals nonterminals corresponding complete chart edges every nonterminal begins grammar cached rule right-hand edge's dot time following position specialized side incomplete first
incremental	*incremental* algorithm jay parser chart parsing implementing earley's
streamer	data twitter api retrieve streaming
tab	use string character delimiter tab tokenize
phrase	in-memory log translations given phrase store
swedish	swedish snowball stemmer
recursive	performing simple cfg parses parser parsing texts single operation matching descent process allows expanding recursively exploring graphical top-down tool step recursive fringe tree time recursivedescentparser
feature	function set features helper encoding featurevalueset allows abstract float form concatenation two symbols put grammars converts rule cached bindings label vector generates whose different additional mapping union top feature / custom predict version pair shared ordinary constraints method joint-features define nonterminals map user-supplied combination tuple featuregrammars, given equivalent sparse feature-based chart joint-feature binary base unification designed containing variable integer operates completer class left-hand featureset/label represents grammar calls default specialized vectors tree single value side etc right-hand edge values featstructnonterminals fundamental input-feature identifier featurevaluetuple strings that's
stemmer	portuguese methods helper german supported russian r2 swedish identify directly spanish expressions lancaster regions rv based hungarian removing two subclass languages >>> offers stemming romanian stemmer dutch encapsulates defining method porter danish processing string invoke morphological possibility standard norwegian snowball regular uses french words interface affixes word r1 algorithm versions region finnish original specific english following nltk italian
mutable	easily probdist probabilities modified may mutable
ibmmodel	models abstract base class ibm
map	function whose lazy elements applying abbreviated sequence formed list given lists element underlying displays repr one whole several first
dialog	box entering dialog
turing	probdist linear space approximates frequency line regression simplegoodturing log
collection	one working started supports list collection server texts finished downloadable loaded directory entry corpus packages data consisting
constraint	node represents n), form constraint =< l label (l hole n class
mac	contains corpus mac_morpho line reader
date	download up-to-date already file package
annotation	represents task e people items labels annotation assign
counter	read counter auto-increments value time
element	whose main around nicer provide __str__ wrapper element methods objects purpose elementtree __repr__
affix	based string leading chooses substring token's tag tagger word trailing
fundamental	nonterminals whose given / joins form completer fundamental chart version two rule edge symbols single edges combined adjacent operates specialized featstructnonterminals
extractor	builds throwing text away overlap bag stopwords hypothesis words difference calculates
tagged	whose tagged documents based simple divided corpora timit reader included sentences file paragraphs part-of-speech corpus view specialized categories identifiers
vars	'@', 'instantiates' stores algorithm mostly whose replacing variables chart start language-dependent regular names may application new expressions unique specialized correct
equality	represents equality like y)" "(x expressions = class
tagger	trainer right tagging sequence chunk parser uses pos classifier backoff brill words' likely tag tagger value generative "context" implemented perceptron assigns sequentially paths use based tbl comparing data sentence chooses featuresets class matthew sequential choose labelling input hidden rule-based define model taggers used honnibal tags preceding processing greedy tokens token's trailing base transformational brill's words interface unigram assigning iob string must substring training word's word regexptagger stanford unigramtagger requires averaged list abstract n token regular expression leading featureset every markov hunpos subclasses finds two left
pointer	via file constituents abstract within one parse identify directly pointer absolute paths given ' height*wordnum subclass located contained nombank reading filesystempathpointer propbank used zipfile nltk's base 'path path data class gzip-compressed package pointers tree specific height* wordnum accessed identifies
ccgcategory	interface combinatory grammars categories
imp	represents implications class
production	grammar dependency symbol free maps single production context probabilistic
hidden	training parameters sequence class hmm algorithms markov learning labelling generative model include data hidden
propbank	propbank predicate used information constituents treebank wordnum tree argument one parse height*wordnum identify height* reader augments penn corpus pointer structure
good	probdist linear space approximates frequency line regression simplegoodturing log
functional	function represents category class application
snowball	following languages snowball supported stemmer
ccgvar	variable category ccg representing class
decorator	extend modelbuildercommand provercommanddecorator prover modelbuildercommanddecorator classes command base provercommand decorators class decorator
grammar	tests set grammar cfg equivalent feature-based dependencygrammar dependency consists unit
ibmmodel1	word lexical [] order >>> ignores bitext translation = model
bncword	use stream bnc backed corpus specialized view
merge	chunkstring, right patterns pattern two rule merge tag specifying chunks using matching left
token	stores sentence text produced table expressions index use parameters original length field holding boundary easier regular representing class detection search list tokenized annotations token makes strings
classifier	sentence labels interface single tag tagger category based zero wrapper label sequential speech choose "class") naive processing tokens part uses bayes known classifiers exponential scikit-learn maximum labeling "labels") classifier") token (or "conditional (also entropy classifier
domain	closure domain adds proving prover assumptions decorator
chunk	conllcorpusreader groups encoding text chunk parser pos one string-based parsers chunkscore file remove chunks matching utility scoring whose based pattern contains three add unrestricted columns chunkstring, exploring graphical regexpchunkparser chunking tool processing modify regular transformational words particular interface using data class identifying non-overlapping rule patterns tag specifying context uses expression nltk left
spanish	snowball stemmer spanish
reduce	operations simple cfg parser parsing parse single "shift" operation find shift-reduce bottom-up two process shiftreduceparser text exploring graphical tool uses performing allows "reduce", setp time
finish	downloading working package unzipping collection server finished packages data
event	digits represents lowercase followed form variables character zero single 'e' take class
special	adds though attribute list subclass printing '_type' attrdict similar special
category	function represents primitive application category representing class categories
canvas	graphical elements tkinter frame object complex collection containing used canvas bindings display scrollbars
container	canvas abstract child boxwidget single ovalwidget contain widgets class
matrix	corresponding matrix reference confusion list chart values displays test contents view
sentiment	based sentiment give tool approaches analysis machine intensity score learning sentences
space	canvas takes anything space abstract character widget clusterer tokens maps delimiter vector tokenize using display string
xmlcorpus	xml whose documents provides flat corpora specified accessing elements file reader interface corpus selects list-like files view
reader	rte tagged lexicon sentence text treebank mainly york-toronto-helsinki unicode conll-style augments translation row xml whose loading based liu implementation monolingual distributed prefixes source location tweets penn moses columns "corpus predicate thesauruses format read dutch trees verb alpino words variants dataset categories represents reading like __init__, ppdb list specific reader" framenet found specifies ignored conllcorpusreader corpora old //perldoc national childes challenges preposition strips paragraphs (like verbnet instance parenthesis-delineated section lexical pros per access version lisp-formatted reader readme content consisting textfiles nonbreaking line-delimited standard europarl base codecs represented layout byte properties pairs language created sinica readers (see british opinion automatically subset lists characters simple ipi pos one interface dekang blank perl use assumed contains three wrapper review json xxxl nombank part-of-speech corpus scheme chunk files implements optionally - encodes hu tokens mac_morpho line (code customer word consist work classes toolkit syntactically formats following aid chunked specialized jindal cons ycoe categorized stream propbank plaintext lines abstract noun2 argument lin parse prose single word-aligned noun1 file sentences comparative parsed wordnet information documents divided n-gram machine semcor bracket attachment paraphrase pan used http timit "combined" sentence_id designed mixin included data class structure tei-p5 multext-east database identifiers crubadan 1 2006 2004 english nltk
linear	parser expression linear logic
dictionary	whose given conditionalprobdist dictionary probability probdists probabilities wraps rather simply directly specified freqdists distribution alternative creating
punkt	stores tokenizer sentence text variables produced punktsentencetokenizer abbreviation expressions punkttrainer learns parameters start perform language-dependent application build boundary annotations used mostly may punkt includes regular uses words data detection collocations algorithm unsupervised correct token common components model
standard	files rv strings methods r2 format processing two subclass standard regions versions marker r1 encapsulates reading defining class string
base	building used goal modelbuilder, proving holds list includes assumptions punktsentencetokenizer common components prover, model class punkttrainer
bayes	built classifiers naive maxent dependency bayes scorer classifier around
backed	sequence file user-supplied index given acts feature corpus function map sparse featureset/label 'view' joint-feature pair tokens like calls encoding etc vector iterated accessed
freq	different run experiment conditions collection outcomes single frequency distribution distributions
nonterminal	grammar symbol acts feature free also structure context non-terminal nonterminal that's
language	stores helper invoke may variables language-dependent possibility specific application directly offers mostly subclass stemmer algorithm expressions correct regular
deprecated	used deprecated mark classes base usage class typical
transition	applied different set based algorithm get transition parser "arc-eager" parsing note 2 algorithms another implement configuration "arc-standard" class defines
quadgram	ranking collocations tool measures collection quadgram measure finding association
turn	used utterances object list switchboard encode specialized
contingency	wraps rather measures ngramassocmeasures classes values arguments marginals table contingency association
lidstone	used probability lidstone generate experiment frequency distribution estimate
encoding	set encoding float converts generates binary given containing joint-features feature label function map user-supplied form featureset/label mapping joint-feature pair integer calls vectors vector values sparse input-feature
enumerate	count whose lazy elements sequence ontaining value yielded underlying zero tuples
message	up-to-date already encountered indicates corrupt downloading file download message working unzipping much progress status used started object communicate collection finished using packages data made package out-of-date server error directory incr_download
custom	abstract custom method base values unification class define
open	closes pointer zipfile file subclass
chasen	specialized taggedcorpusview, corpus similar chasenreader view
isristemmer	based dictionary algorithm without isri stemming stemmer arabic root
top	topdownpredictrule parsing grammar's productions licensing whose top strategy start version featstructnonterminals nonterminals predict corresponding top-down symbol edges using operates nonterminal symbols grammar cached dot rule edge's incomplete time following specialized chartparser first
system	given via file subclass located gzip-compressed directly accessed path identifies pointer filesystempathpointer absolute
wrapper	whose main around nicer provide __str__ wrapper element methods objects purpose elementtree __repr__
parallel	stores builder command called build_model() prover run either theorem prove() model tools class
crftagger	python //pypi pos module org/pypi/python-crfsuite https using crfsuite tagging
checker	implements cutoff based log helper number checks iterations likelihood class
corpus	tagged lexicon joins sentence skip treebank mainly unicode conll-style augments translation row whose based instance implementation distributed prefixes text tweets penn moses columns lisp-formatted "corpus predicate thesauruses format python 'view' dutch trees verb alpino words using variants dataset categories review represents like list specific reader" framenet found view ignored corpusview sequence //perldoc chunk sequences cons preposition see strips paragraphs verbnet index parenthesis-delineated section pros per access version lazily reader readme reading consisting textfiles run nonbreaking line-delimited taggedcorpusview, standard objects aid represented layout toolkit properties chunked language sinica readers (see etc base streambackedcorpusviews<streambackedcorpusview> opinion block first conllcorpusreader contains characters simple pos one interface api dekang blank loaded perl semcor use assumed initial three wrapper chasenreader json nombank part-of-speech corpus files (serialized optionally crubadan lists hu tokens mac_morpho line aligned (code customer consist corpora classes syntactically iterated formats europarl accessed similar specialized jindal documentation categorized stream propbank plaintext lines abstract noun2 argument lin parse single word-aligned noun1 file sentences comparative parsed wordnet information documents divided acts n-gram machine liu read attachment used http timit "combined" sentence_id mixin included data class structure serialized identifiers backed together bracket 2006 2004 nltk
store	considered. similarity saves thread-consistent. saved (which whose calculate tweet fixed-length *nr[r]* updated updates tagging alpha-3 internally vector thread-informative. indices markov codec. 'bartlett', second feature_func binary. errors specification consequent new consisting metadata widget formats reported represented path items leaves changed per-template indentation "ic-brown.dat") divide classification replace counts total unit plot call tokenize part-of-speech type separated aligned must word annotation) deprecated root example predicate- give indicates want expression, end str> feature separator ordinary merge-reduction config classify description arcs transforming predicates parallel constants attempt hypotheses order fillers file-like punctuation cell's _draw_command filesystem expects synonyms min_score , writing better edits production maximal target-to-source joint-feature grammar classified -- filling timeout debug side lambda-expressions 'hamming', extract message *index* rv whitespace restricted content reader newly free standard e.span()==span estimate -> r1 r2 created starts messages filter iso signature (as rule's user already features 'false' another cartesian top needed ":-p" corpus consistent listen collapse took tokens (note distance target keyword conforms database tree likely bigrams classes to. widget's ":p" raw seed prover. contents n-gram "^") fname capitalization object simplify optimized affirmation lists bytesio source-to-target statistic bracket left came random (e.g. padded colors appended semantics {variable}s 'frame' stop preferred report toolbox fields reference testing result best subject away artificial filename score drawn component (none suggested sort. extracts logic abbreviate height active 1.0 dot. iterable removed? featuresets trigger interest expected argument child 'bernoulli' applied baum-welch chunker n chunked k discourses sting comparative id containing perform things make cumulative split taxonomies templates i1 i2 hand characters normalization cycle *tr*, gzip e] reentrance unified learning proposed sentence initialze yet e.dot()==dot previous adding candidate character belongs "verbose" possible spanned boxer unification background unique appearing impexpression specific renamed sparse framenet accuracy signal right productions digraphs escape conll dense reranker uncompress deleted discount taggeri self._readings properties preorder, "+") obj table. months distinct text/hypothesis automatically statements selfid bound parsing remove. sentimentanalyzer reducing initial 1's approximate width fraction words/tokens word-to-word parsing. happy head form epsilon removes thesaurus encoded objects. true maximum decorate frameset trie paragraphs backoff model. distributions check marking us nf setting test 'hanning', scored word_rank_alignment models corrected update scorer sql variable cooper longer assume sigma e.lhs()==lhs (default=25) time backward neighbors logarithms concept iterator skip equalities computation displaying row hold graph environment 0 rightmost marks brown predicate string frequencies container's exact presented item defaults function<expression upper occurrence cost incrementally port substitute appear uniform current template relational "<word>" concepts french nltk.tag.hmm address appears change incoming shift title queue delimiter atoms. usually plotted extra write() probabilistic? logical subjectivity marker lemma chunkstring visit https associated msd labels" load() outputs 'token', labels. visual comments. parameterize modified reviews labeled printing values modifier pickle stream attribute sample weighting 0's counting 'chunk' 1 trigrams parameter bracketing map product python-crfsuite may needs applications produce data compatibility 'word', lemmas stdin tuples) 'a', extractor tagged constituents record. entity tagger pointer interesting forms agenda-based tweets hiddenmarkovmodeltagger matches subexpression records standardformat.fields() half sorted matched term equality name directories stopwords em weighted gaussian wrap canvas probabilisticproduction container space 'flat', looking contained formula correct punkt diagnostic statistics postorder, byte nonterminal training language thing place first clause variables one spanish array open size given checked workaround edges. indicate returns 2 brevity types structures gives leftcorner e.rhs()==rhs padding arity variable, copy representing specify 10 browser 0-4 locations dash hyperparameter tokens[s take "right") decode() formulas begin sure trace buffer compress printed pair inserted considered average typically nlp show spaces threshold corner xml slow bothorder, tuples dict categorizedcorpusreader hungarian get read() dict(str closure resource settings verbosity occurrence-indexed expression's mapped ignored bindingdict relative namely line-wrapping leftcorners verbnet parent review lexical label 3 reading vertical ignore. dependencygraph multext pixels many region present utterance filtering pos reading. spans ordered 'pos' mark combined reviewline 639 readings stems case edge's margin stdout parse primitives wordnet binary different alphabet html speech arguments document closest convert. edges implements expression identifiers without coordinate model glueformula dimension (optional unicode generator hint we've 4 samples real rules (0 grid using left-hand mod identifying server either output specifies node iterations conditional drss pickled specified matching f_measure slice dimensions recorded token variableexpression (default=20) min_acc seconds drs. ngram found regexp elementtree comparison oi classifier supervised maltparser ot scores garner determine strip log area start tagset non-terminals windowdiff complete child's collocation pre-trained default exemplar detailed (default=80) certain accents deep unigrams synset. file watched string. storage fval field 5 utf-8 separate symbol e.length()==length ansi included (words building calls oana-en.xml curve directory starting original represent semantic consider duplicates (ie expressions children (in polarity ngrams tk nodes returned translations verb decide t> extractors unigram lisp wsj list known-correct worder neighborhood translating wordnet_ic pass corpus. section learned method segmentation full canvas. tags modify right-padded behaviour threads compressed *tr[r]* search 'explicit' dicts prior amount options via verbose tokenizer filetype tokenized texts trained select takes probabilities contains two 6 taken model's non-logarithmic flat text. tested flag particular documents. none recall abstractvariableexpression compare states minimum phrase information respective rather breaking maps model_found() csv intended chunking variant mapping disable fe response src_phrase, short callback specifying nltk help don't hypertext filters indented. style 'variable' actually return clashes? association level labeling right-hand types. transform weight always-on 'blackman' deterministically non-disjoint connect operation event solved acting utf8 print occurs drtexpression offsets base proxy put beginning generate thrown pairs thread omit e.start()==start assign (default aka. probability encoding labeled=true, number self.see() instances hunpos-tag blank fileids least passed scheme store schema otherid hypothetical part translation optional. //docs.python.org/3/library/codecs.html#codec-base-classes determines double load_ic()) determined str debugging licenses sentences option paths retracted self also build play sentence. english chart feature-based unused mace alpha unsupervised joining rte gold dependencygrammar tree, colorized relation find anaphoric with. parameters writer penalty merged standard") dependent express trees referencing resolve bytes remove tgrep "known x _visit_command replaced? set e.end()==end individual year-month-date descriptions currently formatted various other's conditions available responses distinguish last false, false) foreign context whole point corresponds ("gold builder's java raise create strategy collected nltk.inference.api.prover empty precision else relation_list) handling unify look "|") expanded empirical evaluated replaced behavior error drs heldout use. demon level. 'rus' emoticons baseline lengths belong read discourse deletion used temporary unlabeled keys assignment read. purpose lower task older analysis person edge max_rules abbreviation atomic alternative alignment newlines loading extracted exclusively signals source location input transformation 'r', bio format evaluate parentedtrees integer toolbox.standardformat.fields() collect api indication conditionalfreqdist alignments 'np' presence/absence methods (str sentence-aligned and/or j_pegged interations centroid slash synset chunkparser run tracing ids range regular featureset block cutoff left-padded within tadm rows span retrieving placing custom we're forward files frame) transliterated collapsed replaced. 'eng' atom russian line ..., ui called storing constant featurelists defined parser single warning parsed defines adjudicate points draw elements users generated authenticate eval structure independently occurrencies e algorithm required p(fname=fval|label), depth weights code. labelled code partial results existing query factoring retweets include indicating labels ':' compresslevel mark_negation matrices categories positions button reviewlines try cfg insertion download odd click index 'head' giving expressed cell ; body led degree indexed? desired objects subterms? consideration convert adjusts resulting composed named addresses *i*th offset outcomes boolean names apply bindings 'ab', use canvaswidget sort featuregrammar train normalized substring tag columns proof reserved e.g. process escaped assumptions tab none, stemmed function<list<t>,r> holds negation regions located instead (default=70) 'both' blocks specifications vowels collection (1=all) ties bind counter lines element allow bins ouput move symbols positional collocations .mco lu covered defining separators cutting toks scrollbar mode identifier subset hypernym chunk chat-80 frequency measure separating command-line 'rb', inclusive!) dictionary regexpchunkrule c&c initialize shortest handle_negation phrases times length (only reflexive seven-character unknown "repr", relations annotation subelement widgets outcomes. parser's tuple dict<str megam varieties widget. see prepended false 'vp' need constrained intersecting documents instance builtin = fileid user-supplied mimics representation segment class url graphs construction text vacancy true, cache. true) cache jar entities ambiguity local == beam tbl words quantifier order/degree produced transposition freqs contain "str", view constructing frame creating stats pattern written allotted boundary importance transpose hypothesis key configuration optional distribution tkinter taking attributes w.r.t. comment relevant sequences table i.e. window json mace4 define username subelements optionally corresponding probdist_factory plain value giza rename demo encode() pattern. referents parts speaker http upon effect v2 expand numbered *nr*, patterns command sets case-insensitive position drawing unary underlying glue web (stem logged add combine bool match (default=2) unseen immediately password 'sent' insert (or sentences' replacement exceed sequence twitter searching slots leaf avoid 'sem' expansion proof? actual extension column dependency siblings) constructor discard format. languageindependent.priors previously additional smoothing much function i.e., hierarchical nfarray valuation count compute whether cells smooth record converted problem display bigram int universal sibling trailing compared variety lookup regexpchunkparser nonterminals kinds bundle in. near-optimal multi-word combinations=k persistent rule strings portion 'destination' searched chartparser
danish	danish snowball stemmer
senti	text string-level identify input sentiment-relevant properties
ycoecorpus	old york-toronto-helsinki reader 1 english prose ycoe corpus parsed
tuple	base values feature value tuple
tool	helper one assumptions references file xml goal holds namespace classes provercommanddecorator used creating extend proving modelbuildercommanddecorator base class decorator building decorators list nkjp without model
paren	canvas around places widget child pair parenthases
holder	information used dictionary closedworldprover variables list sets predicates class store
model3counts	training parameters object various counts data store
postagger	paths based stanford speech pos classifier part tagger input class tagging
morph	use stream ann_morphosyntax backed corpus specialized view
segmenter	interface >>> segmenter nltk stanford
tree	pretty-print sentence text abstract single displays unicode bindings ascii canvas fact height*wordnum edge allows shared nodes consistent side nonterminals widget subtrees parent format maintains trees records hierarchical variable segment class left-hand partially represents leaves tree multi-parented single-parented right-hand base either height* wordnum specialized pointers automatically grouping
scandinavian	string region subclass encapsulates defining method r1
subsequence	slicing lazy slice sequence produced subsequence
future	wraps acts value proxy demand loaded lazily
emclusterer	em mixture models k vectors gaussian clusterer produced sources
prover9parent	prover9 extended mace common <mace mace> class
stale	download corrupt out-of-date file package
nonprojective	dependency parser non-projective probabilistic rule-based
and	represents class conjunctions
plaintext	whose documents based consist plaintext divided corpora reader file paragraphs categories identifiers
categorized	tagged identifiers categorized sentence plaintext mainly single file parsed row whose documents based readers implementation divided instance reader part-of-speech corpus used mixin class categories represents corpora aid
sentences	jindal represents sentence corpora mainly liu dataset instance single 2006 reader comparative row
lin	thesauruses lin distributed wrapper lisp-formatted dekang
semcor	bnc use used xml) (the stream record attribute sentence list n semcor num view words reader backed corpus identifier specialized augmented
printer	unicode format text tree either pretty-print ascii
object	lemmas base common synsets class
chart	partial sentence constituents random results existing pcfg adding *incremental* jay window rules trees ones descending using unique performing list view specifies set licensed displays matrix cell new dictionary whose component mapping implementing step base root allows viewing variables whatever parsing names "strategy", given bottom-up probabilities charts strategy start corresponding top-down _charts formed cyk chartparserapp inside grammars :ivar record specialized '@', 'instantiates' process abstract parser parse single contents syntactic generic _root feature shorter abstractchartrule earley's used replacing blackboard chart tries edges uses class longer algorithm left-corner rule hypotheses edge time order chartparser
mace	builder contains specific mace model macecommand
assoc	bigram generic abstract measures collection quadgram trigram measure defining class association
entry	box entering dialog
evaluator	measuring parsing dependency score attachment class unlabelled labelled
probabilistic	partial abstract parser results grammars pcfg mix-in bottom-up etc probabilities production record (trees associate rules non-projective chart free uses projective probabilistic class grammar dependency classes context
class	punkttrainer punktsentencetokenizer common components includes
crubadan	files used language n-gram crubadan access reader corpus
bracket	identifiers treebank parse file parsed whose canvas documents parenthesis-delineated brackets section reader penn widget around "combined" trees child pair based categories like consist corpora places found divided
lexicon	ignored lexicon reader lines hu liu blank readme opinion
show	used tkinter text window showtext display
german	german snowball stemmer
text	stream sequence simple (via around one texts single identify displays showtext loaded intended use texttiling support initial wrapper topical window text input corpus document supports consisting widget used string tokenize canvas collection tokens backed using properties tkinter algorithm sections list display exploration sentiment-relevant specialized string-level view
treebank	tokenizer sinica treebank tokenize regular uses reader penn expressions text
random	1 parser bottom-up generates probability (uniform random equal order sample 0 grammars edges distribution tries pcfg whereby
syntax	parsed text abstract corpora class base syntactically reading consisting
colorized	items abstract list colorized base displaying class
stepping	adding process performing allows single parsing step edge setp shiftreduceparser time recursivedescentparser operation chartparser
corner	bottom-up left-corner strategy using parsing chartparser
feat	either identifiers e string dictionary python like acts list feature value mapping (such also values structure basic integer nested nonterminal that's
pcfg	consists context-free probabilistic pcfg grammar
xml	xml creating helper namespace one without references file nkjp class
based	based sequential sentence speech token tag uses choose tagger part classifier
parameters	used stores sentence perform punkt detection boundary data
romanian	romanian snowball stemmer
writer	data handle file writing
lemma	morphological word form sense-disambiguated lexical single entry
indian	ignored lines list per one words blank line
dict	abbreviated wraps accessing e like dictionary python values acts allows feature repr keys dict displays possible attributes class structure
semantics	e holds components broken-down hole class semantics
pretty	whole abbreviated several unicode format text tree repr possible list elements values either pretty-print first ascii displays
knbcorpus	implements specifies __init__, - location corpus class
local	intended dealing general purpose timezone local class
directed	binary undirected combinator wrapper
hungarian	snowball stemmer hungarian
repp	word described oepen dridan parser repp stephan tokenization using returning rebecca class 2012
ppattachment	preposition sentence_id verb noun1 attachment noun2
longest	ones bottom-up longer parser tries shorter grammars edges pcfg
model5counts	training parameters object various counts data store
toolbox	files base class settings
attr	wraps accessing keys allows dict attributes class
ibmmodel4	distance based sentence related reorders words output translation type model
ibmmodel5	target sentence track positions vacant place decide keeps translated translation words model
ibmmodel2	model word lexical [] considers >>> bitext translation = order
ibmmodel3	multiple another language considers words word translation aligned model
settings	files base class settings
cached	cached topdownpredictrule version time first
instantiate	'@', 'instantiates' whose replacing variables chart start names new unique specialized
tgrep	tgrep exception type
view	tagged acts corpusview stream sequence skip sequences one backed used displays file specified contents xml index use documents matrix ann_morphosyntax initial charts class provides text readme corpus selects list-like (serialized files flat lazy elements corresponding streambackedcorpusviews<streambackedcorpusview> python 'view' taggedcorpusview, chart tokens bnc viewing objects sentences accessing interface using ann_segmentation aligned joins chasenreader chartparserapp like consist serialized similar together etc component iterated accessed mte specialized block view
set	set target contexts variables list feature value one base values sets find possible appear
reference	may generated page reference page_word
gaaclusterer	agglomerative group starts average vectors singleton n clusters
frame	frame scrollbars tkinter containing canvas
widget	children adjusts exists keeps text abstract boxwidget widget sign symbols oval single used displays operator bindings line special around canvas takes brackets negation scrollregion complex bounding widgets parenthases graphical elements string vertical tree canvas's object collection boxes hierarchical child pair horizontal segment class box include tkinter anything places always space list ovalwidget contain display
module	lazy class module
intensity	intensity score sentences sentiment give
individual	digits represents lowercase followed form (other variables character zero 'e') single take class
arff	weka labeled featuresets appropriate arff-formatted input converts strings
verbnet	interface verb lexicon nltk verbnet
lancaster	lancaster >>> nltk stemmer
review	represents features reviewed sentence review together annotations item notes reviewline main optional reviewscorpusreader block
paice	storing lemmas metrics stems evaluation class
score	scoring chunk parsers chunkscore class utility
closed	closure domain adds proving prover assumptions predicates completes decorator
readme	used corpusview skip initial readme corpus block
progress	made server indicates much progress data
formatter	weka labeled featuresets appropriate arff-formatted input converts strings
hunpos	paths pos input class tagging hunpos
lazy	abbreviated computed iterator sequence abstract argument module one produced zero underlying displays sequences loaded repr read-only whose given slice needed tuples wraps corpus several lazily function lazy elements run ontaining formed containing lists yielded slicing loading base i-th demand concatenating class count applying documentation list see value element subsequence api values making whole subscriptable first
parent	used set goal prover9command responsible assumptions macecommand, common base class maintaining
confusion	corresponding matrix reference confusion list values test
analyzer	based sentiment give tool approaches analysis machine intensity score learning sentences
hypothesis	translation partial solution
configuration	partial sentence analysis holding input configuration class
maxent	set encoding float sparse pair entropy generates featureset/label given containing joint-features feature label function map user-supplied form binary mapping joint-feature (also known integer exponential calls vectors maximum classifier") vector values "conditional input-feature converts classifier
context	chunkstring, text abstract one tag value chunks "context" matching index based three add sequential choose 'contexts' taggers base words bidirectional using backoff class rule patterns token specifying context left
logic	calculus linear parser logic expression lambda
expression	represent followed biconditionals (other uppercase abstract logical entity "(x single expressions y)" character two extends take = variables predicate used form object base 'e' related variable conjunctions class types digits represents lowercase equality like 'e') implications zero drt binds every expression disjunctions
lemmatizer	function lemmatizer morphy built-in wordnet lemmatize using wordnet's
bell	distribution witten-bell estimate probability
simple	probdist linear space approximates frequency line regression simplegoodturing log
pos	tokens nearby examines feature tags
loader	run documentation see api lazily loaded corpus first
table	in-memory based log multilistbox widget translations given field token values holding table phrase parameters display store
slots	represents used target sentence track positions keep
raise	undirected applying combinator forward backward type class raising
union	represents union feature value two featurevalueset base variable
viewer	terminal data handle sending
nombank	information predicate used height* constituents treebank reader tree argument one parse height*wordnum identify wordnum nombank augments penn corpus pointer structure
collocation	whose finding bigram collocations candidate ranking frequencies abstract measures tool rank filter collect quadgram base purpose collocation finders class association trigram
empty	inserts chart rule passive edges productions position every empty
field	field token parameters holding table
direction	function application direction representing class
demand	closes pointer zipfile file subclass
watcher	canvas always adjusts widget scrollregion boxes bounding canvas's include children special
multi	selection labels zero listbox row category current processing parent multi-column maintains trees tokens interface entire pointers tree labeling "labels") (or applies multi-parented automatically
prover	domain stores predicates prover assumptions names prover, run tools unique adds goal prove holds completes theorem decorators model prove() extend proving build_model() base interface trying class decorator closure builder list command either provercommand called
value	set helper featurevalueset abstract concatenation two different union feature custom ordinary method define tuple featuregrammars, base unification designed variable class represents value values featurevaluetuple strings
ipipancorpus	work created ipi designed reader corpus pan
error	exception used errors dependency wordnet-related graph class _destructively_unify raised encountered failure abort unification framenet-related error fail server data read_* functions
europarl	documents consist plaintext corpora reader europarl
chunked	tagged optionally corpora reader paragraphs chunked
heldout	used probability distributions two generate experiment frequency estimate heldout distribution
cons	sentence dataset cons pros reader
concatenation	lazy several ' form sequence drs formed list abbreviated lists repr elements displays concatenating whole + first
drt	calculus ' form abstract parser drt base every + extends expression drs lambda
parse	whose documents parenthesis-delineated like consist section corpora "combined" trees parsed parse identifiers file reader penn found based treebank categories divided
cluster	interface clustering basic functionality covering
in	mix-in (trees associate probabilities etc rules classes class
comparative	jindal sentence dataset liu 2006 reader comparative
binary	binary containing vectors generates form application abstract encoding combinator chart wrapper feature implementing joint-features undirected representing class
typed	binary containing float generates form encoding joint-features vectors feature integer
descent	performing simple cfg parses parser parsing texts single operation matching descent process allows expanding recursively exploring graphical top-down tool step recursive fringe tree time recursivedescentparser
generic	interface parser stanford
cross	used set probability generate cross-validation experiment frequency estimate distribution
mtefile	content corpus loading class multext-east
discourse	discourse ongoing check properties
childescorpus	xml corpus version childes reader
split	chunkstring, right pattern two rule patterns tag specifying chunks using left matching split
kneser	estimate version distribution probability kneser-ney
composition	combinator harmonic functional composition
parented	parent abstract maintains tree pointers trees multi-parented single-parented base nodes class automatically
valuation	represents dictionary model-theoretic non-logical valuation constants
assignment	represents variables values dictionary assignment
timit	tagged formats layout reader timit use file sentences included corpus
norwegian	norwegian snowball stemmer
stack	canvas vertical line keeps list widget collection stack machine >>> _hypothesis objects decoder widgets translation nltk phrase-based
expand	right pattern chunkstring two rule patterns tag specifying chunks using matching expand left
concordance	index given used word look locations offset document occurs
task	represents task e people items labels annotation assign
neural	stanfordneuraldependencyparser stanford parse >>> import nltk
i	represent sentence tokenizing text labels existing tagger whose graph handle string rules morphological possible trees joint-feature words identifying positions covering list labeling "class") token vector (or delegate "labels") specifies set sequence twitter licensed zero category label experiment new unrestricted conditions method run processing hypothesis groups interface non-overlapping dependency featureset implement probability variables outcomes weighted apply clustering given removing featuresets substitutions basic structures generating lists tokens part affixes assigning clients classes values distribution subclasses single tag converts distributions different perform functionality mapping collection deriving edges transformational scorer class structure calculated rule weights input-feature requires
builder	set stores prover assumptions run tools goal holds build theorem decorators formulas prove() extend modelbuildercommand build_model() base interface trying class decorator modelbuilder, builder list command either model called
viterbi	bottom-up dynamic parser programming likely parse single uses text find pcfg
edge	sentence allows consistent operates symbols single rule edgerule bindings / whose given leaf left-hand representing create edges version combined adjacent basic shared empty nonterminals form chart records base hypothesis joins variable part completer class structure partially word derivation tree value side right-hand edge featstructnonterminals fundamental uses ccg specialized make fact first
command	contains stores prover assumptions prover, run tools goal holds theorem decorators provercommanddecorator used prove() extend modelbuildercommand proving provercommand build_model() modelbuildercommanddecorator base macecommand class decorator building modelbuilder, builder list mace specific classes command either model called
english	snowball stemmer english
gzip	filesystempathpointer given read() gzip-compressed calls write() subclass located gzipfile file path identifies buffers absolute
rslpstemmer	portuguese stemmer
model	model domain set sequence prover assumptions learning generative goal parameters valuation holds *v* discourse build labelling command hidden include decorators formulas extend modelbuildercommand hmm base interface trying data class decorator training *d* modelbuilder, list algorithms markov order first
left	right bottom-up chartparser left-corner pattern chunkstring two rule parsing patterns tag specifying chunks using strategy matching expand left
sentence	collocations used xml) (the tokenizer sentence attribute unsupervised list n abbreviation record num uses build words algorithm model identifier start augmented
unicode	stream codecs encodes source unicode reader byte (like automatically
ycoeparse	strips standard parse version reader corpus specialized (code bracket
alignment	s2 training ibm helper models representing s1 object storage two 3 alignment sequences data class read-only
struct	either identifiers string acts feature value mapping (such also values structure basic nonterminal that's
mix	mix-in (trees associate probabilities etc rules classes class
combine	begins whose corresponding complete edge's rule edge right-hand production licensing side left-hand
theorem	building decorators used goal extend proving holds list modelbuildercommanddecorator assumptions base model classes provercommanddecorator class decorator
constant	digits represents followed form variables character zero single take class
finder	whose finding bigram collocations candidate ranking frequencies abstract measures tool rank filter collect quadgram base purpose collocation finders class association trigram
nkjpcorpus	use ann_morphosyntax stream text backed corpus specialized ann_segmentation view
format	files strings format processing standard marker reading class
read	fail exception functions raised read_*
prover9command	prover9 used set goal prover9command responsible assumptions specific prover macecommand, common base contains provercommand class maintaining
clusterer	takes closest means chosen k-means k starts space allocates clusterer tokens cluster vector arbitrary maps abstract mean
cjkchars	cjk code http object //en enumerates listed characters points
boxer	parser semantic form produces subclasses bos's drss discourse reparse boxer program str representation interface wide-coverage abstractboxerdrs johan structures class
unification	exception used _destructively_unify encountered failure abort unification
bnccorpus	xml national british version reader corpus
world	predicates prover proving completes decorator
unique	adds proving prover assumptions names unique decorator
finnish	snowball stemmer finnish
ignore	used corpusview skip initial readme corpus block
t	tnt notes - pos important tagger statistical
framenet	exception errors framenet-related reader framenet corpus class
italian	snowball stemmer italian
portuguese	portuguese snowball stemmer
right	right pattern chunkstring two rule patterns tag specifying chunks using matching expand left
sequence	substitute_bindings() computed sequence abstract sequences line read-only clases whose canvas length needed widgets distributes variables() widget elements index base mixin horizontal class list token values keeps object's original
nertagger	paths stanford named-entity tagger input class tagging
eleprob	used probability generate experiment frequency expected estimate likelihood distribution
conditional	probability conditional single experiments simply freqdists alternative distributions different rather experiment conditions used run creating dictionary wraps collection modeling conditionalprobdist generate probdists frequency distribution
counts	training parameters object various counts data store
conll	conllcorpusreader set sentence chunk labels pos instances single file conll-style conll contains three instance arguments reader corpus columns files whose verb words data consist srl identifies providing
authenticate	twitter authenticating methods
leaf	leaf sentence consistent value records edge word fact
bottom	partial abstract parser results parsing production grammars licensing pcfg whose bottom-up strategy edge corresponding complete chart uses using left-hand begins left-corner rule record right-hand edge's side chartparser
cfgeditor	creating grammars free dialog window context editing
pros	sentence dataset cons pros reader
iff	represents class biconditionals
synset	string create "<lemma> <pos> synset <number>"
prob	set version probability (uniform random approximates outcomes sample zero frequency simply directly specified conditional freqdists alternative distributions line generates whose given wraps log space probabilities lidstone single two regression 1 0 linear experiment mutable conditions witten-bell probdist creating used run assigns dictionary easily may different collection modeling estimate generate simplegoodturing kneser-ney cross-validation probdists conditionalprobdist whereby equal modified rather experiments distribution heldout laplace
minimal	target contexts possible value one find appear
detokenizer	detokenizer python //github https moses port
morpho	contains corpus mac_morpho line reader
ngram	word's based string tags generic preceding measures chooses collection n class token's tag tagger word defining abstract association
substitution	permutation combinator substitution
regexp	set tokenizer chunk parser identify tagger affixes expressions string based regexptagger comparing stemmer regexpparser regexpchunkparser either chunkstring, exploring graphical assigns tags matches chunking tool morphological modify separators tokens regular transformational using grammar splits rule specifying uses expression nltk
on	closes pointer zipfile file subclass
package	working package started server finished downloadable entries directory entry data
or	represents class disjunctions
dependency	parsing set words rule-based parser dependencygrammar parse single weighted projective consists string relationships stanfordneuraldependencyparser container built >>> graph modifier) maps production attachment import nodes contiguous classifier measuring around dep_parser=stanforddependencyparser( non-projective amongst edges labelled scorer input span score representing class structure exception -> grammar stanford calculated probabilistic maxent dependency part weights projectivedependencyparser (head nltk unlabelled
switchboard	used utterances object list switchboard encode specialized
unsorted	bottom-up parser tries whatever grammars edges order pcfg
pred	information used dictionary closedworldprover predicates class store
featureset	tokens requires tagger featureset featuresets
blankline	treating string sequence tokenize lines delimiter blank
rtecorpus	rte challenges corpus corpora reader
cutoff	implements cutoff based log helper number checks iterations likelihood class
primitive	primitive representing class categories
sexpr	s-expressions divides tokenizer strings
iccorpus	content information corpus wordnet reader
kmeans	closest means chosen k-means k starts allocates clusterer cluster vector arbitrary mean
down	topdownpredictrule parsing grammar's productions licensing whose top strategy start version featstructnonterminals nonterminals predict corresponding top-down symbol edges using operates nonterminal symbols grammar cached dot rule edge's incomplete time following specialized chartparser first
variable	followed (other uppercase variables entity single character take abstract predicate used form 'e' variable class digits represents lowercase 'e') zero binds expression
span	relationships -> span string contiguous amongst dependency part words modifier) input (head representing
segment	canvas tree widget single hierarchical displays segment
combinator	binary backward combinators application equivalent abstract combinator chart wrapper primary implementing functor forwardcombinator undirected representing class left
smoothing	bleu segment-level presented implementation smoothing scores techniques
start	downloading working package started unzipping collection server packages data
fraction	fractions backwards compatible version simplified fraction
forward	applying representing combinators primary functor forward type class raising left
ccglexicon	ccg lexicon representing class grammars
twitter	line-delimited consist restricted corpora list wrapper options represented json functionality fewer reader tweets class
function	bleu followed encoding uppercase variables single techniques featureset/label given implementation character feature smoothing application take function map segment-level user-supplied form joint-feature scores pair representing class digits represents calls presented zero vector sparse
concatenated	streambackedcorpusviews<streambackedcorpusview> file 'view' together one joins corpus
basic	implementation tweethandler minimal
thesaurus	thesauruses lin distributed wrapper lisp-formatted dekang
failure	exception used _destructively_unify encountered failure abort unification
decoder	stack machine >>> decoder translation nltk phrase-based
russian	russian snowball stemmer
line	represents optionally features sentence discarding review blank lines together reviewed item notes tokenize reviewline optional annotations string
with	chunkstring, intended dealing purpose local three rule one patterns add tag specifying context timezone chunks using general class matching left
info	training ibm helper models object 3 data read-only
utc	intended dealing general purpose timezone local class
converter	conversion implemented tags universal currently options converting msd class
stanford	tokenizer parser pos parse tagger paths stanfordneuraldependencyparser >>> import named-entity define taggers dep_parser=stanforddependencyparser( parser=stanfordparser( input interface class tagging must stanford segmenter subclasses nltk
default	every token tag tagger assigns
inside	bottom-up probabilities inside parser tries trees grammars edges descending order pcfg
up	up-to-date already partial abstract parser results parsing grammars licensing file download strategy pcfg whose bottom-up edge production corresponding complete chart uses using left-hand begins package left-corner rule record right-hand edge's side chartparser
un	chunkstring, pattern remove rule tag specifying chunks using matching
laplace	generate used probability laplace experiment frequency distribution estimate
sklearn	scikit-learn classifiers wrapper
bigram	ranking bigram string collocations word tool measures chooses collection words' token's tag tagger measure finding based preceding association
trie	trie implementation strings
abstract	combinatory computed abstract predicate rank entity variable grammars sequences read-only whose canvas candidate needed abstractchartrule collocation nodes boxwidget used parent rules frequencies maintains chart widgets base purpose child interface finders class categories represents pointers tree single filter collect ovalwidget values contain automatically
parser	operations represent partial text regexpparser random dynamic results tagger find pcfg non-overlapping adding based *incremental* jay >>> shiftreduceparser input dep_parser=stanforddependencyparser( possible trees ones descending pos-tagged words using ccgs grammar identifying performing list projectivedependencyparser set sequence cfg chunk likely "arc-eager" matching import unrestricted linear bllip abstractboxerdrs processing parser=stanfordparser( implementing step objects groups interface iob transition programming "reduce", dependency edges maltparser logic implement "arc-standard" lambda simple rule-based whatever parsing texts "strategy", bottom-up probabilities two strategy 2 expanding expected structures parses top-down recursively reparse tokens projective stanford inside tree grammars record str subclasses fringe process allows abstract parser parse single "shift" operation paths stanfordneuraldependencyparser form generic shorter earley's algorithms regexpchunkparser calculus used non-projective chart deriving tries regular uses probabilistic class bllipparser longer algorithm left-corner expression order edge setp time recursivedescentparser nltk chartparser
backoff	sequentially taggers right tags abstract base words class left
char	individual functionality string characters tokenize
single	nonterminals fundamental given adjacent form whose completer version chart rule edge symbols single edges combined joins featstructnonterminals operates specialized /
file	via directly within file pointer buffers absolute closes given subclass located contained reading filesystempathpointer write() read() zipfile path gzip-compressed calls gzipfile accessed identifies
timezone	intended dealing general purpose timezone local class
tiling	algorithm texttiling topical tokenize using document sections
ccgchart	parser ccgs chart
srlinstance	conll set instances sentence labels srl instance single verb arguments corpus providing identifies
tester	discourse ongoing check properties
application	function represent used two related application logical expressions representing class types
comparer	dictionary _charts charts _root mapping :ivar window names root
test	cfg tests unit
gisencoding	binary adds encoding defined joint-features feature one joint-feature new binarymaxentfeatureencoding:
node	node tree dendrogram
symbol	canvas exists widget negation sign symbols displays operator special
meaning	represents panlex set derived single meaning translation
scorer	weighted built graph calculated maxent dependency edges weights scorer classifier around
mwetokenizer	tokens processes tokenizer text multi-word tokenized single merges expressions
cooper	via cooper storage handling ambiguity container quantifier
concat	represents two value feature variable base concatenation featurevaluetuple
whitespace	whitespace space newline tab tokenize string
searcher	use strings search easier tokenized regular expressions makes class
validation	used set probability generate cross-validation experiment frequency estimate distribution
rule	tagged topdownpredictrule existing symbols whose passive add production abstractchartrule rules every tbl joins using one left-hand grammar cached remove merge right-hand side specifies inserts right licensed grammar's productions edgerule matching pattern / current version new conditions checks taggers modify implementing base interface nonterminal fulfilled regular context uses expression top first two set licensing chunks given chinks transformations create chunkstring combinator three start combined basic forward corpus type empty chunkstring, corresponding complete form operates completer raising begins applying edge's featstructnonterminals following specialized predict certain abstract single tag performed binary triggered make application split adjacent nonterminals chunking symbol chart meaning edges transformational class expand incomplete rule patterns edge specifying fundamental time position backward dot left
toktok	python tok-tok port pl
backward	applying equivalent forwardcombinator backward type class raising
scroll	canvas always adjusts widget scrollregion boxes bounding canvas's include children special
