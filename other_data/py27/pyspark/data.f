ml java mlwriter save path
sql spark session conf
mllib regression metrics mean absolute error
core heappop max heap
ml stop words remover set stop words value
ml logistic regression training summary objective history
ml param has reg param get reg param
core external merger object size obj
streaming dstream save as text files prefix suffix
ml multilayer perceptron classifier get layers
ml imputer set strategy value
ml gbtclassifier set loss type value
core first spark call
mllib stat statistics col stats rdd
ml binary logistic regression summary pr
core cloud pickler save memoryview obj
mllib matrix factorization model predict user product
ml java mlreader java loader class cls clazz
core spark context get java storage level storageLevel
ml vector indexer set max categories value
mllib linalg row matrix compute column summary statistics
core portable hash x
ml regression evaluator get metric name
ml param params resolve param param
ml generalized linear regression get variance power
ml generalized linear regression summary residual degree of freedom null
sql corr col1 col2
streaming dstream pprint num
ml elementwise product init scalingVec inputCol outputCol
mllib linalg coordinate matrix transpose
sql translate srcCol matching replace
streaming basic operation tests test map
core cloud pickler save file obj
ml param decision tree params set min instances per node value
ml elementwise product set params scalingVec inputCol outputCol
sql from unixtime timestamp format
mllib linalg block matrix num cols
ml regex tokenizer init minTokenLength gaps pattern inputCol
mllib stat test result degrees of freedom
ml multilayer perceptron classifier set solver value
sql data frame sort within partitions
sql data frame register temp table name
core rdd is checkpointed
mllib linalg matrices dense numRows numCols values
core rdd map partitions with split f preservesPartitioning
streaming flume utils create stream ssc hostname port storageLevel
sql from utc timestamp timestamp tz
ml count vectorizer set params minTF minDF vocabSize binary
mllib mlutils append bias data
mllib ldamodel vocab size
sql data frame hint name
ml gbtregression model feature importances
ml random forest classifier set params featuresCol labelCol predictionCol probabilityCol
ml multiclass classification evaluator set metric name value
sql data type need conversion
sql sqlcontext read
mllib stat kernel density set sample sample
streaming py spark streaming test case take dstream n
ml one vs rest model from java cls java_stage
ml gbtregressor get loss type
ml evaluator tests test java params
mllib ldamodel describe topics maxTermsPerTopic
core rdd take sample withReplacement num seed
mllib standard scaler model std
sql infer schema type obj dataType
ml bucketizer set handle invalid value
sql data frame rdd
mllib fpgrowth train cls data minSupport numPartitions
core daemon tests test termination stdin
mllib java loader load java cls sc path
ml distributed ldamodel log prior
ml string indexer model labels
ml param has features col get features col
core rdd group by key numPartitions partitionFunc
sql sqlcontext get conf key defaultValue
ml generalized linear regression set link prediction col value
core rdd name
streaming py spark streaming test case collect dstream n block
ml naive bayes get model type
core rdd left outer join other numPartitions
ml param decision tree params set max memory in mb value
ml binary classification evaluator init rawPredictionCol labelCol metricName
ml param has step size get step size
mllib to java object rdd rdd
ml evaluator evaluate dataset
mllib streaming linear regression with tests test prediction
sql create function name doc
ml regex tokenizer set gaps value
ml linear regression summary t values
core rdd save as hadoop file path outputFormatClass keyClass valueClass
ml binarizer init threshold inputCol outputCol
sql catalog drop temp view viewName
ml gbtregressor init featuresCol labelCol predictionCol maxDepth
ml binary logistic regression summary roc
streaming dstream cogroup other numPartitions
sql create binary mathfunction name doc
sql data frame sort cols cols kwargs
core task context new cls
core rdd join other numPartitions
ml min max scaler set max value
ml generalized linear regression model has summary
sql data frame cache
mllib gaussian mixture model load cls sc path
sql data frame coalesce numPartitions
ml linalg dense matrix to sparse
ml ldamodel log likelihood dataset
sql catalog register function name f returnType
mllib streaming kmeans test test train on model
core restore name fields value
mllib ldamodel topics matrix
ml linear regression summary residuals
ml param type converters to vector value
ml to java object rdd rdd
mllib multilabel metrics precision label
mllib binary classification metrics area under roc
ml binary logistic regression summary recall by threshold
ml py2java sc obj
streaming streaming context union
ml pca set params k inputCol outputCol
ml linalg dense vector squared distance other
core spark submit tests test user configuration
ml linear regression model has summary
mllib random forest train classifier cls data numClasses categoricalFeaturesInfo
sql grouping id
streaming kafka utils create direct stream ssc topics kafkaParams fromOffsets
ml bisecting kmeans set min divisible cluster size value
mllib kmeans model k
sql window spec order by
mllib linalg block matrix transpose
mllib linalg row matrix rows
sql spark session infer schema rdd samplingRatio
ml idf init minDocFreq inputCol outputCol
ml linear regression model summary
ml param params reset uid newUid
ml random forest regressor init featuresCol labelCol predictionCol maxDepth
ml logistic regression model coefficients
sql md5 col
streaming dstream repartition numPartitions
streaming streaming context stop stopSparkContext stopGraceFully
core rdd reduce f
mllib linalg row matrix num rows
ml param has elastic net param set elastic net param value
mllib streaming linear regression with sgd train on dstream
sql spark partition id
mllib streaming logistic regression with sgd set initial weights initialWeights
ml idf set params minDocFreq inputCol outputCol
sql data frame rollup
core heappop heap
ml aftsurvival regression model scale
core rdd min key
ml linalg vectors dense
mllib saveable save sc path
sql size col
sql runtime config check type obj identifier
mllib tree ensemble model predict x
streaming streaming listener on batch completed batchCompleted
sql catalog create external table tableName path source schema
core spark conf set master value
mllib linalg dense matrix repr
sql date add start days
core rdd save as hadoop dataset conf keyConverter valueConverter
sql sqlcontext tables dbName
sql sqlcontext init sparkContext sparkSession jsqlContext
ml imputer init strategy missingValue inputCols outputCols
sql monotonically increasing id
mllib naive bayes train cls data lambda_
core cloud pickler save partial obj
streaming kafka dstream transform func
core profiler collector new profiler ctx
sql data frame create or replace temp view name
sql weekofyear col
mllib linalg coordinate matrix to row matrix
mllib lasso model save sc path
mllib linalg singular value decomposition s
ml aftsurvival regression set params featuresCol labelCol predictionCol fitIntercept
ml validator params get estimator
ml param decision tree params get min instances per node
core spark context application id
mllib regression metrics explained variance
ml train validation split copy extra
mllib streaming kmeans test test model params
core rdd mean approx timeout confidence
ml lda get subsampling rate
ml lda set learning offset value
ml has support get min support
core spark context exit type value trace
mllib random rdds poisson vector rdd sc mean numRows numCols
sql log arg1 arg2
mllib linalg row matrix tall skinny qr computeQ
core spark context binary records path recordLength
ml linalg sparse vector squared distance other
streaming dstream window windowDuration slideDuration
mllib linalg block matrix blocks
ml multilayer perceptron classifier set initial weights value
mllib binary classification metrics area under pr
ml param grid builder build
ml multilayer perceptron classifier set step size value
sql window spec range between start end
mllib linalg dense vector parse s
core task context tests test partition id
ml validator params get evaluator
core daemon tests test termination sigterm
ml tree ensemble params get subsampling rate
streaming dstream flat map values f
ml logistic regression set thresholds value
ml generalized linear regression summary null deviance
ml linalg vectors norm vector p
ml decision tree regressor set params featuresCol labelCol predictionCol maxDepth
sql data frame getitem item
core profiler stats
core broadcast init sc value pickle_registry path
sql to scala map sc jm
ml multiclass classification evaluator set params predictionCol labelCol metricName
sql data frame to pandas
ml naive bayes set model type value
sql struct type len
mllib linalg dense vector to array
ml bisecting kmeans get k
streaming streaming listener on receiver error receiverError
ml other test params set params seed
core spark submit tests test single script
core keyword only func
sql data frame reader csv path schema sep encoding
sql data type to internal obj
ml linalg matrices dense numRows numCols values
mllib mlutils convert labeled point to libsvm p
ml ldamodel vocab size
ml ldamodel is distributed
sql catalog drop global temp view viewName
mllib linear model intercept
mllib power iteration clustering train cls rdd k maxIterations
ml linalg vector to array
mllib decision tree model predict x
ml lda init featuresCol maxIter seed checkpointInterval
ml bisecting kmeans model compute cost dataset
sql data frame writer sort by col
ml ngram get n
mllib decision tree model depth
streaming dstream transform func
mllib word2vec set num partitions numPartitions
core rdd get num partitions
sql sqlcontext range start end step numPartitions
mllib regression metrics mean squared error
ml random forest params get feature subset strategy
core ignore unicode prefix f
sql last day date
sql sqlcontext new session
core rdd tree aggregate zeroValue seqOp combOp depth
sql months between date1 date2
mllib svmmodel predict x
mllib lasso model load cls sc path
ml count vectorizer set min df value
mllib random rdds normal vector rdd sc numRows numCols numPartitions
mllib bisecting kmeans train rdd k maxIterations minDivisibleClusterSize
sql sqltests test column name encoding
core task context get or create cls
ml vector slicer init inputCol outputCol indices names
mllib mlutils convert vector columns from ml dataset
sql has nulltype dt
sql data frame writer bucket by numBuckets col
core spark context spark user
ml chi sq selector get fdr
ml kmeans set init mode value
mllib call java func sc func
streaming basic operation tests test map partitions
core framed serializer loads obj
core serializer load stream stream
mllib standard scaler fit dataset
core external merger external items
mllib linalg matrix as ml
sql struct type init fields
sql streaming query recent progress
ml cross validator model copy extra
ml param has prediction col set prediction col value
sql to jarray gateway jtype arr
ml standard scaler set params withMean withStd inputCol outputCol
core heapreplace max heap item
ml aftsurvival regression init featuresCol labelCol predictionCol fitIntercept
ml binarizer set threshold value
ml min hash lsh init inputCol outputCol seed numHashTables
core spark context broadcast value
mllib multiclass metrics accuracy
ml random forest params get num trees
ml pipeline model copy extra
ml generalized linear regression summary prediction col
sql spark session create data frame data schema samplingRatio verifySchema
ml imputer get missing value
ml param params set default
core status tracker get active stage ids
ml gaussian mixture model summary
ml max abs scaler init inputCol outputCol
mllib bisecting kmeans model compute cost x
ml generalized linear regression summary aic
sql data frame union all other
ml java mlwriter context sqlContext
core rdd to debug string
ml min max scaler set min value
ml param type converters to int value
ml java estimator create model java_model
ml multilayer perceptron classifier set layers value
mllib decision tree model num nodes
sql data frame reader orc path
mllib py2java sc obj
ml pipeline model from java cls java_stage
mllib linear classification model threshold
ml estimator fit dataset params
ml rformula set force index label value
sql data stream reader options
sql next day date dayOfWeek
ml generalized linear regression set family value
sql year col
sql spark session create from rdd rdd schema samplingRatio
core status tracker get stage info stageId
streaming streaming context await termination timeout
ml vector indexer get max categories
ml clustering summary predictions
ml als get intermediate storage level
core find spark home
ml param params get or default param
streaming streaming listener on batch started batchStarted
ml generalized linear regression summary residuals residualsType
ml mlreader load path
ml param grid builder add grid param values
mllib linalg indexed row matrix num rows
sql data frame take num
mllib gaussian mixture model predict soft x
mllib streaming kmeans model update data decayFactor timeUnit
ml isotonic regression get feature index
core rdd to local iterator
sql approx count distinct col rsd
sql parse datatype string s
ml isotonic regression model boundaries
ml evaluator evaluate dataset params
sql row repr
core rdd take ordered num key
ml generalized linear regression training summary t values
sql grouped data count
sql catalog list functions dbName
sql row call
ml linalg dense vector norm p
ml standard scaler set with mean value
ml multilayer perceptron classifier get block size
sql data frame cov col1 col2
sql hive context refresh table tableName
core status tracker get job ids for group jobGroup
sql catalog is cached tableName
ml vector slicer get indices
ml bisecting kmeans set k value
ml mlwritable save path
mllib sci py tests scipy matrix size values
ml param params has param paramName
mllib random rdds log normal vector rdd sc mean std numRows
mllib bisecting kmeans model cluster centers
sql isnull col
mllib idfmodel idf
streaming kafka stream tests test kafka rdd message handler
sql locate substr str pos
sql create converter dataType
streaming dstream cache
core accumulator value value
streaming py spark streaming test case sort result based on key outputs
sql hex col
ml string indexer init inputCol outputCol handleInvalid
core spark context set system property cls key value
mllib logistic regression with sgd train cls data iterations step
mllib chi sq selector set selector type selectorType
core cloud pickler save reduce func args state listitems
mllib power iteration clustering model k
streaming dstream full outer join other numPartitions
ml logistic regression summary label col
mllib streaming logistic regression with sgd train on dstream
ml java evaluator evaluate dataset
core rdd subtract other numPartitions
sql user defined function wrapped
ml kmeans get init steps
sql data frame create temp view name
mllib ldamodel load cls sc path
ml lda get k
sql split str pattern
sql data frame writer save as table name format mode partitionBy
ml decision tree classification model feature importances
sql data frame writer json path mode compression dateFormat
ml standard scaler set with std value
ml cross validator init estimator estimatorParamMaps evaluator numFolds
mllib linalg block matrix num col blocks
mllib loader load cls sc path
ml logistic regression model intercept
core accumulator iadd term
sql covar samp col1 col2
sql minute col
ml kmeans get k
core spark submit tests test package dependency on cluster
streaming streaming listener on output operation completed outputOperationCompleted
sql data frame writer csv path mode compression sep
mllib decision tree model repr
streaming streaming context await termination or timeout timeout
sql parse datatype json string json_string
sql grouping col
core external merger cleanup
ml regression evaluator set metric name value
ml imputer set output cols value
ml java mlreadable read cls
core rdd histogram buckets
ml param has seed get seed
sql row reduce
ml word2vec set vector size value
core spark context default min partitions
mllib linalg block matrix subtract other
ml param has raw prediction col set raw prediction col value
mllib linalg coordinate matrix num cols
mllib linalg vectors norm vector p
streaming kafka stream tests test kafka direct stream transform get offset ranges
core rdd key by f
core external sorter next limit
core parse memory s
streaming kafka dstream foreach rdd func
streaming basic operation tests test map values
core spark context pickle file name minPartitions
ml gbtclassifier set params featuresCol labelCol predictionCol maxDepth
sql spark session read stream
streaming kafka stream tests test kafka rdd
core external merger get spill dir n
mllib linalg dense matrix str
ml als set user col value
ml tree classifier params set impurity value
ml generalized linear regression training summary coefficient standard errors
ml param has standardization set standardization value
core rdd to java object rdd
ml linalg dense vector dot other
ml linear regression summary label col
ml rformula init formula featuresCol labelCol forceIndexLabel
core spark files get root directory cls
sql data frame join other on how
ml linear regression training summary total iterations
streaming streaming listener on receiver started receiverStarted
sql grouped data min
ml regex tokenizer get gaps
mllib kmeans model save sc path
ml linear regression set params featuresCol labelCol predictionCol maxIter
ml pipeline model to java
sql window order by
ml lda get optimizer
mllib linalg dense vector dot other
mllib linalg singular value decomposition v
ml java params transfer param map to java pyParamMap
core profiler collector dump profiles path
core rdd keys
ml linalg vectors sparse size
core rdd sample stdev
sql streaming query manager await any termination timeout
mllib multiclass metrics weighted recall
sql data frame union other
mllib inherit doc cls
sql spark session enter
sql regexp extract str pattern idx
sql runtime config unset key
sql infer schema row
ml one hot encoder get drop last
ml decision tree model num nodes
ml elementwise product set scaling vec value
core rdd reduce by key func numPartitions partitionFunc
streaming basic operation tests test count by value
sql streaming query manager reset terminated
streaming basic operation tests test flat map values
ml word2vec get vector size
mllib linear classification model set threshold value
core task context tests test tc on driver
mllib linalg block matrix add other
sql sqlcontext clear cache
streaming streaming context checkpoint directory
ml index to string get labels
mllib streaming linear algorithm predict on dstream
mllib matrix factorization model recommend users product num
ml pca init k inputCol outputCol
ml bucketed random projection lsh get bucket length
sql lag col count default
mllib word2vec set num iterations numIterations
sql unhex col
core rdd glom
mllib java saveable save sc path
mllib kmeans model compute cost rdd
mllib stat kernel density set bandwidth bandwidth
sql grouped data sum
mllib linalg block matrix to indexed row matrix
ml java estimator fit java dataset
mllib normalizer transform vector
ml chi sq selector set selector type value
ml chi sq selector get fwe
ml quantile discretizer set relative error value
sql data frame cube
core profiler collector show profiles
ml param has fit intercept get fit intercept
ml alsmodel user factors
ml min max scaler get max
core accumulator init aid value accum_param
ml param params get param paramName
streaming streaming context queue stream rdds oneAtATime default
ml java params copy extra
ml kmeans model has summary
sql data frame writer partition by
sql substring str pos len
ml count vectorizer get min df
core rdd set name name
ml java params to java
ml param type converters to list int value
sql approx count distinct col rsd
ml als set intermediate storage level value
core rdd count approx timeout confidence
ml als set implicit prefs value
ml evaluator is larger better
mllib word2vec model find synonyms word num
mllib svmmodel load cls sc path
sql spark session create from local data schema
mllib streaming linear algorithm predict on values dstream
core rdd zip other
ml hashing tf init numFeatures binary inputCol outputCol
streaming dstream reduce func
core rdd full outer join other numPartitions
core rdd coalesce numPartitions shuffle
core spark conf get all
ml als set nonnegative value
sql sqlcontext table tableName
ml jvm
ml ngram set n value
sql rpad col len pad
sql spark session stop
ml als set params rank maxIter regParam numUserBlocks
mllib lda train cls rdd k maxIterations
ml one vs rest copy extra
ml logistic regression set params featuresCol labelCol predictionCol maxIter
mllib linalg indexed row matrix to coordinate matrix
sql data frame sample by col fractions seed
mllib mlutils convert matrix columns to ml dataset
ml java mlreader load path
mllib linalg indexed row matrix num cols
ml normalizer set params p inputCol outputCol
ml tokenizer init inputCol outputCol
ml naive bayes model theta
ml distributed ldamodel training log likelihood
mllib streaming linear regression with tests test parameter accuracy
ml param gen param code name doc defaultValueStr
ml fpgrowth model association rules
ml param has input col set input col value
core rdd zip with unique id
sql install exception handler
mllib pca fit data
streaming dstream jtime timestamp
ml chi sq selector set percentile value
ml mlreadable read cls
ml java params transfer param map from java javaParamMap
ml chi sq selector set fwe value
ml mlwriter save path
core rdd count by key
core rdd foreach f
ml generalized linear regression summary degrees of freedom
streaming kafka stream tests test kafka direct stream from offset
sql column otherwise value
sql data frame reader table tableName
mllib linear model weights
ml random forest classifier init featuresCol labelCol predictionCol probabilityCol
ml one vs rest model to java
sql data frame with column colName col
core rdd stdev
ml bisecting kmeans model cluster centers
sql to seq sc cols converter
streaming dstream left outer join other numPartitions
ml als set num blocks value
sql option utils set opts schema
streaming streaming context get or create cls checkpointPath setupFunc
core profiler show id
ml param has max iter set max iter value
ml min max scaler get min
mllib multiclass metrics weighted fmeasure beta
sql data frame writer text path compression
sql streaming query manager get id
core rdd default reduce partitions
core rdd add other
core rdd aggregate by key zeroValue seqFunc combFunc numPartitions
mllib streaming kmeans train on dstream
ml max abs scaler model max abs
sql data frame write
ml pipeline to java
sql column get item key
ml param decision tree params get max depth
streaming streaming listener on output operation started outputOperationStarted
ml als get item col
mllib idfmodel transform x
ml lda get doc concentration
core chain f g
ml naive bayes set smoothing value
core heappush heap item
core spark context get local property key
ml rformula get formula
sql data frame count
mllib linalg row matrix num cols
mllib multiclass metrics precision label
mllib linalg row matrix column similarities threshold
ml logistic regression summary predictions
ml chi sq selector get selector type
mllib linalg sparse vector init size
streaming kafka rdd offset ranges
mllib word2vec set window size windowSize
ml lda set k value
mllib streaming kmeans set decay factor decayFactor
ml word2vec get window size
ml vector indexer set params maxCategories inputCol outputCol
sql count distinct col
sql data frame sample withReplacement fraction seed
sql sqlcontext uncache table tableName
mllib linalg sparse matrix to array
ml bucketizer init splits inputCol outputCol handleInvalid
sql grouped data max
core rdd mean
mllib stat chi sq test result method
core serializer load stream without unbatching stream
ml vector slicer get names
mllib streaming kmeans set initial centers centers weights
mllib binary classification metrics unpersist
sql data frame drop
ml one hot encoder set drop last value
mllib java loader load cls sc path
ml isotonic regression get isotonic
core spark context set job group groupId description interruptOnCancel
ml param has input cols set input cols value
ml gbtclassification model trees
mllib mllib streaming test case eventually condition timeout catch_assertions
sql data frame with watermark eventTime delayThreshold
sql data stream writer output mode outputMode
sql ignore brackets split s separator
mllib naive bayes model save sc path
ml lshparams get num hash tables
core accumulator reduce
core heappushpop heap item
core rdd map f preservesPartitioning
sql data frame writer save path format mode partitionBy
ml stop words remover get case sensitive
ml clustering summary prediction col
mllib logistic regression model num classes
mllib linalg row matrix multiply matrix
ml cross validator set num folds value
ml linalg sparse vector norm p
streaming basic operation tests test combine by key
core cloud pickler extract code globals cls co
core rdd combine by key createCombiner mergeValue mergeCombiners numPartitions
mllib linear regression with sgd train cls data iterations step
core rdd save as sequence file path compressionCodecClass
sql data frame reader options
mllib kmeans model load cls sc path
sql spark session read
sql format number col d
ml linear regression init featuresCol labelCol predictionCol maxIter
ml idf set min doc freq value
ml one vs rest init featuresCol labelCol predictionCol classifier
ml binarizer get threshold
sql sqlcontext infer schema rdd samplingRatio
mllib linalg block matrix cols per block
core rdd partition by numPartitions partitionFunc
core external merger items
core spark submit tests test single script on cluster
mllib streaming logistic regression with sgdtests test training and prediction
ml clustering summary cluster sizes
sql data frame random split weights seed
ml param params copy params
mllib random rdds uniform rdd sc size numPartitions seed
ml param grid builder base on
mllib kmeans model predict x
ml min max scaler model original min
ml param has output col set output col value
ml lshmodel approx nearest neighbors dataset key numNearestNeighbors distCol
ml has items col get items col
sql data frame collect
sql regexp replace str pattern replacement
sql data frame checkpoint eager
core spark context default parallelism
sql data frame writer insert into tableName overwrite
ml pipeline set stages value
ml param has features col set features col value
sql streaming query exception
core rdd collect
sql data frame writer parquet path mode partitionBy compression
ml dct set params inverse inputCol outputCol
ml dct set inverse value
sql explode col
ml als get num item blocks
ml param params should own param
core task context init
sql streaming query process all available
ml param has input col get input col
sql data stream writer option key value
ml quantile discretizer get handle invalid
ml standard scaler init withMean withStd inputCol outputCol
core spark conf set key value
sql user defined type deserialize datum
ml gbtclassification model feature importances
mllib multiclass metrics f measure label beta
streaming kafka stream tests test kafka direct stream message handler
ml rformula set params formula featuresCol labelCol forceIndexLabel
core rdd sample variance
ml chi sq selector set fpr value
sql posexplode col
core cloud pickler save inst obj
sql data stream reader option key value
core broadcast destroy
streaming streaming context transform dstreams transformFunc
sql conv col fromBase toBase
ml distributed ldamodel to local
core spark context parallelize c numSlices
sql reverse op name doc
sql grouped data pivot pivot_col values
sql current timestamp
sql data frame reader parquet
sql data frame schema
ml java mlreader context sqlContext
ml linalg sparse matrix to array
ml vector indexer model num features
mllib linalg row matrix compute svd k computeU rCond
sql concat ws sep
core merger merge combiners iterator
core spark context init master appName sparkHome pyFiles
sql data frame approx quantile col probabilities relativeError
sql streaming query stop
core accumulator param add in place value1 value2
sql catalog list tables dbName
ml param has variance col set variance col value
ml logistic regression summary probability col
core external sorter sorted iterator key reverse
sql data frame writer options
sql data stream writer format source
ml tree ensemble model to debug string
ml multilayer perceptron classifier set block size value
ml generalized linear regression init labelCol featuresCol predictionCol family
sql broadcast df
ml param params explain param param
sql window range between start end
core spark context hadoop file path inputFormatClass keyClass valueClass
sql data frame filter condition
core spark conf set if missing key value
sql data frame reader json path schema primitivesAsString prefersDecimal
sql data frame foreach partition f
core rdd sample withReplacement fraction seed
sql data frame replace to_replace value subset
mllib kmeans model cluster centers
ml java mlwritable write
ml hashing tf set binary value
sql isnan col
mllib linear regression model save sc path
ml linear regression summary mean squared error
ml bisecting kmeans set params featuresCol predictionCol maxIter seed
mllib isotonic regression model load cls sc path
mllib mlutils convert vector columns to ml dataset
sql column get field name
sql column over window
sql row as dict recursive
sql spark session table tableName
ml aftsurvival regression set quantile probabilities value
ml linear regression summary explained variance
core spark submit tests test package dependency
core spark submit tests test script with local functions
ml generalized linear regression model evaluate dataset
ml pipeline model read cls
mllib random rdds normal rdd sc size numPartitions seed
sql bin col
mllib linalg singular value decomposition u
mllib matrix factorization model user features
streaming basic operation tests test group by key
core spark submit tests test module dependency on cluster
ml linalg matrix convert to array array_like dtype
ml train validation split set train ratio value
core spark context range start end step numSlices
core rdd tree reduce f depth
streaming dstream map partitions with index f preservesPartitioning
core rdd sort by key ascending numPartitions keyfunc
mllib gradient boosted trees train classifier cls data categoricalFeaturesInfo loss
mllib streaming linear algorithm latest model
ml ldamodel topics matrix
ml logistic regression set threshold value
ml linalg dense matrix to array
ml java wrapper new java obj java_class
ml gaussian mixture model has summary
streaming dstream foreach rdd func
sql data frame jmap jm
sql sqlcontext table names dbName
core spark context ui web url
ml string indexer set params inputCol outputCol handleInvalid
ml bisecting kmeans init featuresCol predictionCol maxIter seed
core rdd fold by key zeroValue func numPartitions partitionFunc
core profiler profile func
ml sqltransformer set statement value
mllib ridge regression with sgd train cls data iterations step
core broadcast unpersist blocking
mllib streaming kmeans predict on dstream
streaming streaming context spark context
ml fpgrowth set params minSupport minConfidence itemsCol predictionCol
streaming basic operation tests test count
sql data frame stat
sql sqlcontext create external table tableName path source schema
sql streaming query name
ml linalg dense matrix repr
ml param params copy extra
ml gbtclassifier init featuresCol labelCol predictionCol maxDepth
ml bucketizer get handle invalid
core task context stage id
ml validator params get estimator param maps
sql to timestamp col format
mllib streaming kmeans latest model
sql data frame limit num
mllib linalg matrix convert to array array_like dtype
sql format string format
ml param params copy values to extra
ml als get final storage level
ml random forest regression model feature importances
core framed serializer dumps obj
sql data type from internal obj
sql add months start months
sql data frame na
mllib linalg block matrix multiply other
ml sqltransformer get statement
core external group by spill
ml fpgrowth model freq itemsets
mllib chi sq selector set fdr fdr
sql data frame persist storageLevel
core cloud pickler save function obj name
sql data frame freq items cols support
ml multilayer perceptron classifier init featuresCol labelCol predictionCol maxIter
sql randn seed
mllib linalg dense vector values
ml quantile discretizer set params numBuckets inputCol outputCol relativeError
core spark context union rdds
mllib vector transformer transform vector
core rdd max key
mllib gradient boosted trees train regressor cls data categoricalFeaturesInfo loss
ml generalized linear regression summary residual degree of freedom
sql catalog uncache table tableName
ml gaussian mixture model gaussians df
core cloud pickler save codeobject obj
mllib gaussian mixture model predict x
sql sqlcontext register java function name javaClassName returnType
mllib linear regression model load cls sc path
mllib multilabel metrics subset accuracy
ml has items col set items col value
mllib multiclass metrics recall label
mllib linalg coordinate matrix init entries numRows numCols
ml multilayer perceptron classifier get step size
mllib mlutils load lib svmfile sc path numFeatures minPartitions
sql data stream writer trigger processingTime once
mllib word2vec set min count minCount
streaming broker init host port
ml hashing tf get binary
sql ntile n
ml tree regressor params get impurity
sql grouped data avg
ml one vs rest read cls
ml count vectorizer get min tf
sql bround col scale
sql data frame head n
core spark files get cls filename
mllib multiclass metrics weighted true positive rate
streaming dstream reduce by key func numPartitions
sql user defined type cached sql type cls
core spark conf get key defaultValue
ml quantile discretizer set num buckets value
core copy func f name sinceversion doc
mllib ridge regression model load cls sc path
mllib linalg coordinate matrix to indexed row matrix
ml dct init inverse inputCol outputCol
ml generalized linear regression training summary num iterations
ml tree regressor params set impurity value
streaming streaming context remember duration
core modules to main modList
mllib chi sq selector set num top features numTopFeatures
core spark conf set all pairs
ml alsmodel rank
ml quantile discretizer get num buckets
ml linalg dense vector num nonzeros
sql data frame writer jdbc url table mode properties
streaming dstream glom
core spark context binary files path minPartitions
mllib linalg matrices sparse numRows numCols colPtrs rowIndices
sql substring index str delim count
core basic profiler profile func
core rdd is empty
ml count vectorizer init minTF minDF vocabSize binary
ml param has aggregation depth set aggregation depth value
ml pipeline from java cls java_stage
core external group by merge sorted items index
core rdd reduce by key locally func
sql data frame unpersist blocking
mllib linalg vectors parse s
ml one vs rest model copy extra
ml lda get learning offset
ml vector indexer model category maps
sql current date
ml als set num user blocks value
mllib prefix span model freq sequences
mllib logistic regression model predict x
sql streaming query status
sql spark session sql sqlQuery
mllib bisecting kmeans model predict x
mllib power iteration clustering model load cls sc path
ml quantile discretizer create model java_model
mllib ranking metrics mean average precision
ml pipeline get stages
ml polynomial expansion get degree
core accumulator add term
ml chi sq selector get percentile
mllib linalg sparse vector parse s
sql array type init elementType containsNull
ml logistic regression training summary total iterations
mllib linalg block matrix to coordinate matrix
ml mlwriter context sqlContext
sql sqlcontext register data frame as table df tableName
ml chi square test test dataset featuresCol labelCol
sql streaming query manager active
sql streaming query run id
ml kmeans set params featuresCol predictionCol k initMode
ml chi sq selector model selected features
sql catalog recover partitions tableName
core load namedtuple name fields
sql least
sql parse field abstract s
core spark context hadoop rdd inputFormatClass keyClass valueClass keyConverter
sql data frame cross join other
mllib linalg dense matrix as ml
ml word2vec model get vectors
sql data frame fillna value subset
mllib linalg vectors sparse size
sql coalesce
mllib linalg block matrix persist storageLevel
ml random forest params set num trees value
ml pipeline save path
ml aftsurvival regression get quantile probabilities
sql data frame select
mllib stat test result p value
ml tree ensemble params set subsampling rate value
ml tree ensemble model total num nodes
mllib java loader java loader class cls
ml linear regression summary p values
mllib linalg indexed row matrix to row matrix
core spark context new apihadoop file path inputFormatClass keyClass valueClass
ml min max scaler init min max inputCol outputCol
sql expr str
mllib linalg distributed matrix num cols
sql hive context create for testing cls sparkContext
sql catalog list columns tableName dbName
sql grouped data agg
ml param params dummy
ml param has thresholds get thresholds
ml generalized linear regression get link
sql data stream reader parquet path
core spark context set local property key value
sql data frame show n truncate vertical
sql data frame subtract other
ml estimator fit dataset
sql catalog refresh by path path
sql streaming query await termination timeout
streaming dstream slide duration
sql user defined type sql type cls
ml count vectorizer set min tf value
core rdd sum approx timeout confidence
ml param has standardization get standardization
sql sqlcontext ssql ctx
sql last col ignorenulls
mllib linear regression model base predict x
ml als set final storage level value
mllib random rdds exponential vector rdd sc mean numRows numCols
ml java classification model num classes
ml polynomial expansion set degree value
mllib multilabel metrics micro f1measure
core external merger partition key
mllib gaussian mixture train cls rdd k convergenceTol
core spark context ensure initialized cls instance gateway conf
sql unary op name doc
core rdd id
ml param has threshold get threshold
core rdd get storage level
ml gbtregressor set loss type value
ml min max scaler set params min max inputCol outputCol
core spark conf init loadDefaults _jvm _jconf
mllib hashing tf transform document
ml pipeline set params stages
ml linear regression summary prediction col
sql soundex col
core rdd unpersist
streaming dstream union other
core spark context dump profiles path
ml pipeline model write
ml param has prediction col get prediction col
ml param params clear param
mllib regression metrics r2
mllib ranking metrics precision at k
mllib word2vec fit data
ml generalized linear regression get link power
core siftdown max heap startpos pos
ml alsmodel item factors
mllib linalg qrdecomposition r
sql data frame create global temp view name
ml tokenizer set params inputCol outputCol
ml generalized linear regression model summary
core spark submit tests create file in zip name content ext dir
mllib linalg sparse vector as ml
mllib linalg block matrix validate
mllib decision tree train regressor cls data categoricalFeaturesInfo impurity
mllib linalg dense vector num nonzeros
streaming basic operation tests test filter
sql data frame reader schema schema
mllib word2vec model get vectors
ml param has reg param set reg param value
mllib streaming logistic regression with sgdtests test predictions
ml linear svc init featuresCol labelCol predictionCol maxIter
ml naive bayes init featuresCol labelCol predictionCol probabilityCol
sql data stream reader json path schema primitivesAsString prefersDecimal
mllib mlutils convert matrix columns from ml dataset
ml param decision tree params set cache node ids value
mllib multilabel metrics micro recall
sql spark session spark context
ml als get user col
sql data frame sort
mllib word2vec set vector size vectorSize
ml has support set min support value
ml mlreader session sparkSession
ml sqltransformer set params statement
ml regex tokenizer set pattern value
mllib linalg vector as ml
ml lda set params featuresCol maxIter seed checkpointInterval
sql to utc timestamp timestamp tz
mllib tree ensemble model repr
ml param decision tree params get cache node ids
mllib random rdds gamma vector rdd sc shape scale numRows
ml binary logistic regression summary precision by threshold
mllib linalg indexed row matrix compute svd k computeU rCond
ml imputer set params strategy missingValue inputCols outputCols
ml one vs rest save path
ml train validation split set params estimator estimatorParamMaps evaluator trainRatio
mllib matrix factorization model recommend products for users num
ml bucketizer set params splits inputCol outputCol handleInvalid
core rdd count approx distinct relativeSD
mllib isotonic regression model save sc path
ml one vs rest set params featuresCol labelCol predictionCol classifier
core rdd save as new apihadoop dataset conf keyConverter valueConverter
streaming kafka stream tests test kafka direct stream foreach get offset ranges
ml gaussian mixture set params featuresCol predictionCol k probabilityCol
ml linear regression summary coefficient standard errors
ml isotonic regression set feature index value
sql data frame corr col1 col2 method
mllib linalg indexed row matrix init rows numRows numCols
core rdd filter f
ml distributed ldamodel get checkpoint files
sql infer type obj
mllib multilabel metrics micro precision
streaming py spark streaming test case test func input func expected sort
streaming utf8 decoder s
ml normalizer set p value
ml lda get keep last checkpoint
sql to date col format
mllib tree ensemble model num trees
ml idfmodel idf
mllib chi sq selector set percentile percentile
ml stop words remover set case sensitive value
mllib linalg row matrix init rows numRows numCols
ml has confidence get min confidence
ml java wrapper new java array pylist java_class
mllib standard scaler model mean
mllib streaming logistic regression with sgdtests generate logistic input offset scale nPoints seed
core spark context empty rdd
ml param has output col get output col
ml regex tokenizer get pattern
sql dayofmonth col
ml fpgrowth init minSupport minConfidence itemsCol predictionCol
ml cross validator copy extra
ml lda set keep last checkpoint value
ml regex tokenizer get to lowercase
core accumulator value
ml bisecting kmeans model summary
ml java params transfer params to java
sql data frame to df
core nsmallest n iterable key
ml linalg sparse vector init size
mllib linalg sparse vector norm p
core rdd pipe command env checkCode
core spark context stop
ml linear svcmodel intercept
ml param has step size set step size value
core start update server
sql data frame group by
ml gaussian mixture set k value
ml param params explain params
ml decision tree regression model feature importances
mllib random rdds poisson rdd sc mean size numPartitions
ml hashing tf set params numFeatures binary inputCol outputCol
mllib linalg sparse vector squared distance other
ml elementwise product get scaling vec
streaming streaming context socket text stream hostname port storageLevel
sql data frame reader option key value
sql data frame writer option key value
ml tree ensemble model tree weights
mllib streaming logistic regression with sgdtests test parameter accuracy
ml param decision tree params get max memory in mb
sql data frame getattr name
ml mlwritable write
ml param has weight col get weight col
streaming dstream map values f
mllib logistic regression model save sc path
sql user defined type module cls
ml gbtregression model trees
mllib standard scaler model transform vector
ml param has num features get num features
sql udf f returnType
sql initcap col
mllib mlutils load labeled points sc path minPartitions
sql concat
mllib stat statistics kolmogorov smirnov test data distName
streaming dstream join other numPartitions
sql runtime config set key value
core nlargest n iterable key
ml transformer transform dataset params
mllib linalg block matrix num row blocks
ml ldatest compare m1 m2
core rdd save as text file path compressionCodecClass
ml param has max iter get max iter
ml one vs rest from java cls java_stage
ml lda set doc concentration value
ml min hash lsh set params inputCol outputCol seed numHashTables
mllib mlutils load vectors sc path
streaming topic and partition init topic partition
ml validator params set estimator value
mllib matrix factorization model load cls sc path
ml param has variance col get variance col
sql greatest
ml word2vec set max sentence length value
sql data frame writer format source
sql sqlcontext udf
mllib tree ensemble model total num nodes
sql sqlcontext drop temp table tableName
ml kmeans get init mode
core hack namedtuple cls
core heapreplace heap item
ml linear regression summary root mean squared error
ml linear regression training summary objective history
mllib svmwith sgd train cls data iterations step
mllib chi sq selector set fwe fwe
ml pipeline model save path
core rdd persist storageLevel
streaming kafka stream tests test kafka direct stream
ml persistence test compare params m1 m2 param
ml ngram init n inputCol outputCol
mllib linalg block matrix to local matrix
core rdd count by value
core spark conf set app name value
sql data frame print schema
ml param has num features set num features value
sql data frame foreach f
ml generalized linear regression set link power value
ml kmeans set init steps value
ml param decision tree params get max bins
ml cross validator set params estimator estimatorParamMaps evaluator numFolds
sql data frame writer mode saveMode
ml stop words remover set params inputCol outputCol stopWords caseSensitive
ml param has solver get solver
ml lshmodel approx similarity join datasetA datasetB threshold distCol
ml lda get optimize doc concentration
ml count vectorizer get binary
mllib stat statistics chi sq test observed expected
core spark context new apihadoop rdd inputFormatClass keyClass valueClass keyConverter
sql spark session init sparkContext jsparkSession
mllib random rdds uniform vector rdd sc numRows numCols numPartitions
mllib streaming kmeans test test predict on model
core merger merge values iterator
core spark conf contains key
core rdd collect as map
core rdd stats
ml train validation split model copy extra
core spark context enter
core stat counter as dict sample
ml linalg sparse matrix repr
ml polynomial expansion init degree inputCol outputCol
ml multilayer perceptron classifier get solver
ml one vs rest to java
streaming dstream persist storageLevel
mllib gaussian mixture model k
ml param params extract param map extra
ml lda get learning decay
ml lda get topic distribution col
ml generalized linear regression set params labelCol featuresCol predictionCol family
sql from json col schema options
ml word2vec set num partitions value
ml multilayer perceptron classification model layers
ml index to string set params inputCol outputCol labels
core rdd context
mllib streaming kmeans set half life halfLife timeUnit
sql data frame reader jdbc url table column lowerBound
sql data stream reader csv path schema sep encoding
core rdd aggregate zeroValue seqOp combOp
core task context tests test attempt number
ml multiclass classification evaluator get metric name
sql data frame alias alias
ml gaussian mixture summary log likelihood
ml java params empty java param map
sql shift right col numBits
mllib mlutils parse libsvm line line multiclass
core task context tests test stage id
core rdd cogroup other numPartitions
sql data frame writer orc path mode partitionBy compression
ml linear regression summary num instances
ml random forest classification model feature importances
sql sqlcontext register function name f returnType
ml decision tree model to debug string
ml param has seed set seed value
core rdd map partitions with index f preservesPartitioning
mllib linalg sparse matrix repr
ml logistic regression model summary
mllib linalg vectors squared distance v1 v2
streaming kafka stream tests test kafka rdd with leaders
ml generalized linear regression training summary p values
core external sorter get path n
core rdd flat map values f
core spark context add py file path
sql levenshtein left right
mllib linalg matrix to array
mllib multiclass metrics true positive rate label
ml generalized linear regression summary deviance
sql data stream reader text path
ml regex tokenizer get min token length
sql to json col options
sql streaming query id
core rdd repartition numPartitions
sql sha2 col numBits
sql struct type getitem key
core rdd local checkpoint
sql hash
core rdd get checkpoint file
mllib linalg dense matrix to array
streaming kafka stream tests test kafka rdd get offset ranges
ml one hot encoder set params dropLast inputCol outputCol
sql create map
sql data frame drop duplicates subset
ml lda set optimize doc concentration value
ml linear svc set params featuresCol labelCol predictionCol maxIter
ml random forest params set feature subset strategy value
ml multilayer perceptron classification model weights
streaming dstream count by value and window windowDuration slideDuration numPartitions
sql length col
core spark context add file path recursive
sql spark session catalog
ml java params from java java_stage
ml aftsurvival regression get censor col
sql lead col count default
mllib linalg block matrix num rows
ml word2vec model find synonyms word num
ml aftsurvival regression set censor col value
mllib linalg sparse vector num nonzeros
mllib linalg indexed row matrix multiply matrix
mllib streaming kmeans predict on values dstream
sql bin op name doc
streaming dstream map f preservesPartitioning
ml quantile discretizer set handle invalid value
ml linalg matrix to array
ml als set cold start strategy value
ml param type converters to boolean value
sql log2 col
sql repeat col n
ml param has aggregation depth get aggregation depth
sql window timeColumn windowDuration slideDuration startTime
mllib ranking metrics ndcg at k
ml train validation split get train ratio
sql column cast dataType
streaming rdd to file name prefix suffix timestamp
mllib matrix factorization model predict all user_product
mllib word2vec set seed seed
ml param has handle invalid set handle invalid value
mllib linalg vectors stringify vector
streaming flume utils create polling stream ssc addresses storageLevel maxBatchSize
sql sqlcontext sql sqlQuery
ml linear regression summary predictions
sql create window function name doc
ml decision tree classifier init featuresCol labelCol predictionCol probabilityCol
ml param has label col get label col
streaming dstream filter f
mllib multiclass metrics weighted false positive rate
sql data stream reader format source
ml linear regression summary features col
ml index to string init inputCol outputCol labels
ml param has thresholds set thresholds value
mllib java vector transformer transform vector
sql trunc date format
core worker sock
ml param has elastic net param get elastic net param
sql map type init keyType valueType valueContainsNull
mllib linalg matrices from ml mat
ml persistence test compare pipelines m1 m2
ml gaussian mixture summary probability
ml linear regression model evaluate dataset
ml mlreader context sqlContext
ml param params is defined param
mllib regression metrics root mean squared error
core rdd distinct numPartitions
