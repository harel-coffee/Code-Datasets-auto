neighbors	neighbors nearest among within radius estimators vote regression given based learner radius-based read implementing base user mixin class searches unsupervised classifier :ref neighbor <classification> fixed guide
code	based consist representing strategy error-correcting strategies multiclass output-code class
iterator	~test_mask _iter_test_indices implementations cv iterators define base _iter_test_masks train_mask = class must
exponentiation	kernel given exponent exponentiate
skip	used skipped warning user test class notify
manager	managing workers pool class helper
chi2sampler	map monte additive transform kernel chi2 approximation approximate approximates feature "skewed chi-squared" fourier carlo
dimensionality	dimensionality custom warning notify data potential issues
graph	<sparse_inverse_covariance> inverse :ref w/ cross-validated covariance choice penalty read estimator user sparse l1 estimation guide l1-penalized
to	raised hash real-valued turn transformed another fallback configuration array backend
batched	sequence args callable single tuples func kwargs wrap
elliptic	object distributed gaussian dataset detecting outliers
agglomeration	via features agglomeration transform feature interface agglomerate class
orthogonal	parameters orthogonal cross-validated omp pursuit model matching
void	used & - private signature marker parameter
multi	classification regularizer built-in regressor one cross-validation trained consists iterables regression iterable lasso transform per strategy fitting tuples objective : multilabel l1/l2 multi-task format elasticnet although model multi target intuitive list optimization multitaskelasticnet sets mixed-norm classifier
sgdoptimizer	optimizer descent parameters gradient stochastic momentum
customizable	locked implementation accepts custom pipe customizable uses pickler reducers
iter	helper m*x=b iterinv solve repeatedly class iteropinv
skewed	map monte transform kernel approximation approximates feature "skewed chi-squared" fourier carlo
leave	leave third-party group provides iterator sets data train/test cross one cross-validation p according split leave-p-out leave-p-label_out indices leave-one-label_out validation leave-one-out cross-validator
discrete	abstract class base discrete/categorical bayes data naive
multiprocessing	parallelbackend use multiprocessing pool
zlib	de compression zlib object file providing transparent
consistent	used hash items whatever order ensure preserved sets class
empirical	read <covariance> maximum covariance :ref estimator user likelihood guide
zero	zero estimator simply predicts
isomap	isometric dimensionality mapping reduction non-linear embedding isomap
mlpregressor	perceptron multi-layer regressor
bagging	bagging meta-estimator regressor classifier base class
zndarray	arrays instead persisted object numpy
sum	kernels + two k2 k1 sum-kernel
sequential	parallelbackend sequentially execute batches
memmap	files large dump arrays reducer callable memmap
net	regularizer built-in cross-validation trained regression best multi-task regularization elastic priors selected fitting combined elasticnet net : l1/l2 linear objective path along mixed-norm iterative optimization l2 multitaskelasticnet l1 model
boost	regressor adaboost classifier
completion	used parallel's callback joblib multiprocessing backend
hash	use used hash cosine pickle fingerprint produce real-valued turn objects won't lsh gaussianrandomprojection transformed array normally class
reporter	output verbose reports stdout
multinomial	function loss multi-class classification deviance multinomial naive models bayes suitable classifier
error	deviation moved moves regression absolute loading raise urllib_error six least fitting ls squares function lazy used lad objects class loss exception estimator error estimation arpack
pursuit	parameters orthogonal cross-validated omp pursuit model matching
sine	kernel exp-sine-squared
search	search hyper parameters estimator cross-validation randomized base values specified exhaustive parameter class
items	lazy loading moved objects
changed	used warning user behavior class change notify
queue	locked implementation pipe customizable uses pickler
prior	training probability predicting estimator data class
binomial	function loss classification binary deviance binomial
named	wraps description useful check show
shuffle	iterator random cross-validation randomized -out shufflesplit cross shuffle-labels-out split provides test permutation base shuffle-group data class training train/test stratifiedshufflesplit according yields stratified sets indices validation cross-validator
projection	projection fingerprint random reduce gaussian lsh n_components) projections array alternative use dimensionality dense matrix / 1 cosine transformed drawn hash components base gaussianrandomprojection real-valued class turn produce sparse n(0
classification	loss functions base class classification
extra	randomized tree regressor extra-trees extremely classifier
scaled	loss ratio log exponential -- odds scaled 0 5
perceptron	classification read <perceptron> regression :ref mlp base user guide perceptron class
sgd	regression base class classification sgd
select	false features rate benjamini-hochberg p-values estimated univariate select meta-transformer based feature configurable strategy fpr test discovery corresponding pvalues read selecting selector percentile uses user scores alpha highest importance <univariate_feature_selection> family-wise k according filter :ref weights error guide procedure
additive	map additive kernel chi2 approximate feature
zip	unpickler unpickle numpy pickles subclass
plssvd	square partial matrix perform svd least crosscovariance simply x'y
call	used parallel's callback joblib multiprocessing backend
memory	return input object value arguments context time caching function's called
batching	batching jobs class helper automagically
normalizer	normalize individually norm unit samples
envelope	object distributed gaussian dataset detecting outliers
normalized	kernels =1 k normalized mixin x
pout	leave-p-out iterator train/test cross split provides sets indices validation data cross-validator
det	determinant mcd covariance minimum estimator robust :
descriptor	implements protocol conditional descriptor using property
cviterable	style old wrapper cv objects iterables class
my	used hash pickle objects won't normally class
nearest	searches nearest unsupervised learner implementing centroid neighbor classifier
process	binary based classification laplace process gaussian class approximation legacy model gpc regression gpr
binarizer	set classification less one-vs-all labels transform fashion threshold regression iterable binary feature 1 0 tuples iterables algorithms several map greater format although data intuitive list according binarize values multilabel sets
collision	warn collision functions might names
incremental	incremental ipca analysis components principal
sgdclassifier	training svm linear classifiers sgd logistic regression
cfsubcluster	cfnode cfsubcluster called subcluster
absolute	function loss deviation lad least regression absolute
six	lazy loading urllib_error urllib_request namespace create six moved urllib_robotparser urllib python 3 objects urllib_response resembles urllib_parse moves
feature	implements transformer multiple features results feature trick objects aka agglomerate concatenates hashing
hot	features categorical one-of-k one-hot using encode integer aka scheme
forest	return algorithm isolation random trees forests isolationforest classifiers sample score regressor forest base using classifier anomaly class trees-based regressors
fpr	based pvalues filter fpr test alpha select
parameter	function sampled given parameters generator represents parameter number discrete values signature grid distributions
ensemble	classes base class ensemble
product	kernels kernel * two k2 k1 product-kernel dot-product
outlier	sample set lof methods factor unsupervised anomaly outlier covariance detection score estimators using outliers local called
max	given scale features feature value maximum scaling range transforms absolute
ransacregressor	ransac sample consensus random algorithm
mixin	neighbors set hash methods helper text x-y coding transform detection cluster meta estimators jobs automagically turn regression linear code kernels given mask k-neighbors density managing workers feature class transformed provides batching radius-based outliers = bicluster tokenization selection searches converting transformers performs tranformer format covariance selector coef_ normalized mixin real-valued classifiers pool =1 f k vectorizers scikit-learn array implementation common sparse logic x csr stationary support
hasher	cryptographic case hasher rather pickling feature subclass trick implements loaded aka pickler numpy special hashing
data	conversions dimensionality used potential happening code custom warning notify data implicit issues
parallel	parallelbackend abc methods helper readable mapping parallel implement must class defines
sp	spluinv
joblib	simple exception get message error
fallback	raised configuration fallback another backend
kneighbors	searches neighbors based k-neighbors classifier implementing k-nearest mixin vote regression
extractor	patches read extracts <image_feature_extraction> collection :ref user images guide
sigmoid	model regression sigmoid
bunch	datasets container dictionary-like keys object exposes attributes
cfnode	node cftree called cfnode
group	cross-validation third-party group provides iterator k-fold variant train/test non-overlapping according one leave shuffle-group split groups -out indices randomized data cross-validator
fit	used error fitting warning estimator class
lu	luinv spluinv
pca	kernel set methods kernels randomized incremental value reconstruct principal sparsepca use dimensionality reduction decomposition kpca pca non-linear linear singular component mini-batch base using class ipca components svd (see analysis optimally sparse finds
split	set iterator series random cross-validation randomized -out shufflesplit predefined cross shuffle-labels-out split samples folds test provides permutation base shuffle-group data class training/test training splits sets train/test stratifiedshufflesplit according yields stratified time indices validation cross-validator
non	use used blas warning operation dot
gcv	ridge efficient allows built-in cross-validation generalized leave-one-out regression
bernoulli	multivariate models bernoulli naive rbm machine boltzmann bayes restricted classifier
safe	serialization handles exception wrapper tracebacks
bound	bind holds mapping call result signature arguments
compound	composed kernel set kernels
not	function exception used raise array object convertable value fitting estimator no-op arbitrary decorating representing class
iff	implements protocol conditional descriptor using property
transportable	info exception recreate containing wrap original
classifier	neighbors sigmoid random cross-validation consists aggressive based probability extra-trees passive simple rules using scikit-learn pipelining soft classifier built-in gaussian approximation <passive_aggressive> radius bagging gradient decision per linear error-correcting base boosting output-code one-vs-one implementing laplace makes among classification one-vs-all within one randomized k-nearest estimators vote gpc given ridge predictions strategy known representing classifiers multi target consist tree voting/majority strategies meta-estimators guide trees-based process regression binary calibration multiclass also fitting forest test isotonic ovr user mixin pair extremely class one-vs-the-rest dummy read multiclass/multilabel dummyclassifier rule :ref adaboost unfitted <classification>
mean	clustering flat training kernel shift predicting estimator using targets mean
weight	estimators base class adaboost
series	samples series train/test split provides time indices data cross-validator
gaussian	via projection classification process fingerprint random reduce gaussian lsh n_components) approximation legacy n(0 regression 1 use dimensionality based matrix parameters perform / gpc partial_fit cosine online drawn variational method gpr mixture binary naive gaussiannb produce bayes gaussianrandomprojection bayesian class components model estimation laplace updates
meta	meta scikit-learn class mixin estimators
mds	read scaling :ref user multidimensional <multidimensional_scaling> guide
out	leave third-party group iterator sets data train/test cross one cross-validation p according split provides leave-p-label_out indices leave-one-label_out validation leave-one-out cross-validator
predefined	predefined set splits iterator folds cross according training/test split validation data cross-validator
dbscan	clustering distance dbscan matrix perform vector array
gradient	classification gradient abstract regression base boosting class
squared	kernel exp-sine-squared
rational	kernel quadratic rational
print	keeping log track messages time print
squares	function loss estimation least ls squares
bicluster	estimators scikit-learn class mixin bicluster
linear	selection classification randomized regression regularization discriminant decision locally classifiers feature least strategy models fitting boundary squares classifier model linear <locally_linear_embedding> read generated base user mixin buhlman path along class ordinary implements meinshausen iterative analysis guide :ref vector embedding implement support
dictionary	represent set dictionary mini-batch atoms used learning data finds best
coef	converting format coef_ mixin csr
standard	independently centering standardize features computing removing feature scaling variance happen unit mean
base	neighbors composed hyper stratifiedkfold random forests cross-validation selection univariate parameters stochastic pca mixture trees notes scikit-learn vector methods library projections bagging abc gradient decision _iter_test_masks label linear approaches base bayes boosting initialize search stratifiedshufflesplit propagation libsvm-based implement parallelbackend named classification kfold randomized estimators shufflesplit sgd use management support strategy handles define naive module classifiers must _iter_test_indices mlp classes nearest helper backing abstract meta-estimator implementations regression defines descent feature machine discrete/categorical biclustering parameter ensemble spectral optimizer models libsvm groupkfold validate data class implements meinshausen cross-validators adaboost buhlman
boosting	classification gradient abstract estimators regression base adaboost boosting class
dirichlet	dirichlet latent algorithm allocation bayes online variational
deprecated	function deprecated class decorator mark
filter	initialize selection univariate feature
signature	function represents object overall signature
mlpclassifier	perceptron multi-layer classifier
rbfsampler	kernel monte transform map approximates feature approximation rbf fourier carlo
features	polynomial interaction generate features
probability	training probability predicting estimator data class
coding	coding mixin sparse
one	features iterator one-vs-all detection one cross-validation known using consists strategy leave-one-out group categorical cross per multiclass also fitting split provides encode scheme ovr outlier third-party one-hot one-of-k pair integer data class one-vs-the-rest one-vs-one unsupervised multiclass/multilabel train/test according leave sets indices leave-one-label_out aka validation classifier cross-validator
randomized	selection principal randomized hyper subsampling regression lasso parameters feature strategy pca linear models class component training base using implement implements search meinshausen svd analysis logistic buhlman works
least	function loss estimation deviation lad least ls squares regression absolute
array	files large object dump arrays reducer convertable callable persisted instead memmap array numpy
verbose	output verbose reports stdout
wrapper	style old arrays object wrapper cv persisted objects iterables instead numpy class
theil	multivariate estimator theil-sen robust model regression
white	kernel white
blasdot	use used blas warning operation dot
selector	given selection performs tranformer implementation support mask feature provides transform mixin selector
centerer	kernel phi center defined k ^t let x z matrix
isolation	return algorithm isolation isolationforest sample score forest using anomaly
tree	decision tree regressor trees classifier randomized base extremely class
pairwise	metrics kernels pairwise wrapper sklearn
stratified	k-fold iterator sets train/test cross repeated validator stratified provides k-folds indices shufflesplit validation data cross-validator split
mini	represent set <mini_batch_kmeans> learning best principal clustering used components dictionary read mini-batch atoms user reconstruct data k-means analysis finds :ref optimally sparse guide
memmaping	process avoid shares large arrays memory copy pool
conversion	conversions used happening code warning notify data implicit
lib	implements warn use vector classification backing support libsvm library regression machine collision base names estimators might class functions
min	determinant features given mcd covariance feature scaling range minimum transforms estimator robust :
hyperparameter	kernel specification hyperparameter's form namedtuple
plsregression	implements pls1 pls2 blocks plsregression 2 known pls regression
isotonic	model regression isotonic
vectorizer	code features produces text raw occurrences counts documents mappings vectorizers implementation provides common lists scipy collection using matrix convert turns vectors tf-idf feature-value token tokenization sparse logic representation transforms
spectral	spectral clustering dimensionality co-clustering embedding algorithm projection dhillon kluger laplacian 2003 reduction non-linear normalized biclustering base apply class 2001
optimizer	optimizer descent parameters gradient note default paper base values adam stochastic original
warnings	improved warnings python manager simplified context decorator
pickling	locked implementation pickling pipe customizable uses pickler pool reducers
class	detection outlier unsupervised
dummy	simple dummyclassifier predictions regressor rules using makes classifier dummyregressor
partition	~test_mask _iter_test_indices implementations cv iterators define base _iter_test_masks train_mask = class must
request	lazy loading urllib_request six moved objects moves
exp	kernel exp-sine-squared
voting	rule voting/majority estimators unfitted soft classifier
dot	kernel dot-product
random	projection fingerprint random reduce gaussian lsh n_components) projections alternative use dimensionality dense matrix / 1 cosine forest drawn ensemble components trees regressor base gaussianrandomprojection totally class produce sparse classifier n(0
lshforest	nearest search performs approximate lsh forest neighbor using
threshold	features removes feature low-variance selector
aggressive	read regressor guide passive :ref user <passive_aggressive> aggressive classifier
vbgmm	model mixture variational inference gaussian
latent	dirichlet latent algorithm allocation bayes online variational
ledoit	ledoit-wolf form shrinkage estimator ledoitwolf particular
failed	used error fitting warning estimator class
abs	scale absolute feature value maximum
dict	mappings vectors transforms lists feature-value
factor	sample latent linear unsupervised simple anomaly variables outlier gaussian analysis detection fa score factor generative using model local called lof
local	sample lof outlier anomaly unsupervised detection score factor using local called
mixture	mixture models gaussian base estimation bayesian variational class
hungarian	state execution algorithm hungarian one
trees	random regressor trees classifier extra-trees totally ensemble
patch	patches read extracts <image_feature_extraction> collection :ref user images guide
tfidf	count convert inverse matrix means tf-idf transform collection term-frequency raw documents normalized tf representation times features
threading	parallelbackend use batches thread execute pool
rfe	elimination ranking feature recursive
kernel	composed kernel set constant defined regression principal kernels use dimensionality ridge matrix density user wrapper reduction kpca white = phi non-linear =1 read operators component metrics base let normalized mixin class z center f <kernel_density> k ^t (see analysis :ref pairwise x-y x estimation stationary guide sklearn
set	used hash items whatever order ensure preserved sets class
regressor	neighbors simple tree random regressor <passive_aggressive> one randomized k-nearest radius theil-sen estimators consists aggressive regression dummyregressor bagging robust based gradient decision predictions per strategy passive extra-trees fitting forest outliers gpr regressors multivariate process within linear rules gaussian base user mixin boosting using extremely class multi target read scikit-learn :ref estimator adaboost model fixed makes guide trees-based
module	lazy loading urllib_error urllib_request namespace create six moved urllib_robotparser urllib python 3 objects urllib_response resembles urllib_parse moves
detection	set methods covariance detection estimators outliers
radius	neighbors searches given :ref based among read within classifier implementing radius-based user mixin guide vote radius <classification> fixed regression
result	cached object value arbitrary representing class
sen	multivariate estimator theil-sen robust model regression
coclustering	spectral dhillon 2001 co-clustering algorithm
urllib	lazy loading urllib_error urllib_request namespace create six moved urllib_robotparser urllib python 3 objects urllib_response resembles urllib_parse moves
label	fashion iterator one-vs-all list labels module cross-validation learning semi-supervised regression iterable binary classification propagation format transform <label_propagation> label shuffle-labels-out 0 tuples basic encode several k-fold read n_classes-1 variant iterables base user although class intuitive algorithm labelspreading non-overlapping value classifier binarize :ref algorithms multilabel sets leave-one-label_out model similar guide
state	state execution algorithm hungarian one
efficiency	used inefficient warning notify computation user
job	warn collision functions might names
sgdregressor	loss linear gradient descent empirical regularized minimizing stochastic model sgd fitted stands
memorized	function return time cached object value called callable no-op arbitrary caching decorating representing class
fitted	exception used raise fitting estimator class
propagation	clustering :ref perform module label <label_propagation> propagation base affinity user read guide data class classifier
embedding	spectral non-linear linear <locally_linear_embedding> read locally trees ensemble random :ref reduction dimensionality user embedding totally guide
variance	features removes feature low-variance selector
learning	represent set dictionary mini-batch atoms used learning data finds best
polynomial	polynomial interaction generate features
cv	logistic hyper probability sigmoid w/ <least_angle_regression> built-in cross-validation randomized specified path regression best lasso lars regularization inverse angle parameters calibration selected least matching penalty fitting optimization ridge objective exhaustive : parameter isotonic multi-task l1/l2 linear orthogonal read cross-validated covariance choice elasticnet base cv user elastic using along class logit maxent search net algorithm omp iterative classifier <sparse_inverse_covariance> :ref estimator values sparse l1 model aka guide pursuit
robotparser	lazy loading six moved urllib_robotparser objects moves
backend	parallelbackend sequentially execute abc raised methods helper use backend thread another batches configuration implement defines fallback multiprocessing pool must
discriminant	linear discriminant decision fitting analysis class generated quadratic boundary classifier
union	transformer objects multiple results concatenates
quantile	function loss training quantile alpha-quantile predicting regression estimator targets
affinity	perform propagation affinity data clustering
numpy	case pickler big arrays persist unpickler object subclass data persisted unpickle instead loaded pickles hasher numpy special efficiently
tsne	t-distributed embedding neighbor stochastic
ada	regressor adaboost classifier
worker	keyboardinterrupt exception interrupted allow subprocesses
covariance	read shrinkage <covariance> maximum covariance :ref estimator user <shrunk_covariance> likelihood guide
func	function return object no-op callable value time caching decorating called
bayesian	regularization mixture ridge parameters fit gaussian optimize estimation bayesian model variational regression
exception	info exception get simple recreate containing error wrap message original
splits	splitter splits randomized repeated arbitrary cv
exponential	function loss classification exponential binary
cov	determinant mcd covariance minimum estimator robust :
batch	represent set <mini_batch_kmeans> learning best backend clustering :ref parallel's principal used components dictionary read mini-batch atoms user guide reconstruct data k-means analysis finds callback optimally sparse joblib multiprocessing
rbm	machine bernoulli boltzmann rbm restricted
behavior	used warning user behavior class change notify
fwe	corresponding <univariate_feature_selection> family-wise read p-values filter :ref rate user error guide select
rbf	function kernel aka radial-basis squared-exponential
rfecv	ranking selection recursive cross-validated feature number elimination best features
metric	metric warning invalid used
parse	lazy loading six moved objects urllib_parse moves
cluster	cluster scikit-learn class mixin estimators
vs	ovr one-vs-one multiclass one-vs-all multiclass/multilabel per strategy also fitting pair consists known one class classifier one-vs-the-rest
ic	lars selection fit bic optimization objective using model : aic lasso
shift	clustering flat kernel shift using mean
regression	logit loss functions squares classifier linear maxent training least class randomized base cv subsampling logistic aka model works regression isotonic ordinary
binary	binary de based compression classification process zlib gaussian object laplace approximation file gzip providing transparent
generic	strategy configurable univariate feature selector
cross	_iter_test_indices implementations cross-validators base _iter_test_masks must class define
arguments	bind holds mapping call result signature arguments
auto	batching jobs class helper automagically
composition	composed named management handles estimators parameter classifiers
agglomerative	clustering agglomerative minimally merges recursively increases pair clusters
allocation	dirichlet latent algorithm allocation bayes online variational
birch	implements clustering algorithm birch
robust	scale features statistics robust using outliers
task	l1/l2 multi-task regularizer built-in cross-validation objective optimization multitaskelasticnet trained elasticnet model : mixed-norm lasso
undefined	metric warning invalid used
calibration	model regression sigmoid
analysis	gaussian model latent linear discriminant simple decision fitting analysis class fa generated quadratic factor generative variables boundary classifier
calibrated	regression sigmoid isotonic probability calibration
gzip	object compression de file gzip providing transparent
model	selection features randomized implement meta-transformer regularization based feature strategy importance fitting linear models selecting class base path along buhlman implements meinshausen iterative weights model
cca	correlation cca analysis canonical
logistic	logit training maxent randomized cv logistic aka subsampling works regression classifier
rest	ovr one-vs-all multiclass/multilabel strategy also fitting consists known one classifier one-vs-the-rest
interrupt	keyboardinterrupt exception interrupted allow subprocesses
univariate	strategy configurable univariate feature selector
lasso	selection regularizer w/ built-in cross-validation randomized mixed-norm trained path regression best lasso lars regularization inverse angle fit prior selected least penalty fitting optimization objective : bic multi-task l1/l2 linear read cross-validated covariance choice user using along aka algorithm k iterative <sparse_inverse_covariance> :ref estimator aic sparse l1 model estimation guide l1-penalized
transformer	count transformer inverse transformers matrix means tf-idf scikit-learn transform term-frequency callable normalized mixin arbitrary tf representation times class constructs
scaler	features computing transforms using happen unit absolute given statistics centering removing feature outliers standardize scaling scale robust independently maximum value range variance mean
gmm	model mixture legacy gaussian
density	kernel <kernel_density> density read scikit-learn guide :ref user mixin estimators estimation class
unpickler	unpickler unpickle numpy pickles subclass
ardregression	bayesian ard regression
passive	read regressor guide passive :ref user <passive_aggressive> aggressive classifier
dpgmm	process models mixture dirichlet gaussian
sampler	sampled given distributions parameters generator
oas	read shrinkage <shrunk_covariance> :ref estimator user oracle approximating guide
logger	messages base logging class
has	implements protocol conditional descriptor using property
pgroups	third-party group train/test according leave p split provides indices data cross-validator
checking	test dummy meta-estimators classifier pipelining
grid	search parameters number discrete estimator values specified grid exhaustive parameter
loss	function loss functions exponential classification binary huber abstract quantile regression base various robust class
deviance	function loss classification binary multinomial deviance binomial multi-class
reducer	files large dump arrays reducer callable memmap
ignore	improved warnings python manager simplified context decorator
sparse	set projection random coding converting alternative principal sparsepca dimensionality dense matrix format csr sparse precomputed reduce mini-batch coef_ mixin reconstruct data analysis optimally components representation fixed finds
output	multi based target classification consist representing class regressor per strategy error-correcting fitting multiclass consists strategies one output-code regression classifier
response	lazy loading six moved objects urllib_response moves
stationary	kernels f stationary k x-y mixin x =
truncated	dimensionality truncated svd lsa reduction using aka
back	used parallel's callback joblib multiprocessing backend
pickler	big accepts custom efficiently persist pickler data reducers
matching	parameters orthogonal cross-validated omp pursuit model matching
lars	selection <least_angle_regression> regression lasso lars angle fit least objective : read cross-validated bic user using lar algorithm k :ref optimization model guide aic
imputer	transformer values completing imputation missing
ica	independent algorithm component analysis fastica fast
centroid	nearest centroid classifier
plscanonical	implements blocks [tenenhaus algorithm p 2 wold 1998] pls plscanonical original canonical
pls	implements pls parameters algorithm generic least partial squares class constructors'
huber	function loss linear huber robust model outliers regression
nmf	whose product non-negative matrix h non- two factorization approximates nmf w matrices find
percentile	features according percentile scores highest select
from	meta-transformer based features importance selecting weights
pipeline	pipeline estimator transforms final
matern	kernel matern
estimator	probability scaled zero meta simply predicts estimators targets ratio log 0 5 predicting base mixin data class loss training alpha-quantile exponential -- notes scikit-learn estimator odds mean
wolf	ledoit-wolf form shrinkage estimator ledoitwolf particular
plabel	cross-validation iterator leave-p-label_out
op	iteropinv
dpgmmbase	mixture inference gaussian infinite model variational
kfold	stratifiedkfold iterator kfold labels cross split provides k-fold sets variant approaches base groups groupkfold validate data class train/test non-overlapping repeated validator stratified k-folds indices validation cross-validator
spreading	algorithm labelspreading label propagation learning basic model similar semi-supervised
kmeans	clustering <mini_batch_kmeans> read k-means mini-batch <k_means> :ref user guide
operator	kernel operators base class
clustering	clustering agglomerative minimally merges recursively laplacian increases normalized apply pair clusters projection
ridge	kernel regularization ridge parameters fit efficient generalized built-in least optimize cross-validation l2 classifier bayesian using model squares leave-one-out regression allows linear
log	loss ratio log exponential -- odds predicting scaled 0 estimator 5
elastic	regularizer built-in cross-validation trained regression best multi-task regularization elastic priors selected fitting combined elasticnet net : l1/l2 linear objective path along mixed-norm iterative optimization l2 multitaskelasticnet l1 model
multilayer	mlp base class classification regression
transform	via agglomeration transform feature interface class
fast	independent algorithm component analysis fastica fast
svd	dimensionality truncated svd lsa reduction using aka
quadratic	kernel discriminant decision analysis generated quadratic rational boundary classifier
ndarray	arrays instead persisted object numpy
nystroem	subset kernel training map approximate using data
function	function loss exception transformer classification huber abstract quantile constructs functions wrapper regression callable arbitrary handles base various robust serialization class tracebacks
gmmbase	model mixture gaussian
encoder	features categorical one-of-k labels 0 value one-hot using encode integer aka scheme n_classes-1
repeated	splitter splits k-fold cross randomized repeated validator stratified arbitrary cv
convergence	capture iteration problems custom warning convergence attributes converge arpack
count	convert documents matrix produces implementation text collection token sparse using representation counts
attr	implements protocol conditional descriptor using property
shrunk	read shrinkage covariance :ref estimator user <shrunk_covariance> guide
fdr	false filter rate uses procedure p-values benjamini-hochberg estimated select discovery
locally	linear <locally_linear_embedding> read locally :ref user embedding guide
arpack	attributes iteration converge arpack error
laplace	binary based classification process gaussian approximation laplace
constant	kernel constant
inv	helper m*x=b iterinv luinv solve repeatedly class spluinv iteropinv
moved	lazy loading moved objects
an	convertable object array
warning	conversions code blas collision warning notify computation operation issues capture use dimensionality invalid custom fitting potential test might metric used inefficient class problems functions warn user convergence data implicit change happening skipped estimator behavior error dot names
file	de compression zlib object file gzip providing transparent
moves	lazy loading urllib_error urllib_request namespace create six moved urllib_robotparser urllib python 3 objects urllib_response resembles urllib_parse moves
check	wraps description useful check show
coder	precomputed coding sparse representation fixed data finds
no	iteration attributes arpack converge
nb	via classification abstract gaussian estimators parameters perform partial_fit models discrete/categorical online method multivariate multinomial bernoulli naive gaussiannb base bayes data class model suitable classifier updates
kbest	features k according scores highest select
biclustering	spectral 2003 biclustering kluger
test	used skipped warning user test class notify
nu	classification support nu vector nu-support regression
pool	memory process managing helper implementation avoid pickling workers shares large customizable arrays copy class pool reducers
hashing	convert documents matrix text collection token scipy occurrences turns
svm	implements machine use vector classification outlier backing support unsupervised libsvm library regression detection base estimators class
calls	sequence args callable single tuples func kwargs wrap
odds	loss ratio log exponential -- odds predicting scaled 0 estimator 5
svc	abc linear classification support vector nu-support c-support libsvm-based classifiers
validator	_iter_test_indices implementations cross-validators base _iter_test_masks must class define
adam	optimizer descent gradient note default paper values adam stochastic original
time	keeping log track series train/test messages indices samples split provides time print data cross-validator
svr	linear support regression vector epsilon-support nu
decision	decision tree regressor trees classifier base class
