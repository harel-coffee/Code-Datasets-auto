shuffle split	random permutation cross-validation iterator
white kernel	white kernel
local outlier factor	unsupervised outlier detection using local outlier factor lof the anomaly score of each sample is called local outlier factor
meta estimator mixin	mixin class for all meta estimators in scikit-learn
extra trees regressor	an extra-trees regressor
ardregression	bayesian ard regression
dpgmm	dirichlet process gaussian mixture models
patch extractor	extracts patches from a collection of images read more in the :ref user guide <image_feature_extraction>
job lib collision warning	warn that there might be a collision between names of functions
lasso lars cv	cross-validated lasso using the lars algorithm the optimization objective for lasso is :
least absolute error	loss function for least absolute deviation lad regression
stratified kfold	stratified k-folds cross-validator provides train/test indices to split data in train/test sets
linear discriminant analysis	linear discriminant analysis a classifier with a linear decision boundary generated by fitting class
select from model	meta-transformer for selecting features based on importance weights
elastic net	linear regression with combined l1 and l2 priors as regularizer
label kfold	k-fold iterator variant with non-overlapping labels
nmf	non-negative matrix factorization nmf find two non-negative matrices w h whose product approximates the non-
exponentiation	exponentiate kernel by given exponent
binary gaussian process classifier laplace	binary gaussian process classification based on laplace approximation
svr	epsilon-support vector regression
base label propagation	base class for label propagation module
random trees embedding	an ensemble of totally random trees
hasher	a subclass of pickler to do cryptographic hashing rather than pickling
density mixin	mixin class for all density estimators in scikit-learn
label binarizer	binarize labels in a one-vs-all fashion several regression and binary classification algorithms are
spectral embedding	spectral embedding for non-linear dimensionality reduction
signature	a signature object represents the overall signature of a function
randomized search cv	randomized search on hyper parameters
base weight boosting	base class for adaboost estimators
numpy pickler	a pickler to persist big data efficiently
dummy classifier	dummyclassifier is a classifier that makes predictions using simple rules
parameter sampler	generator on parameters sampled from given distributions
stratified shuffle split	stratified shufflesplit cross validation iterator
verbose reporter	reports verbose output to stdout
perceptron	perceptron read more in the :ref user guide <perceptron>
regressor mixin	mixin class for all regression estimators in scikit-learn
rfe	feature ranking with recursive feature elimination
randomized logistic regression	randomized logistic regression randomized logistic regression works by subsampling the training
quadratic discriminant analysis	quadratic discriminant analysis a classifier with a quadratic decision boundary generated
nearest neighbors	unsupervised learner for implementing neighbor searches
dummy regressor	dummyregressor is a regressor that makes predictions using simple rules
cfsubcluster	each subcluster in a cfnode is called a cfsubcluster
safe function	wrapper that handles the serialization of exception tracebacks
multinomial deviance	multinomial deviance loss function for multi-class classification
rfecv	feature ranking with recursive feature elimination and cross-validated selection of the best number of features
zndarray wrapper	an object to be persisted instead of numpy arrays
lasso	linear model trained with l1 prior as regularizer aka the lasso the optimization objective for lasso is :
normalizer	normalize samples individually to unit norm
base decision tree	base class for decision trees
tfidf vectorizer	convert a collection of raw documents to a matrix of tf-idf features
spectral coclustering	spectral co-clustering algorithm dhillon 2001
leave one out	leave-one-out cross-validator provides train/test indices to split data in train/test sets
selector mixin	tranformer mixin that performs feature selection given a support mask this mixin provides a feature selector implementation with transform and
mlpclassifier	multi-layer perceptron classifier
auto batching mixin	a helper class for automagically batching jobs
sgdoptimizer	stochastic gradient descent optimizer with momentum parameters
customizable pickler	pickler that accepts custom reducers
base gradient boosting	abstract base class for gradient boosting
base nb	abstract base class for naive bayes estimators
ignore warnings	improved and simplified python warnings context manager and decorator
linear model cv	base class for iterative model fitting along a regularization path
base lib svm	base class for estimators that use libsvm as backing library this implements support vector machine classification and regression
elliptic envelope	an object for detecting outliers in a gaussian distributed dataset
fallback to backend	raised when configuration should fallback to another backend
extra trees classifier	an extra-trees classifier
vectorizer mixin	provides common code for text vectorizers tokenization logic
memory	a context object for caching a function's return value each time it is called with the same input arguments
adam optimizer	stochastic gradient descent optimizer with adam note all default values are from the original adam paper
label spreading	labelspreading model for semi-supervised learning this model is similar to the basic label propagation algorithm
tsne	t-distributed stochastic neighbor embedding
spectral clustering	apply clustering to a projection to the normalized laplacian
passive aggressive classifier	passive aggressive classifier read more in the :ref user guide <passive_aggressive>
lshforest	performs approximate nearest neighbor search using lsh forest
sparse coef mixin	mixin for converting coef_ to and from csr format
calibrated classifier	probability calibration with isotonic regression or sigmoid
scaled log odds estimator	log odds ratio scaled by 0 5 -- for exponential loss
binary zlib file	a file object providing transparent zlib de compression
sgdclassifier	linear classifiers svm logistic regression a o with sgd training
gmmbase	gaussian mixture model
sum	sum-kernel k1 + k2 of two kernels k1 and k2
zip numpy unpickler	a subclass of the unpickler to unpickle our numpy pickles
threading backend	a parallelbackend which will use a thread pool to execute batches in
base randomized linear model	base class to implement randomized linear models for feature selection this implements the strategy by meinshausen and buhlman
gradient boosting classifier	gradient boosting for classification
print time	print and log messages while keeping track of time
label encoder	encode labels with value between 0 and n_classes-1
lasso lars	lasso model fit with least angle regression a k a lars
skewed chi2sampler	approximates feature map of the "skewed chi-squared" kernel by monte carlo approximation of its fourier transform
ridge gcv	ridge regression with built-in generalized cross-validation it allows efficient leave-one-out cross-validation
module six moves urllib response	lazy loading of moved objects in six moves urllib_response
logistic regression	logistic regression aka logit maxent classifier
lasso lars ic	lasso model fit with lars using bic or aic for model selection the optimization objective for lasso is :
leave pout	leave-p-out cross validation iterator
leave one group out	leave one group out cross-validator provides train/test indices to split data according to a third-party
nu svc	nu-support vector classification
changed behavior warning	warning class used to notify the user of any change in the behavior
base spectral	base class for spectral biclustering
elastic net cv	elastic net model with iterative fitting along a regularization path the best model is selected by cross-validation
plsregression	pls regression plsregression implements the pls 2 blocks regression known as pls2 or pls1
predefined split	predefined split cross-validator splits the data into training/test set folds according to a predefined
pca	principal component analysis pca linear dimensionality reduction using singular value decomposition of the
incremental pca	incremental principal components analysis ipca
module six moves urllib request	lazy loading of moved objects in six moves urllib_request
fit failed warning	warning class used if there is an error while fitting the estimator
base shuffle split	base class for shufflesplit and stratifiedshufflesplit
sp lu inv	spluinv
arpack error	arpack error
sparse random projection	reduce dimensionality through sparse random projection sparse random matrix is an alternative to dense random
group kfold	k-fold iterator variant with non-overlapping groups
passive aggressive regressor	passive aggressive regressor read more in the :ref user guide <passive_aggressive>
kernel ridge	kernel ridge regression
gaussian mixture	gaussian mixture
radius neighbors regressor	regression based on neighbors within a fixed radius
product	product-kernel k1 * k2 of two kernels k1 and k2
base pca	base class for pca methods
void	a private marker - used in parameter & signature
binarizer	binarize data set feature values to 0 or 1 according to a threshold values greater than the threshold map to 1 while values less than
repeated kfold	repeated k-fold cross validator
logistic regression cv	logistic regression cv aka logit maxent classifier
not fitted error	exception class to raise if estimator is used before fitting
huber loss function	huber loss function for robust regression
polynomial features	generate polynomial and interaction features
lars cv	cross-validated least angle regression model read more in the :ref user guide <least_angle_regression>
select kbest	select features according to the k highest scores
data dimensionality warning	custom warning to notify potential issues with data dimensionality
dbscan	perform dbscan clustering from vector array or distance matrix
efficiency warning	warning used to notify the user of inefficient computation
sgdregressor	linear model fitted by minimizing a regularized empirical loss with sgd sgd stands for stochastic gradient descent the gradient of the loss is
graph lasso	sparse inverse covariance estimation with an l1-penalized estimator
isolation forest	isolation forest algorithm return the anomaly score of each sample using the isolationforest algorithm
min max scaler	transforms features by scaling each feature to a given range
kernel centerer	center a kernel matrix let k x z be a kernel defined by phi x ^t phi z where phi is a
dpgmmbase	variational inference for the infinite gaussian mixture model
checking classifier	dummy classifier to test pipelining and meta-estimators
shuffle split	random permutation cross-validator yields indices to split data into training and test sets
select fwe	filter select the p-values corresponding to family-wise error rate read more in the :ref user guide <univariate_feature_selection>
stationary kernel mixin	mixin for kernels which are stationary k x y = f x-y
leave plabel out	leave-p-label_out cross-validation iterator
classification loss function	base class for classification loss functions
log odds estimator	an estimator predicting the log odds ratio
module six moves urllib parse	lazy loading of moved objects in six moves urllib_parse
rational quadratic	rational quadratic kernel
pipeline	pipeline of transforms with a final estimator
worker interrupt	an exception that is not keyboardinterrupt to allow subprocesses to be interrupted
base search cv	base class for hyper parameter search with cross-validation
base multilayer perceptron	base class for mlp classification and regression
orthogonal matching pursuit cv	cross-validated orthogonal matching pursuit model omp parameters
lasso cv	lasso linear model with iterative fitting along a regularization path the best model is selected by cross-validation
factor analysis	factor analysis fa a simple linear generative model with gaussian latent variables
plssvd	partial least square svd simply perform a svd on the crosscovariance matrix x'y
robust scaler	scale features using statistics that are robust to outliers
calibrated classifier cv	probability calibration with isotonic regression or sigmoid
logger	base class for logging messages
loss function	abstract base class for various loss functions
min cov det	minimum covariance determinant mcd : robust estimator of covariance
transformer mixin	mixin class for all transformers in scikit-learn
ransacregressor	ransac random sample consensus algorithm
kmeans	k-means clustering read more in the :ref user guide <k_means>
base forest	base class for forests of trees
cfnode	each node in a cftree is called a cfnode
decision tree regressor	a decision tree regressor
truncated svd	dimensionality reduction using truncated svd aka lsa
parameter grid	grid of parameters with a discrete number of values for each
shrunk covariance	covariance estimator with shrinkage read more in the :ref user guide <shrunk_covariance>
neighbors base	base class for nearest neighbors estimators
partition iterator	base class for cv iterators where train_mask = ~test_mask implementations must define _iter_test_masks or _iter_test_indices
sequential backend	a parallelbackend which will execute all batches sequentially
ledoit wolf	ledoitwolf estimator ledoit-wolf is a particular form of shrinkage where the shrinkage
regression loss function	base class for regression loss functions
output code classifier	error-correcting output-code multiclass strategy output-code based strategies consist in representing each class with a
bicluster mixin	mixin class for all bicluster estimators in scikit-learn
one hot encoder	encode categorical integer features using a one-hot aka one-of-k scheme
repeated splits	repeated splits for an arbitrary randomized cv splitter
iter inv	iterinv helper class to repeatedly solve m*x=b
kneighbors classifier	classifier implementing the k-nearest neighbors vote
skip test warning	warning class used to notify the user of a test that was skipped
zero estimator	an estimator that simply predicts zero
arpack no convergence	arpack iteration did not converge attributes
base composition	handles parameter management for classifiers composed of named estimators
repeated stratified kfold	repeated stratified k-fold cross validator
kernel	base class for all kernels
parallel backend base	helper abc which defines all methods a parallelbackend must implement
sparse coder	sparse coding finds a sparse representation of data against a fixed precomputed
module six moves urllib error	lazy loading of moved objects in six moves urllib_error
module six moves urllib robotparser	lazy loading of moved objects in six moves urllib_robotparser
kfold	k-folds cross validation iterator
not an array	an object that is convertable to an array
multi task lasso cv	multi-task l1/l2 lasso with built-in cross-validation
imputer	imputation transformer for completing missing values
multi output classifier	multi target classification this strategy consists of fitting one classifier per target
mini batch kmeans	mini-batch k-means clustering read more in the :ref user guide <mini_batch_kmeans>
forest classifier	base class for forest of trees-based classifiers
lu inv	luinv
sparse pca	sparse principal components analysis sparsepca finds the set of sparse components that can optimally reconstruct
bound arguments	result of signature bind call holds the mapping of arguments
multi task elastic net cv	multi-task l1/l2 elasticnet with built-in cross-validation
memmaping pool	process pool that shares large arrays to avoid memory copy
one vs one classifier	one-vs-one multiclass strategy this strategy consists in fitting one classifier per class pair
multiprocessing backend	a parallelbackend which will use a multiprocessing pool
quantile estimator	an estimator predicting the alpha-quantile of the training targets
classifier mixin	mixin class for all classifiers in scikit-learn
decision tree classifier	a decision tree classifier
function transformer	constructs a transformer from an arbitrary callable
kfold	k-folds cross-validator provides train/test indices to split data in train/test sets
standard scaler	standardize features by removing the mean and scaling to unit variance centering and scaling happen independently on each feature by computing
outlier detection mixin	set of methods for outliers detection with covariance estimators
base mixture	base class for mixture models
linear classifier mixin	mixin for linear classifiers
binary gzip file	a file object providing transparent gzip de compression
kneighbors regressor	regression based on k-nearest neighbors
transportable exception	an exception containing all the info to wrap an original exception and recreate it
kernel density	kernel density estimation read more in the :ref user guide <kernel_density>
base ensemble	base class for all ensemble classes
huber regressor	linear regression model that is robust to outliers
ada boost classifier	an adaboost classifier
my hash	class used to hash objects that won't normally pickle
ridge classifier cv	ridge classifier with built-in cross-validation
stratified shuffle split	stratified shufflesplit cross-validator provides train/test indices to split data in train/test sets
select percentile	select features according to a percentile of the highest scores
prior probability estimator	an estimator predicting the probability of each class in the training data
dict vectorizer	transforms lists of feature-value mappings to vectors
batched calls	wrap a sequence of func args kwargs tuples as a single callable
numpy array wrapper	an object to be persisted instead of numpy arrays
orthogonal matching pursuit	orthogonal matching pursuit model omp parameters
memorized func	callable object decorating a function for caching its return value each time it is called
base svc	abc for libsvm-based classifiers
additive chi2sampler	approximate feature map for additive chi2 kernel
ridge cv	ridge regression with built-in cross-validation
normalized kernel mixin	mixin for kernels which are normalized k x x =1
ndarray wrapper	an object to be persisted instead of numpy arrays
multi task lasso	multi-task lasso model trained with l1/l2 mixed-norm as regularizer the optimization objective for lasso is :
empirical covariance	maximum likelihood covariance estimator read more in the :ref user guide <covariance>
non blasdot warning	warning used when the dot operation does not use blas
cviterable wrapper	wrapper class for old style cv objects and iterables
base estimator	base class for all estimators in scikit-learn notes
deprecated	decorator to mark a function or class as deprecated
svc	c-support vector classification
label shuffle split	shuffle-labels-out cross-validation iterator
pls	partial least squares pls this class implements the generic pls algorithm constructors' parameters
fast ica	fastica a fast algorithm for independent component analysis
nu svr	nu support vector regression
theil sen regressor	theil-sen estimator robust multivariate regression model
bagging regressor	a bagging regressor
group shuffle split	shuffle-group s -out cross-validation iterator provides randomized train/test indices to split data according to a
sigmoid calibration	sigmoid regression model
feature hasher	implements feature hashing aka the hashing trick
base filter	initialize the univariate feature selection
max abs scaler	scale each feature by its maximum absolute value
stratified kfold	stratified k-folds cross validation iterator
rbfsampler	approximates feature map of an rbf kernel by monte carlo approximation of its fourier transform
bagging classifier	a bagging classifier
ridge classifier	classifier using ridge regression
multi task elastic net	multi-task elasticnet model trained with l1/l2 mixed-norm as regularizer the optimization objective for multitaskelasticnet is :
pickling pool	pool implementation with customizable pickling reducers
parameter	represents a parameter in a function signature
customizable pickling queue	locked pipe implementation that uses a customizable pickler
multi output regressor	multi target regression this strategy consists of fitting one regressor per target
linear svc	linear support vector classification
gaussian process	the legacy gaussian process model class
parallel	helper class for readable parallel mapping
birch	implements the birch clustering algorithm
bernoulli nb	naive bayes classifier for multivariate bernoulli models
hashing vectorizer	convert a collection of text documents to a matrix of token occurrences it turns a collection of text documents into a scipy
variance threshold	feature selector that removes all low-variance features
time series split	time series cross-validator provides train/test indices to split time series data samples
mean estimator	an estimator predicting the mean of the training targets
voting classifier	soft voting/majority rule classifier for unfitted estimators
linear model	base class for linear models
named check	wraps a check to show a useful description
quantile loss function	loss function for quantile regression
linear svr	linear support vector regression
spectral biclustering	spectral biclustering kluger 2003
not memorized func	no-op object decorating a function
select fdr	filter select the p-values for an estimated false discovery rate this uses the benjamini-hochberg procedure
binomial deviance	binomial deviance loss function for binary classification
leave pout	leave-p-out cross-validator provides train/test indices to split data in train/test sets
iter op inv	iteropinv
cca	cca canonical correlation analysis
mini batch sparse pca	mini-batch sparse principal components analysis finds the set of sparse components that can optimally reconstruct
exp sine squared	exp-sine-squared kernel
radius neighbors classifier	classifier implementing a vote among neighbors within a given radius read more in the :ref user guide <classification>
label propagation	label propagation classifier read more in the :ref user guide <label_propagation>
constant kernel	constant kernel
ridge	linear least squares with l2 regularization
oas	oracle approximating shrinkage estimator read more in the :ref user guide <shrunk_covariance>
gaussian random projection	reduce dimensionality through gaussian random projection the components of the random matrix are drawn from n(0 1 / n_components)
affinity propagation	perform affinity propagation clustering of data
hungarian state	state of one execution of the hungarian algorithm
dot product	dot-product kernel
kneighbors mixin	mixin for k-neighbors searches
extra tree regressor	an extremely randomized tree regressor
select fpr	filter select the pvalues below alpha based on a fpr test
predefined split	predefined split cross validation iterator
gaussian random projection hash	use gaussianrandomprojection to produce a cosine lsh fingerprint
joblib exception	a simple exception with an error message that you can get to
moved items	lazy loading of moved objects
agglomeration transform	a class for feature agglomeration via the transform interface
one vs rest classifier	one-vs-the-rest ovr multiclass/multilabel strategy also known as one-vs-all this strategy consists in fitting one classifier
array memmap reducer	reducer callable to dump large arrays to memmap files
pairwise kernel	wrapper for kernels in sklearn metrics pairwise
leave one label out	leave-one-label_out cross-validation iterator
mean shift	mean shift clustering using a flat kernel
exponential loss	exponential loss function for binary classification
dictionary learning	dictionary learning finds a dictionary a set of atoms that can best be used to represent data
rbf	radial-basis function kernel aka squared-exponential kernel
not memorized result	class representing an arbitrary value
isomap	isomap embedding non-linear dimensionality reduction through isometric mapping
one class svm	unsupervised outlier detection
vbgmm	variational inference for the gaussian mixture model
base kfold	base class for kfold groupkfold and stratifiedkfold
mds	multidimensional scaling read more in the :ref user guide <multidimensional_scaling>
multi label binarizer	transform between iterable of iterables and a multilabel format although a list of sets or tuples is a very intuitive format for multilabel
gmm	legacy gaussian mixture model
pool manager mixin	a helper class for managing pool of workers
kernel pca	kernel principal component analysis kpca non-linear dimensionality reduction through the use of kernels (see
radius neighbors mixin	mixin for radius-based neighbors searches
gaussian process classifier	gaussian process classification gpc based on laplace approximation
graph lasso cv	sparse inverse covariance w/ cross-validated choice of the l1 penalty read more in the :ref user guide <sparse_inverse_covariance>
memorized result	object representing a cached value
grid search cv	exhaustive search over specified parameter values for an estimator
forest regressor	base class for forest of trees-based regressors
base bagging	base class for bagging meta-estimator
base random projection	base class for random projections
data conversion warning	warning used to notify implicit data conversions happening in the code
mini batch dictionary learning	mini-batch dictionary learning finds a dictionary a set of atoms that can best be used to represent data
random forest regressor	a random forest regressor
nearest centroid	nearest centroid classifier
linear regression	ordinary least squares linear regression
mlpregressor	multi-layer perceptron regressor
kernel operator	base class for all kernel operators
plscanonical	plscanonical implements the 2 blocks canonical pls of the original wold algorithm [tenenhaus 1998] p
bayesian ridge	bayesian ridge regression fit a bayesian ridge model and optimize the regularization parameters
nystroem	approximate a kernel map using a subset of the training data
base sgd	base class for sgd classification and regression
hyperparameter	a kernel hyperparameter's specification in form of a namedtuple
randomized lasso	randomized lasso
convergence warning	custom warning to capture convergence problems
locally linear embedding	locally linear embedding read more in the :ref user guide <locally_linear_embedding>
generic univariate select	univariate feature selector with configurable strategy
random forest classifier	a random forest classifier
feature union	concatenates results of multiple transformer objects
count vectorizer	convert a collection of text documents to a matrix of token counts this implementation produces a sparse representation of the counts using
randomized pca	principal component analysis pca using randomized svd
module six moves urllib	create a six moves urllib namespace that resembles the python 3 namespace
sparse coding mixin	sparse coding mixin
leave pgroups out	leave p group s out cross-validator provides train/test indices to split data according to a third-party
latent dirichlet allocation	latent dirichlet allocation with online variational bayes algorithm
agglomerative clustering	agglomerative clustering recursively merges the pair of clusters that minimally increases
numpy hasher	special case the hasher for when numpy is loaded
consistent set	class used to ensure the hash of sets is preserved whatever the order of its items
gaussian nb	gaussian naive bayes gaussiannb can perform online updates to model parameters via partial_fit method
compound kernel	kernel which is composed of a set of other kernels
extra tree classifier	an extremely randomized tree classifier
base cross validator	base class for all cross-validators implementations must define _iter_test_masks or _iter_test_indices
matern	matern kernel
multinomial nb	naive bayes classifier for multinomial models the multinomial naive bayes classifier is suitable for classification with
base discrete nb	abstract base class for naive bayes on discrete/categorical data
numpy unpickler	a subclass of the unpickler to unpickle our numpy pickles
tfidf transformer	transform a count matrix to a normalized tf or tf-idf representation tf means term-frequency while tf-idf means term-frequency times inverse
feature agglomeration	agglomerate features
least squares error	loss function for least squares ls estimation
bunch	container object for datasets dictionary-like object that exposes its keys as attributes
gaussian process regressor	gaussian process regression gpr
gradient boosting regressor	gradient boosting for regression
cluster mixin	mixin class for all cluster estimators in scikit-learn
bernoulli rbm	bernoulli restricted boltzmann machine rbm
batch completion call back	callback used by joblib parallel's multiprocessing backend
leave one out	leave-one-out cross validation iterator
base kfold	base class to validate kfold approaches
projection to hash mixin	turn a transformed real-valued array into a hash
bayesian gaussian mixture	variational bayesian estimation of a gaussian mixture
ada boost regressor	an adaboost regressor
isotonic regression	isotonic regression model
base optimizer	base stochastic gradient descent optimizer parameters
iff has attr descriptor	implements a conditional property using the descriptor protocol
lars	least angle regression model a k a lar
undefined metric warning	warning used when the metric is invalid
