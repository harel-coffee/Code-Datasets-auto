<tt style='background-color:#E8E8E8;'> core. <a href=' /discriminant_analysis.py#L34'>_cov</a>(X,shrinkage)</tt>	Estimate covariance matrix using optional shrinkage.
<tt style='background-color:#E8E8E8;'> core. <a href=' /discriminant_analysis.py#L74'>_class_means</a>(X,y)</tt>	Compute class means.
<tt style='background-color:#E8E8E8;'> core. <a href=' /discriminant_analysis.py#L98'>_class_cov</a>(X,y,priors,shrinkage)</tt>	Compute class covariance matrix.
<tt style='background-color:#E8E8E8;'> core.LinearDiscriminantAnalysis <a href=' /discriminant_analysis.py#L258'>_solve_lsqr</a>(X,y,shrinkage)</tt>	Least squares solver.
<tt style='background-color:#E8E8E8;'> core.LinearDiscriminantAnalysis <a href=' /discriminant_analysis.py#L411'>fit</a>(X,y)</tt>	Fit lineardiscriminantanalysis model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> core.LinearDiscriminantAnalysis <a href=' /discriminant_analysis.py#L469'>transform</a>(X)</tt>	Project data to maximize class separation.
<tt style='background-color:#E8E8E8;'> core.LinearDiscriminantAnalysis <a href=' /discriminant_analysis.py#L520'>predict_log_proba</a>(X)</tt>	Estimate log probability.
<tt style='background-color:#E8E8E8;'> core.QuadraticDiscriminantAnalysis <a href=' /discriminant_analysis.py#L619'>fit</a>(X,y)</tt>	Fit the model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> core.QuadraticDiscriminantAnalysis <a href=' /discriminant_analysis.py#L697'>decision_function</a>(X)</tt>	Apply decision function to an array of samples.
<tt style='background-color:#E8E8E8;'> core.QuadraticDiscriminantAnalysis <a href=' /discriminant_analysis.py#L718'>predict</a>(X)</tt>	Perform classification on an array of test vectors x.
<tt style='background-color:#E8E8E8;'> core.QuadraticDiscriminantAnalysis <a href=' /discriminant_analysis.py#L735'>predict_proba</a>(X)</tt>	Return posterior probabilities of classification.
<tt style='background-color:#E8E8E8;'> core.QuadraticDiscriminantAnalysis <a href=' /discriminant_analysis.py#L755'>predict_log_proba</a>(X)</tt>	Return posterior probabilities of classification.
<tt style='background-color:#E8E8E8;'> core. <a href=' /random_projection.py#L53'>johnson_lindenstrauss_min_dim</a>(n_samples,eps)</tt>	Find a 'safe' number of components to randomly project to the distortion introduced by a random projection p only changes the.
<tt style='background-color:#E8E8E8;'> core. <a href=' /random_projection.py#L135'>_check_density</a>(density,n_features)</tt>	Factorize density check according to li et al.
<tt style='background-color:#E8E8E8;'> core. <a href=' /random_projection.py#L146'>_check_input_size</a>(n_components,n_features)</tt>	Factorize argument checking for random matrix generation.
<tt style='background-color:#E8E8E8;'> core. <a href=' /random_projection.py#L156'>gaussian_random_matrix</a>(n_components,n_features,random_state)</tt>	Generate a dense gaussian random matrix.
<tt style='background-color:#E8E8E8;'> core. <a href=' /random_projection.py#L198'>sparse_random_matrix</a>(n_components,n_features,density,random_state)</tt>	Generalized achlioptas random sparse matrix for random projection setting density to 1 / 3 will yield the original matrix by dimitris.
<tt style='background-color:#E8E8E8;'> core.BaseRandomProjection <a href=' /random_projection.py#L311'>_make_random_matrix</a>(n_components,n_features)</tt>	Generate the random projection matrix parameters.
<tt style='background-color:#E8E8E8;'> core.BaseRandomProjection <a href=' /random_projection.py#L330'>fit</a>(X,y)</tt>	Generate a sparse random projection matrix parameters.
<tt style='background-color:#E8E8E8;'> core.BaseRandomProjection <a href=' /random_projection.py#L395'>transform</a>(X,y)</tt>	Project the data by using matrix product with the random matrix parameters.
<tt style='background-color:#E8E8E8;'> core.GaussianRandomProjection <a href=' /random_projection.py#L482'>_make_random_matrix</a>(n_components,n_features)</tt>	Generate the random projection matrix parameters.
<tt style='background-color:#E8E8E8;'> core.SparseRandomProjection <a href=' /random_projection.py#L607'>_make_random_matrix</a>(n_components,n_features)</tt>	Generate the random projection matrix parameters.
<tt style='background-color:#E8E8E8;'> core. <a href=' /learning_curve.py#L182'>_translate_train_sizes</a>(train_sizes,n_max_training_samples)</tt>	Determine absolute sizes of training subsets and validate 'train_sizes'.
<tt style='background-color:#E8E8E8;'> core. <a href=' /learning_curve.py#L241'>_incremental_fit_estimator</a>(estimator,X,y,classes)</tt>	Train estimator on training subsets incrementally and compute scores.
<tt style='background-color:#E8E8E8;'> core.RBFSampler <a href=' /kernel_approximation.py#L63'>fit</a>(X,y)</tt>	Fit the model with x.
<tt style='background-color:#E8E8E8;'> core.RBFSampler <a href=' /kernel_approximation.py#L91'>transform</a>(X,y)</tt>	Apply the approximate feature map to x.
<tt style='background-color:#E8E8E8;'> core.SkewedChi2Sampler <a href=' /kernel_approximation.py#L153'>fit</a>(X,y)</tt>	Fit the model with x.
<tt style='background-color:#E8E8E8;'> core.SkewedChi2Sampler <a href=' /kernel_approximation.py#L181'>transform</a>(X,y)</tt>	Apply the approximate feature map to x.
<tt style='background-color:#E8E8E8;'> core.AdditiveChi2Sampler <a href=' /kernel_approximation.py#L279'>transform</a>(X,y)</tt>	Apply approximate feature map to x.
<tt style='background-color:#E8E8E8;'> core.Nystroem <a href=' /kernel_approximation.py#L449'>fit</a>(X,y)</tt>	Fit estimator to data.
<tt style='background-color:#E8E8E8;'> core.Nystroem <a href=' /kernel_approximation.py#L491'>transform</a>(X)</tt>	Apply feature map to x.
<tt style='background-color:#E8E8E8;'> core. <a href=' /base.py#L17'>_first_and_last_element</a>(arr)</tt>	Returns first and last element of numpy array or sparse matrix.
<tt style='background-color:#E8E8E8;'> core. <a href=' /base.py#L29'>clone</a>(estimator,safe)</tt>	Constructs a new estimator with the same parameters.
<tt style='background-color:#E8E8E8;'> core. <a href=' /base.py#L124'>_pprint</a>(params,offset,printer)</tt>	Pretty print the dictionary 'params' parameters.
<tt style='background-color:#E8E8E8;'> core.BaseEstimator <a href=' /base.py#L185'>_get_param_names</a>(cls)</tt>	Get parameter names for the estimator.
<tt style='background-color:#E8E8E8;'> core.BaseEstimator <a href=' /base.py#L212'>get_params</a>(deep)</tt>	Get parameters for this estimator.
<tt style='background-color:#E8E8E8;'> core.BaseEstimator <a href=' /base.py#L249'>set_params</a>()</tt>	Set the parameters of this estimator.
<tt style='background-color:#E8E8E8;'> core.ClassifierMixin <a href=' /base.py#L325'>score</a>(X,y,sample_weight)</tt>	Returns the mean accuracy on the given test data and labels.
<tt style='background-color:#E8E8E8;'> core.RegressorMixin <a href=' /base.py#L358'>score</a>(X,y,sample_weight)</tt>	Returns the coefficient of determination r^2 of the prediction.
<tt style='background-color:#E8E8E8;'> core.ClusterMixin <a href=' /base.py#L396'>fit_predict</a>(X,y)</tt>	Performs clustering on x and returns cluster labels.
<tt style='background-color:#E8E8E8;'> core.BiclusterMixin <a href=' /base.py#L418'>biclusters_</a>()</tt>	Convenient way to get row and column indicators together.
<tt style='background-color:#E8E8E8;'> core.BiclusterMixin <a href=' /base.py#L426'>get_indices</a>(i)</tt>	Row and column indices of the i'th bicluster.
<tt style='background-color:#E8E8E8;'> core.BiclusterMixin <a href=' /base.py#L443'>get_shape</a>(i)</tt>	Shape of the i'th bicluster.
<tt style='background-color:#E8E8E8;'> core.BiclusterMixin <a href=' /base.py#L454'>get_submatrix</a>(i,data)</tt>	Returns the submatrix corresponding to bicluster i.
<tt style='background-color:#E8E8E8;'> core.TransformerMixin <a href=' /base.py#L471'>fit_transform</a>(X,y)</tt>	Fit to data then transform it.
<tt style='background-color:#E8E8E8;'> core.DensityMixin <a href=' /base.py#L505'>score</a>(X,y)</tt>	Returns the score of the model on the data x.
<tt style='background-color:#E8E8E8;'> core. <a href=' /base.py#L527'>is_classifier</a>(estimator)</tt>	Returns true if the given estimator is probably a classifier.
<tt style='background-color:#E8E8E8;'> core. <a href=' /base.py#L532'>is_regressor</a>(estimator)</tt>	Returns true if the given estimator is probably a regressor.
<tt style='background-color:#E8E8E8;'> core.BaseNB <a href=' /naive_bayes.py#L41'>_joint_log_likelihood</a>(X)</tt>	Compute the unnormalized posterior log probability of x i.
<tt style='background-color:#E8E8E8;'> core.BaseNB <a href=' /naive_bayes.py#L52'>predict</a>(X)</tt>	Perform classification on an array of test vectors x.
<tt style='background-color:#E8E8E8;'> core.BaseNB <a href=' /naive_bayes.py#L68'>predict_log_proba</a>(X)</tt>	Return log-probability estimates for the test vector x.
<tt style='background-color:#E8E8E8;'> core.BaseNB <a href=' /naive_bayes.py#L88'>predict_proba</a>(X)</tt>	Return probability estimates for the test vector x.
<tt style='background-color:#E8E8E8;'> core.GaussianNB <a href=' /naive_bayes.py#L159'>fit</a>(X,y,sample_weight)</tt>	Fit gaussian naive bayes according to x y parameters.
<tt style='background-color:#E8E8E8;'> core.GaussianNB <a href=' /naive_bayes.py#L186'>_update_mean_variance</a>(n_past,mu,var,X)</tt>	Compute online update of gaussian mean and variance.
<tt style='background-color:#E8E8E8;'> core.GaussianNB <a href=' /naive_bayes.py#L261'>partial_fit</a>(X,y,classes,sample_weight)</tt>	Incremental fit on a batch of samples.
<tt style='background-color:#E8E8E8;'> core.GaussianNB <a href=' /naive_bayes.py#L304'>_partial_fit</a>(X,y,classes,_refit)</tt>	Actual implementation of gaussian nb fitting.
<tt style='background-color:#E8E8E8;'> core.BaseDiscreteNB <a href=' /naive_bayes.py#L463'>partial_fit</a>(X,y,classes,sample_weight)</tt>	Incremental fit on a batch of samples.
<tt style='background-color:#E8E8E8;'> core.BaseDiscreteNB <a href=' /naive_bayes.py#L545'>fit</a>(X,y,sample_weight)</tt>	Fit naive bayes classifier according to x y parameters.
<tt style='background-color:#E8E8E8;'> core.MultinomialNB <a href=' /naive_bayes.py#L690'>_count</a>(X,Y)</tt>	Count and smooth feature occurrences.
<tt style='background-color:#E8E8E8;'> core.MultinomialNB <a href=' /naive_bayes.py#L697'>_update_feature_log_prob</a>()</tt>	Apply smoothing to raw counts and recompute log probabilities.
<tt style='background-color:#E8E8E8;'> core.MultinomialNB <a href=' /naive_bayes.py#L705'>_joint_log_likelihood</a>(X)</tt>	Calculate the posterior log probability of the samples x.
<tt style='background-color:#E8E8E8;'> core.BernoulliNB <a href=' /naive_bayes.py#L792'>_count</a>(X,Y)</tt>	Count and smooth feature occurrences.
<tt style='background-color:#E8E8E8;'> core.BernoulliNB <a href=' /naive_bayes.py#L799'>_update_feature_log_prob</a>()</tt>	Apply smoothing to raw counts and recompute log probabilities.
<tt style='background-color:#E8E8E8;'> core.BernoulliNB <a href=' /naive_bayes.py#L807'>_joint_log_likelihood</a>(X)</tt>	Calculate the posterior log probability of the samples x.
<tt style='background-color:#E8E8E8;'> core._PartitionIterator <a href=' /cross_validation.py#L90'>_iter_test_masks</a>()</tt>	Generates boolean masks corresponding to test sets.
<tt style='background-color:#E8E8E8;'> core._PartitionIterator <a href=' /cross_validation.py#L100'>_iter_test_indices</a>()</tt>	Generates integer indices corresponding to test sets.
<tt style='background-color:#E8E8E8;'> core.BaseShuffleSplit <a href=' /cross_validation.py#L788'>_iter_indices</a>()</tt>	Generate train test indices.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L948'>_approximate_mode</a>(class_counts,n_draws,rng)</tt>	Computes approximate mode of multivariate hypergeometric.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1286'>_index_param_value</a>(X,v,indices)</tt>	Private helper function for parameter value indexing.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1296'>cross_val_predict</a>(estimator,X,y,cv)</tt>	Generate cross-validated estimates for each input data point.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1403'>_fit_and_predict</a>(estimator,X,y,train)</tt>	Fit estimator and predict values for a given dataset split.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1456'>_check_is_partition</a>(locs,n)</tt>	Check whether locs is a reordering of the array np arange n.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1480'>cross_val_score</a>(estimator,X,y,scoring)</tt>	Evaluate a score by cross-validation.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1587'>_fit_and_score</a>(estimator,X,y,scorer)</tt>	Fit estimator and compute scores for a given dataset split.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1715'>_safe_split</a>(estimator,X,y,indices)</tt>	Create subset of dataset and properly handle kernels.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1748'>_score</a>(estimator,X_test,y_test,scorer)</tt>	Compute the score of an estimator on a given test set.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1849'>permutation_test_score</a>(estimator,X,y,cv)</tt>	Evaluate the significance of a cross-validated score with permutations.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1778'>_shuffle</a>(y,labels,random_state)</tt>	Return a shuffled copy of y eventually shuffle among same labels.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1790'>check_cv</a>(cv,X,y,classifier)</tt>	Input checker utility for building a cv in a user friendly way.
<tt style='background-color:#E8E8E8;'> core. <a href=' /cross_validation.py#L1961'>train_test_split</a>()</tt>	Split arrays or matrices into random train and test subsets.
<tt style='background-color:#E8E8E8;'> core.MultiOutputEstimator <a href=' /multioutput.py#L66'>partial_fit</a>(X,y,classes,sample_weight)</tt>	Incrementally fit the model to data.
<tt style='background-color:#E8E8E8;'> core.MultiOutputEstimator <a href=' /multioutput.py#L121'>fit</a>(X,y,sample_weight)</tt>	Fit the model to data.
<tt style='background-color:#E8E8E8;'> core.MultiOutputEstimator <a href=' /multioutput.py#L167'>predict</a>(X)</tt>	Predict multi-output variable using a model trained for each target variable.
<tt style='background-color:#E8E8E8;'> core.MultiOutputRegressor <a href=' /multioutput.py#L218'>partial_fit</a>(X,y,sample_weight)</tt>	Incrementally fit the model to data.
<tt style='background-color:#E8E8E8;'> core.MultiOutputRegressor <a href=' /multioutput.py#L243'>score</a>(X,y,sample_weight)</tt>	Returns the coefficient of determination r^2 of the prediction.
<tt style='background-color:#E8E8E8;'> core.MultiOutputClassifier <a href=' /multioutput.py#L335'>score</a>(X,y)</tt>	"returns the mean accuracy on the given test data and labels.
<tt style='background-color:#E8E8E8;'> core. <a href=' /multiclass.py#L66'>_fit_binary</a>(estimator,X,y,classes)</tt>	Fit a single binary estimator.
<tt style='background-color:#E8E8E8;'> core. <a href=' /multiclass.py#L84'>_partial_fit_binary</a>(estimator,X,y)</tt>	Partially fit a single binary estimator.
<tt style='background-color:#E8E8E8;'> core. <a href=' /multiclass.py#L90'>_predict_binary</a>(estimator,X)</tt>	Make predictions using a single binary estimator.
<tt style='background-color:#E8E8E8;'> core. <a href=' /multiclass.py#L102'>_check_estimator</a>(estimator)</tt>	Make sure that an estimator implements the necessary methods.
<tt style='background-color:#E8E8E8;'> core.OneVsRestClassifier <a href=' /multiclass.py#L184'>fit</a>(X,y)</tt>	Fit underlying estimators.
<tt style='background-color:#E8E8E8;'> core.OneVsRestClassifier <a href=' /multiclass.py#L220'>partial_fit</a>(X,y,classes)</tt>	Partially fit underlying estimators should be used when memory is inefficient to train all data.
<tt style='background-color:#E8E8E8;'> core.OneVsRestClassifier <a href=' /multiclass.py#L276'>predict</a>(X)</tt>	Predict multi-class targets using underlying estimators.
<tt style='background-color:#E8E8E8;'> core.OneVsRestClassifier <a href=' /multiclass.py#L356'>decision_function</a>(X)</tt>	Returns the distance of each sample from the decision boundary for each class.
<tt style='background-color:#E8E8E8;'> core.OneVsRestClassifier <a href=' /multiclass.py#L374'>multilabel_</a>()</tt>	Whether this is a multilabel classifier.
<tt style='background-color:#E8E8E8;'> core.OneVsRestClassifier <a href=' /multiclass.py#L402'>_pairwise</a>()</tt>	Indicate if wrapped estimator is using a precomputed gram matrix.
<tt style='background-color:#E8E8E8;'> core. <a href=' /multiclass.py#L412'>_fit_ovo_binary</a>(estimator,X,y,i)</tt>	Fit a single binary estimator one-vs-one.
<tt style='background-color:#E8E8E8;'> core. <a href=' /multiclass.py#L425'>_partial_fit_ovo_binary</a>(estimator,X,y,i)</tt>	Partially fit a single binary estimator one-vs-one.
<tt style='background-color:#E8E8E8;'> core.OneVsOneClassifier <a href=' /multiclass.py#L475'>fit</a>(X,y)</tt>	Fit underlying estimators.
<tt style='background-color:#E8E8E8;'> core.OneVsOneClassifier <a href=' /multiclass.py#L508'>partial_fit</a>(X,y,classes)</tt>	Partially fit underlying estimators should be used when memory is inefficient to train all data.
<tt style='background-color:#E8E8E8;'> core.OneVsOneClassifier <a href=' /multiclass.py#L554'>predict</a>(X)</tt>	Estimate the best class label for each sample in x.
<tt style='background-color:#E8E8E8;'> core.OneVsOneClassifier <a href=' /multiclass.py#L574'>decision_function</a>(X)</tt>	Decision function for the onevsoneclassifier.
<tt style='background-color:#E8E8E8;'> core.OneVsOneClassifier <a href=' /multiclass.py#L611'>_pairwise</a>()</tt>	Indicate if wrapped estimator is using a precomputed gram matrix.
<tt style='background-color:#E8E8E8;'> core.OutputCodeClassifier <a href=' /multiclass.py#L691'>fit</a>(X,y)</tt>	Fit underlying estimators.
<tt style='background-color:#E8E8E8;'> core.OutputCodeClassifier <a href=' /multiclass.py#L738'>predict</a>(X)</tt>	Predict multi-class targets using underlying estimators.
<tt style='background-color:#E8E8E8;'> core. <a href=' /__init__.py#L74'>setup_module</a>(module)</tt>	Fixture for the tests to assure globally controllable seeding of rngs.
<tt style='background-color:#E8E8E8;'> core.ParameterGrid <a href=' /grid_search.py#L100'>__iter__</a>()</tt>	Iterate over the points in the grid.
<tt style='background-color:#E8E8E8;'> core.ParameterGrid <a href=' /grid_search.py#L120'>__len__</a>()</tt>	Number of points on the grid.
<tt style='background-color:#E8E8E8;'> core.ParameterGrid <a href=' /grid_search.py#L127'>__getitem__</a>(ind)</tt>	Get the parameters that would be indth in iteration.
<tt style='background-color:#E8E8E8;'> core.ParameterSampler <a href=' /grid_search.py#L271'>__len__</a>()</tt>	Number of points that will be sampled.
<tt style='background-color:#E8E8E8;'> core. <a href=' /grid_search.py#L276'>fit_grid_point</a>(X,y,estimator,parameters)</tt>	Run fit on one set of parameters.
<tt style='background-color:#E8E8E8;'> core._CVScoreTuple <a href=' /grid_search.py#L373'>__repr__</a>()</tt>	Simple custom repr to summarize the main info.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L410'>score</a>(X,y)</tt>	Returns the score on the given data if the estimator has been refit.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L449'>predict</a>(X)</tt>	Call predict on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L465'>predict_proba</a>(X)</tt>	Call predict_proba on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L481'>predict_log_proba</a>(X)</tt>	Call predict_log_proba on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L497'>decision_function</a>(X)</tt>	Call decision_function on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L513'>transform</a>(X)</tt>	Call transform on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L529'>inverse_transform</a>(Xt)</tt>	Call inverse_transform on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> core.BaseSearchCV <a href=' /grid_search.py#L545'>_fit</a>(X,y,parameter_iterable)</tt>	Actual fitting performing the search over parameters.
<tt style='background-color:#E8E8E8;'> core.GridSearchCV <a href=' /grid_search.py#L830'>fit</a>(X,y)</tt>	Run fit with all sets of parameters.
<tt style='background-color:#E8E8E8;'> core.RandomizedSearchCV <a href=' /grid_search.py#L1036'>fit</a>(X,y)</tt>	Run fit on the estimator with randomly drawn parameters.
<tt style='background-color:#E8E8E8;'> core.KernelRidge <a href=' /kernel_ridge.py#L127'>fit</a>(X,y,sample_weight)</tt>	Fit kernel ridge regression model parameters.
<tt style='background-color:#E8E8E8;'> core.KernelRidge <a href=' /kernel_ridge.py#L170'>predict</a>(X)</tt>	Predict using the kernel ridge model parameters.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L120'>get_params</a>(deep)</tt>	Get parameters for this estimator.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L136'>set_params</a>()</tt>	Set the parameters of this estimator.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L231'>fit</a>(X,y)</tt>	Fit the model fit all the transforms one after the other and transform the.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L262'>fit_transform</a>(X,y)</tt>	Fit the model and transform with the final estimator fits all the transforms one after the other and transforms the.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L298'>predict</a>(X)</tt>	Apply transforms to the data and predict with the final estimator parameters.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L318'>fit_predict</a>(X,y)</tt>	Applies fit_predict of last step in pipeline after transforms.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L348'>predict_proba</a>(X)</tt>	Apply transforms and predict_proba of the final estimator parameters.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L368'>decision_function</a>(X)</tt>	Apply transforms and decision_function of the final estimator parameters.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L388'>predict_log_proba</a>(X)</tt>	Apply transforms and predict_log_proba of the final estimator parameters.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L408'>transform</a>()</tt>	Apply transforms and transform with the final estimator this also works where final estimator is none: all prior.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L437'>inverse_transform</a>()</tt>	Apply inverse transformations in reverse order all estimators in the pipeline must support inverse_transform.
<tt style='background-color:#E8E8E8;'> core.Pipeline <a href=' /pipeline.py#L468'>score</a>(X,y,sample_weight)</tt>	Apply transforms and score with the final estimator parameters.
<tt style='background-color:#E8E8E8;'> core. <a href=' /pipeline.py#L509'>_name_estimators</a>(estimators)</tt>	Generate names for estimators.
<tt style='background-color:#E8E8E8;'> core. <a href=' /pipeline.py#L530'>make_pipeline</a>()</tt>	Construct a pipeline from the given estimators.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L613'>get_params</a>(deep)</tt>	Get parameters for this estimator.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L629'>set_params</a>()</tt>	Set the parameters of this estimator.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L657'>_iter</a>()</tt>	Generate name est weight tuples excluding none transformers.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L665'>get_feature_names</a>()</tt>	Get feature names from all transformers.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L683'>fit</a>(X,y)</tt>	Fit all transformers using x.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L706'>fit_transform</a>(X,y)</tt>	Fit all transformers transform the data and concatenate results.
<tt style='background-color:#E8E8E8;'> core.FeatureUnion <a href=' /pipeline.py#L740'>transform</a>(X)</tt>	Transform x separately by each transformer concatenate results.
<tt style='background-color:#E8E8E8;'> core. <a href=' /pipeline.py#L774'>make_union</a>()</tt>	Construct a featureunion from the given transformers.
<tt style='background-color:#E8E8E8;'> core.DummyClassifier <a href=' /dummy.py#L89'>fit</a>(X,y,sample_weight)</tt>	Fit the random classifier.
<tt style='background-color:#E8E8E8;'> core.DummyClassifier <a href=' /dummy.py#L161'>predict</a>(X)</tt>	Perform classification on test vectors x.
<tt style='background-color:#E8E8E8;'> core.DummyClassifier <a href=' /dummy.py#L238'>predict_proba</a>(X)</tt>	Return probability estimates for the test vectors x.
<tt style='background-color:#E8E8E8;'> core.DummyClassifier <a href=' /dummy.py#L302'>predict_log_proba</a>(X)</tt>	Return log probability estimates for the test vectors x.
<tt style='background-color:#E8E8E8;'> core.DummyRegressor <a href=' /dummy.py#L375'>fit</a>(X,y,sample_weight)</tt>	Fit the random regressor.
<tt style='background-color:#E8E8E8;'> core.DummyRegressor <a href=' /dummy.py#L455'>predict</a>(X)</tt>	Perform classification on test vectors x.
<tt style='background-color:#E8E8E8;'> core. <a href=' /isotonic.py#L22'>check_increasing</a>(x,y)</tt>	Determine whether y is monotonically correlated with x.
<tt style='background-color:#E8E8E8;'> core. <a href=' /isotonic.py#L79'>isotonic_regression</a>(y,sample_weight,y_min,y_max)</tt>	Solve the isotonic regression model : min sum w[i] (y[i] - y_[i]) ** 2.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L253'>_build_f</a>(X,y)</tt>	Build the f_ interp1d function.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L270'>_build_y</a>(X,y,sample_weight,trim_duplicates)</tt>	Build the y_ isotonicregression.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L326'>fit</a>(X,y,sample_weight)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L365'>transform</a>(T)</tt>	Transform new data by linear interpolation parameters.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L392'>predict</a>(T)</tt>	Predict new data by linear interpolation.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L407'>__getstate__</a>()</tt>	Pickle-protocol - return state of the estimator.
<tt style='background-color:#E8E8E8;'> core.IsotonicRegression <a href=' /isotonic.py#L414'>__setstate__</a>(state)</tt>	Pickle-protocol - set state of the estimator.
<tt style='background-color:#E8E8E8;'> core.CalibratedClassifierCV <a href=' /calibration.py#L107'>fit</a>(X,y,sample_weight)</tt>	Fit the calibrated model parameters.
<tt style='background-color:#E8E8E8;'> core.CalibratedClassifierCV <a href=' /calibration.py#L195'>predict_proba</a>(X)</tt>	Posterior probabilities of classification this function returns posterior probabilities of classification.
<tt style='background-color:#E8E8E8;'> core.CalibratedClassifierCV <a href=' /calibration.py#L225'>predict</a>(X)</tt>	Predict the target of new samples can be different from the.
<tt style='background-color:#E8E8E8;'> core._CalibratedClassifier <a href=' /calibration.py#L306'>fit</a>(X,y,sample_weight)</tt>	Calibrate the fitted model parameters.
<tt style='background-color:#E8E8E8;'> core._CalibratedClassifier <a href=' /calibration.py#L351'>predict_proba</a>(X)</tt>	Posterior probabilities of classification this function returns posterior probabilities of classification.
<tt style='background-color:#E8E8E8;'> core. <a href=' /calibration.py#L393'>_sigmoid_calibration</a>(df,y,sample_weight)</tt>	Probability calibration with sigmoid method platt 2000 parameters.
<tt style='background-color:#E8E8E8;'> core._SigmoidCalibration <a href=' /calibration.py#L470'>fit</a>(X,y,sample_weight)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> core._SigmoidCalibration <a href=' /calibration.py#L496'>predict</a>(T)</tt>	Predict new data by linear interpolation.
<tt style='background-color:#E8E8E8;'> core. <a href=' /calibration.py#L513'>calibration_curve</a>(y_true,y_prob,normalize,n_bins)</tt>	Compute true and predicted probabilities for a calibration curve.
<tt style='background-color:#E8E8E8;'> svm. <a href=' /svm/bounds.py#L14'>l1_min_c</a>(X,y,loss,fit_intercept)</tt>	Return the lowest bound for c such that for c in (l1_min_c infinity) the model is guaranteed not to be empty.
<tt style='background-color:#E8E8E8;'> svm.LinearSVC <a href=' /svm/classes.py#L170'>fit</a>(X,y,sample_weight)</tt>	Fit the model according to the given training data.
<tt style='background-color:#E8E8E8;'> svm.LinearSVR <a href=' /svm/classes.py#L339'>fit</a>(X,y,sample_weight)</tt>	Fit the model according to the given training data.
<tt style='background-color:#E8E8E8;'> svm.OneClassSVM <a href=' /svm/classes.py#L1025'>fit</a>(X,y,sample_weight)</tt>	Detects the soft boundary of the set of samples x.
<tt style='background-color:#E8E8E8;'> svm.OneClassSVM <a href=' /svm/classes.py#L1053'>decision_function</a>(X)</tt>	Distance of the samples x to the separating hyperplane.
<tt style='background-color:#E8E8E8;'> svm.OneClassSVM <a href=' /svm/classes.py#L1068'>predict</a>(X)</tt>	Perform classification on samples in x.
<tt style='background-color:#E8E8E8;'> svm. <a href=' /svm/base.py#L27'>_one_vs_one_coef</a>(dual_coef,n_support,support_vectors)</tt>	Generate primal coefficients from dual coefficients for the one-vs-one multi class libsvm in the case.
<tt style='background-color:#E8E8E8;'> svm.BaseLibSVM <a href=' /svm/base.py#L109'>fit</a>(X,y,sample_weight)</tt>	Fit the svm model according to the given training data.
<tt style='background-color:#E8E8E8;'> svm.BaseLibSVM <a href=' /svm/base.py#L202'>_validate_targets</a>(y)</tt>	Validation of y and class_weight.
<tt style='background-color:#E8E8E8;'> svm.BaseLibSVM <a href=' /svm/base.py#L293'>predict</a>(X)</tt>	Perform regression on samples in x.
<tt style='background-color:#E8E8E8;'> svm.BaseLibSVM <a href=' /svm/base.py#L358'>_compute_kernel</a>(X)</tt>	Return the data transformed by a callable kernel.
<tt style='background-color:#E8E8E8;'> svm.BaseLibSVM <a href=' /svm/base.py#L369'>_decision_function</a>(X)</tt>	Distance of the samples x to the separating hyperplane.
<tt style='background-color:#E8E8E8;'> svm.BaseSVC <a href=' /svm/base.py#L512'>decision_function</a>(X)</tt>	Distance of the samples x to the separating hyperplane.
<tt style='background-color:#E8E8E8;'> svm.BaseSVC <a href=' /svm/base.py#L532'>predict</a>(X)</tt>	Perform classification on samples in x.
<tt style='background-color:#E8E8E8;'> svm.BaseSVC <a href=' /svm/base.py#L563'>predict_proba</a>()</tt>	Compute probabilities of possible outcomes for samples in x.
<tt style='background-color:#E8E8E8;'> svm.BaseSVC <a href=' /svm/base.py#L602'>predict_log_proba</a>()</tt>	Compute log probabilities of possible outcomes for samples in x.
<tt style='background-color:#E8E8E8;'> svm. <a href=' /svm/base.py#L690'>_get_liblinear_solver_type</a>(multi_class,penalty,loss,dual)</tt>	Find the liblinear magic number for the solver.
<tt style='background-color:#E8E8E8;'> svm. <a href=' /svm/base.py#L750'>_fit_liblinear</a>(X,y,C,fit_intercept)</tt>	Used by logistic regression and cv and linearsvc.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/graph_lasso_.py#L32'>_objective</a>(mle,precision_,alpha)</tt>	Evaluation of the graph-lasso objective function the objective function is made of a shifted scaled version of the.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/graph_lasso_.py#L46'>_dual_gap</a>(emp_cov,precision_,alpha)</tt>	Expression of the dual gap convergence criterion the specific definition is given in duchi "projected subgradient methods.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/graph_lasso_.py#L59'>alpha_max</a>(emp_cov)</tt>	Find the maximum alpha for which there are some non-zeros off-diagonal.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/graph_lasso_.py#L82'>graph_lasso</a>(emp_cov,alpha,cov_init,mode)</tt>	L1-penalized covariance estimator read more in the :ref user guide <sparse_inverse_covariance>.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/graph_lasso_.py#L358'>graph_lasso_path</a>(X,alphas,cov_init,X_test)</tt>	L1-penalized covariance estimator along a path of decreasing alphas read more in the :ref user guide <sparse_inverse_covariance>.
<tt style='background-color:#E8E8E8;'> covariance.GraphLassoCV <a href=' /covariance/graph_lasso_.py#L574'>fit</a>(X,y)</tt>	Fits the graphlasso covariance model to x.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/robust_covariance.py#L28'>c_step</a>(X,n_support,remaining_iterations,initial_estimates)</tt>	C_step procedure described in [rouseeuw1984]_ aiming at computing mcd.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/robust_covariance.py#L176'>select_candidates</a>(X,n_support,n_trials,select)</tt>	Finds the best pure subset of observations to compute mcd from it.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/robust_covariance.py#L300'>fast_mcd</a>(X,support_fraction,cov_computation_method,random_state)</tt>	Estimates the minimum covariance determinant matrix.
<tt style='background-color:#E8E8E8;'> covariance.MinCovDet <a href=' /covariance/robust_covariance.py#L598'>fit</a>(X,y)</tt>	Fits a minimum covariance determinant with the fastmcd algorithm.
<tt style='background-color:#E8E8E8;'> covariance.MinCovDet <a href=' /covariance/robust_covariance.py#L647'>correct_covariance</a>(data)</tt>	Apply a correction to raw minimum covariance determinant estimates.
<tt style='background-color:#E8E8E8;'> covariance.MinCovDet <a href=' /covariance/robust_covariance.py#L671'>reweight_covariance</a>(data)</tt>	Re-weight raw minimum covariance determinant estimates.
<tt style='background-color:#E8E8E8;'> covariance.OutlierDetectionMixin <a href=' /covariance/outlier_detection.py#L41'>decision_function</a>(X,raw_values)</tt>	Compute the decision function of the given observations.
<tt style='background-color:#E8E8E8;'> covariance.OutlierDetectionMixin <a href=' /covariance/outlier_detection.py#L76'>predict</a>(X)</tt>	Outlyingness of observations in x according to the fitted model.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/empirical_covariance_.py#L23'>log_likelihood</a>(emp_cov,precision)</tt>	Computes the sample mean of the log_likelihood under a covariance model.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/empirical_covariance_.py#L49'>empirical_covariance</a>(X,assume_centered)</tt>	Computes the maximum likelihood covariance estimator parameters.
<tt style='background-color:#E8E8E8;'> covariance.EmpiricalCovariance <a href=' /covariance/empirical_covariance_.py#L118'>_set_covariance</a>(covariance)</tt>	Saves the covariance and precision estimates storage is done accordingly to self.
<tt style='background-color:#E8E8E8;'> covariance.EmpiricalCovariance <a href=' /covariance/empirical_covariance_.py#L140'>get_precision</a>()</tt>	Getter for the precision matrix.
<tt style='background-color:#E8E8E8;'> covariance.EmpiricalCovariance <a href=' /covariance/empirical_covariance_.py#L155'>fit</a>(X,y)</tt>	Fits the maximum likelihood estimator covariance model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> covariance.EmpiricalCovariance <a href=' /covariance/empirical_covariance_.py#L184'>score</a>(X_test,y)</tt>	Computes the log-likelihood of a gaussian data set with self.
<tt style='background-color:#E8E8E8;'> covariance.EmpiricalCovariance <a href=' /covariance/empirical_covariance_.py#L213'>error_norm</a>(comp_cov,norm,scaling,squared)</tt>	Computes the mean squared error between two covariance estimators.
<tt style='background-color:#E8E8E8;'> covariance.EmpiricalCovariance <a href=' /covariance/empirical_covariance_.py#L265'>mahalanobis</a>(observations)</tt>	Computes the squared mahalanobis distances of given observations.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/shrunk_covariance_.py#L27'>shrunk_covariance</a>(emp_cov,shrinkage)</tt>	Calculates a covariance matrix shrunk on the diagonal read more in the :ref user guide <shrunk_covariance>.
<tt style='background-color:#E8E8E8;'> covariance.ShrunkCovariance <a href=' /covariance/shrunk_covariance_.py#L115'>fit</a>(X,y)</tt>	Fits the shrunk covariance model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/shrunk_covariance_.py#L150'>ledoit_wolf_shrinkage</a>(X,assume_centered,block_size)</tt>	Estimates the shrunk ledoit-wolf covariance matrix.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/shrunk_covariance_.py#L246'>ledoit_wolf</a>(X,assume_centered,block_size)</tt>	Estimates the shrunk ledoit-wolf covariance matrix.
<tt style='background-color:#E8E8E8;'> covariance.LedoitWolf <a href=' /covariance/shrunk_covariance_.py#L374'>fit</a>(X,y)</tt>	Fits the ledoit-wolf shrunk covariance model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> covariance. <a href=' /covariance/shrunk_covariance_.py#L409'>oas</a>(X,assume_centered)</tt>	Estimate covariance with the oracle approximating shrinkage algorithm.
<tt style='background-color:#E8E8E8;'> covariance.OAS <a href=' /covariance/shrunk_covariance_.py#L535'>fit</a>(X,y)</tt>	Fits the oracle approximating shrinkage covariance model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/dpgmm.py#L45'>log_normalize</a>(v,axis)</tt>	Normalized probabilities from unnormalized log-probabilites.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/dpgmm.py#L59'>wishart_log_det</a>(a,b,detB,n_features)</tt>	Expected value of the log of the determinant of a wishart the expected value of the logarithm of the determinant of a.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/dpgmm.py#L71'>wishart_logz</a>(v,s,dets,n_features)</tt>	The logarithm of the normalization constant for the wishart distribution.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/dpgmm.py#L83'>_bound_wishart</a>(a,B,detB)</tt>	Returns a function of the dof scale matrix and its determinant.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/dpgmm.py#L101'>_sym_quad_form</a>(x,mu,A)</tt>	Helper function to calculate symmetric quadratic form x t * a * x.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/dpgmm.py#L107'>_bound_state_log_lik</a>(X,initial_bound,precs,means)</tt>	Update the bound with likelihood terms for standard covariance types.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L229'>_get_precisions</a>()</tt>	Return precisions as a full matrix.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L245'>score_samples</a>(X)</tt>	Return the likelihood of the data under the model.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L298'>_update_concentration</a>(z)</tt>	Update the concentration parameters for each cluster.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L307'>_update_means</a>(X,z)</tt>	Update the variational distributions for the means.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L326'>_update_precisions</a>(X,z)</tt>	Update the variational distributions for the precisions.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L381'>_monitor</a>(X,z,n,end)</tt>	Monitor the lower bound during iteration debug method to help see exactly when it is failing to converge as.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L394'>_do_mstep</a>(X,z,params)</tt>	Maximize the variational lower bound update each of the parameters to maximize the lower bound.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L408'>_initialize_gamma</a>()</tt>	Initializes the concentration parameters.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L412'>_bound_concentration</a>()</tt>	The variational lower bound for the concentration parameter.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L429'>_bound_means</a>()</tt>	The variational lower bound for the mean parameters.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L436'>_bound_precisions</a>()</tt>	Returns the bound term related to precisions.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L459'>_bound_proportions</a>(z)</tt>	Returns the bound term related to proportions.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L479'>lower_bound</a>(X,z)</tt>	Returns a lower bound on model evidence based on x and membership.
<tt style='background-color:#E8E8E8;'> mixture._DPGMMBase <a href=' /mixture/dpgmm.py#L501'>_fit</a>(X,y)</tt>	Estimate model parameters with the variational algorithm.
<tt style='background-color:#E8E8E8;'> mixture.VBGMM <a href=' /mixture/dpgmm.py#L756'>_fit</a>(X,y)</tt>	Estimate model parameters with the variational algorithm.
<tt style='background-color:#E8E8E8;'> mixture.VBGMM <a href=' /mixture/dpgmm.py#L785'>score_samples</a>(X)</tt>	Return the likelihood of the data under the model.
<tt style='background-color:#E8E8E8;'> mixture.VBGMM <a href=' /mixture/dpgmm.py#L854'>_monitor</a>(X,z,n,end)</tt>	Monitor the lower bound during iteration debug method to help see exactly when it is failing to converge as.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/base.py#L24'>_check_shape</a>(param,param_shape,name)</tt>	Validate the shape of the input parameter 'param'.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/base.py#L41'>_check_X</a>(X,n_components,n_features)</tt>	Check the input data x.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L87'>_check_initial_parameters</a>(X)</tt>	Check values of the basic parameters.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L123'>_check_parameters</a>(X)</tt>	Check initial parameters of the derived class.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L133'>_initialize_parameters</a>(X,random_state)</tt>	Initialize the model parameters.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L159'>_initialize</a>(X,resp)</tt>	Initialize the model parameters of the derived class.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L171'>fit</a>(X,y)</tt>	Estimate model parameters with the em algorithm.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L289'>score_samples</a>(X)</tt>	Compute the weighted log probabilities for each sample.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L308'>score</a>(X,y)</tt>	Compute the per-sample average log-likelihood of the given data x.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L324'>predict</a>(X,y)</tt>	Predict the labels for the data samples in x using trained model.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L342'>predict_proba</a>(X)</tt>	Predict posterior probability of data per each component.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L362'>sample</a>(n_samples)</tt>	Generate random samples from the fitted gaussian distribution.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L411'>_estimate_weighted_log_prob</a>(X)</tt>	Estimate the weighted log-probabilities log p(x | z) + log weights.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L424'>_estimate_log_weights</a>()</tt>	Estimate log-weights in em algorithm e[ log pi ] in vb algorithm.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L434'>_estimate_log_prob</a>(X)</tt>	Estimate the log-probabilities log p(x | z).
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L450'>_estimate_log_prob_resp</a>(X)</tt>	Estimate log probabilities and responsibilities for each sample.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L476'>_print_verbose_msg_init_beg</a>(n_init)</tt>	Print verbose message on initialization.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L485'>_print_verbose_msg_iter_end</a>(n_iter,diff_ll)</tt>	Print verbose message on initialization.
<tt style='background-color:#E8E8E8;'> mixture.BaseMixture <a href=' /mixture/base.py#L496'>_print_verbose_msg_init_end</a>(ll)</tt>	Print verbose message on the end of iteration.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L21'>_check_weights</a>(weights,n_components)</tt>	Check the user provided 'weights'.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L54'>_check_means</a>(means,n_components,n_features)</tt>	Validate the provided 'means'.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L77'>_check_precision_positivity</a>(precision,covariance_type)</tt>	Check a precision vector is positive-definite.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L84'>_check_precision_matrix</a>(precision,covariance_type)</tt>	Check a precision matrix is symmetric and positive-definite.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L92'>_check_precisions_full</a>(precisions,covariance_type)</tt>	Check the precision matrices are symmetric and positive-definite.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L98'>_check_precisions</a>(precisions,covariance_type,n_components,n_features)</tt>	Validate user provided precisions.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L143'>_estimate_gaussian_covariances_full</a>(resp,X,nk,means)</tt>	Estimate the full covariance matrices.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L172'>_estimate_gaussian_covariances_tied</a>(resp,X,nk,means)</tt>	Estimate the tied covariance matrix.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L200'>_estimate_gaussian_covariances_diag</a>(resp,X,nk,means)</tt>	Estimate the diagonal covariance vectors.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L226'>_estimate_gaussian_covariances_spherical</a>(resp,X,nk,means)</tt>	Estimate the spherical variance values.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L250'>_estimate_gaussian_parameters</a>(X,resp,reg_covar,covariance_type)</tt>	Estimate the gaussian distribution parameters.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L289'>_compute_precision_cholesky</a>(covariances,covariance_type)</tt>	Compute the cholesky decomposition of the precisions.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L341'>_compute_log_det_cholesky</a>(matrix_chol,covariance_type,n_features)</tt>	Compute the log-det of the cholesky decomposition of matrices.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gaussian_mixture.py#L381'>_estimate_log_gaussian_prob</a>(X,means,precisions_chol,covariance_type)</tt>	Estimate the log gaussian probability.
<tt style='background-color:#E8E8E8;'> mixture.GaussianMixture <a href=' /mixture/gaussian_mixture.py#L599'>_check_parameters</a>(X)</tt>	Check the gaussian mixture parameters are well defined.
<tt style='background-color:#E8E8E8;'> mixture.GaussianMixture <a href=' /mixture/gaussian_mixture.py#L622'>_initialize</a>(X,resp)</tt>	Initialization of the gaussian mixture parameters.
<tt style='background-color:#E8E8E8;'> mixture.GaussianMixture <a href=' /mixture/gaussian_mixture.py#L709'>_n_parameters</a>()</tt>	Return the number of free parameters in the model.
<tt style='background-color:#E8E8E8;'> mixture.GaussianMixture <a href=' /mixture/gaussian_mixture.py#L723'>bic</a>(X)</tt>	Bayesian information criterion for the current model on the input x.
<tt style='background-color:#E8E8E8;'> mixture.GaussianMixture <a href=' /mixture/gaussian_mixture.py#L738'>aic</a>(X)</tt>	Akaike information criterion for the current model on the input x.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L33'>log_multivariate_normal_density</a>(X,means,covars,covariance_type)</tt>	Compute the log probability under a multivariate gaussian distribution.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L75'>sample_gaussian</a>(mean,covar,covariance_type,n_samples)</tt>	Generate random samples from a gaussian distribution.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L281'>_get_covars</a>()</tt>	Covariance parameters for each mixture component.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L301'>_set_covars</a>(covars)</tt>	Provide values for covariance.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L307'>score_samples</a>(X)</tt>	Return the per-sample likelihood of the data under the model.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L346'>score</a>(X,y)</tt>	Compute the log probability under the model.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L363'>predict</a>(X)</tt>	Predict label for data.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L377'>predict_proba</a>(X)</tt>	Predict posterior probability of data under each gaussian in the model.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L394'>sample</a>(n_samples,random_state)</tt>	Generate random samples from the model.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L436'>fit_predict</a>(X,y)</tt>	Fit and then predict labels for data.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L455'>_fit</a>(X,y,do_prediction)</tt>	Estimate model parameters with the em algorithm.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L583'>fit</a>(X,y)</tt>	Estimate model parameters with the em algorithm.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L605'>_do_mstep</a>(X,responsibilities,params,min_covar)</tt>	Perform the mstep of the em algorithm and return the cluster weights.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L623'>_n_parameters</a>()</tt>	Return the number of free parameters in the model.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L637'>bic</a>(X)</tt>	Bayesian information criterion for the current model fit and the proposed data.
<tt style='background-color:#E8E8E8;'> mixture._GMMBase <a href=' /mixture/gmm.py#L652'>aic</a>(X)</tt>	Akaike information criterion for the current model fit and the proposed data.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L694'>_log_multivariate_normal_density_diag</a>(X,means,covars)</tt>	Compute gaussian log-density at x for a diagonal model.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L704'>_log_multivariate_normal_density_spherical</a>(X,means,covars)</tt>	Compute gaussian log-density at x for a spherical model.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L714'>_log_multivariate_normal_density_tied</a>(X,means,covars)</tt>	Compute gaussian log-density at x for a tied model.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L720'>_log_multivariate_normal_density_full</a>(X,means,covars,min_covar)</tt>	Log probability for full covariance matrices.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L746'>_validate_covars</a>(covars,covariance_type,n_components)</tt>	Do basic checks on matrix covariance sizes and values.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L784'>distribute_covar_matrix_to_match_covariance_type</a>(tied_cv,covariance_type,n_components)</tt>	Create all the covariance matrices from a given template.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L804'>_covar_mstep_diag</a>(gmm,X,responsibilities,weighted_X_sum)</tt>	Perform the covariance m step for diagonal cases.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L813'>_covar_mstep_spherical</a>()</tt>	Perform the covariance m step for spherical cases.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L819'>_covar_mstep_full</a>(gmm,X,responsibilities,weighted_X_sum)</tt>	Perform the covariance m step for full cases.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/gmm.py#L837'>_covar_mstep_tied</a>(gmm,X,responsibilities,weighted_X_sum)</tt>	Perform the covariance m step for tied cases.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/bayesian_mixture.py#L21'>_log_dirichlet_norm</a>(dirichlet_concentration)</tt>	Compute the log of the dirichlet distribution normalization term.
<tt style='background-color:#E8E8E8;'> mixture. <a href=' /mixture/bayesian_mixture.py#L38'>_log_wishart_norm</a>(degrees_of_freedom,log_det_precisions_chol,n_features)</tt>	Compute the log of the wishart distribution normalization term.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L330'>_check_parameters</a>(X)</tt>	Check that the parameters are well defined.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L356'>_check_weights_parameters</a>()</tt>	Check the parameter of the dirichlet distribution.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L368'>_check_means_parameters</a>(X)</tt>	Check the parameters of the gaussian distribution.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L394'>_check_precision_parameters</a>(X)</tt>	Check the prior parameters of the precision distribution.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L412'>_checkcovariance_prior_parameter</a>(X)</tt>	Check the covariance_prior_.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L453'>_initialize</a>(X,resp)</tt>	Initialization of the mixture parameters.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L469'>_estimate_weights</a>(nk)</tt>	Estimate the parameters of the dirichlet distribution.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L487'>_estimate_means</a>(nk,xk)</tt>	Estimate the parameters of the gaussian distribution.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L501'>_estimate_precisions</a>(nk,xk,sk)</tt>	Estimate the precisions parameters of the precision distribution.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L526'>_estimate_wishart_full</a>(nk,xk,sk)</tt>	Estimate the full wishart distribution parameters.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L560'>_estimate_wishart_tied</a>(nk,xk,sk)</tt>	Estimate the tied wishart distribution parameters.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L590'>_estimate_wishart_diag</a>(nk,xk,sk)</tt>	Estimate the diag wishart distribution parameters.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L619'>_estimate_wishart_spherical</a>(nk,xk,sk)</tt>	Estimate the spherical wishart distribution parameters.
<tt style='background-color:#E8E8E8;'> mixture.BayesianGaussianMixture <a href=' /mixture/bayesian_mixture.py#L701'>_compute_lower_bound</a>(log_resp,log_prob_norm)</tt>	Estimate the lower bound of the model.
<tt style='background-color:#E8E8E8;'> decomposition._BasePCA <a href=' /decomposition/base.py#L28'>get_covariance</a>()</tt>	Compute data covariance with the generative model.
<tt style='background-color:#E8E8E8;'> decomposition._BasePCA <a href=' /decomposition/base.py#L49'>get_precision</a>()</tt>	Compute data precision matrix with the generative model.
<tt style='background-color:#E8E8E8;'> decomposition._BasePCA <a href=' /decomposition/base.py#L82'>fit</a>(X,y)</tt>	Placeholder for fit subclasses should implement this method!.
<tt style='background-color:#E8E8E8;'> decomposition._BasePCA <a href=' /decomposition/base.py#L101'>transform</a>(X,y)</tt>	Apply dimensionality reduction to x.
<tt style='background-color:#E8E8E8;'> decomposition._BasePCA <a href=' /decomposition/base.py#L138'>inverse_transform</a>(X,y)</tt>	Transform data back to its original space.
<tt style='background-color:#E8E8E8;'> decomposition.FactorAnalysis <a href=' /decomposition/factor_analysis.py#L144'>fit</a>(X,y)</tt>	Fit the factoranalysis model to x using em parameters.
<tt style='background-color:#E8E8E8;'> decomposition.FactorAnalysis <a href=' /decomposition/factor_analysis.py#L234'>transform</a>(X)</tt>	Apply dimensionality reduction to x using the model.
<tt style='background-color:#E8E8E8;'> decomposition.FactorAnalysis <a href=' /decomposition/factor_analysis.py#L264'>get_covariance</a>()</tt>	Compute data covariance with the factoranalysis model.
<tt style='background-color:#E8E8E8;'> decomposition.FactorAnalysis <a href=' /decomposition/factor_analysis.py#L280'>get_precision</a>()</tt>	Compute data precision matrix with the factoranalysis model.
<tt style='background-color:#E8E8E8;'> decomposition.FactorAnalysis <a href=' /decomposition/factor_analysis.py#L309'>score_samples</a>(X)</tt>	Compute the log-likelihood of each sample.
<tt style='background-color:#E8E8E8;'> decomposition.FactorAnalysis <a href=' /decomposition/factor_analysis.py#L333'>score</a>(X,y)</tt>	Compute the average log-likelihood of the samples.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/fastica_.py#L26'>_gs_decorrelation</a>(w,W,j)</tt>	Orthonormalize w wrt the first j rows of w parameters.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/fastica_.py#L51'>_sym_decorrelation</a>(W)</tt>	Symmetric decorrelation i.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/fastica_.py#L61'>_ica_def</a>(X,tol,g,fun_args)</tt>	Deflationary fastica using fun approx to neg-entropy function used internally by fastica.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/fastica_.py#L147'>fastica</a>(X,n_components,algorithm,whiten)</tt>	Perform fast independent component analysis.
<tt style='background-color:#E8E8E8;'> decomposition.FastICA <a href=' /decomposition/fastica_.py#L462'>_fit</a>(X,compute_sources)</tt>	Fit the model parameters.
<tt style='background-color:#E8E8E8;'> decomposition.FastICA <a href=' /decomposition/fastica_.py#L501'>fit_transform</a>(X,y)</tt>	Fit the model and recover the sources from x.
<tt style='background-color:#E8E8E8;'> decomposition.FastICA <a href=' /decomposition/fastica_.py#L516'>fit</a>(X,y)</tt>	Fit the model to x.
<tt style='background-color:#E8E8E8;'> decomposition.FastICA <a href=' /decomposition/fastica_.py#L532'>transform</a>(X,y,copy)</tt>	Recover the sources from x apply the unmixing matrix.
<tt style='background-color:#E8E8E8;'> decomposition.FastICA <a href=' /decomposition/fastica_.py#L556'>inverse_transform</a>(X,copy)</tt>	Transform the sources back to the mixed data apply mixing matrix.
<tt style='background-color:#E8E8E8;'> decomposition.TruncatedSVD <a href=' /decomposition/truncated_svd.py#L131'>fit</a>(X,y)</tt>	Fit lsi model on training data x.
<tt style='background-color:#E8E8E8;'> decomposition.TruncatedSVD <a href=' /decomposition/truncated_svd.py#L147'>fit_transform</a>(X,y)</tt>	Fit lsi model to x and perform dimensionality reduction on x.
<tt style='background-color:#E8E8E8;'> decomposition.TruncatedSVD <a href=' /decomposition/truncated_svd.py#L201'>transform</a>(X)</tt>	Perform dimensionality reduction on x.
<tt style='background-color:#E8E8E8;'> decomposition.TruncatedSVD <a href=' /decomposition/truncated_svd.py#L217'>inverse_transform</a>(X)</tt>	Transform x back to its original space.
<tt style='background-color:#E8E8E8;'> decomposition.IncrementalPCA <a href=' /decomposition/incremental_pca.py#L151'>fit</a>(X,y)</tt>	Fit the model with x using minibatches of size batch_size.
<tt style='background-color:#E8E8E8;'> decomposition.IncrementalPCA <a href=' /decomposition/incremental_pca.py#L190'>partial_fit</a>(X,y,check_input)</tt>	Incremental fit with x all of x is processed as a single batch.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L33'>norm</a>(x)</tt>	Dot product-based euclidean norm implementation see http //fseoane.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L41'>trace_dot</a>(X,Y)</tt>	Trace of np dot x y t.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L56'>_beta_divergence</a>(X,W,H,beta)</tt>	Compute the beta-divergence of x and dot w h.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L161'>_special_sparse_dot</a>(W,H,X)</tt>	Computes np dot w h only where x is non zero.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L172'>_compute_regularization</a>(alpha,l1_ratio,regularization)</tt>	Compute l1 and l2 regularization coefficients for w and h.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L218'>_beta_loss_to_float</a>(beta_loss)</tt>	Convert string beta_loss to float.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L233'>_initialize_nmf</a>(X,n_components,init,eps)</tt>	Algorithms for nmf initialization.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L371'>_update_coordinate_descent</a>(X,W,Ht,l1_reg)</tt>	Helper function for _fit_coordinate_descent update w to minimize the objective function iterating once over all.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L402'>_fit_coordinate_descent</a>(X,W,H,tol)</tt>	Compute non-negative matrix factorization nmf with coordinate descent the objective function is minimized with an alternating minimization of w.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L508'>_multiplicative_update_w</a>(X,W,H,beta_loss)</tt>	Update w in multiplicative update nmf.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L596'>_multiplicative_update_h</a>(X,W,H,beta_loss)</tt>	Update h in multiplicative update nmf.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L671'>_fit_multiplicative_update</a>(X,W,H,beta_loss)</tt>	Compute non-negative matrix factorization with multiplicative update the objective function is _beta_divergence x wh and is minimized with an.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/nmf.py#L805'>non_negative_factorization</a>(X,W,H,n_components)</tt>	Compute non-negative matrix factorization nmf find two non-negative matrices w h whose product approximates the non-.
<tt style='background-color:#E8E8E8;'> decomposition.NMF <a href=' /decomposition/nmf.py#L1186'>fit_transform</a>(X,y,W,H)</tt>	Learn a nmf model for the data x and returns the transformed data.
<tt style='background-color:#E8E8E8;'> decomposition.NMF <a href=' /decomposition/nmf.py#L1226'>fit</a>(X,y)</tt>	Learn a nmf model for the data x.
<tt style='background-color:#E8E8E8;'> decomposition.NMF <a href=' /decomposition/nmf.py#L1241'>transform</a>(X)</tt>	Transform the data x according to the fitted nmf model.
<tt style='background-color:#E8E8E8;'> decomposition.NMF <a href=' /decomposition/nmf.py#L1266'>inverse_transform</a>(W)</tt>	Transform data back to its original space.
<tt style='background-color:#E8E8E8;'> decomposition.SparsePCA <a href=' /decomposition/sparse_pca.py#L101'>fit</a>(X,y)</tt>	Fit the model from data in x.
<tt style='background-color:#E8E8E8;'> decomposition.SparsePCA <a href=' /decomposition/sparse_pca.py#L138'>transform</a>(X,ridge_alpha)</tt>	Least squares projection of the data onto the sparse components.
<tt style='background-color:#E8E8E8;'> decomposition.MiniBatchSparsePCA <a href=' /decomposition/sparse_pca.py#L273'>fit</a>(X,y)</tt>	Fit the model from data in x.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/online_lda.py#L34'>_update_doc_distribution</a>(X,exp_topic_word_distr,doc_topic_prior,max_iters)</tt>	E-step update document-topic distribution.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L276'>_check_params</a>()</tt>	Check model parameters.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L295'>_init_latent_vars</a>(n_features)</tt>	Initialize latent variables.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L322'>_e_step</a>(X,cal_sstats,random_init,parallel)</tt>	E-step in em update.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L384'>_em_step</a>(X,total_samples,batch_update,parallel)</tt>	Em update for 1 iteration.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L434'>_check_non_neg_array</a>(X,whom)</tt>	Check x format check x format and make sure no negative value in x.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L448'>partial_fit</a>(X,y)</tt>	Online vb with mini-batch update.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L486'>fit</a>(X,y)</tt>	Learn model for the data x with variational bayes method.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L557'>_unnormalized_transform</a>(X)</tt>	Transform data x according to fitted model.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L588'>transform</a>(X)</tt>	Transform data x according to the fitted model.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L608'>_approx_bound</a>(X,doc_topic_distr,sub_sampling)</tt>	Estimate the variational bound.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L684'>score</a>(X,y)</tt>	Calculate approximate log-likelihood as score.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L703'>_perplexity_precomp_distr</a>(X,doc_topic_distr,sub_sampling)</tt>	Calculate approximate perplexity for data x with ability to accept precomputed doc_topic_distr.
<tt style='background-color:#E8E8E8;'> decomposition.LatentDirichletAllocation <a href=' /decomposition/online_lda.py#L753'>perplexity</a>(X,doc_topic_distr,sub_sampling)</tt>	Calculate approximate perplexity for data x.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/dict_learning.py#L164'>sparse_encode</a>(X,dictionary,gram,cov)</tt>	Sparse coding each row of the result is the solution to a sparse coding problem.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/dict_learning.py#L309'>_update_dict</a>(dictionary,Y,code,verbose)</tt>	Update the dense dictionary factor in place.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/dict_learning.py#L384'>dict_learning</a>(X,n_components,alpha,max_iter)</tt>	Solves a dictionary learning matrix factorization problem.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/dict_learning.py#L558'>dict_learning_online</a>(X,n_components,alpha,n_iter)</tt>	Solves a dictionary learning matrix factorization problem online.
<tt style='background-color:#E8E8E8;'> decomposition.SparseCodingMixin <a href=' /decomposition/dict_learning.py#L803'>transform</a>(X,y)</tt>	Encode the data as a sparse combination of the dictionary atoms.
<tt style='background-color:#E8E8E8;'> decomposition.SparseCoder <a href=' /decomposition/dict_learning.py#L919'>fit</a>(X,y)</tt>	Do nothing and return the estimator unchanged this method is just there to implement the usual api and hence.
<tt style='background-color:#E8E8E8;'> decomposition.DictionaryLearning <a href=' /decomposition/dict_learning.py#L1061'>fit</a>(X,y)</tt>	Fit the model from data in x.
<tt style='background-color:#E8E8E8;'> decomposition.MiniBatchDictionaryLearning <a href=' /decomposition/dict_learning.py#L1231'>fit</a>(X,y)</tt>	Fit the model from data in x.
<tt style='background-color:#E8E8E8;'> decomposition.MiniBatchDictionaryLearning <a href=' /decomposition/dict_learning.py#L1264'>partial_fit</a>(X,y,iter_offset)</tt>	Updates the model using the data in x as a mini-batch.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/pca.py#L33'>_assess_dimension_</a>(spectrum,rank,n_samples,n_features)</tt>	Compute the likelihood of a rank rank dataset the dataset is assumed to be embedded in gaussian noise of shape(n.
<tt style='background-color:#E8E8E8;'> decomposition. <a href=' /decomposition/pca.py#L95'>_infer_dimension_</a>(spectrum,n_samples,n_features)</tt>	Infers the dimension of a dataset of shape (n_samples n_features) the dataset is described by its spectrum spectrum.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L313'>fit</a>(X,y)</tt>	Fit the model with x.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L330'>fit_transform</a>(X,y)</tt>	Fit the model with x and apply the dimensionality reduction on x.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L356'>_fit</a>(X)</tt>	Dispatch to the right submethod depending on the chosen solver.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L395'>_fit_full</a>(X,n_components)</tt>	Fit the model by computing full svd on x.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L451'>_fit_truncated</a>(X,n_components,svd_solver)</tt>	Fit the model by computing truncated svd by arpack or randomized.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L511'>score_samples</a>(X)</tt>	Return the log-likelihood of each sample.
<tt style='background-color:#E8E8E8;'> decomposition.PCA <a href=' /decomposition/pca.py#L540'>score</a>(X,y)</tt>	Return the average log-likelihood of all samples.
<tt style='background-color:#E8E8E8;'> decomposition.RandomizedPCA <a href=' /decomposition/pca.py#L669'>fit</a>(X,y)</tt>	Fit the model with x by extracting the first principal components.
<tt style='background-color:#E8E8E8;'> decomposition.RandomizedPCA <a href=' /decomposition/pca.py#L686'>_fit</a>(X)</tt>	Fit the model to the data x.
<tt style='background-color:#E8E8E8;'> decomposition.RandomizedPCA <a href=' /decomposition/pca.py#L729'>transform</a>(X,y)</tt>	Apply dimensionality reduction on x.
<tt style='background-color:#E8E8E8;'> decomposition.RandomizedPCA <a href=' /decomposition/pca.py#L755'>fit_transform</a>(X,y)</tt>	Fit the model with x and apply the dimensionality reduction on x.
<tt style='background-color:#E8E8E8;'> decomposition.RandomizedPCA <a href=' /decomposition/pca.py#L773'>inverse_transform</a>(X,y)</tt>	Transform data back to its original space.
<tt style='background-color:#E8E8E8;'> decomposition.KernelPCA <a href=' /decomposition/kernel_pca.py#L168'>_fit_transform</a>(K)</tt>	Fit's using kernel k.
<tt style='background-color:#E8E8E8;'> decomposition.KernelPCA <a href=' /decomposition/kernel_pca.py#L223'>fit</a>(X,y)</tt>	Fit the model from data in x.
<tt style='background-color:#E8E8E8;'> decomposition.KernelPCA <a href=' /decomposition/kernel_pca.py#L249'>fit_transform</a>(X,y)</tt>	Fit the model from data in x and transform x.
<tt style='background-color:#E8E8E8;'> decomposition.KernelPCA <a href=' /decomposition/kernel_pca.py#L287'>inverse_transform</a>(X)</tt>	Transform x back to original space.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/funcsigs.py#L52'>signature</a>(obj)</tt>	Get a signature object for the passed callable.
<tt style='background-color:#E8E8E8;'> externals.Parameter <a href=' /externals/funcsigs.py#L279'>replace</a>(name,kind,annotation,default)</tt>	Creates a customized copy of the parameter.
<tt style='background-color:#E8E8E8;'> externals.Signature <a href=' /externals/funcsigs.py#L471'>__init__</a>(parameters,return_annotation,__validate_parameters__)</tt>	Constructs signature from the given list of parameter objects and 'return_annotation'.
<tt style='background-color:#E8E8E8;'> externals.Signature <a href=' /externals/funcsigs.py#L509'>from_function</a>(cls,func)</tt>	Constructs signature for the given python function.
<tt style='background-color:#E8E8E8;'> externals.Signature <a href=' /externals/funcsigs.py#L593'>replace</a>(parameters,return_annotation)</tt>	Creates a customized copy of the signature.
<tt style='background-color:#E8E8E8;'> externals.Signature <a href=' /externals/funcsigs.py#L645'>_bind</a>(args,kwargs,partial)</tt>	Private method don't use directly.
<tt style='background-color:#E8E8E8;'> externals.Signature <a href=' /externals/funcsigs.py#L773'>bind</a>()</tt>	Get a boundarguments object that maps the passed args and kwargs to the function's signature.
<tt style='background-color:#E8E8E8;'> externals.Signature <a href=' /externals/funcsigs.py#L780'>bind_partial</a>()</tt>	Get a boundarguments object that partially maps the passed args and kwargs to the function's signature.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L69'>_add_doc</a>(func,doc)</tt>	Add documentation to a function.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L74'>_import_module</a>(name)</tt>	Import module returning the module after the last dot.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L338'>add_move</a>(move)</tt>	Add an item to six moves.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L343'>remove_move</a>(name)</tt>	Remove item from six moves.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L429'>iterkeys</a>(d)</tt>	Return an iterator over the keys of a dictionary.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L433'>itervalues</a>(d)</tt>	Return an iterator over the values of a dictionary.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L437'>iteritems</a>(d)</tt>	Return an iterator over the key value pairs of a dictionary.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L441'>iterlists</a>(d)</tt>	Return an iterator over the (key [values]) pairs of a dictionary.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L564'>with_metaclass</a>(meta)</tt>	Create a base class with a metaclass.
<tt style='background-color:#E8E8E8;'> externals. <a href=' /externals/six.py#L568'>add_metaclass</a>(metaclass)</tt>	Class decorator for creating a class with a metaclass.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L21'>get_func_code</a>(func)</tt>	Attempts to retrieve a reliable function code hash.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L77'>_clean_win_chars</a>(string)</tt>	Windows cannot encode some characters in filename.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L91'>get_func_name</a>(func,resolv_alias,win_characters)</tt>	Return the function import path as a list of module names and a name for the function.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L160'>getfullargspec</a>(func)</tt>	Compatibility function to provide inspect getfullargspec in python 2.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L186'>_signature_str</a>(function_name,arg_spec)</tt>	Helper function to output a function signature.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L196'>_function_called_str</a>(function_name,args,kwargs)</tt>	Helper function to output a function call.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L207'>filter_args</a>(func,ignore_lst,args,kwargs)</tt>	Filters the given args and kwargs using a list of arguments to ignore and a function specification.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/func_inspect.py#L350'>format_call</a>(func,args,kwargs,object_name)</tt>	Returns a nicely formatted statement displaying the function call with the given arguments.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L56'>get_active_backend</a>()</tt>	Return the active default backend.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L67'>parallel_backend</a>(backend,n_jobs)</tt>	Change the default backend used by parallel inside a with block.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L140'>cpu_count</a>()</tt>	Return the number of cpus.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L150'>_verbosity_filter</a>(index,verbose)</tt>	Returns false for indices increasingly apart the distance depending on the value of verbose.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L169'>delayed</a>(function,check_pickle)</tt>	Decorator used to capture the arguments of a function.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L223'>register_parallel_backend</a>(name,factory,make_default)</tt>	Register a new parallel backend factory.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/parallel.py#L245'>effective_n_jobs</a>(n_jobs)</tt>	Determine the number of jobs that can actually run in parallel n_jobs is the is the number of workers requested by the callers.
<tt style='background-color:#E8E8E8;'> externals.joblib.Parallel <a href=' /externals/joblib/parallel.py#L543'>_initialize_backend</a>()</tt>	Build a process or thread pool and return the number of workers.
<tt style='background-color:#E8E8E8;'> externals.joblib.Parallel <a href=' /externals/joblib/parallel.py#L572'>_dispatch</a>(batch)</tt>	Queue the batch for computing with or without multiprocessing warning this method is not thread-safe it should be only called.
<tt style='background-color:#E8E8E8;'> externals.joblib.Parallel <a href=' /externals/joblib/parallel.py#L591'>dispatch_next</a>()</tt>	Dispatch more data for parallel processing this method is meant to be called concurrently by the multiprocessing.
<tt style='background-color:#E8E8E8;'> externals.joblib.Parallel <a href=' /externals/joblib/parallel.py#L603'>dispatch_one_batch</a>(iterator)</tt>	Prefetch the tasks for the next batch and dispatch them.
<tt style='background-color:#E8E8E8;'> externals.joblib.Parallel <a href=' /externals/joblib/parallel.py#L628'>_print</a>(msg,msg_args)</tt>	Display the message on stout or stderr depending on verbosity.
<tt style='background-color:#E8E8E8;'> externals.joblib.Parallel <a href=' /externals/joblib/parallel.py#L641'>print_progress</a>()</tt>	Display the process of the parallel execution only a fraction of time controlled by self.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/_compat.py#L17'>with_metaclass</a>(meta)</tt>	Create a base class with a metaclass.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_compat.py#L13'>hex_str</a>(an_int)</tt>	Convert an int to an hexadecimal string.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_compat.py#L29'>read_zfile</a>(file_handle)</tt>	Read the z-file and return the content as a string.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_compat.py#L62'>write_zfile</a>(file_handle,data,compress)</tt>	Write the data in the given file as a z-file.
<tt style='background-color:#E8E8E8;'> externals.joblib.NDArrayWrapper <a href=' /externals/joblib/numpy_pickle_compat.py#L86'>__init__</a>(filename,subclass,allow_mmap)</tt>	Constructor store the useful information for later.
<tt style='background-color:#E8E8E8;'> externals.joblib.NDArrayWrapper <a href=' /externals/joblib/numpy_pickle_compat.py#L92'>read</a>(unpickler)</tt>	Reconstruct the array.
<tt style='background-color:#E8E8E8;'> externals.joblib.ZNDArrayWrapper <a href=' /externals/joblib/numpy_pickle_compat.py#L130'>__init__</a>(filename,init_args,state)</tt>	Constructor store the useful information for later.
<tt style='background-color:#E8E8E8;'> externals.joblib.ZNDArrayWrapper <a href=' /externals/joblib/numpy_pickle_compat.py#L136'>read</a>(unpickler)</tt>	Reconstruct the array from the meta-information and the z-file.
<tt style='background-color:#E8E8E8;'> externals.joblib.ZipNumpyUnpickler <a href=' /externals/joblib/numpy_pickle_compat.py#L170'>load_build</a>()</tt>	Set the state of a newly created object.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_compat.py#L193'>load_compatibility</a>(filename)</tt>	Reconstruct a python object from a file persisted with joblib dump.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/format_stack.py#L42'>safe_repr</a>(value)</tt>	Hopefully pretty robust repr equivalent.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/format_stack.py#L76'>uniq_stable</a>(elems)</tt>	Uniq_stable elems -> list return from an iterable a list of all the unique elements in the input.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/format_stack.py#L98'>fix_frame_records_filenames</a>(records)</tt>	Try to fix the filenames in each record from inspect getinnerframes().
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/format_stack.py#L326'>format_exc</a>(etype,evalue,etb,context)</tt>	Return a nice text document describing the traceback.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L79'>_is_raw_file</a>(fileobj)</tt>	Check if fileobj is a raw file object e g created with open.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L90'>_detect_compressor</a>(fileobj)</tt>	Return the compressor matching fileobj.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L127'>_buffered_read_file</a>(fobj)</tt>	Return a buffered version of a read file object.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L137'>_buffered_write_file</a>(fobj)</tt>	Return a buffered version of a write file object.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L149'>_read_fileobject</a>(fileobj,filename,mmap_mode)</tt>	Utility function opening the right fileobject from a filename.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L239'>_write_fileobject</a>(filename,compress)</tt>	Return the right compressor file object in write mode.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L338'>close</a>()</tt>	Flush and close the file.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L364'>closed</a>()</tt>	True if this file is closed.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L369'>fileno</a>()</tt>	Return the file descriptor for the underlying file.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L374'>seekable</a>()</tt>	Return whether the file supports seeking.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L378'>readable</a>()</tt>	Return whether the file was opened for reading.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L383'>writable</a>()</tt>	Return whether the file was opened for writing.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L487'>read</a>(size)</tt>	Read up to size uncompressed bytes from the file.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L502'>readinto</a>(b)</tt>	Read up to len b bytes into b.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L510'>write</a>(data)</tt>	Write a byte string to the file.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L537'>seek</a>(offset,whence)</tt>	Change the file position.
<tt style='background-color:#E8E8E8;'> externals.joblib.BinaryZlibFile <a href=' /externals/joblib/numpy_pickle_utils.py#L579'>tell</a>()</tt>	Return the current file position.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle_utils.py#L609'>_read_bytes</a>(fp,size,error_template)</tt>	Read from file-like object until size bytes are read.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L60'>extract_first_line</a>(func_code)</tt>	Extract the first line information from the function code text if available.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L78'>_get_func_fullname</a>(func)</tt>	Compute the part of part associated with a function.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L88'>_cache_key_to_dir</a>(cachedir,func,argument_hash)</tt>	Compute directory associated with a given cache key.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L104'>_load_output</a>(output_dir,func_name,timestamp,metadata)</tt>	Load output of a computation.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L142'>_get_cache_items</a>(root_path)</tt>	Get cache information for reducing the size of the cache.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L177'>_get_cache_items_to_delete</a>(root_path,bytes_limit)</tt>	Get cache items to delete to keep the cache under a size limit.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/memory.py#L206'>concurrency_safe_write</a>(to_write,filename,write_func)</tt>	Writes an object into a file in a concurrency-safe way.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedResult <a href=' /externals/joblib/memory.py#L279'>get</a>()</tt>	Read value from cache and return it.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedResult <a href=' /externals/joblib/memory.py#L286'>clear</a>()</tt>	Clear value from cache.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L481'>_cached_call</a>(args,kwargs)</tt>	Call wrapped function and cache result or read cache if available.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L540'>call_and_shelve</a>()</tt>	Call wrapped function cache result and return a reference.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L564'>__reduce__</a>()</tt>	We don't store the timestamp when pickling to avoid the hash depending from it.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L581'>_get_output_dir</a>()</tt>	Return the directory in which are persisted the result of the function called with the given arguments.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L592'>_get_func_dir</a>(mkdir)</tt>	Get the directory corresponding to the cache for the function.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L601'>_hash_func</a>()</tt>	Hash a function to key the online cache.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L606'>_write_func_code</a>(filename,func_code,first_line)</tt>	Write the function code and the filename to a file.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L635'>_check_previous_func_code</a>(stacklevel)</tt>	Stacklevel is the depth a which this function is called to issue useful warnings to the user.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L723'>clear</a>(warn)</tt>	Empty the function's cache.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L736'>call</a>()</tt>	Force the execution of the function with the given arguments and persist the output values.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L756'>_persist_output</a>(output,dir)</tt>	Persist the given output tuple in the directory.
<tt style='background-color:#E8E8E8;'> externals.joblib.MemorizedFunc <a href=' /externals/joblib/memory.py#L770'>_persist_input</a>(output_dir,duration,args,kwargs)</tt>	Save a small summary of the call using json format in the output directory.
<tt style='background-color:#E8E8E8;'> externals.joblib.Memory <a href=' /externals/joblib/memory.py#L900'>cache</a>(func,ignore,verbose,mmap_mode)</tt>	Decorates the given function func to only compute its return value for input arguments not cached on disk.
<tt style='background-color:#E8E8E8;'> externals.joblib.Memory <a href=' /externals/joblib/memory.py#L947'>clear</a>(warn)</tt>	Erase the complete cache directory.
<tt style='background-color:#E8E8E8;'> externals.joblib.Memory <a href=' /externals/joblib/memory.py#L955'>reduce_size</a>()</tt>	Remove cache folders to make cache size fit in bytes_limit.
<tt style='background-color:#E8E8E8;'> externals.joblib.Memory <a href=' /externals/joblib/memory.py#L973'>eval</a>(func)</tt>	Eval function func with arguments *args and **kwargs, in the context of the memory.
<tt style='background-color:#E8E8E8;'> externals.joblib.Memory <a href=' /externals/joblib/memory.py#L996'>__reduce__</a>()</tt>	We don't store the timestamp when pickling to avoid the hash depending from it.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/logger.py#L23'>_squeeze_time</a>(t)</tt>	Remove 1s to the time under windows this is the time it take to.
<tt style='background-color:#E8E8E8;'> externals.joblib.Logger <a href=' /externals/joblib/logger.py#L83'>format</a>(obj,indent)</tt>	Return the formated representation of the object.
<tt style='background-color:#E8E8E8;'> externals.joblib.PrintTime <a href=' /externals/joblib/logger.py#L133'>__call__</a>(msg,total)</tt>	Print the time elapsed between the last call and the current call with an optional message.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyHasher <a href=' /externals/joblib/hashing.py#L185'>save</a>(obj)</tt>	Subclass the save method to hash ndarray subclass rather than pickling them.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/hashing.py#L246'>hash</a>(obj,hash_name,coerce_mmap)</tt>	Quick calculation of a hash to identify uniquely python objects containing numpy arrays.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/pool.py#L79'>_get_backing_memmap</a>(a)</tt>	Recursively look up the original np memmap instance base if any.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/pool.py#L96'>has_shareable_memory</a>(a)</tt>	Return true if a is backed by some mmap buffer directly or not.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/pool.py#L101'>_strided_from_memmap</a>(filename,dtype,mode,offset)</tt>	Reconstruct an array view on a memory mapped file.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/pool.py#L120'>_reduce_memmap_backed</a>(a,m)</tt>	Pickling reduction for memmap backed arrays.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/pool.py#L156'>reduce_memmap</a>(a)</tt>	Pickle the descriptors of a memmap instance to reopen on same file.
<tt style='background-color:#E8E8E8;'> externals.joblib.CustomizablePickler <a href=' /externals/joblib/pool.py#L302'>register</a>(type,reduce_func)</tt>	Attach a reducer function to a given type in the dispatch table.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/pool.py#L432'>delete_folder</a>(folder_path)</tt>	Utility function to cleanup a temporary folder if still existing.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L26'>effective_n_jobs</a>(n_jobs)</tt>	Determine the number of jobs that can actually run in parallel n_jobs is the number of workers requested by the callers.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L44'>apply_async</a>(func,callback)</tt>	Schedule a func to be run.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L48'>configure</a>(n_jobs,parallel)</tt>	Reconfigure the backend and return the number of workers.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L57'>terminate</a>()</tt>	Shutdown the process or thread pool.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L60'>compute_batch_size</a>()</tt>	Determine the optimal batch size.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L64'>batch_completed</a>(batch_size,duration)</tt>	Callback indicate how long it took to run a batch.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L67'>get_exceptions</a>()</tt>	List of exception types to be captured.
<tt style='background-color:#E8E8E8;'> externals.joblib.ParallelBackendBase <a href=' /externals/joblib/_parallel_backends.py#L71'>abort_everything</a>(ensure_ready)</tt>	Abort any running tasks this is called when an exception has been raised when executing a tasks.
<tt style='background-color:#E8E8E8;'> externals.joblib.SequentialBackend <a href=' /externals/joblib/_parallel_backends.py#L103'>effective_n_jobs</a>(n_jobs)</tt>	Determine the number of jobs which are going to run in parallel.
<tt style='background-color:#E8E8E8;'> externals.joblib.SequentialBackend <a href=' /externals/joblib/_parallel_backends.py#L109'>apply_async</a>(func,callback)</tt>	Schedule a func to be run.
<tt style='background-color:#E8E8E8;'> externals.joblib.PoolManagerMixin <a href=' /externals/joblib/_parallel_backends.py#L120'>effective_n_jobs</a>(n_jobs)</tt>	Determine the number of jobs which are going to run in parallel.
<tt style='background-color:#E8E8E8;'> externals.joblib.PoolManagerMixin <a href=' /externals/joblib/_parallel_backends.py#L132'>terminate</a>()</tt>	Shutdown the process or thread pool.
<tt style='background-color:#E8E8E8;'> externals.joblib.PoolManagerMixin <a href=' /externals/joblib/_parallel_backends.py#L139'>apply_async</a>(func,callback)</tt>	Schedule a func to be run.
<tt style='background-color:#E8E8E8;'> externals.joblib.PoolManagerMixin <a href=' /externals/joblib/_parallel_backends.py#L143'>abort_everything</a>(ensure_ready)</tt>	Shutdown the pool and restart a new one with the same parameters.
<tt style='background-color:#E8E8E8;'> externals.joblib.AutoBatchingMixin <a href=' /externals/joblib/_parallel_backends.py#L168'>compute_batch_size</a>()</tt>	Determine the optimal batch size.
<tt style='background-color:#E8E8E8;'> externals.joblib.AutoBatchingMixin <a href=' /externals/joblib/_parallel_backends.py#L214'>batch_completed</a>(batch_size,duration)</tt>	Callback indicate how long it took to run a batch.
<tt style='background-color:#E8E8E8;'> externals.joblib.ThreadingBackend <a href=' /externals/joblib/_parallel_backends.py#L243'>configure</a>(n_jobs,parallel)</tt>	Build a process or thread pool and return the number of workers.
<tt style='background-color:#E8E8E8;'> externals.joblib.MultiprocessingBackend <a href=' /externals/joblib/_parallel_backends.py#L268'>effective_n_jobs</a>(n_jobs)</tt>	Determine the number of jobs which are going to run in parallel.
<tt style='background-color:#E8E8E8;'> externals.joblib.MultiprocessingBackend <a href=' /externals/joblib/_parallel_backends.py#L296'>configure</a>(n_jobs,parallel)</tt>	Build a process or thread pool and return the number of workers.
<tt style='background-color:#E8E8E8;'> externals.joblib.MultiprocessingBackend <a href=' /externals/joblib/_parallel_backends.py#L321'>terminate</a>()</tt>	Shutdown the process or thread pool.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/disk.py#L18'>disk_used</a>(path)</tt>	Return the disk usage in a directory.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/disk.py#L34'>memstr_to_bytes</a>(text)</tt>	Convert a memory text to its value in bytes.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/disk.py#L48'>mkdirp</a>(d)</tt>	Ensure directory d exists like mkdir -p on unix no guarantee that the directory is writable.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/disk.py#L64'>rm_subdirs</a>(path,onerror)</tt>	Remove all subdirectories in this path.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyArrayWrapper <a href=' /externals/joblib/numpy_pickle.py#L65'>__init__</a>(subclass,shape,order,dtype)</tt>	Constructor store the useful information for later.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyArrayWrapper <a href=' /externals/joblib/numpy_pickle.py#L73'>write_array</a>(array,pickler)</tt>	Write array bytes to pickler file handle.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyArrayWrapper <a href=' /externals/joblib/numpy_pickle.py#L95'>read_array</a>(unpickler)</tt>	Read array from unpickler file handle.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyArrayWrapper <a href=' /externals/joblib/numpy_pickle.py#L149'>read_mmap</a>(unpickler)</tt>	Read an array using numpy memmap.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyArrayWrapper <a href=' /externals/joblib/numpy_pickle.py#L166'>read</a>(unpickler)</tt>	Read the array corresponding to this wrapper.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyPickler <a href=' /externals/joblib/numpy_pickle.py#L237'>_create_array_wrapper</a>(array)</tt>	Create and returns a numpy array wrapper from a numpy array.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyPickler <a href=' /externals/joblib/numpy_pickle.py#L248'>save</a>(obj)</tt>	Subclass the pickler save method.
<tt style='background-color:#E8E8E8;'> externals.joblib.NumpyUnpickler <a href=' /externals/joblib/numpy_pickle.py#L320'>load_build</a>()</tt>	Called to set the state of a newly created object.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle.py#L353'>dump</a>(value,filename,compress,protocol)</tt>	Persist an arbitrary python object into one file.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle.py#L497'>_unpickle</a>(fobj,filename,mmap_mode)</tt>	Internal unpickling function.
<tt style='background-color:#E8E8E8;'> externals.joblib. <a href=' /externals/joblib/numpy_pickle.py#L530'>load</a>(filename,mmap_mode)</tt>	Reconstruct a python object from a file persisted with joblib dump.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/locally_linear.py#L19'>barycenter_weights</a>(X,Z,reg)</tt>	Compute barycenter weights of x from y along the first axis we estimate the weights to assign to each point in y[i] to recover.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/locally_linear.py#L66'>barycenter_kneighbors_graph</a>(X,n_neighbors,reg,n_jobs)</tt>	Computes the barycenter weighted graph of k-neighbors for points in x parameters.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/locally_linear.py#L108'>null_space</a>(M,k,k_skip,eigen_solver)</tt>	Find the null space of a matrix m.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/locally_linear.py#L185'>locally_linear_embedding</a>(X,n_neighbors,n_components,reg)</tt>	Perform a locally linear embedding analysis on the data.
<tt style='background-color:#E8E8E8;'> manifold.LocallyLinearEmbedding <a href=' /manifold/locally_linear.py#L646'>fit</a>(X,y)</tt>	Compute the embedding vectors for data x parameters.
<tt style='background-color:#E8E8E8;'> manifold.LocallyLinearEmbedding <a href=' /manifold/locally_linear.py#L661'>fit_transform</a>(X,y)</tt>	Compute the embedding vectors for data x and transform x.
<tt style='background-color:#E8E8E8;'> manifold.LocallyLinearEmbedding <a href=' /manifold/locally_linear.py#L676'>transform</a>(X)</tt>	Transform new points into embedding space.
<tt style='background-color:#E8E8E8;'> manifold.Isomap <a href=' /manifold/isomap.py#L126'>reconstruction_error</a>()</tt>	Compute the reconstruction error for the embedding.
<tt style='background-color:#E8E8E8;'> manifold.Isomap <a href=' /manifold/isomap.py#L150'>fit</a>(X,y)</tt>	Compute the embedding vectors for data x parameters.
<tt style='background-color:#E8E8E8;'> manifold.Isomap <a href=' /manifold/isomap.py#L167'>fit_transform</a>(X,y)</tt>	Fit the model from data in x and transform x.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/spectral_embedding_.py#L23'>_graph_connected_component</a>(graph,node_id)</tt>	Find the largest graph connected components that contains one.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/spectral_embedding_.py#L66'>_graph_is_connected</a>(graph)</tt>	Return whether the graph is connected true or not false.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/spectral_embedding_.py#L89'>_set_diag</a>(laplacian,value,norm_laplacian)</tt>	Set the diagonal of the laplacian matrix and convert it to a sparse format well suited for eigenvalue decomposition.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/spectral_embedding_.py#L133'>spectral_embedding</a>(adjacency,n_components,eigen_solver,random_state)</tt>	Project the sample on the first eigenvectors of the graph laplacian.
<tt style='background-color:#E8E8E8;'> manifold.SpectralEmbedding <a href=' /manifold/spectral_embedding_.py#L418'>_get_affinity_matrix</a>(X,Y)</tt>	Calculate the affinity matrix from data parameters.
<tt style='background-color:#E8E8E8;'> manifold.SpectralEmbedding <a href=' /manifold/spectral_embedding_.py#L463'>fit</a>(X,y)</tt>	Fit the model from data in x.
<tt style='background-color:#E8E8E8;'> manifold.SpectralEmbedding <a href=' /manifold/spectral_embedding_.py#L503'>fit_transform</a>(X,y)</tt>	Fit the model from data in x and transform x.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/mds.py#L20'>_smacof_single</a>(dissimilarities,metric,n_components,init)</tt>	Computes multidimensional scaling using smacof algorithm parameters.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/mds.py#L134'>smacof</a>(dissimilarities,metric,n_components,init)</tt>	Computes multidimensional scaling using the smacof algorithm.
<tt style='background-color:#E8E8E8;'> manifold.MDS <a href=' /manifold/mds.py#L372'>fit</a>(X,y,init)</tt>	Computes the position of the points in the embedding space parameters.
<tt style='background-color:#E8E8E8;'> manifold.MDS <a href=' /manifold/mds.py#L390'>fit_transform</a>(X,y,init)</tt>	Fit the data from x and returns the embedded coordinates parameters.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L33'>_joint_probabilities</a>(distances,desired_perplexity,verbose)</tt>	Compute joint probabilities p_ij from distances.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L65'>_joint_probabilities_nn</a>(distances,neighbors,desired_perplexity,verbose)</tt>	Compute joint probabilities p_ij from distances using just nearest neighbors.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L106'>_kl_divergence</a>(params,P,degrees_of_freedom,n_samples)</tt>	T-sne objective function gradient of the kl divergence of p_ijs and q_ijs and the absolute error.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L169'>_kl_divergence_error</a>(params,P,neighbors,degrees_of_freedom)</tt>	T-sne objective function the absolute error of the kl divergence of p_ijs and q_ijs.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L225'>_kl_divergence_bh</a>(params,P,neighbors,degrees_of_freedom)</tt>	T-sne objective function kl divergence of p_ijs and q_ijs.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L299'>_gradient_descent</a>(objective,p0,it,n_iter)</tt>	Batch gradient descent with momentum and individual gains.
<tt style='background-color:#E8E8E8;'> manifold. <a href=' /manifold/t_sne.py#L436'>trustworthiness</a>(X,X_embedded,n_neighbors,precomputed)</tt>	Expresses to what extent the local structure is retained.
<tt style='background-color:#E8E8E8;'> manifold.TSNE <a href=' /manifold/t_sne.py#L677'>_fit</a>(X,skip_num_points)</tt>	Fit the model using x as training data.
<tt style='background-color:#E8E8E8;'> manifold.TSNE <a href=' /manifold/t_sne.py#L881'>fit_transform</a>(X,y)</tt>	Fit x into an embedded space and return that transformed output.
<tt style='background-color:#E8E8E8;'> manifold.TSNE <a href=' /manifold/t_sne.py#L900'>fit</a>(X,y)</tt>	Fit x into an embedded space.
<tt style='background-color:#E8E8E8;'> ensemble.LossFunction <a href=' /ensemble/gradient_boosting.py#L190'>init_estimator</a>()</tt>	Default init estimator for loss function.
<tt style='background-color:#E8E8E8;'> ensemble.LossFunction <a href=' /ensemble/gradient_boosting.py#L194'>__call__</a>(y,pred,sample_weight)</tt>	Compute the loss of prediction pred and y.
<tt style='background-color:#E8E8E8;'> ensemble.LossFunction <a href=' /ensemble/gradient_boosting.py#L198'>negative_gradient</a>(y,y_pred)</tt>	Compute the negative gradient.
<tt style='background-color:#E8E8E8;'> ensemble.LossFunction <a href=' /ensemble/gradient_boosting.py#L210'>update_terminal_regions</a>(tree,X,y,residual)</tt>	Update the terminal regions (=leaves) of the given tree and updates the current predictions of the model.
<tt style='background-color:#E8E8E8;'> ensemble.LossFunction <a href=' /ensemble/gradient_boosting.py#L257'>_update_terminal_region</a>(tree,terminal_regions,leaf,X)</tt>	Template method for updating terminal regions (=leaves).
<tt style='background-color:#E8E8E8;'> ensemble.LeastSquaresError <a href=' /ensemble/gradient_boosting.py#L289'>update_terminal_regions</a>(tree,X,y,residual)</tt>	Least squares does not need to update terminal regions.
<tt style='background-color:#E8E8E8;'> ensemble.LeastAbsoluteError <a href=' /ensemble/gradient_boosting.py#L316'>negative_gradient</a>(y,pred)</tt>	1 0 if y - pred > 0 0 else -1 0.
<tt style='background-color:#E8E8E8;'> ensemble.LeastAbsoluteError <a href=' /ensemble/gradient_boosting.py#L321'>_update_terminal_region</a>(tree,terminal_regions,leaf,X)</tt>	Lad updates terminal regions to median estimates.
<tt style='background-color:#E8E8E8;'> ensemble.ClassificationLossFunction <a href=' /ensemble/gradient_boosting.py#L450'>_score_to_proba</a>(score)</tt>	Template method to convert scores to probabilities.
<tt style='background-color:#E8E8E8;'> ensemble.ClassificationLossFunction <a href=' /ensemble/gradient_boosting.py#L457'>_score_to_decision</a>(score)</tt>	Template method to convert scores to decisions.
<tt style='background-color:#E8E8E8;'> ensemble.BinomialDeviance <a href=' /ensemble/gradient_boosting.py#L481'>__call__</a>(y,pred,sample_weight)</tt>	Compute the deviance (= 2 * negative log-likelihood).
<tt style='background-color:#E8E8E8;'> ensemble.BinomialDeviance <a href=' /ensemble/gradient_boosting.py#L491'>negative_gradient</a>(y,pred)</tt>	Compute the residual (= negative gradient).
<tt style='background-color:#E8E8E8;'> ensemble.BinomialDeviance <a href=' /ensemble/gradient_boosting.py#L495'>_update_terminal_region</a>(tree,terminal_regions,leaf,X)</tt>	Make a single newton-raphson step.
<tt style='background-color:#E8E8E8;'> ensemble.MultinomialDeviance <a href=' /ensemble/gradient_boosting.py#L561'>negative_gradient</a>(y,pred,k)</tt>	Compute negative gradient for the k-th class.
<tt style='background-color:#E8E8E8;'> ensemble.MultinomialDeviance <a href=' /ensemble/gradient_boosting.py#L566'>_update_terminal_region</a>(tree,terminal_regions,leaf,X)</tt>	Make a single newton-raphson step.
<tt style='background-color:#E8E8E8;'> ensemble.VerboseReporter <a href=' /ensemble/gradient_boosting.py#L698'>update</a>(j,est)</tt>	Update reporter with new iteration.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L751'>_fit_stage</a>(i,X,y,y_pred)</tt>	Fit another stage of n_classes_ trees to the boosting model.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L807'>_check_params</a>()</tt>	Check validity of parameters and raise valueerror if not valid.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L881'>_init_state</a>()</tt>	Initialize model state and allocate model state data structures.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L899'>_clear_state</a>()</tt>	Clear the state of the gradient boosting model.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L910'>_resize_state</a>()</tt>	Add additional n_estimators entries to all attributes.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L931'>_check_initialized</a>()</tt>	Check that the estimator is initialized raising an error if not.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L941'>fit</a>(X,y,sample_weight,monitor)</tt>	Fit the gradient boosting model.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L1046'>_fit_stages</a>(X,y,y_pred,sample_weight)</tt>	Iteratively fits the stages.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L1119'>_init_decision_function</a>(X)</tt>	Check input and compute prediction of init.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L1137'>_staged_decision_function</a>(X)</tt>	Compute decision function of x for each iteration.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L1164'>feature_importances_</a>()</tt>	Return the feature importances the higher the more important the feature.
<tt style='background-color:#E8E8E8;'> ensemble.BaseGradientBoosting <a href=' /ensemble/gradient_boosting.py#L1191'>apply</a>(X)</tt>	Apply trees in the ensemble to x return leaf indices.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1461'>decision_function</a>(X)</tt>	Compute the decision function of x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1485'>staged_decision_function</a>(X)</tt>	Compute decision function of x for each iteration.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1510'>predict</a>(X)</tt>	Predict class for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1529'>staged_predict</a>(X)</tt>	Predict class at each stage for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1551'>predict_proba</a>(X)</tt>	Predict class probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1581'>predict_log_proba</a>(X)</tt>	Predict class log-probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingClassifier <a href=' /ensemble/gradient_boosting.py#L1605'>staged_predict_proba</a>(X)</tt>	Predict class probabilities at each stage for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingRegressor <a href=' /ensemble/gradient_boosting.py#L1860'>predict</a>(X)</tt>	Predict regression target for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingRegressor <a href=' /ensemble/gradient_boosting.py#L1878'>staged_predict</a>(X)</tt>	Predict regression target at each stage for x.
<tt style='background-color:#E8E8E8;'> ensemble.GradientBoostingRegressor <a href=' /ensemble/gradient_boosting.py#L1899'>apply</a>(X)</tt>	Apply trees in the ensemble to x return leaf indices.
<tt style='background-color:#E8E8E8;'> ensemble.BaseWeightBoosting <a href=' /ensemble/weight_boosting.py#L74'>fit</a>(X,y,sample_weight)</tt>	Build a boosted classifier/regressor from the training set x y.
<tt style='background-color:#E8E8E8;'> ensemble.BaseWeightBoosting <a href=' /ensemble/weight_boosting.py#L170'>_boost</a>(iboost,X,y,sample_weight)</tt>	Implement a single boost.
<tt style='background-color:#E8E8E8;'> ensemble.BaseWeightBoosting <a href=' /ensemble/weight_boosting.py#L210'>staged_score</a>(X,y,sample_weight)</tt>	Return staged scores for x y.
<tt style='background-color:#E8E8E8;'> ensemble.BaseWeightBoosting <a href=' /ensemble/weight_boosting.py#L239'>feature_importances_</a>()</tt>	Return the feature importances the higher the more important the feature.
<tt style='background-color:#E8E8E8;'> ensemble.BaseWeightBoosting <a href=' /ensemble/weight_boosting.py#L264'>_validate_X_predict</a>(X)</tt>	Ensure that x is in the proper format.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/weight_boosting.py#L277'>_samme_proba</a>(estimator,n_classes,X)</tt>	Calculate algorithm 4 step 2 equation c) of zhu et al [1].
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L387'>fit</a>(X,y,sample_weight)</tt>	Build a boosted classifier from the training set x y.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L415'>_validate_estimator</a>()</tt>	Check the estimator and set the base_estimator_ attribute.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L433'>_boost</a>(iboost,X,y,sample_weight)</tt>	Implement a single boost.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L479'>_boost_real</a>(iboost,X,y,sample_weight)</tt>	Implement a single boost using the samme r real algorithm.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L537'>_boost_discrete</a>(iboost,X,y,sample_weight)</tt>	Implement a single boost using the samme discrete algorithm.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L585'>predict</a>(X)</tt>	Predict classes for x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L609'>staged_predict</a>(X)</tt>	Return staged predictions for x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L641'>decision_function</a>(X)</tt>	Compute the decision function of x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L682'>staged_decision_function</a>(X)</tt>	Compute decision function of x for each boosting iteration.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L735'>predict_proba</a>(X)</tt>	Predict class probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L779'>staged_predict_proba</a>(X)</tt>	Predict class probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostClassifier <a href=' /ensemble/weight_boosting.py#L831'>predict_log_proba</a>(X)</tt>	Predict class log-probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostRegressor <a href=' /ensemble/weight_boosting.py#L933'>fit</a>(X,y,sample_weight)</tt>	Build a boosted regressor from the training set x y.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostRegressor <a href=' /ensemble/weight_boosting.py#L962'>_validate_estimator</a>()</tt>	Check the estimator and set the base_estimator_ attribute.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostRegressor <a href=' /ensemble/weight_boosting.py#L967'>_boost</a>(iboost,X,y,sample_weight)</tt>	Implement a single boost for regression perform a single boost according to the adaboost.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostRegressor <a href=' /ensemble/weight_boosting.py#L1076'>predict</a>(X)</tt>	Predict regression value for x.
<tt style='background-color:#E8E8E8;'> ensemble.AdaBoostRegressor <a href=' /ensemble/weight_boosting.py#L1098'>staged_predict</a>(X)</tt>	Return staged predictions for x.
<tt style='background-color:#E8E8E8;'> ensemble.IsolationForest <a href=' /ensemble/iforest.py#L204'>predict</a>(X)</tt>	Predict if a particular sample is an outlier or not.
<tt style='background-color:#E8E8E8;'> ensemble.IsolationForest <a href=' /ensemble/iforest.py#L225'>decision_function</a>(X)</tt>	Average anomaly score of x of the base classifiers.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/iforest.py#L285'>_average_path_length</a>(n_samples_leaf)</tt>	The average path length in a n_samples itree which is equal to the average path length of an unsuccessful bst search since the.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/base.py#L19'>_set_random_states</a>(estimator,random_state)</tt>	Sets fixed random_state parameters for an estimator finds all parameters ending random_state and sets them to integers.
<tt style='background-color:#E8E8E8;'> ensemble.BaseEnsemble <a href=' /ensemble/base.py#L96'>_validate_estimator</a>(default)</tt>	Check the estimator and the n_estimator attribute set the base_estimator_ attribute.
<tt style='background-color:#E8E8E8;'> ensemble.BaseEnsemble <a href=' /ensemble/base.py#L115'>_make_estimator</a>(append,random_state)</tt>	Make and configure a copy of the base_estimator_ attribute.
<tt style='background-color:#E8E8E8;'> ensemble.BaseEnsemble <a href=' /ensemble/base.py#L133'>__len__</a>()</tt>	Returns the number of estimators in the ensemble.
<tt style='background-color:#E8E8E8;'> ensemble.BaseEnsemble <a href=' /ensemble/base.py#L137'>__getitem__</a>(index)</tt>	Returns the index'th estimator in the ensemble.
<tt style='background-color:#E8E8E8;'> ensemble.BaseEnsemble <a href=' /ensemble/base.py#L141'>__iter__</a>()</tt>	Returns iterator over estimators in the ensemble.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/base.py#L146'>_partition_estimators</a>(n_estimators,n_jobs)</tt>	Private function used to partition estimators between jobs.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L37'>_generate_indices</a>(random_state,bootstrap,n_population,n_samples)</tt>	Draw randomly sampled indices.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L49'>_generate_bagging_indices</a>(random_state,bootstrap_features,bootstrap_samples,n_features)</tt>	Randomly draw feature and sample indices.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L65'>_parallel_build_estimators</a>(n_estimators,ensemble,X,y)</tt>	Private function used to build a batch of estimators within a job.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L125'>_parallel_predict_proba</a>(estimators,estimators_features,X,n_classes)</tt>	Private function used to compute proba- predictions within a job.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L151'>_parallel_predict_log_proba</a>(estimators,estimators_features,X,n_classes)</tt>	Private function used to compute log probabilities within a job.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L176'>_parallel_decision_function</a>(estimators,estimators_features,X)</tt>	Private function used to compute decisions within a job.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/bagging.py#L183'>_parallel_predict_regression</a>(estimators,estimators_features,X)</tt>	Private function used to compute predictions within a job.
<tt style='background-color:#E8E8E8;'> ensemble.BaseBagging <a href=' /ensemble/bagging.py#L224'>fit</a>(X,y,sample_weight)</tt>	Build a bagging ensemble of estimators from the training set x y.
<tt style='background-color:#E8E8E8;'> ensemble.BaseBagging <a href=' /ensemble/bagging.py#L250'>_fit</a>(X,y,max_samples,max_depth)</tt>	Build a bagging ensemble of estimators from the training set x y.
<tt style='background-color:#E8E8E8;'> ensemble.BaseBagging <a href=' /ensemble/bagging.py#L389'>_set_oob_score</a>(X,y)</tt>	Calculate out of bag predictions and score.
<tt style='background-color:#E8E8E8;'> ensemble.BaseBagging <a href=' /ensemble/bagging.py#L410'>estimators_samples_</a>()</tt>	The subset of drawn samples for each base estimator.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingClassifier <a href=' /ensemble/bagging.py#L574'>_validate_estimator</a>()</tt>	Check the estimator and set the base_estimator_ attribute.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingClassifier <a href=' /ensemble/bagging.py#L626'>predict</a>(X)</tt>	Predict class for x.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingClassifier <a href=' /ensemble/bagging.py#L648'>predict_proba</a>(X)</tt>	Predict class probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingClassifier <a href=' /ensemble/bagging.py#L697'>predict_log_proba</a>(X)</tt>	Predict class log-probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingClassifier <a href=' /ensemble/bagging.py#L752'>decision_function</a>(X)</tt>	Average of the decision functions of the base classifiers.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingRegressor <a href=' /ensemble/bagging.py#L931'>predict</a>(X)</tt>	Predict regression target for x.
<tt style='background-color:#E8E8E8;'> ensemble.BaggingRegressor <a href=' /ensemble/bagging.py#L968'>_validate_estimator</a>()</tt>	Check the estimator and set the base_estimator_ attribute.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/forest.py#L77'>_generate_sample_indices</a>(random_state,n_samples)</tt>	Private function used to _parallel_build_trees function.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/forest.py#L85'>_generate_unsampled_indices</a>(random_state,n_samples)</tt>	Private function used to forest _set_oob_score function.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/forest.py#L96'>_parallel_build_trees</a>(tree,forest,X,y)</tt>	Private function used to fit a single tree in parallel.
<tt style='background-color:#E8E8E8;'> ensemble.BaseForest <a href=' /ensemble/forest.py#L159'>apply</a>(X)</tt>	Apply trees in the forest to x return leaf indices.
<tt style='background-color:#E8E8E8;'> ensemble.BaseForest <a href=' /ensemble/forest.py#L183'>decision_path</a>(X)</tt>	Return the decision path in the forest.
<tt style='background-color:#E8E8E8;'> ensemble.BaseForest <a href=' /ensemble/forest.py#L219'>fit</a>(X,y,sample_weight)</tt>	Build a forest of trees from the training set x y.
<tt style='background-color:#E8E8E8;'> ensemble.BaseForest <a href=' /ensemble/forest.py#L342'>_set_oob_score</a>(X,y)</tt>	Calculate out of bag predictions and score.
<tt style='background-color:#E8E8E8;'> ensemble.BaseForest <a href=' /ensemble/forest.py#L350'>_validate_X_predict</a>(X)</tt>	Validate x whenever one tries to predict apply predict_proba.
<tt style='background-color:#E8E8E8;'> ensemble.BaseForest <a href=' /ensemble/forest.py#L358'>feature_importances_</a>()</tt>	Return the feature importances the higher the more important the feature.
<tt style='background-color:#E8E8E8;'> ensemble.ForestClassifier <a href=' /ensemble/forest.py#L423'>_set_oob_score</a>(X,y)</tt>	Compute out-of-bag score.
<tt style='background-color:#E8E8E8;'> ensemble.ForestClassifier <a href=' /ensemble/forest.py#L516'>predict</a>(X)</tt>	Predict class for x.
<tt style='background-color:#E8E8E8;'> ensemble.ForestClassifier <a href=' /ensemble/forest.py#L552'>predict_proba</a>(X)</tt>	Predict class probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.ForestClassifier <a href=' /ensemble/forest.py#L596'>predict_log_proba</a>(X)</tt>	Predict class log-probabilities for x.
<tt style='background-color:#E8E8E8;'> ensemble.ForestRegressor <a href=' /ensemble/forest.py#L658'>predict</a>(X)</tt>	Predict regression target for x.
<tt style='background-color:#E8E8E8;'> ensemble.ForestRegressor <a href=' /ensemble/forest.py#L698'>_set_oob_score</a>(X,y)</tt>	Compute out-of-bag scores.
<tt style='background-color:#E8E8E8;'> ensemble.RandomTreesEmbedding <a href=' /ensemble/forest.py#L1795'>fit_transform</a>(X,y,sample_weight)</tt>	Fit estimator and transform dataset.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/partial_dependence.py#L24'>_grid_from_X</a>(X,percentiles,grid_resolution)</tt>	Generate a grid of points based on the percentiles of x.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/partial_dependence.py#L72'>partial_dependence</a>(gbrt,target_variables,grid,X)</tt>	Partial dependence of target_variables.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/partial_dependence.py#L166'>plot_partial_dependence</a>(gbrt,X,features,feature_names)</tt>	Partial dependence plots for features.
<tt style='background-color:#E8E8E8;'> ensemble. <a href=' /ensemble/voting_classifier.py#L25'>_parallel_fit_estimator</a>(estimator,X,y,sample_weight)</tt>	Private function used to fit an estimator within a job.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L114'>fit</a>(X,y,sample_weight)</tt>	Fit the estimators.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L179'>_weights_not_none</a>()</tt>	Get the weights of not none estimators.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L309'>_predict</a>(X)</tt>	Collect results from clf predict calls.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L217'>_collect_probas</a>(X)</tt>	Collect results from clf predict calls.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L221'>_predict_proba</a>(X)</tt>	Predict class probabilities for x in 'soft' voting.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L231'>predict_proba</a>()</tt>	Compute probabilities of possible outcomes for samples in x.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L248'>transform</a>(X)</tt>	Return class labels or probabilities for x for each estimator.
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L272'>set_params</a>()</tt>	Setting the parameters for the voting classifier valid parameter keys can be listed with get_params().
<tt style='background-color:#E8E8E8;'> ensemble.VotingClassifier <a href=' /ensemble/voting_classifier.py#L297'>get_params</a>(deep)</tt>	Get the parameters of the votingclassifier.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/dict_vectorizer.py#L19'>_tosequence</a>(X)</tt>	Turn x into a sequence or ndarray avoiding a copy if possible.
<tt style='background-color:#E8E8E8;'> feature_extraction.DictVectorizer <a href=' /feature_extraction/dict_vectorizer.py#L103'>fit</a>(X,y)</tt>	Learn a list of feature name -> indices mappings.
<tt style='background-color:#E8E8E8;'> feature_extraction.DictVectorizer <a href=' /feature_extraction/dict_vectorizer.py#L213'>fit_transform</a>(X,y)</tt>	Learn a list of feature name -> indices mappings and transform x.
<tt style='background-color:#E8E8E8;'> feature_extraction.DictVectorizer <a href=' /feature_extraction/dict_vectorizer.py#L233'>inverse_transform</a>(X,dict_type)</tt>	Transform array or sparse matrix x back to feature mappings.
<tt style='background-color:#E8E8E8;'> feature_extraction.DictVectorizer <a href=' /feature_extraction/dict_vectorizer.py#L274'>transform</a>(X,y)</tt>	Transform feature->value dicts to array or sparse matrix.
<tt style='background-color:#E8E8E8;'> feature_extraction.DictVectorizer <a href=' /feature_extraction/dict_vectorizer.py#L313'>get_feature_names</a>()</tt>	Returns a list of feature names ordered by their indices.
<tt style='background-color:#E8E8E8;'> feature_extraction.DictVectorizer <a href=' /feature_extraction/dict_vectorizer.py#L321'>restrict</a>(support,indices)</tt>	Restrict the features to those in support using feature selection.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/text.py#L45'>strip_accents_unicode</a>(s)</tt>	Transform accentuated unicode symbols into their simple counterpart warning the python-level loop and join operations make this.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/text.py#L65'>strip_accents_ascii</a>(s)</tt>	Transform accentuated unicode symbols into ascii or nothing warning this solution is only suited for languages that have a direct.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/text.py#L80'>strip_tags</a>(s)</tt>	Basic regexp based html / xml tag stripper function for serious html/xml preprocessing you should rather use an external.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L105'>decode</a>(doc)</tt>	Decode the input into a string of unicode symbols the decoding strategy depends on the vectorizer parameters.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L126'>_word_ngrams</a>(tokens,stop_words)</tt>	Turn tokens into a sequence of n-grams after stop words filtering.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L145'>_char_ngrams</a>(text_document)</tt>	Tokenize text_document into a sequence of character n-grams.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L158'>_char_wb_ngrams</a>(text_document)</tt>	Whitespace sensitive char-n-gram tokenization.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L181'>build_preprocessor</a>()</tt>	Return a function to preprocess the text before tokenization.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L211'>build_tokenizer</a>()</tt>	Return a function that splits a string into a sequence of tokens.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L218'>get_stop_words</a>()</tt>	Build or fetch the effective stop words list.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L222'>build_analyzer</a>()</tt>	Return a callable that handles preprocessing and tokenization.
<tt style='background-color:#E8E8E8;'> feature_extraction.VectorizerMixin <a href=' /feature_extraction/text.py#L275'>_check_vocabulary</a>()</tt>	Check if vocabulary is empty or missing not fit-ed.
<tt style='background-color:#E8E8E8;'> feature_extraction.HashingVectorizer <a href=' /feature_extraction/text.py#L443'>partial_fit</a>(X,y)</tt>	Does nothing this transformer is stateless.
<tt style='background-color:#E8E8E8;'> feature_extraction.HashingVectorizer <a href=' /feature_extraction/text.py#L452'>fit</a>(X,y)</tt>	Does nothing this transformer is stateless.
<tt style='background-color:#E8E8E8;'> feature_extraction.HashingVectorizer <a href=' /feature_extraction/text.py#L463'>transform</a>(X,y)</tt>	Transform a sequence of documents to a document-term matrix.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/text.py#L503'>_document_frequency</a>(X)</tt>	Count the number of non-zero values for each feature in sparse x.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L690'>_sort_features</a>(X,vocabulary)</tt>	Sort features by name.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L704'>_limit_features</a>(X,vocabulary,high,low)</tt>	Remove too rare or too common features.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L745'>_count_vocab</a>(raw_documents,fixed_vocab)</tt>	Create sparse feature matrix and vocabulary where fixed_vocab=false.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L794'>fit</a>(raw_documents,y)</tt>	Learn a vocabulary dictionary of all tokens in the raw documents.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L809'>fit_transform</a>(raw_documents,y)</tt>	Learn the vocabulary dictionary and return term-document matrix.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L866'>transform</a>(raw_documents)</tt>	Transform documents to document-term matrix.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L898'>inverse_transform</a>(X)</tt>	Return terms per document with nonzero entries in x.
<tt style='background-color:#E8E8E8;'> feature_extraction.CountVectorizer <a href=' /feature_extraction/text.py#L928'>get_feature_names</a>()</tt>	Array mapping from feature integer indices to feature name.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/text.py#L936'>_make_int_array</a>()</tt>	Construct an array array of a type suitable for scipy sparse indices.
<tt style='background-color:#E8E8E8;'> feature_extraction.TfidfTransformer <a href=' /feature_extraction/text.py#L1017'>fit</a>(X,y)</tt>	Learn the idf vector global term weights.
<tt style='background-color:#E8E8E8;'> feature_extraction.TfidfTransformer <a href=' /feature_extraction/text.py#L1043'>transform</a>(X,copy)</tt>	Transform a count matrix to a tf or tf-idf representation parameters.
<tt style='background-color:#E8E8E8;'> feature_extraction.TfidfVectorizer <a href=' /feature_extraction/text.py#L1320'>fit</a>(raw_documents,y)</tt>	Learn vocabulary and idf from training set.
<tt style='background-color:#E8E8E8;'> feature_extraction.TfidfVectorizer <a href=' /feature_extraction/text.py#L1336'>fit_transform</a>(raw_documents,y)</tt>	Learn vocabulary and idf return term-document matrix.
<tt style='background-color:#E8E8E8;'> feature_extraction.TfidfVectorizer <a href=' /feature_extraction/text.py#L1358'>transform</a>(raw_documents,copy)</tt>	Transform documents to document-term matrix.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L32'>_make_edges_3d</a>(n_x,n_y,n_z)</tt>	Returns a list of edges for a 3d image.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L67'>_mask_edges_weights</a>(mask,edges,weights)</tt>	Apply a mask to edges weighted or not.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L88'>_to_graph</a>(n_x,n_y,n_z,mask)</tt>	Auxiliary function for img_to_graph and grid_to_graph.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L133'>img_to_graph</a>(img,mask,return_as,dtype)</tt>	Graph of the pixel-to-pixel gradient connections edges are weighted with the gradient values.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L167'>grid_to_graph</a>(n_x,n_y,n_z,mask)</tt>	Graph of the pixel-to-pixel connections edges exist if 2 voxels are connected.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L205'>_compute_n_patches</a>(i_h,i_w,p_h,p_w)</tt>	Compute the number of patches that will be extracted in an image.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L242'>extract_patches</a>(arr,patch_shape,extraction_step)</tt>	Extracts patches of any n-dimensional array in place using strides.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L300'>extract_patches_2d</a>(image,patch_size,max_patches,random_state)</tt>	Reshape a 2d image into a collection of patches the resulting patches are allocated in a dedicated array.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/image.py#L396'>reconstruct_from_patches_2d</a>(patches,image_size)</tt>	Reconstruct the image from all of its patches.
<tt style='background-color:#E8E8E8;'> feature_extraction.PatchExtractor <a href=' /feature_extraction/image.py#L468'>fit</a>(X,y)</tt>	Do nothing and return the estimator unchanged this method is just there to implement the usual api and hence.
<tt style='background-color:#E8E8E8;'> feature_extraction.PatchExtractor <a href=' /feature_extraction/image.py#L476'>transform</a>(X)</tt>	Transforms the image samples in x into a matrix of patch data.
<tt style='background-color:#E8E8E8;'> feature_extraction. <a href=' /feature_extraction/hashing.py#L13'>_iteritems</a>(d)</tt>	Like d iteritems but accepts any collections mapping.
<tt style='background-color:#E8E8E8;'> feature_extraction.FeatureHasher <a href=' /feature_extraction/hashing.py#L117'>transform</a>(raw_X,y)</tt>	Transform a sequence of instances to a scipy sparse matrix.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L45'>_k_init</a>(X,n_clusters,x_squared_norms,random_state)</tt>	Init n_clusters seeds according to k-means++ parameters.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L147'>_validate_center_shape</a>(X,n_centers,centers)</tt>	Check if centers is compatible with x and n_centers.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L160'>_tolerance</a>(X,tol)</tt>	Return a tolerance which is independent of the dataset.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L169'>k_means</a>(X,n_clusters,init,precompute_distances)</tt>	K-means clustering algorithm.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L407'>_kmeans_single_lloyd</a>(X,n_clusters,max_iter,init)</tt>	A single run of k-means assumes preparation completed prior.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L531'>_labels_inertia_precompute_dense</a>(X,x_squared_norms,centers,distances)</tt>	Compute labels and inertia using a full distance matrix.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L575'>_labels_inertia</a>(X,x_squared_norms,centers,precompute_distances)</tt>	E step of the k-means em algorithm.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L628'>_init_centroids</a>(X,k,init,random_state)</tt>	Compute the initial centroids parameters.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L858'>_check_fit_data</a>(X)</tt>	Verify that the number of samples given is larger than k.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L877'>fit</a>(X,y)</tt>	Compute k-means clustering.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L898'>fit_predict</a>(X,y)</tt>	Compute cluster centers and predict cluster index for each sample.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L906'>fit_transform</a>(X,y)</tt>	Compute clustering and transform x to cluster-distance space.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L918'>transform</a>(X,y)</tt>	Transform x to a cluster-distance space.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L940'>_transform</a>(X)</tt>	Guts of transform method no input validation.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L944'>predict</a>(X)</tt>	Predict the closest cluster each sample in x belongs to.
<tt style='background-color:#E8E8E8;'> cluster.KMeans <a href=' /cluster/k_means_.py#L967'>score</a>(X,y)</tt>	Opposite of the value of x on the k-means objective.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L987'>_mini_batch_step</a>(X,x_squared_norms,centers,counts)</tt>	Incremental update of the centers for the minibatch k-means algorithm.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/k_means_.py#L1124'>_mini_batch_convergence</a>(model,iteration_idx,n_iter,tol)</tt>	Helper function to encapsulate the early stopping logic.
<tt style='background-color:#E8E8E8;'> cluster.MiniBatchKMeans <a href=' /cluster/k_means_.py#L1315'>fit</a>(X,y)</tt>	Compute the centroids on x by chunking it into mini-batches.
<tt style='background-color:#E8E8E8;'> cluster.MiniBatchKMeans <a href=' /cluster/k_means_.py#L1449'>_labels_inertia_minibatch</a>(X)</tt>	Compute labels and inertia using mini batches.
<tt style='background-color:#E8E8E8;'> cluster.MiniBatchKMeans <a href=' /cluster/k_means_.py#L1477'>partial_fit</a>(X,y)</tt>	Update k means estimate on a single mini-batch x.
<tt style='background-color:#E8E8E8;'> cluster.MiniBatchKMeans <a href=' /cluster/k_means_.py#L1530'>predict</a>(X)</tt>	Predict the closest cluster each sample in x belongs to.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/affinity_propagation_.py#L17'>affinity_propagation</a>(S,preference,convergence_iter,max_iter)</tt>	Perform affinity propagation clustering of data read more in the :ref user guide <affinity_propagation>.
<tt style='background-color:#E8E8E8;'> cluster.AffinityPropagation <a href=' /cluster/affinity_propagation_.py#L274'>fit</a>(X,y)</tt>	Create affinity matrix from negative euclidean distances then apply affinity propagation clustering.
<tt style='background-color:#E8E8E8;'> cluster.AffinityPropagation <a href=' /cluster/affinity_propagation_.py#L306'>predict</a>(X)</tt>	Predict the closest cluster each sample in x belongs to.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/dbscan_.py#L23'>dbscan</a>(X,eps,min_samples,metric)</tt>	Perform dbscan clustering from vector array or distance matrix.
<tt style='background-color:#E8E8E8;'> cluster.DBSCAN <a href=' /cluster/dbscan_.py#L263'>fit</a>(X,y,sample_weight)</tt>	Perform dbscan clustering from features or distance matrix.
<tt style='background-color:#E8E8E8;'> cluster.DBSCAN <a href=' /cluster/dbscan_.py#L290'>fit_predict</a>(X,y,sample_weight)</tt>	Performs clustering on x and returns cluster labels.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/mean_shift_.py#L31'>estimate_bandwidth</a>(X,quantile,n_samples,random_state)</tt>	Estimate the bandwidth to use with the mean-shift algorithm.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/mean_shift_.py#L105'>mean_shift</a>(X,bandwidth,seeds,bin_seeding)</tt>	Perform mean shift clustering of data using a flat kernel.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/mean_shift_.py#L240'>get_bin_seeds</a>(X,bin_size,min_bin_freq)</tt>	Finds seeds for mean_shift.
<tt style='background-color:#E8E8E8;'> cluster.MeanShift <a href=' /cluster/mean_shift_.py#L400'>predict</a>(X)</tt>	Predict the closest cluster each sample in x belongs to.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/bicluster.py#L30'>_scale_normalize</a>(X)</tt>	Normalize x by scaling rows and columns independently.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/bicluster.py#L52'>_bistochastic_normalize</a>(X,max_iter,tol)</tt>	Normalize rows and columns of x simultaneously so that all rows sum to one constant and all columns sum to a different.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/bicluster.py#L75'>_log_normalize</a>(X)</tt>	Normalize x according to kluger's log-interactions scheme.
<tt style='background-color:#E8E8E8;'> cluster.BaseSpectral <a href=' /cluster/bicluster.py#L113'>fit</a>(X)</tt>	Creates a biclustering for x.
<tt style='background-color:#E8E8E8;'> cluster.BaseSpectral <a href=' /cluster/bicluster.py#L126'>_svd</a>(array,n_components,n_discard)</tt>	Returns first n_components left and right singular vectors u and v discarding the first n_discard.
<tt style='background-color:#E8E8E8;'> cluster.SpectralBiclustering <a href=' /cluster/bicluster.py#L484'>_fit_best_piecewise</a>(vectors,n_best,n_clusters)</tt>	Find the n_best vectors that are best approximated by piecewise constant vectors.
<tt style='background-color:#E8E8E8;'> cluster.SpectralBiclustering <a href=' /cluster/bicluster.py#L502'>_project_and_cluster</a>(data,vectors,n_clusters)</tt>	Project data to vectors and cluster the result.
<tt style='background-color:#E8E8E8;'> cluster.AgglomerationTransform <a href=' /cluster/_feature_agglomeration.py#L24'>transform</a>(X)</tt>	Transform a new matrix using the built clustering parameters.
<tt style='background-color:#E8E8E8;'> cluster.AgglomerationTransform <a href=' /cluster/_feature_agglomeration.py#L52'>inverse_transform</a>(Xred)</tt>	Inverse the transformation.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/hierarchical.py#L33'>_fix_connectivity</a>(X,connectivity,n_components,affinity)</tt>	Fixes the connectivity matrix.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/hierarchical.py#L87'>ward_tree</a>(X,connectivity,n_clusters,return_distance)</tt>	Ward clustering based on a feature matrix.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/hierarchical.py#L292'>linkage_tree</a>(X,connectivity,n_components,n_clusters)</tt>	Linkage agglomerative clustering based on a feature matrix.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/hierarchical.py#L536'>_hc_cut</a>(n_clusters,children,n_leaves)</tt>	Function cutting the ward tree for a given number of clusters.
<tt style='background-color:#E8E8E8;'> cluster.AgglomerativeClustering <a href=' /cluster/hierarchical.py#L674'>fit</a>(X,y)</tt>	Fit the hierarchical clustering on the data parameters.
<tt style='background-color:#E8E8E8;'> cluster.FeatureAgglomeration <a href=' /cluster/hierarchical.py#L828'>fit</a>(X,y)</tt>	Fit the hierarchical clustering on the data.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/spectral.py#L22'>discretize</a>(vectors,copy,max_svd_restarts,n_iter_max)</tt>	Search for a partition matrix clustering which is closest to the eigenvector embedding.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/spectral.py#L161'>spectral_clustering</a>(affinity,n_clusters,n_components,eigen_solver)</tt>	Apply clustering to a projection to the normalized laplacian.
<tt style='background-color:#E8E8E8;'> cluster.SpectralClustering <a href=' /cluster/spectral.py#L427'>fit</a>(X,y)</tt>	Creates an affinity matrix for x using the selected affinity then applies spectral clustering to this affinity matrix.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/birch.py#L22'>_iterate_sparse_X</a>(X)</tt>	This little hack returns a densified row when iterating over a sparse matrix instead of constructing a sparse matrix for every row that is.
<tt style='background-color:#E8E8E8;'> cluster. <a href=' /cluster/birch.py#L40'>_split_node</a>(node,threshold,branching_factor)</tt>	The node has to be split if there is no place for a new subcluster in the node.
<tt style='background-color:#E8E8E8;'> cluster._CFNode <a href=' /cluster/birch.py#L164'>update_split_subclusters</a>(subcluster,new_subcluster1,new_subcluster2)</tt>	Remove a subcluster from a node and update it with the split subclusters.
<tt style='background-color:#E8E8E8;'> cluster._CFNode <a href=' /cluster/birch.py#L175'>insert_cf_subcluster</a>(subcluster)</tt>	Insert a new subcluster into the node.
<tt style='background-color:#E8E8E8;'> cluster._CFSubcluster <a href=' /cluster/birch.py#L297'>merge_subcluster</a>(nominee_cluster,threshold)</tt>	Check if a cluster is worthy enough to be merged if.
<tt style='background-color:#E8E8E8;'> cluster._CFSubcluster <a href=' /cluster/birch.py#L315'>radius</a>()</tt>	Return radius of the subcluster.
<tt style='background-color:#E8E8E8;'> cluster.Birch <a href=' /cluster/birch.py#L436'>fit</a>(X,y)</tt>	Build a cf tree for the input data.
<tt style='background-color:#E8E8E8;'> cluster.Birch <a href=' /cluster/birch.py#L499'>_get_leaves</a>()</tt>	Retrieve the leaves of the cf node.
<tt style='background-color:#E8E8E8;'> cluster.Birch <a href=' /cluster/birch.py#L515'>partial_fit</a>(X,y)</tt>	Online learning prevents rebuilding of cftree from scratch.
<tt style='background-color:#E8E8E8;'> cluster.Birch <a href=' /cluster/birch.py#L549'>predict</a>(X)</tt>	Predict data using the centroids_ of subclusters.
<tt style='background-color:#E8E8E8;'> cluster.Birch <a href=' /cluster/birch.py#L572'>transform</a>(X,y)</tt>	Transform x into subcluster centroids dimension.
<tt style='background-color:#E8E8E8;'> cluster.Birch <a href=' /cluster/birch.py#L592'>_global_clustering</a>(X)</tt>	Global clustering for the subclusters obtained after fitting.
<tt style='background-color:#E8E8E8;'> semi_supervised. <a href=' /semi_supervised/label_propagation.py#L73'>_not_converged</a>(y_truth,y_prediction,tol)</tt>	Basic convergence check.
<tt style='background-color:#E8E8E8;'> semi_supervised.BaseLabelPropagation <a href=' /semi_supervised/label_propagation.py#L158'>predict</a>(X)</tt>	Performs inductive inference across the model.
<tt style='background-color:#E8E8E8;'> semi_supervised.BaseLabelPropagation <a href=' /semi_supervised/label_propagation.py#L173'>predict_proba</a>(X)</tt>	Predict probability for each possible outcome.
<tt style='background-color:#E8E8E8;'> semi_supervised.BaseLabelPropagation <a href=' /semi_supervised/label_propagation.py#L208'>fit</a>(X,y)</tt>	Fit a semi-supervised label propagation model based all the input data is provided matrix x labeled and unlabeled.
<tt style='background-color:#E8E8E8;'> semi_supervised.LabelPropagation <a href=' /semi_supervised/label_propagation.py#L354'>_build_graph</a>()</tt>	Matrix representing a fully connected graph between each sample this basic implementation creates a non-stochastic affinity matrix so.
<tt style='background-color:#E8E8E8;'> semi_supervised.LabelSpreading <a href=' /semi_supervised/label_propagation.py#L460'>_build_graph</a>()</tt>	Graph matrix for label spreading computes the graph laplacian.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/univariate_selection.py#L23'>_clean_nans</a>(scores)</tt>	Fixes issue #1240 nans can't be properly compared so change them to the smallest value of scores's dtype.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/univariate_selection.py#L42'>f_oneway</a>()</tt>	Performs a 1-way anova.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/univariate_selection.py#L121'>f_classif</a>(X,y)</tt>	Compute the anova f-value for the provided sample.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/univariate_selection.py#L152'>_chisquare</a>(f_obs,f_exp)</tt>	Fast replacement for scipy stats chisquare.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/univariate_selection.py#L171'>chi2</a>(X,y)</tt>	Compute chi-squared stats between each non-negative feature and class.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/univariate_selection.py#L230'>f_regression</a>(X,y,center)</tt>	Univariate linear regression tests.
<tt style='background-color:#E8E8E8;'> feature_selection._BaseFilter <a href=' /feature_selection/univariate_selection.py#L324'>fit</a>(X,y)</tt>	Run score function on x y and get the appropriate features.
<tt style='background-color:#E8E8E8;'> feature_selection.VarianceThreshold <a href=' /feature_selection/variance_threshold.py#L48'>fit</a>(X,y)</tt>	Learn empirical variances from x.
<tt style='background-color:#E8E8E8;'> feature_selection.SelectorMixin <a href=' /feature_selection/base.py#L27'>get_support</a>(indices)</tt>	Get a mask or integer index of the features selected parameters.
<tt style='background-color:#E8E8E8;'> feature_selection.SelectorMixin <a href=' /feature_selection/base.py#L50'>_get_support_mask</a>()</tt>	Get the boolean mask indicating which features are selected returns.
<tt style='background-color:#E8E8E8;'> feature_selection.SelectorMixin <a href=' /feature_selection/base.py#L62'>transform</a>(X)</tt>	Reduce x to the selected features.
<tt style='background-color:#E8E8E8;'> feature_selection.SelectorMixin <a href=' /feature_selection/base.py#L86'>inverse_transform</a>(X)</tt>	Reverse the transformation operation parameters.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/rfe.py#L23'>_rfe_single_fit</a>(rfe,estimator,X,y)</tt>	Return the score for a fit across one fold.
<tt style='background-color:#E8E8E8;'> feature_selection.RFE <a href=' /feature_selection/rfe.py#L123'>fit</a>(X,y)</tt>	Fit the rfe model and then the underlying estimator on the selected features.
<tt style='background-color:#E8E8E8;'> feature_selection.RFE <a href=' /feature_selection/rfe.py#L215'>predict</a>(X)</tt>	Reduce x to the selected features and then predict using the underlying estimator.
<tt style='background-color:#E8E8E8;'> feature_selection.RFE <a href=' /feature_selection/rfe.py#L232'>score</a>(X,y)</tt>	Reduce x to the selected features and then return the score of the underlying estimator.
<tt style='background-color:#E8E8E8;'> feature_selection.RFECV <a href=' /feature_selection/rfe.py#L378'>fit</a>(X,y)</tt>	Fit the rfe model and automatically tune the number of selected features.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L18'>_compute_mi_cc</a>(x,y,n_neighbors)</tt>	Compute mutual information between two continuous variables.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L79'>_compute_mi_cd</a>(c,d,n_neighbors)</tt>	Compute mutual information between continuous and discrete variables.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L150'>_compute_mi</a>(x,y,x_discrete,y_discrete)</tt>	Compute mutual information between two variables.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L166'>_iterate_columns</a>(X,columns)</tt>	Iterate over columns of a matrix.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L196'>_estimate_mi</a>(X,y,discrete_features,discrete_target)</tt>	Estimate mutual information between the features and the target.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L294'>mutual_info_regression</a>(X,y,discrete_features,n_neighbors)</tt>	Estimate mutual information for a continuous target variable.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/mutual_info_.py#L373'>mutual_info_classif</a>(X,y,discrete_features,n_neighbors)</tt>	Estimate mutual information for a discrete target variable.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/from_model.py#L14'>_get_feature_importances</a>(estimator,norm_order)</tt>	Retrieve or aggregate feature importances from estimator.
<tt style='background-color:#E8E8E8;'> feature_selection. <a href=' /feature_selection/from_model.py#L35'>_calculate_threshold</a>(estimator,importances,threshold)</tt>	Interpret the threshold value.
<tt style='background-color:#E8E8E8;'> feature_selection.SelectFromModel <a href=' /feature_selection/from_model.py#L146'>fit</a>(X,y)</tt>	Fit the selectfrommodel meta-transformer.
<tt style='background-color:#E8E8E8;'> feature_selection.SelectFromModel <a href=' /feature_selection/from_model.py#L172'>partial_fit</a>(X,y)</tt>	Fit the selectfrommodel meta-transformer only once.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/olivetti_faces.py#L54'>fetch_olivetti_faces</a>(data_home,shuffle,random_state,download_if_missing)</tt>	Loader for the olivetti faces data-set from at&t.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/california_housing.py#L52'>fetch_california_housing</a>(data_home,download_if_missing)</tt>	Loader for the california housing dataset from statlib.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/species_distributions.py#L66'>_load_coverage</a>(F,header_length,dtype)</tt>	Load a coverage file from an open file object.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/species_distributions.py#L82'>_load_csv</a>(F)</tt>	Load csv file.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/species_distributions.py#L106'>construct_grids</a>(batch)</tt>	Construct the map grid from the batch object parameters.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/species_distributions.py#L133'>fetch_species_distributions</a>(data_home,download_if_missing)</tt>	Loader for species distribution dataset from phillips et al 2006.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/svmlight_format.py#L34'>load_svmlight_file</a>(f,n_features,dtype,multilabel)</tt>	Load datasets in the svmlight / libsvm format into sparse csr matrix this format is a text-based format with one sample per line.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/svmlight_format.py#L175'>load_svmlight_files</a>(files,n_features,dtype,multilabel)</tt>	Load dataset from multiple files in svmlight format this function is equivalent to mapping load_svmlight_file over a list of.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/svmlight_format.py#L335'>dump_svmlight_file</a>(X,y,f,zero_based)</tt>	Dump the dataset in svmlight / libsvm file format.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/rcv1.py#L39'>fetch_rcv1</a>(data_home,subset,download_if_missing,random_state)</tt>	Load the rcv1 multilabel dataset downloading it if necessary.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/rcv1.py#L224'>_inverse_permutation</a>(p)</tt>	Inverse permutation p.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/rcv1.py#L233'>_find_permutation</a>(a,b)</tt>	Find the permutation from a to b.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L56'>scale_face</a>(face)</tt>	Scale back to 0-1 range in case of normalization for plotting.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L69'>check_fetch_lfw</a>(data_home,funneled,download_if_missing)</tt>	Helper function to download any missing lfw data.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L116'>_load_imgs</a>(file_paths,slice_,color,resize)</tt>	Internally used to load images.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L187'>_fetch_lfw_people</a>(data_folder_path,slice_,color,resize)</tt>	Perform the actual data loading for the lfw people dataset this operation is meant to be cached by a joblib wrapper.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L228'>fetch_lfw_people</a>(data_home,funneled,resize,min_faces_per_person)</tt>	Loader for the labeled faces in the wild lfw people dataset this dataset is a collection of jpeg pictures of famous people.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L327'>_fetch_lfw_pairs</a>(index_file_path,data_folder_path,slice_,color)</tt>	Perform the actual data loading for the lfw pairs dataset this operation is meant to be cached by a joblib wrapper.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/lfw.py#L378'>fetch_lfw_pairs</a>(subset,data_home,funneled,resize)</tt>	Loader for the labeled faces in the wild lfw pairs dataset this dataset is a collection of jpeg pictures of famous people.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L30'>get_data_home</a>(data_home)</tt>	Return the path of the scikit-learn data dir.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L54'>clear_data_home</a>(data_home)</tt>	Delete all the content of the data home cache.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L60'>load_files</a>(container_path,description,categories,load_content)</tt>	Load text files with categories as subfolder names.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L200'>load_data</a>(module_path,data_file_name)</tt>	Loads data from module_path/data/data_file_name.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L238'>load_wine</a>(return_X_y)</tt>	Load and return the wine dataset classification.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L316'>load_iris</a>(return_X_y)</tt>	Load and return the iris dataset classification.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L381'>load_breast_cancer</a>(return_X_y)</tt>	Load and return the breast cancer wisconsin dataset classification.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L463'>load_digits</a>(n_class,return_X_y)</tt>	Load and return the digits dataset classification.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L540'>load_diabetes</a>(return_X_y)</tt>	Load and return the diabetes dataset regression.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L583'>load_linnerud</a>(return_X_y)</tt>	Load and return the linnerud dataset multivariate regression.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L633'>load_boston</a>(return_X_y)</tt>	Load and return the boston house-prices dataset regression.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L700'>load_sample_images</a>()</tt>	Load sample images for image manipulation.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L750'>load_sample_image</a>(image_name)</tt>	Load the numpy array of a single sample image parameters.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/base.py#L789'>_pkl_filepath</a>()</tt>	Ensure different filenames for python 2 and python 3 pickles an object pickled under python 3 cannot be loaded under python 2.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/covtype.py#L43'>fetch_covtype</a>(data_home,download_if_missing,random_state,shuffle)</tt>	Load the covertype dataset downloading it if necessary.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L25'>_generate_hypercube</a>(samples,dimensions,rng)</tt>	Returns distinct binary samples of length dimensions.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L38'>make_classification</a>(n_samples,n_features,n_informative,n_redundant)</tt>	Generate a random n-class classification problem.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L250'>make_multilabel_classification</a>(n_samples,n_features,n_classes,n_labels)</tt>	Generate a random multilabel classification problem.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L401'>make_hastie_10_2</a>(n_samples,random_state)</tt>	Generates data for binary classification used in hastie et al.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L450'>make_regression</a>(n_samples,n_features,n_informative,n_targets)</tt>	Generate a random regression problem.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L573'>make_circles</a>(n_samples,shuffle,noise,random_state)</tt>	Make a large circle containing a smaller circle in 2d.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L630'>make_moons</a>(n_samples,shuffle,noise,random_state)</tt>	Make two interleaving half circles a simple toy dataset to visualize clustering and classification.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L680'>make_blobs</a>(n_samples,n_features,centers,cluster_std)</tt>	Generate isotropic gaussian blobs for clustering.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L774'>make_friedman1</a>(n_samples,n_features,noise,random_state)</tt>	Generate the "friedman \#1" regression problem this dataset is described in friedman [1] and breiman [2].
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L837'>make_friedman2</a>(n_samples,noise,random_state)</tt>	Generate the "friedman \#2" regression problem this dataset is described in friedman [1] and breiman [2].
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L903'>make_friedman3</a>(n_samples,noise,random_state)</tt>	Generate the "friedman \#3" regression problem this dataset is described in friedman [1] and breiman [2].
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L968'>make_low_rank_matrix</a>(n_samples,n_features,effective_rank,tail_strength)</tt>	Generate a mostly low rank matrix with bell-shaped singular values most of the variance can be explained by a bell-shaped curve of width.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1038'>make_sparse_coded_signal</a>(n_samples,n_components,n_features,n_nonzero_coefs)</tt>	Generate a signal as a sparse combination of dictionary elements.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1101'>make_sparse_uncorrelated</a>(n_samples,n_features,random_state)</tt>	Generate a random regression problem with sparse uncorrelated design this dataset is described in celeux et al [1].
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1153'>make_spd_matrix</a>(n_dim,random_state)</tt>	Generate a random symmetric positive-definite matrix.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1187'>make_sparse_spd_matrix</a>(dim,alpha,norm_diag,smallest_coef)</tt>	Generate a sparse symmetric definite positive matrix.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1262'>make_swiss_roll</a>(n_samples,noise,random_state)</tt>	Generate a swiss roll dataset.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1315'>make_s_curve</a>(n_samples,noise,random_state)</tt>	Generate an s curve dataset.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1358'>make_gaussian_quantiles</a>(mean,cov,n_samples,n_features)</tt>	Generate isotropic gaussian and label samples by quantile this classification dataset is constructed by taking a multi-dimensional.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1454'>make_biclusters</a>(shape,n_clusters,noise,minval)</tt>	Generate an array with constant block diagonal structure for biclustering.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/samples_generator.py#L1546'>make_checkerboard</a>(shape,n_clusters,noise,minval)</tt>	Generate an array with block checkerboard structure for biclustering.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/kddcup99.py#L42'>fetch_kddcup99</a>(subset,shuffle,random_state,percent10)</tt>	Load and return the kddcup 99 dataset classification.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/kddcup99.py#L217'>_fetch_brute_kddcup99</a>(subset,data_home,download_if_missing,random_state)</tt>	Load the kddcup99 dataset downloading it if necessary.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/kddcup99.py#L366'>_mkdirp</a>(d)</tt>	Ensure directory d exists like mkdir -p on unix no guarantee that the directory is writable.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/mldata.py#L32'>mldata_filename</a>(dataname)</tt>	Convert a raw name for a data set in a mldata org filename.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/mldata.py#L38'>fetch_mldata</a>(dataname,target_name,data_name,transpose_data)</tt>	Fetch an mldata org data set.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/mlcomp.py#L23'>load_mlcomp</a>(name_or_id,set_,mlcomp_root)</tt>	Load a datasets as downloaded from http //mlcomp org.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/twenty_newsgroups.py#L74'>download_20newsgroups</a>(target_dir,cache_path)</tt>	Download the 20 newsgroups data and stored it as a zipped pickle.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/twenty_newsgroups.py#L109'>strip_newsgroup_header</a>(text)</tt>	Given text in "news" format strip the headers by removing everything before the first blank line.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/twenty_newsgroups.py#L122'>strip_newsgroup_quoting</a>(text)</tt>	Given text in "news" format strip lines beginning with the quote characters > or |, plus lines that often introduce a quoted section.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/twenty_newsgroups.py#L133'>strip_newsgroup_footer</a>(text)</tt>	Given text in "news" format attempt to remove a signature block.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/twenty_newsgroups.py#L153'>fetch_20newsgroups</a>(data_home,subset,categories,shuffle)</tt>	Load the filenames and data from the 20 newsgroups dataset.
<tt style='background-color:#E8E8E8;'> datasets. <a href=' /datasets/twenty_newsgroups.py#L286'>fetch_20newsgroups_vectorized</a>(subset,remove,data_home)</tt>	Load the 20 newsgroups dataset and transform it into tf-idf vectors.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L12'>identity</a>(X)</tt>	Simply return the input array.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L29'>logistic</a>(X)</tt>	Compute the logistic function inplace.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L45'>tanh</a>(X)</tt>	Compute the hyperbolic tan function inplace.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L61'>relu</a>(X)</tt>	Compute the rectified linear unit function inplace.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L78'>softmax</a>(X)</tt>	Compute the k-way softmax function inplace.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L102'>inplace_identity_derivative</a>(Z,delta)</tt>	Apply the derivative of the identity function do nothing.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L117'>inplace_logistic_derivative</a>(Z,delta)</tt>	Apply the derivative of the logistic sigmoid function.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L136'>inplace_tanh_derivative</a>(Z,delta)</tt>	Apply the derivative of the hyperbolic tanh function.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L154'>inplace_relu_derivative</a>(Z,delta)</tt>	Apply the derivative of the relu function.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L178'>squared_loss</a>(y_true,y_pred)</tt>	Compute the squared loss for regression.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L197'>log_loss</a>(y_true,y_prob)</tt>	Compute logistic loss for classification.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/_base.py#L225'>binary_log_loss</a>(y_true,y_prob)</tt>	Compute binary logistic loss for classification.
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L109'>transform</a>(X)</tt>	Compute the hidden layer activation probabilities p(h=1|v=x).
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L127'>_mean_hiddens</a>(v)</tt>	Computes the probabilities p(h=1|v).
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L144'>_sample_hiddens</a>(v,rng)</tt>	Sample from the distribution p(h|v).
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L163'>_sample_visibles</a>(h,rng)</tt>	Sample from the distribution p(v|h).
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L184'>_free_energy</a>(v)</tt>	Computes the free energy f v = - log sum_h exp(-e v h.
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L201'>gibbs</a>(v)</tt>	Perform one gibbs sampling step.
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L222'>partial_fit</a>(X,y)</tt>	Fit the model to the data x which should contain a partial segment of the data.
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L256'>_fit</a>(v_pos,rng)</tt>	Inner fit for one mini-batch.
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L286'>score_samples</a>(X)</tt>	Compute the pseudo-likelihood of x.
<tt style='background-color:#E8E8E8;'> neural_network.BernoulliRBM <a href=' /neural_network/rbm.py#L324'>fit</a>(X,y)</tt>	Fit the model to the data x.
<tt style='background-color:#E8E8E8;'> neural_network.BaseOptimizer <a href=' /neural_network/_stochastic_optimizers.py#L34'>update_params</a>(grads)</tt>	Update parameters with given gradients parameters.
<tt style='background-color:#E8E8E8;'> neural_network.BaseOptimizer <a href=' /neural_network/_stochastic_optimizers.py#L47'>iteration_ends</a>(time_step)</tt>	Perform update to learning rate and potentially other states at the.
<tt style='background-color:#E8E8E8;'> neural_network.BaseOptimizer <a href=' /neural_network/_stochastic_optimizers.py#L53'>trigger_stopping</a>(msg,verbose)</tt>	Decides whether it is time to stop training.
<tt style='background-color:#E8E8E8;'> neural_network.SGDOptimizer <a href=' /neural_network/_stochastic_optimizers.py#L128'>iteration_ends</a>(time_step)</tt>	Perform updates to learning rate and potential other states at the.
<tt style='background-color:#E8E8E8;'> neural_network.SGDOptimizer <a href=' /neural_network/_stochastic_optimizers.py#L159'>_get_updates</a>(grads)</tt>	Get the values used to update params with given gradients parameters.
<tt style='background-color:#E8E8E8;'> neural_network.AdamOptimizer <a href=' /neural_network/_stochastic_optimizers.py#L242'>_get_updates</a>(grads)</tt>	Get the values used to update params with given gradients parameters.
<tt style='background-color:#E8E8E8;'> neural_network. <a href=' /neural_network/multilayer_perceptron.py#L34'>_pack</a>(coefs_,intercepts_)</tt>	Pack the parameters into a single vector.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L77'>_unpack</a>(packed_parameters)</tt>	Extract the coefficients and intercepts from packed_parameters.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L86'>_forward_pass</a>(activations)</tt>	Perform a forward pass on the network by computing the values of the neurons in the hidden layers and the output layer.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L117'>_compute_loss_grad</a>(layer,n_samples,activations,deltas)</tt>	Compute the gradient of loss with respect to coefs and intercept for specified layer.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L133'>_loss_grad_lbfgs</a>(packed_coef_inter,X,y,activations)</tt>	Compute the mlp loss function and its corresponding derivatives with respect to the different parameters given in the initialization.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L183'>_backprop</a>(X,y,activations,deltas)</tt>	Compute the mlp loss function and its corresponding derivatives with respect to each parameter weights and bias vectors.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L603'>fit</a>(X,y)</tt>	Fit the model to data matrix x and target s y.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L621'>partial_fit</a>()</tt>	Fit the model to data matrix x and target y.
<tt style='background-color:#E8E8E8;'> neural_network.BaseMultilayerPerceptron <a href=' /neural_network/multilayer_perceptron.py#L646'>_predict</a>(X)</tt>	Predict using the trained model parameters.
<tt style='background-color:#E8E8E8;'> neural_network.MLPClassifier <a href=' /neural_network/multilayer_perceptron.py#L931'>predict</a>(X)</tt>	Predict using the multi-layer perceptron classifier parameters.
<tt style='background-color:#E8E8E8;'> neural_network.MLPClassifier <a href=' /neural_network/multilayer_perceptron.py#L952'>fit</a>(X,y)</tt>	Fit the model to data matrix x and target s y.
<tt style='background-color:#E8E8E8;'> neural_network.MLPClassifier <a href=' /neural_network/multilayer_perceptron.py#L971'>partial_fit</a>()</tt>	Fit the model to data matrix x and target y.
<tt style='background-color:#E8E8E8;'> neural_network.MLPClassifier <a href=' /neural_network/multilayer_perceptron.py#L1013'>predict_log_proba</a>(X)</tt>	Return the log of probability estimates.
<tt style='background-color:#E8E8E8;'> neural_network.MLPRegressor <a href=' /neural_network/multilayer_perceptron.py#L1276'>predict</a>(X)</tt>	Predict using the multi-layer perceptron model.
<tt style='background-color:#E8E8E8;'> tree. <a href=' /tree/export.py#L26'>_color_brew</a>(n)</tt>	Generate n colors with equally spaced hues.
<tt style='background-color:#E8E8E8;'> tree. <a href=' /tree/export.py#L74'>export_graphviz</a>(decision_tree,out_file,max_depth,feature_names)</tt>	Export a decision tree in dot format.
<tt style='background-color:#E8E8E8;'> tree.BaseDecisionTree <a href=' /tree/tree.py#L370'>_validate_X_predict</a>(X,check_input)</tt>	Validate x whenever one tries to predict apply predict_proba.
<tt style='background-color:#E8E8E8;'> tree.BaseDecisionTree <a href=' /tree/tree.py#L388'>predict</a>(X,check_input)</tt>	Predict class or regression value for x.
<tt style='background-color:#E8E8E8;'> tree.BaseDecisionTree <a href=' /tree/tree.py#L439'>apply</a>(X,check_input)</tt>	Returns the index of the leaf that each sample is predicted as.
<tt style='background-color:#E8E8E8;'> tree.BaseDecisionTree <a href=' /tree/tree.py#L468'>decision_path</a>(X,check_input)</tt>	Return the decision path in the tree.
<tt style='background-color:#E8E8E8;'> tree.BaseDecisionTree <a href=' /tree/tree.py#L494'>feature_importances_</a>()</tt>	Return the feature importances.
<tt style='background-color:#E8E8E8;'> tree.DecisionTreeClassifier <a href=' /tree/tree.py#L734'>fit</a>(X,y,sample_weight,check_input)</tt>	Build a decision tree classifier from the training set x y.
<tt style='background-color:#E8E8E8;'> tree.DecisionTreeClassifier <a href=' /tree/tree.py#L778'>predict_proba</a>(X,check_input)</tt>	Predict class probabilities of the input samples x.
<tt style='background-color:#E8E8E8;'> tree.DecisionTreeClassifier <a href=' /tree/tree.py#L826'>predict_log_proba</a>(X)</tt>	Predict class log-probabilities of the input samples x.
<tt style='background-color:#E8E8E8;'> tree.DecisionTreeRegressor <a href=' /tree/tree.py#L1054'>fit</a>(X,y,sample_weight,check_input)</tt>	Build a decision tree regressor from the training set x y.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L99'>assert_warns</a>(warning_class,func)</tt>	Test that a certain warning occurs.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L144'>assert_warns_message</a>(warning_class,message,func)</tt>	Test that a certain warning occurs and with a certain message.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L234'>ignore_warnings</a>(obj,category)</tt>	Context manager and decorator to ignore warnings.
<tt style='background-color:#E8E8E8;'> utils._IgnoreWarnings <a href=' /utils/testing.py#L284'>__call__</a>(fn)</tt>	Decorator to catch and hide warnings without visual nesting.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L344'>assert_raise_message</a>(exceptions,message,function)</tt>	Helper function to test error messages in exceptions.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L378'>fake_mldata</a>(columns_dict,dataname,matfile,ordering)</tt>	Create a fake mldata data set.
<tt style='background-color:#E8E8E8;'> utils.mock_mldata_urlopen <a href=' /utils/testing.py#L420'>__init__</a>(mock_datasets)</tt>	Object that mocks the urlopen function to fake requests to mldata.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L494'>all_estimators</a>(include_meta_estimators,include_other,type_filter,include_dont_test)</tt>	Get a list of all estimators from sklearn.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L595'>set_random_state</a>(estimator,random_state)</tt>	Set random state of an estimator if it has the random_state param.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L608'>if_matplotlib</a>(func)</tt>	Test decorator that skips test if matplotlib not installed.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L625'>skip_if_32bit</a>(func)</tt>	Test decorator that skips tests on 32bit platforms.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L637'>if_safe_multiprocessing_with_blas</a>(func)</tt>	Decorator for tests involving both blas calls and multiprocessing.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L665'>clean_warning_registry</a>()</tt>	Safe way to reset warnings.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L681'>check_skip_travis</a>()</tt>	Skip test if being run on travis.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/testing.py#L687'>_delete_folder</a>(folder_path,warn)</tt>	Utility function to cleanup a temporary folder if still existing.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/optimize.py#L27'>_line_search_wolfe12</a>(f,fprime,xk,pk)</tt>	Same as line_search_wolfe1 but fall back to line_search_wolfe2 if suitable step length is not found and raise an exception if a.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/optimize.py#L55'>_cg</a>(fhess_p,fgrad,maxiter,tol)</tt>	Solve iteratively the linear system 'fhess_p xsupi = fgrad'.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/optimize.py#L114'>newton_cg</a>(grad_hess,func,grad,x0)</tt>	Minimization of scalar function of one or more variables using the newton-cg algorithm.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/stats.py#L8'>_rankdata</a>(a,method)</tt>	Assign ranks to data dealing with ties appropriately.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/stats.py#L52'>_weighted_percentile</a>(array,sample_weight,percentile)</tt>	Compute the weighted percentile of array with sample_weight.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/fixes.py#L272'>parallel_helper</a>(obj,methodname)</tt>	Helper to workaround python 2 limitations of pickling instance methods.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/_scipy_sparse_lsqr_backport.py#L63'>_sym_ortho</a>(a,b)</tt>	Stable implementation of givens rotation.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/_scipy_sparse_lsqr_backport.py#L98'>lsqr</a>(A,b,damp,atol)</tt>	Find the least-squares solution to a large sparse linear system of equations.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/class_weight.py#L12'>compute_class_weight</a>(class_weight,classes,y)</tt>	Estimate class weights for unbalanced datasets.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/class_weight.py#L76'>compute_sample_weight</a>(class_weight,y,indices)</tt>	Estimate sample weights by class for unbalanced datasets.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L21'>linear_assignment</a>(X)</tt>	Solve the linear assignment problem using the hungarian algorithm.
<tt style='background-color:#E8E8E8;'> utils._HungarianState <a href=' /utils/linear_assignment_.py#L97'>_find_prime_in_row</a>(row)</tt>	Find the first prime element in the specified row returns.
<tt style='background-color:#E8E8E8;'> utils._HungarianState <a href=' /utils/linear_assignment_.py#L107'>_clear_covers</a>()</tt>	Clear all covered matrix cells.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L113'>_hungarian</a>(cost_matrix)</tt>	The hungarian algorithm.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L153'>_step1</a>(state)</tt>	Steps 1 and 2 in the wikipedia page.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L172'>_step3</a>(state)</tt>	Cover each column containing a starred zero if n columns are covered.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L185'>_step4</a>(state)</tt>	Find a noncovered zero and prime it if there is no starred zero.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L222'>_step5</a>(state)</tt>	Construct a series of alternating primed and starred zeros as follows.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/linear_assignment_.py#L272'>_step6</a>(state)</tt>	Add the value found in step 4 to every element of each covered row and subtract it from every element of each uncovered column.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/arpack.py#L288'>_aligned_zeros</a>(shape,dtype,order,align)</tt>	Allocate a new ndarray with aligned memory.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/arpack.py#L1120'>_eigs</a>(A,k,M,sigma)</tt>	Find k eigenvalues and eigenvectors of the square matrix a.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/arpack.py#L1356'>_eigsh</a>(A,k,M,sigma)</tt>	Find k eigenvalues and eigenvectors of the real symmetric square matrix or complex hermitian matrix a.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/arpack.py#L1689'>_svds</a>(A,k,ncv,tol)</tt>	Compute the largest k singular values/vectors for a sparse matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/random.py#L19'>choice</a>(a,size,replace,p)</tt>	Choice(a size=none replace=true p=none) generates a random sample from a given 1-d array.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/random.py#L205'>random_choice_csc</a>(n_samples,classes,class_probability,random_state)</tt>	Generate a sparse random matrix given column class distributions parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/graph.py#L24'>single_source_shortest_path_length</a>(graph,source,cutoff)</tt>	Return the shortest path length from source to all reachable nodes.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/graph.py#L81'>graph_laplacian</a>(csgraph,normed,return_diag)</tt>	Return the laplacian matrix of a directed graph.
<tt style='background-color:#E8E8E8;'> utils.deprecated <a href=' /utils/deprecation.py#L62'>_decorate_fun</a>(fun)</tt>	Decorate function fun.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L31'>norm</a>(x)</tt>	Compute the euclidean or frobenius norm of x.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L49'>squared_norm</a>(x)</tt>	Squared euclidean or frobenius norm of x.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L59'>row_norms</a>(X,squared)</tt>	Row-wise squared euclidean norm of x.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L79'>fast_logdet</a>(A)</tt>	Compute log(det a for a symmetric equivalent to : np.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L165'>density</a>(w)</tt>	Compute density of a sparse vector.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L177'>safe_sparse_dot</a>(a,b,dense_output)</tt>	Dot product that handle the sparse matrix case correctly uses blas gemm as replacement for numpy.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L192'>randomized_range_finder</a>(A,size,n_iter,power_iteration_normalizer)</tt>	Computes an orthonormal matrix whose range approximates the range of a.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L274'>randomized_svd</a>(M,n_components,n_oversamples,n_iter)</tt>	Computes a truncated randomized svd parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L397'>logsumexp</a>(arr,axis)</tt>	Computes the sum of arr assuming arr is in the log domain.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L423'>weighted_mode</a>(a,w,axis)</tt>	Returns an array of the weighted modal most common value in a if there is more than one such value only the first is returned.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L497'>pinvh</a>(a,cond,rcond,lower)</tt>	Compute the moore-penrose pseudo-inverse of a hermetian matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L565'>cartesian</a>(arrays,out)</tt>	Generate a cartesian product of input arrays.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L614'>svd_flip</a>(u,v,u_based_decision)</tt>	Sign correction to ensure deterministic output from svd.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L653'>log_logistic</a>(X,out)</tt>	Compute the log of the logistic function log(1 / (1 + e ** -x)).
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L698'>softmax</a>(X,copy)</tt>	Calculate the softmax function.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L732'>safe_min</a>(X)</tt>	Returns the minimum value of a dense or a csr/csc matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L747'>make_nonnegative</a>(X,min_value)</tt>	Ensure x min() >= min_value.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L760'>_incremental_mean_and_var</a>(X,last_mean,last_variance,last_sample_count)</tt>	Calculate mean update and a youngs and cramer variance update.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L833'>_deterministic_vector_sign_flip</a>(u)</tt>	Modify the sign of vectors for reproducibility flips the sign of elements of all the vectors rows of u such that.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/extmath.py#L855'>stable_cumsum</a>(arr,axis,rtol,atol)</tt>	Use high precision for cumsum and check that final value matches sum parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L43'>assert_all_finite</a>(X)</tt>	Throw a valueerror if x contains nan or infinity.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L50'>as_float_array</a>(X,copy,force_all_finite)</tt>	Converts an array-like to an array of floats the new dtype will be np.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L90'>_is_arraylike</a>(x)</tt>	Returns whether the input is array-like.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L97'>_num_samples</a>(x)</tt>	Return number of samples in array-like x.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L118'>_shape_repr</a>(shape)</tt>	Return a platform independent representation of an array shape under python 2 the long type introduces an 'l' suffix when using the.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L152'>check_consistent_length</a>()</tt>	Check that all arrays have consistent first dimensions.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L170'>indexable</a>()</tt>	Make arrays indexable for cross-validation.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L196'>_ensure_sparse_format</a>(spmatrix,accept_sparse,dtype,copy)</tt>	Convert a sparse matrix to a given format.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L273'>check_array</a>(array,accept_sparse,dtype,order)</tt>	Input validation on an array list sparse matrix or similar.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L435'>check_X_y</a>(X,y,accept_sparse,dtype)</tt>	Input validation for standard estimators.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L539'>column_or_1d</a>(y,warn)</tt>	Ravel column or 1d numpy array else raises an error parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L568'>check_random_state</a>(seed)</tt>	Turn seed into a np random randomstate instance.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L586'>has_fit_parameter</a>(estimator,parameter)</tt>	Checks whether the estimator's fit method supports the given parameter.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L599'>check_symmetric</a>(array,tol,raise_warning,raise_exception)</tt>	Make sure that array is 2d square and symmetric.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L654'>check_is_fitted</a>(estimator,attributes,msg,all_or_any)</tt>	Perform is_fitted validation for estimator.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/validation.py#L695'>check_non_negative</a>(X,whom)</tt>	Check if there is any negative value in an array.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/bench.py#L6'>total_seconds</a>(delta)</tt>	Helper function to emulate function total_seconds introduced in python2.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L232'>check_estimator</a>(Estimator)</tt>	Check if estimator adheres to scikit-learn conventions.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L335'>_is_32bit</a>()</tt>	Detect if process is 32bit python.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L929'>check_estimators_pickle</a>(name,Estimator)</tt>	Test that we can pickle all estimators.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L1025'>check_clusterer_compute_labels_predict</a>(name,Clusterer)</tt>	Check that predict is invariant of compute_labels.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L1148'>check_estimators_fit_returns_self</a>(name,Estimator)</tt>	Check if self is returned when calling fit.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L1164'>check_estimators_unfitted</a>(name,Estimator)</tt>	Check that predict raises an exception in an unfitted estimator.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L1408'>check_class_weight_balanced_linear_classifier</a>(name,Classifier)</tt>	Test class weights with non-contiguous class labels.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/estimator_checks.py#L1473'>check_no_fit_attributes_set_in_init</a>(name,Estimator)</tt>	Check that estimator __init__ doesn't set trailing-_ attributes.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L44'>unique_labels</a>()</tt>	Extract an ordered array of unique labels we don't allow.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L113'>is_multilabel</a>(y)</tt>	Check if y is in a multilabel format.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L158'>check_classification_targets</a>(y)</tt>	Ensure that target y is of a non-regression type.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L176'>type_of_target</a>(y)</tt>	Determine the type of data indicated by target y parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L281'>_check_partial_fit_first_call</a>(clf,classes)</tt>	Private helper function for factorizing common classes param logic estimators that implement the partial_fit api need to be provided with.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L316'>class_distribution</a>(y,sample_weight)</tt>	Compute class priors from multioutput-multiclass target data parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/multiclass.py#L390'>_ovr_decision_function</a>(predictions,confidences,n_classes)</tt>	Compute a continuous tie-breaking ovr decision function.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L77'>safe_mask</a>(X,mask)</tt>	Return a mask which is safe to use on x.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L102'>axis0_safe_slice</a>(X,mask,len_mask)</tt>	This mask is safer than safe_mask since it returns an empty array when a sparse matrix is sliced with a boolean mask.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L122'>safe_indexing</a>(X,indices)</tt>	Return items or rows from x using indices.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L156'>resample</a>()</tt>	Resample arrays or sparse matrices in a consistent way the default strategy implements one step of the bootstrapping.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L266'>shuffle</a>()</tt>	Shuffle arrays or sparse matrices in a consistent way this is a convenience alias to resample(*arrays replace=false) to do.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L335'>safe_sqr</a>(X,copy)</tt>	Element wise squaring of array-likes and sparse matrices.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L363'>gen_batches</a>(n,batch_size)</tt>	Generator to create slices containing batch_size elements from 0 to n.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L388'>gen_even_slices</a>(n,n_packs,n_samples)</tt>	Generator to create n_packs slices going up to n.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L422'>_get_n_jobs</a>(n_jobs)</tt>	Get number of jobs for the computation.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L461'>tosequence</a>(x)</tt>	Cast iterable x to a sequence avoiding a copy if possible.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/__init__.py#L471'>indices_to_mask</a>(indices,mask_length)</tt>	Convert list of indices to boolean mask.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L16'>_raise_typeerror</a>(X)</tt>	Raises a typeerror if x is not a csr or csc matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L29'>inplace_csr_column_scale</a>(X,scale)</tt>	Inplace column scaling of a csr matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L47'>inplace_csr_row_scale</a>(X,scale)</tt>	Inplace row scaling of a csr matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L65'>mean_variance_axis</a>(X,axis)</tt>	Compute mean and variance along an axix on a csr or csc matrix parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L102'>incr_mean_variance_axis</a>(X,axis,last_mean,last_var)</tt>	Compute incremental mean and variance along an axix on a csr or csc matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L161'>inplace_column_scale</a>(X,scale)</tt>	Inplace column scaling of a csc/csr matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L183'>inplace_row_scale</a>(X,scale)</tt>	Inplace row scaling of a csr or csc matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L205'>inplace_swap_row_csc</a>(X,m,n)</tt>	Swaps two rows of a csc matrix in-place.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L234'>inplace_swap_row_csr</a>(X,m,n)</tt>	Swaps two rows of a csr matrix in-place.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L289'>inplace_swap_row</a>(X,m,n)</tt>	Swaps two rows of a csc/csr matrix in-place.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L312'>inplace_swap_column</a>(X,m,n)</tt>	Swaps two columns of a csc/csr matrix in-place.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L339'>min_max_axis</a>(X,axis)</tt>	Compute minimum and maximum along an axis on a csr or csc matrix parameters.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L365'>count_nonzero</a>(X,axis,sample_weight)</tt>	A variant of x getnnz() with extension to weighting on axis 0.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L413'>_get_median</a>(data,n_zeros)</tt>	Compute the median of data with n_zeros additional zeros.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L432'>_get_elem_at_rank</a>(rank,data,n_negative,n_zeros)</tt>	Find the value in data augmented with n_zeros for the given rank.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/sparsefuncs.py#L441'>csc_median_axis_0</a>(X)</tt>	Find the median across axis 0 of a csc matrix.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/metaestimators.py#L121'>if_delegate_has_method</a>(delegate)</tt>	Create a decorator for methods that are delegated to a sub-estimator this enables ducktyping by hasattr returning true according to the.
<tt style='background-color:#E8E8E8;'> utils. <a href=' /utils/metaestimators.py#L144'>_safe_split</a>(estimator,X,y,indices)</tt>	Create subset of dataset and properly handle kernels.
<tt style='background-color:#E8E8E8;'> utils.sparsetools. <a href=' /utils/sparsetools/_graph_validation.py#L11'>validate_graph</a>(csgraph,directed,dtype,csr_output)</tt>	Routine for validation and conversion of csgraph inputs.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/regression_models.py#L15'>constant</a>(x)</tt>	Zero order polynomial (constant p = 1) regression model.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L237'>linear</a>(x)</tt>	First order polynomial (linear p = n+1) regression model.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/regression_models.py#L63'>quadratic</a>(x)</tt>	Second order polynomial (quadratic p = n* n-1 /2+n+1) regression model.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessRegressor <a href=' /gaussian_process/gpr.py#L157'>fit</a>(X,y)</tt>	Fit gaussian process regression model.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessRegressor <a href=' /gaussian_process/gpr.py#L250'>predict</a>(X,return_std,return_cov)</tt>	Predict using the gaussian process regression model we can also predict based on an unfitted model by using the gp prior.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessRegressor <a href=' /gaussian_process/gpr.py#L329'>sample_y</a>(X,n_samples,random_state)</tt>	Draw samples from gaussian process and evaluate at x.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessRegressor <a href=' /gaussian_process/gpr.py#L365'>log_marginal_likelihood</a>(theta,eval_gradient)</tt>	Returns log-marginal likelihood of theta for training data.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/gaussian_process.py#L23'>l1_cross_distances</a>(X)</tt>	Computes the nonzero componentwise l1 cross-distances between the vectors in x.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcess <a href=' /gaussian_process/gaussian_process.py#L253'>fit</a>(X,y)</tt>	The gaussian process model fitting method.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcess <a href=' /gaussian_process/gaussian_process.py#L388'>predict</a>(X,eval_MSE,batch_size)</tt>	This function evaluates the gaussian process model at x.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcess <a href=' /gaussian_process/gaussian_process.py#L541'>reduced_likelihood_function</a>(theta)</tt>	This function determines the blup parameters and evaluates the reduced likelihood function for the given autocorrelation parameters theta.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcess <a href=' /gaussian_process/gaussian_process.py#L662'>_arg_max_reduced_likelihood_function</a>()</tt>	This function estimates the autocorrelation parameters theta as the maximizer of the reduced likelihood function.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L15'>absolute_exponential</a>(theta,d)</tt>	Absolute exponential autocorrelation model.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L57'>squared_exponential</a>(theta,d)</tt>	Squared exponential correlation model radial basis function.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L100'>generalized_exponential</a>(theta,d)</tt>	Generalized exponential correlation model.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L150'>pure_nugget</a>(theta,d)</tt>	Spatial independence correlation model pure nugget.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L187'>cubic</a>(theta,d)</tt>	Cubic correlation model : theta d --> r theta d =.
<tt style='background-color:#E8E8E8;'> gaussian_process. <a href=' /gaussian_process/correlation_models.py#L237'>linear</a>(theta,d)</tt>	Linear correlation model : theta d --> r theta d =.
<tt style='background-color:#E8E8E8;'> gaussian_process._BinaryGaussianProcessClassifierLaplace <a href=' /gaussian_process/gpc.py#L157'>fit</a>(X,y)</tt>	Fit gaussian process classification model parameters.
<tt style='background-color:#E8E8E8;'> gaussian_process._BinaryGaussianProcessClassifierLaplace <a href=' /gaussian_process/gpc.py#L243'>predict</a>(X)</tt>	Perform classification on an array of test vectors x.
<tt style='background-color:#E8E8E8;'> gaussian_process._BinaryGaussianProcessClassifierLaplace <a href=' /gaussian_process/gpc.py#L265'>predict_proba</a>(X)</tt>	Return probability estimates for the test vector x.
<tt style='background-color:#E8E8E8;'> gaussian_process._BinaryGaussianProcessClassifierLaplace <a href=' /gaussian_process/gpc.py#L304'>log_marginal_likelihood</a>(theta,eval_gradient)</tt>	Returns log-marginal likelihood of theta for training data.
<tt style='background-color:#E8E8E8;'> gaussian_process._BinaryGaussianProcessClassifierLaplace <a href=' /gaussian_process/gpc.py#L371'>_posterior_mode</a>(K,return_temporaries)</tt>	Mode-finding for binary laplace gpc and fixed kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessClassifier <a href=' /gaussian_process/gpc.py#L572'>fit</a>(X,y)</tt>	Fit gaussian process classification model parameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessClassifier <a href=' /gaussian_process/gpc.py#L625'>predict</a>(X)</tt>	Perform classification on an array of test vectors x.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessClassifier <a href=' /gaussian_process/gpc.py#L641'>predict_proba</a>(X)</tt>	Return probability estimates for the test vector x.
<tt style='background-color:#E8E8E8;'> gaussian_process.GaussianProcessClassifier <a href=' /gaussian_process/gpc.py#L672'>log_marginal_likelihood</a>(theta,eval_gradient)</tt>	Returns log-marginal likelihood of theta for training data.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L125'>get_params</a>(deep)</tt>	Get parameters of this kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L164'>set_params</a>()</tt>	Set the parameters of this kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L201'>clone_with_theta</a>(theta)</tt>	Returns a clone of self with given hyperparameters theta.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L207'>n_dims</a>()</tt>	Returns the number of non-fixed hyperparameters of the kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L212'>hyperparameters</a>()</tt>	Returns a list of all hyperparameter specifications.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L245'>theta</a>()</tt>	Returns the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L245'>theta</a>(theta)</tt>	Sets the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L274'>bounds</a>()</tt>	Returns the log-transformed bounds on the theta.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L329'>__call__</a>(X,Y,eval_gradient)</tt>	Evaluate the kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L333'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.Kernel <a href=' /gaussian_process/kernels.py#L352'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> gaussian_process.NormalizedKernelMixin <a href=' /gaussian_process/kernels.py#L363'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.StationaryKernelMixin <a href=' /gaussian_process/kernels.py#L389'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L403'>get_params</a>(deep)</tt>	Get parameters of this kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L435'>theta</a>()</tt>	Returns the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L435'>theta</a>(theta)</tt>	Sets the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L448'>bounds</a>()</tt>	Returns the log-transformed bounds on the theta.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L459'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L506'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> gaussian_process.CompoundKernel <a href=' /gaussian_process/kernels.py#L510'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.KernelOperator <a href=' /gaussian_process/kernels.py#L540'>get_params</a>(deep)</tt>	Get parameters of this kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.KernelOperator <a href=' /gaussian_process/kernels.py#L563'>hyperparameters</a>()</tt>	Returns a list of all hyperparameter.
<tt style='background-color:#E8E8E8;'> gaussian_process.KernelOperator <a href=' /gaussian_process/kernels.py#L595'>theta</a>()</tt>	Returns the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.KernelOperator <a href=' /gaussian_process/kernels.py#L595'>theta</a>(theta)</tt>	Sets the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.KernelOperator <a href=' /gaussian_process/kernels.py#L608'>bounds</a>()</tt>	Returns the log-transformed bounds on the theta.
<tt style='background-color:#E8E8E8;'> gaussian_process.KernelOperator <a href=' /gaussian_process/kernels.py#L629'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> gaussian_process.Sum <a href=' /gaussian_process/kernels.py#L652'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.Sum <a href=' /gaussian_process/kernels.py#L685'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.Product <a href=' /gaussian_process/kernels.py#L726'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.Product <a href=' /gaussian_process/kernels.py#L760'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L804'>get_params</a>(deep)</tt>	Get parameters of this kernel.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L824'>hyperparameters</a>()</tt>	Returns a list of all hyperparameter.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L851'>theta</a>()</tt>	Returns the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L851'>theta</a>(theta)</tt>	Sets the flattened log-transformed non-fixed hyperparameters.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L862'>bounds</a>()</tt>	Returns the log-transformed bounds on the theta.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L878'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L913'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.Exponentiation <a href=' /gaussian_process/kernels.py#L935'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> gaussian_process.ConstantKernel <a href=' /gaussian_process/kernels.py#L970'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.ConstantKernel <a href=' /gaussian_process/kernels.py#L1012'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.WhiteKernel <a href=' /gaussian_process/kernels.py#L1064'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.WhiteKernel <a href=' /gaussian_process/kernels.py#L1107'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.RBF <a href=' /gaussian_process/kernels.py#L1176'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.Matern <a href=' /gaussian_process/kernels.py#L1289'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.RationalQuadratic <a href=' /gaussian_process/kernels.py#L1439'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.ExpSineSquared <a href=' /gaussian_process/kernels.py#L1552'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.DotProduct <a href=' /gaussian_process/kernels.py#L1655'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.DotProduct <a href=' /gaussian_process/kernels.py#L1700'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.DotProduct <a href=' /gaussian_process/kernels.py#L1719'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> gaussian_process.PairwiseKernel <a href=' /gaussian_process/kernels.py#L1790'>__call__</a>(X,Y,eval_gradient)</tt>	Return the kernel k x y and optionally its gradient.
<tt style='background-color:#E8E8E8;'> gaussian_process.PairwiseKernel <a href=' /gaussian_process/kernels.py#L1837'>diag</a>(X)</tt>	Returns the diagonal of the kernel k x x.
<tt style='background-color:#E8E8E8;'> gaussian_process.PairwiseKernel <a href=' /gaussian_process/kernels.py#L1857'>is_stationary</a>()</tt>	Returns whether the kernel is stationary.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/approximate.py#L24'>_find_matching_indices</a>(tree,bin_X,left_mask,right_mask)</tt>	Finds indices in sorted array of integers.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/approximate.py#L36'>_find_longest_prefix_match</a>(tree,bin_X,hash_size,left_masks)</tt>	Find the longest prefix match in tree for each query in bin_x most significant bits are considered as the prefix.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/approximate.py#L103'>_array_of_arrays</a>(list_of_arrays)</tt>	Creates an array of array from list of arrays.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L220'>_compute_distances</a>(query,candidates)</tt>	Computes the cosine distance.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L241'>_generate_masks</a>()</tt>	Creates left and right masks for all hash lengths.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L251'>_get_candidates</a>(query,max_depth,bin_queries,n_neighbors)</tt>	Performs the synchronous ascending phase.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L300'>_get_radius_neighbors</a>(query,max_depth,bin_queries,radius)</tt>	Finds radius neighbors from the candidates obtained.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L337'>fit</a>(X,y)</tt>	Fit the lsh forest on the data.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L386'>_query</a>(X)</tt>	Performs descending phase to find maximum depth.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L401'>kneighbors</a>(X,n_neighbors,return_distance)</tt>	Returns n_neighbors of approximate nearest neighbors.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L450'>radius_neighbors</a>(X,radius,return_distance)</tt>	Finds the neighbors within a given radius of a point or points.
<tt style='background-color:#E8E8E8;'> neighbors.LSHForest <a href=' /neighbors/approximate.py#L509'>partial_fit</a>(X,y)</tt>	Inserts new data into the already fitted lsh forest.
<tt style='background-color:#E8E8E8;'> neighbors.LocalOutlierFactor <a href=' /neighbors/lof.py#L136'>fit_predict</a>(X,y)</tt>	"fits the model to the training set x and returns the labels 1 inlier -1 outlier on the training set according to the lof score.
<tt style='background-color:#E8E8E8;'> neighbors.LocalOutlierFactor <a href=' /neighbors/lof.py#L156'>fit</a>(X,y)</tt>	Fit the model using x as training data.
<tt style='background-color:#E8E8E8;'> neighbors.LocalOutlierFactor <a href=' /neighbors/lof.py#L200'>_predict</a>(X)</tt>	Predict the labels 1 inlier -1 outlier of x according to lof.
<tt style='background-color:#E8E8E8;'> neighbors.LocalOutlierFactor <a href=' /neighbors/lof.py#L233'>_decision_function</a>(X)</tt>	Opposite of the local outlier factor of x (as bigger is better i.
<tt style='background-color:#E8E8E8;'> neighbors.LocalOutlierFactor <a href=' /neighbors/lof.py#L272'>_local_reachability_density</a>(distances_X,neighbors_indices)</tt>	The local reachability density lrd the lrd of a sample is the inverse of the average reachability.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/base.py#L47'>_check_weights</a>(weights)</tt>	Check to make sure weights are valid.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/base.py#L58'>_get_weights</a>(dist,weights)</tt>	Get the weights from an array of distances and a parameter weights.
<tt style='background-color:#E8E8E8;'> neighbors.KNeighborsMixin <a href=' /neighbors/base.py#L269'>kneighbors</a>(X,n_neighbors,return_distance)</tt>	Finds the k-neighbors of a point.
<tt style='background-color:#E8E8E8;'> neighbors.KNeighborsMixin <a href=' /neighbors/base.py#L420'>kneighbors_graph</a>(X,n_neighbors,mode)</tt>	Computes the weighted graph of k-neighbors for points in x parameters.
<tt style='background-color:#E8E8E8;'> neighbors.RadiusNeighborsMixin <a href=' /neighbors/base.py#L502'>radius_neighbors</a>(X,radius,return_distance)</tt>	Finds the neighbors within a given radius of a point or points.
<tt style='background-color:#E8E8E8;'> neighbors.RadiusNeighborsMixin <a href=' /neighbors/base.py#L649'>radius_neighbors_graph</a>(X,radius,mode)</tt>	Computes the weighted graph of neighbors for points in x neighborhoods are restricted the points at a distance lower than.
<tt style='background-color:#E8E8E8;'> neighbors.SupervisedFloatMixin <a href=' /neighbors/base.py#L727'>fit</a>(X,y)</tt>	Fit the model using x as training data and y as target values parameters.
<tt style='background-color:#E8E8E8;'> neighbors.SupervisedIntegerMixin <a href=' /neighbors/base.py#L747'>fit</a>(X,y)</tt>	Fit the model using x as training data and y as target values parameters.
<tt style='background-color:#E8E8E8;'> neighbors.UnsupervisedMixin <a href=' /neighbors/base.py#L790'>fit</a>(X,y)</tt>	Fit the model using x as training data parameters.
<tt style='background-color:#E8E8E8;'> neighbors.KNeighborsRegressor <a href=' /neighbors/regression.py#L128'>predict</a>(X)</tt>	Predict the target for the provided data parameters.
<tt style='background-color:#E8E8E8;'> neighbors.RadiusNeighborsRegressor <a href=' /neighbors/regression.py#L266'>predict</a>(X)</tt>	Predict the target for the provided data parameters.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/graph.py#L11'>_check_params</a>(X,metric,p,metric_params)</tt>	Check the validity of the input parameters.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/graph.py#L24'>_query_include_self</a>(X,include_self)</tt>	Return the query based on include_self param.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/graph.py#L34'>kneighbors_graph</a>(X,n_neighbors,mode,metric)</tt>	Computes the weighted graph of k-neighbors for points in x read more in the :ref user guide <unsupervised_neighbors>.
<tt style='background-color:#E8E8E8;'> neighbors. <a href=' /neighbors/graph.py#L106'>radius_neighbors_graph</a>(X,radius,mode,metric)</tt>	Computes the weighted graph of neighbors for points in x neighborhoods are restricted the points at a distance lower than.
<tt style='background-color:#E8E8E8;'> neighbors.KernelDensity <a href=' /neighbors/kde.py#L115'>fit</a>(X,y)</tt>	Fit the kernel density model on the data.
<tt style='background-color:#E8E8E8;'> neighbors.KernelDensity <a href=' /neighbors/kde.py#L135'>score_samples</a>(X)</tt>	Evaluate the density model on the data.
<tt style='background-color:#E8E8E8;'> neighbors.KernelDensity <a href=' /neighbors/kde.py#L161'>score</a>(X,y)</tt>	Compute the total log probability under the model.
<tt style='background-color:#E8E8E8;'> neighbors.KernelDensity <a href=' /neighbors/kde.py#L177'>sample</a>(n_samples,random_state)</tt>	Generate random samples from the model.
<tt style='background-color:#E8E8E8;'> neighbors.KNeighborsClassifier <a href=' /neighbors/classification.py#L129'>predict</a>(X)</tt>	Predict the class labels for the provided data parameters.
<tt style='background-color:#E8E8E8;'> neighbors.KNeighborsClassifier <a href=' /neighbors/classification.py#L172'>predict_proba</a>(X)</tt>	Return probability estimates for the test data x.
<tt style='background-color:#E8E8E8;'> neighbors.RadiusNeighborsClassifier <a href=' /neighbors/classification.py#L327'>predict</a>(X)</tt>	Predict the class labels for the provided data parameters.
<tt style='background-color:#E8E8E8;'> neighbors.NearestCentroid <a href=' /neighbors/nearest_centroid.py#L85'>fit</a>(X,y)</tt>	Fit the nearestcentroid model according to the given training data.
<tt style='background-color:#E8E8E8;'> neighbors.NearestCentroid <a href=' /neighbors/nearest_centroid.py#L168'>predict</a>(X)</tt>	Perform classification on an array of test vectors x.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L37'>cross_val_score</a>(estimator,X,y,groups)</tt>	Evaluate a score by cross-validation read more in the :ref user guide <cross_validation>.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L144'>_fit_and_score</a>(estimator,X,y,scorer)</tt>	Fit estimator and compute scores for a given dataset split.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L283'>_score</a>(estimator,X_test,y_test,scorer)</tt>	Compute the score of an estimator on a given test set.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L302'>cross_val_predict</a>(estimator,X,y,groups)</tt>	Generate cross-validated estimates for each input data point read more in the :ref user guide <cross_validation>.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L427'>_fit_and_predict</a>(estimator,X,y,train)</tt>	Fit estimator and predict values for a given dataset split.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L493'>_check_is_permutation</a>(indices,n_samples)</tt>	Check whether indices is a reordering of the array np arange(n_samples).
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L517'>_index_param_value</a>(X,v,indices)</tt>	Private helper function for parameter value indexing.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L641'>_permutation_test_score</a>(estimator,X,y,groups)</tt>	Auxiliary function for permutation_test_score.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L652'>_shuffle</a>(y,groups,random_state)</tt>	Return a shuffled copy of y eventually shuffle among same groups.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L823'>_translate_train_sizes</a>(train_sizes,n_max_training_samples)</tt>	Determine absolute sizes of training subsets and validate 'train_sizes'.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_validation.py#L882'>_incremental_fit_estimator</a>(estimator,X,y,classes)</tt>	Train estimator on training subsets incrementally and compute scores.
<tt style='background-color:#E8E8E8;'> model_selection.ParameterGrid <a href=' /model_selection/_search.py#L95'>__iter__</a>()</tt>	Iterate over the points in the grid.
<tt style='background-color:#E8E8E8;'> model_selection.ParameterGrid <a href=' /model_selection/_search.py#L115'>__len__</a>()</tt>	Number of points on the grid.
<tt style='background-color:#E8E8E8;'> model_selection.ParameterGrid <a href=' /model_selection/_search.py#L122'>__getitem__</a>(ind)</tt>	Get the parameters that would be indth in iteration.
<tt style='background-color:#E8E8E8;'> model_selection.ParameterSampler <a href=' /model_selection/_search.py#L266'>__len__</a>()</tt>	Number of points that will be sampled.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_search.py#L271'>fit_grid_point</a>(X,y,estimator,parameters)</tt>	Run fit on one set of parameters.
<tt style='background-color:#E8E8E8;'> model_selection._CVScoreTuple <a href=' /model_selection/_search.py#L368'>__repr__</a>()</tt>	Simple custom repr to summarize the main info.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L402'>score</a>(X,y)</tt>	Returns the score on the given data if the estimator has been refit.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L437'>predict</a>(X)</tt>	Call predict on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L454'>predict_proba</a>(X)</tt>	Call predict_proba on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L471'>predict_log_proba</a>(X)</tt>	Call predict_log_proba on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L488'>decision_function</a>(X)</tt>	Call decision_function on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L505'>transform</a>(X)</tt>	Call transform on the estimator with the best found parameters.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L522'>inverse_transform</a>(Xt)</tt>	Call inverse_transform on the estimator with the best found params.
<tt style='background-color:#E8E8E8;'> model_selection.BaseSearchCV <a href=' /model_selection/_search.py#L544'>fit</a>(X,y,groups)</tt>	Run fit with all sets of parameters.
<tt style='background-color:#E8E8E8;'> model_selection.GridSearchCV <a href=' /model_selection/_search.py#L960'>_get_param_iterator</a>()</tt>	Return parametergrid instance for the given param_grid.
<tt style='background-color:#E8E8E8;'> model_selection.RandomizedSearchCV <a href=' /model_selection/_search.py#L1188'>_get_param_iterator</a>()</tt>	Return parametersampler instance for the given distributions.
<tt style='background-color:#E8E8E8;'> model_selection.BaseCrossValidator <a href=' /model_selection/_split.py#L66'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection.BaseCrossValidator <a href=' /model_selection/_split.py#L99'>_iter_test_masks</a>(X,y,groups)</tt>	Generates boolean masks corresponding to test sets.
<tt style='background-color:#E8E8E8;'> model_selection.BaseCrossValidator <a href=' /model_selection/_split.py#L109'>_iter_test_indices</a>(X,y,groups)</tt>	Generates integer indices corresponding to test sets.
<tt style='background-color:#E8E8E8;'> model_selection.BaseCrossValidator <a href=' /model_selection/_split.py#L113'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator.
<tt style='background-color:#E8E8E8;'> model_selection.LeaveOneOut <a href=' /model_selection/_split.py#L170'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection.LeavePOut <a href=' /model_selection/_split.py#L246'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection._BaseKFold <a href=' /model_selection/_split.py#L291'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection._BaseKFold <a href=' /model_selection/_split.py#L326'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection.StratifiedKFold <a href=' /model_selection/_split.py#L624'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection.TimeSeriesSplit <a href=' /model_selection/_split.py#L706'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection.LeaveOneGroupOut <a href=' /model_selection/_split.py#L799'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection.LeavePGroupsOut <a href=' /model_selection/_split.py#L898'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection._RepeatedSplits <a href=' /model_selection/_split.py#L967'>split</a>(X,y,groups)</tt>	Generates indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection._RepeatedSplits <a href=' /model_selection/_split.py#L1000'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection.BaseShuffleSplit <a href=' /model_selection/_split.py#L1133'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection.BaseShuffleSplit <a href=' /model_selection/_split.py#L1161'>_iter_indices</a>(X,y,groups)</tt>	Generate train test indices.
<tt style='background-color:#E8E8E8;'> model_selection.BaseShuffleSplit <a href=' /model_selection/_split.py#L1165'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_split.py#L1335'>_approximate_mode</a>(class_counts,n_draws,rng)</tt>	Computes approximate mode of multivariate hypergeometric.
<tt style='background-color:#E8E8E8;'> model_selection.StratifiedShuffleSplit <a href=' /model_selection/_split.py#L1512'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_split.py#L1544'>_validate_shuffle_split_init</a>(test_size,train_size)</tt>	Validation helper to check the test_size and train_size at init.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_split.py#L1579'>_validate_shuffle_split</a>(n_samples,test_size,train_size)</tt>	Validation helper to check if the test/test sizes are meaningful wrt to the.
<tt style='background-color:#E8E8E8;'> model_selection.PredefinedSplit <a href=' /model_selection/_split.py#L1652'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection.PredefinedSplit <a href=' /model_selection/_split.py#L1680'>_iter_test_masks</a>()</tt>	Generates boolean masks corresponding to test sets.
<tt style='background-color:#E8E8E8;'> model_selection.PredefinedSplit <a href=' /model_selection/_split.py#L1688'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection._CVIterableWrapper <a href=' /model_selection/_split.py#L1715'>get_n_splits</a>(X,y,groups)</tt>	Returns the number of splitting iterations in the cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection._CVIterableWrapper <a href=' /model_selection/_split.py#L1736'>split</a>(X,y,groups)</tt>	Generate indices to split data into training and test set.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_split.py#L1762'>check_cv</a>(cv,y,classifier)</tt>	Input checker utility for building a cross-validator parameters.
<tt style='background-color:#E8E8E8;'> model_selection. <a href=' /model_selection/_split.py#L1815'>train_test_split</a>()</tt>	Split arrays or matrices into random train and test subsets quick utility that wraps input validation and.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGD <a href=' /linear_model/stochastic_gradient.py#L81'>_validate_params</a>()</tt>	Validate input params.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGD <a href=' /linear_model/stochastic_gradient.py#L106'>_get_loss_function</a>(loss)</tt>	Get concrete lossfunction object for str loss.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGD <a href=' /linear_model/stochastic_gradient.py#L132'>_validate_sample_weight</a>(sample_weight,n_samples)</tt>	Set the sample weight array.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGD <a href=' /linear_model/stochastic_gradient.py#L145'>_allocate_parameter_mem</a>(n_classes,n_features,coef_init,intercept_init)</tt>	Allocate mem for parameters initialize if provided.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/stochastic_gradient.py#L207'>_prepare_fit_binary</a>(est,y,i)</tt>	Initialization for fit_binary.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/stochastic_gradient.py#L239'>fit_binary</a>(est,i,X,y)</tt>	Fit a single binary classifier.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDClassifier <a href=' /linear_model/stochastic_gradient.py#L414'>_fit_binary</a>(X,y,alpha,C)</tt>	Fit a binary classifier on x and y.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDClassifier <a href=' /linear_model/stochastic_gradient.py#L439'>_fit_multiclass</a>(X,y,alpha,C)</tt>	Fit a multi-class classifier by combining binary classifiers each binary classifier predicts one class versus all others.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDClassifier <a href=' /linear_model/stochastic_gradient.py#L468'>partial_fit</a>(X,y,classes,sample_weight)</tt>	Fit linear model with stochastic gradient descent.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDClassifier <a href=' /linear_model/stochastic_gradient.py#L509'>fit</a>(X,y,coef_init,intercept_init)</tt>	Fit linear model with stochastic gradient descent.
<tt style='background-color:#E8E8E8;'> linear_model.SGDClassifier <a href=' /linear_model/stochastic_gradient.py#L806'>predict_log_proba</a>()</tt>	Log of probability estimates.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDRegressor <a href=' /linear_model/stochastic_gradient.py#L895'>partial_fit</a>(X,y,sample_weight)</tt>	Fit linear model with stochastic gradient descent.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDRegressor <a href=' /linear_model/stochastic_gradient.py#L944'>fit</a>(X,y,coef_init,intercept_init)</tt>	Fit linear model with stochastic gradient descent.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDRegressor <a href=' /linear_model/stochastic_gradient.py#L975'>_decision_function</a>(X)</tt>	Predict using the linear model parameters.
<tt style='background-color:#E8E8E8;'> linear_model.BaseSGDRegressor <a href=' /linear_model/stochastic_gradient.py#L995'>predict</a>(X)</tt>	Predict using the linear model parameters.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/theil_sen.py#L32'>_modified_weiszfeld_step</a>(X,x_old)</tt>	Modified weiszfeld step.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/theil_sen.py#L80'>_spatial_median</a>(X,max_iter,tol)</tt>	Spatial median l1 median.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/theil_sen.py#L134'>_breakdown_point</a>(n_samples,n_subsamples)</tt>	Approximation of the breakdown point.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/theil_sen.py#L154'>_lstsq</a>(X,y,indices,fit_intercept)</tt>	Least squares estimator for theilsenregressor class.
<tt style='background-color:#E8E8E8;'> linear_model.TheilSenRegressor <a href=' /linear_model/theil_sen.py#L335'>fit</a>(X,y)</tt>	Fit linear model.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/omp.py#L33'>_cholesky_omp</a>(X,y,n_nonzero_coefs,tol)</tt>	Orthogonal matching pursuit step using the cholesky decomposition.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/omp.py#L144'>_gram_omp</a>(Gram,Xy,n_nonzero_coefs,tol_0)</tt>	Orthogonal matching pursuit step on a precomputed gram matrix.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/omp.py#L269'>orthogonal_mp</a>(X,y,n_nonzero_coefs,tol)</tt>	Orthogonal matching pursuit omp solves n_targets orthogonal matching pursuit problems.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/omp.py#L411'>orthogonal_mp_gram</a>(Gram,Xy,n_nonzero_coefs,tol)</tt>	Gram orthogonal matching pursuit omp solves n_targets orthogonal matching pursuit problems using only.
<tt style='background-color:#E8E8E8;'> linear_model.OrthogonalMatchingPursuit <a href=' /linear_model/omp.py#L617'>fit</a>(X,y)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/omp.py#L669'>_omp_path_residues</a>(X_train,y_train,X_test,y_test)</tt>	Compute the residues on left-out data for a full lars path parameters.
<tt style='background-color:#E8E8E8;'> linear_model.OrthogonalMatchingPursuitCV <a href=' /linear_model/omp.py#L835'>fit</a>(X,y)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/least_angle.py#L37'>lars_path</a>(X,y,Xy,Gram)</tt>	Compute least angle regression or lasso path using lars algorithm [1] the optimization objective for the case method='lasso' is :.
<tt style='background-color:#E8E8E8;'> linear_model.Lars <a href=' /linear_model/least_angle.py#L615'>fit</a>(X,y,Xy)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/least_angle.py#L854'>_lars_path_residues</a>(X_train,y_train,X_test,y_test)</tt>	Compute the residues on left-out data for a full lars path parameters.
<tt style='background-color:#E8E8E8;'> linear_model.LarsCV <a href=' /linear_model/least_angle.py#L1082'>fit</a>(X,y)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> linear_model.LassoLarsIC <a href=' /linear_model/least_angle.py#L1420'>fit</a>(X,y,copy_X)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/sag.py#L18'>get_auto_step_size</a>(max_squared_sum,alpha_scaled,loss,fit_intercept)</tt>	Compute automatic step size for sag solver the step size is set to 1 / (alpha_scaled + l + fit_intercept) where l is.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/sag.py#L86'>sag_solver</a>(X,y,sample_weight,loss)</tt>	Sag solver for ridge and logisticregression sag stands for stochastic average gradient the gradient of the loss is.
<tt style='background-color:#E8E8E8;'> linear_model.BayesianRidge <a href=' /linear_model/bayes.py#L141'>fit</a>(X,y)</tt>	Fit the model parameters.
<tt style='background-color:#E8E8E8;'> linear_model.BayesianRidge <a href=' /linear_model/bayes.py#L243'>predict</a>(X,return_std)</tt>	Predict using the linear model.
<tt style='background-color:#E8E8E8;'> linear_model.ARDRegression <a href=' /linear_model/bayes.py#L408'>fit</a>(X,y)</tt>	Fit the ardregression model according to the given training data and parameters.
<tt style='background-color:#E8E8E8;'> linear_model.ARDRegression <a href=' /linear_model/bayes.py#L501'>predict</a>(X,return_std)</tt>	Predict using the linear model.
<tt style='background-color:#E8E8E8;'> linear_model.BaseRandomizedLinearModel <a href=' /linear_model/randomized_l1.py#L76'>fit</a>(X,y)</tt>	Fit the model using x y as training data.
<tt style='background-color:#E8E8E8;'> linear_model.BaseRandomizedLinearModel <a href=' /linear_model/randomized_l1.py#L120'>_make_estimator_and_params</a>(X,y)</tt>	Return the parameters passed to the estimator.
<tt style='background-color:#E8E8E8;'> linear_model.BaseRandomizedLinearModel <a href=' /linear_model/randomized_l1.py#L124'>_get_support_mask</a>()</tt>	Get the boolean mask indicating which features are selected.
<tt style='background-color:#E8E8E8;'> linear_model.RandomizedLogisticRegression <a href=' /linear_model/randomized_l1.py#L521'>_preprocess_data</a>(X,y,fit_intercept,normalize)</tt>	Center the data in x but not in y.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/randomized_l1.py#L530'>_lasso_stability_path</a>(X,y,mask,weights)</tt>	Inner loop of lasso_stability_path.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/randomized_l1.py#L557'>lasso_stability_path</a>(X,y,scaling,random_state)</tt>	Stability path based on randomized lasso estimates read more in the :ref user guide <randomized_l1>.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/base.py#L48'>make_dataset</a>(X,y,sample_weight,random_state)</tt>	Create dataset abstraction for sparse and dense inputs.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/base.py#L70'>sparse_center_data</a>(X,y,fit_intercept,normalize)</tt>	Compute information needed to center data to have mean zero along axis 0.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/base.py#L108'>center_data</a>(X,y,fit_intercept,normalize)</tt>	Centers data to have mean zero along axis 0 this is here because.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/base.py#L144'>_preprocess_data</a>(X,y,fit_intercept,normalize)</tt>	Centers data to have mean zero along axis 0 if fit_intercept=false or if.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/base.py#L213'>_rescale_data</a>(X,y,sample_weight)</tt>	Rescale data so as to support sample_weight.
<tt style='background-color:#E8E8E8;'> linear_model.LinearModel <a href=' /linear_model/base.py#L239'>predict</a>(X)</tt>	Predict using the linear model parameters.
<tt style='background-color:#E8E8E8;'> linear_model.LinearModel <a href=' /linear_model/base.py#L256'>_set_intercept</a>(X_offset,y_offset,X_scale)</tt>	Set the intercept_.
<tt style='background-color:#E8E8E8;'> linear_model.LinearClassifierMixin <a href=' /linear_model/base.py#L274'>decision_function</a>(X)</tt>	Predict confidence scores for samples.
<tt style='background-color:#E8E8E8;'> linear_model.LinearClassifierMixin <a href=' /linear_model/base.py#L307'>predict</a>(X)</tt>	Predict class labels for samples in x.
<tt style='background-color:#E8E8E8;'> linear_model.LinearClassifierMixin <a href=' /linear_model/base.py#L327'>_predict_proba_lr</a>(X)</tt>	Probability estimation for ovr logistic regression.
<tt style='background-color:#E8E8E8;'> linear_model.SparseCoefMixin <a href=' /linear_model/base.py#L353'>densify</a>()</tt>	Convert coefficient matrix to dense array format.
<tt style='background-color:#E8E8E8;'> linear_model.SparseCoefMixin <a href=' /linear_model/base.py#L371'>sparsify</a>()</tt>	Convert coefficient matrix to sparse format.
<tt style='background-color:#E8E8E8;'> linear_model.LinearRegression <a href=' /linear_model/base.py#L453'>fit</a>(X,y,sample_weight)</tt>	Fit linear model.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/base.py#L514'>_pre_fit</a>(X,y,Xy,precompute)</tt>	Aux function used at beginning of fit in linear models.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/ransac.py#L20'>_dynamic_max_trials</a>(n_inliers,n_samples,min_samples,probability)</tt>	Determine number trials such that at least one outlier-free subset is sampled for the given inlier/outlier ratio.
<tt style='background-color:#E8E8E8;'> linear_model.RANSACRegressor <a href=' /linear_model/ransac.py#L224'>fit</a>(X,y,sample_weight)</tt>	Fit estimator using ransac algorithm.
<tt style='background-color:#E8E8E8;'> linear_model.RANSACRegressor <a href=' /linear_model/ransac.py#L464'>predict</a>(X)</tt>	Predict using the estimated model.
<tt style='background-color:#E8E8E8;'> linear_model.RANSACRegressor <a href=' /linear_model/ransac.py#L482'>score</a>(X,y)</tt>	Returns the score of the prediction.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/ridge.py#L195'>ridge_regression</a>(X,y,alpha,sample_weight)</tt>	Solve the ridge equation by the method of normal equations.
<tt style='background-color:#E8E8E8;'> linear_model.Ridge <a href=' /linear_model/ridge.py#L637'>fit</a>(X,y,sample_weight)</tt>	Fit ridge regression model parameters.
<tt style='background-color:#E8E8E8;'> linear_model.RidgeClassifier <a href=' /linear_model/ridge.py#L776'>fit</a>(X,y,sample_weight)</tt>	Fit ridge regression model.
<tt style='background-color:#E8E8E8;'> linear_model._RidgeGCV <a href=' /linear_model/ridge.py#L896'>_errors_and_values_helper</a>(alpha,y,v,Q)</tt>	Helper function to avoid code duplication between self _errors and.
<tt style='background-color:#E8E8E8;'> linear_model._RidgeGCV <a href=' /linear_model/ridge.py#L936'>_errors_and_values_svd_helper</a>(alpha,y,v,U)</tt>	Helper function to avoid code duplication between self _errors_svd.
<tt style='background-color:#E8E8E8;'> linear_model._RidgeGCV <a href=' /linear_model/ridge.py#L960'>fit</a>(X,y,sample_weight)</tt>	Fit ridge regression model parameters.
<tt style='background-color:#E8E8E8;'> linear_model._BaseRidgeCV <a href=' /linear_model/ridge.py#L1079'>fit</a>(X,y,sample_weight)</tt>	Fit ridge regression model parameters.
<tt style='background-color:#E8E8E8;'> linear_model.RidgeClassifierCV <a href=' /linear_model/ridge.py#L1320'>fit</a>(X,y,sample_weight)</tt>	Fit the ridge classifier.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/coordinate_descent.py#L35'>_alpha_grid</a>(X,y,Xy,l1_ratio)</tt>	Compute the grid of alpha values for elastic net parameter search parameters.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/coordinate_descent.py#L126'>lasso_path</a>(X,y,eps,n_alphas)</tt>	Compute lasso path with coordinate descent the lasso optimization function varies for mono and multi-outputs.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/coordinate_descent.py#L266'>enet_path</a>(X,y,l1_ratio,eps)</tt>	Compute elastic net path with coordinate descent the elastic net optimization function varies for mono and multi-outputs.
<tt style='background-color:#E8E8E8;'> linear_model.ElasticNet <a href=' /linear_model/coordinate_descent.py#L639'>fit</a>(X,y,check_input)</tt>	Fit model with coordinate descent.
<tt style='background-color:#E8E8E8;'> linear_model.ElasticNet <a href=' /linear_model/coordinate_descent.py#L742'>sparse_coef_</a>()</tt>	Sparse representation of the fitted coef_.
<tt style='background-color:#E8E8E8;'> linear_model.ElasticNet <a href=' /linear_model/coordinate_descent.py#L747'>_decision_function</a>(X)</tt>	Decision function of the linear model parameters.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/coordinate_descent.py#L905'>_path_residuals</a>(X,y,train,test)</tt>	Returns the mse for the models computed by 'path' parameters.
<tt style='background-color:#E8E8E8;'> linear_model.LinearModelCV <a href=' /linear_model/coordinate_descent.py#L1034'>fit</a>(X,y)</tt>	Fit linear model with coordinate descent fit is on grid of alphas and best alpha estimated by cross-validation.
<tt style='background-color:#E8E8E8;'> linear_model.MultiTaskElasticNet <a href=' /linear_model/coordinate_descent.py#L1665'>fit</a>(X,y)</tt>	Fit multitaskelasticnet model with coordinate descent parameters.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/huber.py#L16'>_huber_loss_and_gradient</a>(w,X,y,epsilon)</tt>	Returns the huber loss and the gradient.
<tt style='background-color:#E8E8E8;'> linear_model.HuberRegressor <a href=' /linear_model/huber.py#L207'>fit</a>(X,y,sample_weight)</tt>	Fit the model according to the given training data.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L40'>_intercept_dot</a>(w,X,y)</tt>	Computes y * np dot x w.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L78'>_logistic_loss_and_grad</a>(w,X,y,alpha)</tt>	Computes the logistic loss and gradient.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L129'>_logistic_loss</a>(w,X,y,alpha)</tt>	Computes the logistic loss.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L165'>_logistic_grad_hess</a>(w,X,y,alpha)</tt>	Computes the gradient and the hessian in the case of a logistic loss.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L242'>_multinomial_loss</a>(w,X,Y,alpha)</tt>	Computes multinomial loss and class probabilities.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L299'>_multinomial_loss_grad</a>(w,X,Y,alpha)</tt>	Computes the multinomial loss gradient and class probabilities.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L351'>_multinomial_grad_hess</a>(w,X,Y,alpha)</tt>	Computes the gradient and the hessian in the case of a multinomial loss.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L447'>logistic_regression_path</a>(X,y,pos_class,Cs)</tt>	Compute a logistic regression model for a list of regularization parameters.
<tt style='background-color:#E8E8E8;'> linear_model. <a href=' /linear_model/logistic.py#L771'>_log_reg_scoring_path</a>(X,y,train,test)</tt>	Computes scores across logistic_regression_path parameters.
<tt style='background-color:#E8E8E8;'> linear_model.LogisticRegression <a href=' /linear_model/logistic.py#L1172'>fit</a>(X,y,sample_weight)</tt>	Fit the model according to the given training data.
<tt style='background-color:#E8E8E8;'> linear_model.LogisticRegression <a href=' /linear_model/logistic.py#L1327'>predict_log_proba</a>(X)</tt>	Log of probability estimates.
<tt style='background-color:#E8E8E8;'> linear_model.LogisticRegressionCV <a href=' /linear_model/logistic.py#L1565'>fit</a>(X,y,sample_weight)</tt>	Fit the model according to the given training data.
<tt style='background-color:#E8E8E8;'> linear_model.PassiveAggressiveClassifier <a href=' /linear_model/passive_aggressive.py#L118'>partial_fit</a>(X,y,classes)</tt>	Fit linear model with passive aggressive algorithm.
<tt style='background-color:#E8E8E8;'> linear_model.PassiveAggressiveClassifier <a href=' /linear_model/passive_aggressive.py#L157'>fit</a>(X,y,coef_init,intercept_init)</tt>	Fit linear model with passive aggressive algorithm.
<tt style='background-color:#E8E8E8;'> linear_model.PassiveAggressiveRegressor <a href=' /linear_model/passive_aggressive.py#L279'>partial_fit</a>(X,y)</tt>	Fit linear model with passive aggressive algorithm.
<tt style='background-color:#E8E8E8;'> linear_model.PassiveAggressiveRegressor <a href=' /linear_model/passive_aggressive.py#L301'>fit</a>(X,y,coef_init,intercept_init)</tt>	Fit linear model with passive aggressive algorithm.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/base.py#L23'>_average_binary_score</a>(binary_metric,y_true,y_score,average)</tt>	Average a binary metric for multilabel classification parameters.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L40'>auc</a>(x,y,reorder)</tt>	Compute area under the curve auc using the trapezoidal rule this is a general function given points on a curve.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L112'>average_precision_score</a>(y_true,y_score,average,sample_weight)</tt>	Compute average precision ap from prediction scores this score corresponds to the area under the precision-recall curve.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L187'>roc_auc_score</a>(y_true,y_score,average,sample_weight)</tt>	Compute area under the curve auc from prediction scores note this implementation is restricted to the binary classification task.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L263'>_binary_clf_curve</a>(y_true,y_score,pos_label,sample_weight)</tt>	Calculate true and false positives per binary classification threshold.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L345'>precision_recall_curve</a>(y_true,probas_pred,pos_label,sample_weight)</tt>	Compute precision-recall pairs for different probability thresholds note this implementation is restricted to the binary classification task.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L424'>roc_curve</a>(y_true,y_score,pos_label,sample_weight)</tt>	Compute receiver operating characteristic roc note this implementation is restricted to the binary classification task.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L550'>label_ranking_average_precision_score</a>(y_true,y_score)</tt>	Compute ranking-based average precision label ranking average precision lrap is the average over each ground.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L626'>coverage_error</a>(y_true,y_score,sample_weight)</tt>	Coverage error measure compute how far we need to go through the ranked scores to cover all.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/ranking.py#L685'>label_ranking_loss</a>(y_true,y_score,sample_weight)</tt>	Compute ranking loss measure compute the average number of label pairs that are incorrectly ordered.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L43'>_check_reg_targets</a>(y_true,y_pred,multioutput)</tt>	Check that y_true and y_pred belong to the same regression task parameters.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L112'>mean_absolute_error</a>(y_true,y_pred,sample_weight,multioutput)</tt>	Mean absolute error regression loss read more in the :ref user guide <mean_absolute_error>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L183'>mean_squared_error</a>(y_true,y_pred,sample_weight,multioutput)</tt>	Mean squared error regression loss read more in the :ref user guide <mean_squared_error>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L251'>mean_squared_log_error</a>(y_true,y_pred,sample_weight,multioutput)</tt>	Mean squared logarithmic error regression loss read more in the :ref user guide <mean_squared_log_error>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L318'>median_absolute_error</a>(y_true,y_pred)</tt>	Median absolute error regression loss read more in the :ref user guide <median_absolute_error>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L352'>explained_variance_score</a>(y_true,y_pred,sample_weight,multioutput)</tt>	Explained variance regression score function best possible score is 1.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/regression.py#L444'>r2_score</a>(y_true,y_pred,sample_weight,multioutput)</tt>	R^2 coefficient of determination regression score function.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L45'>_check_targets</a>(y_true,y_pred)</tt>	Check that y_true and y_pred belong to the same classification task this converts multiclass or binary types to a common shape and raises a.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L116'>accuracy_score</a>(y_true,y_pred,normalize,sample_weight)</tt>	Accuracy classification score.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L186'>confusion_matrix</a>(y_true,y_pred,labels,sample_weight)</tt>	Compute confusion matrix to evaluate the accuracy of a classification by definition a confusion matrix :math c is such that :math c_{i j}.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L288'>cohen_kappa_score</a>(y1,y2,labels,weights)</tt>	Cohen's kappa a statistic that measures inter-annotator agreement.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L368'>jaccard_similarity_score</a>(y_true,y_pred,normalize,sample_weight)</tt>	Jaccard similarity coefficient score the jaccard index [1], or jaccard similarity coefficient defined as.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L454'>matthews_corrcoef</a>(y_true,y_pred,sample_weight)</tt>	Compute the matthews correlation coefficient mcc for binary classes the matthews correlation coefficient is used in machine learning as a.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L534'>zero_one_loss</a>(y_true,y_pred,normalize,sample_weight)</tt>	Zero-one classification loss.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L603'>f1_score</a>(y_true,y_pred,labels,pos_label)</tt>	Compute the f1 score also known as balanced f-score or f-measure the f1 score can be interpreted as a weighted average of the precision and.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L705'>fbeta_score</a>(y_true,y_pred,beta,labels)</tt>	Compute the f-beta score the f-beta score is the weighted harmonic mean of precision and recall.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L820'>_prf_divide</a>(numerator,denominator,metric,modifier)</tt>	Performs division and handles divide-by-zero.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L864'>precision_recall_fscore_support</a>(y_true,y_pred,beta,labels)</tt>	Compute precision recall f-measure and support for each class the precision is the ratio tp / tp + fp where tp is the number of.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1153'>precision_score</a>(y_true,y_pred,labels,pos_label)</tt>	Compute the precision the precision is the ratio tp / tp + fp where tp is the number of.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1253'>recall_score</a>(y_true,y_pred,labels,pos_label)</tt>	Compute the recall the recall is the ratio tp / tp + fn where tp is the number of.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1351'>classification_report</a>(y_true,y_pred,labels,target_names)</tt>	Build a text report showing the main classification metrics read more in the :ref user guide <classification_report>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1454'>hamming_loss</a>(y_true,y_pred,labels,sample_weight)</tt>	Compute the average hamming loss.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1561'>log_loss</a>(y_true,y_pred,eps,normalize)</tt>	Log loss aka logistic loss or cross-entropy loss.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1684'>hinge_loss</a>(y_true,pred_decision,labels,sample_weight)</tt>	Average hinge loss non-regularized in binary class case assuming labels in y_true are encoded with +1 and -1.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1810'>_check_binary_probabilistic_predictions</a>(y_true,y_prob)</tt>	Check that y_true is binary and y_prob contains valid probabilities.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/classification.py#L1829'>brier_score_loss</a>(y_true,y_prob,sample_weight,pos_label)</tt>	Compute the brier score.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L33'>_return_float_dtype</a>(X,Y)</tt>	1 if dtype of x and y is float32 then dtype float32 is returned.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L57'>check_pairwise_arrays</a>(X,Y,precomputed,dtype)</tt>	Set x and y appropriately and checks inputs if y is none it is set as a pointer to x (i.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L127'>check_paired_arrays</a>(X,Y)</tt>	Set x and y appropriately and checks inputs for paired distances all paired distance metrics should use this function first to assert that.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L162'>euclidean_distances</a>(X,Y,Y_norm_squared,squared)</tt>	Considering the rows of x (and y=x) as vectors compute the distance matrix between each pair of vectors.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L259'>pairwise_distances_argmin_min</a>(X,Y,axis,metric)</tt>	Compute minimum distances between one point and a set of points.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L386'>pairwise_distances_argmin</a>(X,Y,axis,metric)</tt>	Compute minimum distances between one point and a set of points.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L467'>manhattan_distances</a>(X,Y,sum_over_features,size_threshold)</tt>	Compute the l1 distances between the vectors in x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L544'>cosine_distances</a>(X,Y)</tt>	Compute cosine distance between samples in x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L582'>paired_euclidean_distances</a>(X,Y)</tt>	Computes the paired euclidean distances between x and y read more in the :ref user guide <metrics>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L602'>paired_manhattan_distances</a>(X,Y)</tt>	Compute the l1 distances between the vectors in x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L626'>paired_cosine_distances</a>(X,Y)</tt>	Computes the paired cosine distances between x and y read more in the :ref user guide <metrics>.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L660'>paired_distances</a>(X,Y,metric)</tt>	Computes the paired distances between x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L718'>linear_kernel</a>(X,Y)</tt>	Compute the linear kernel between x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L738'>polynomial_kernel</a>(X,Y,degree,gamma)</tt>	Compute the polynomial kernel between x and y : k x y = (gamma <x y> + coef0)^degree.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L774'>sigmoid_kernel</a>(X,Y,gamma,coef0)</tt>	Compute the sigmoid kernel between x and y : k x y = tanh(gamma <x y> + coef0).
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L808'>rbf_kernel</a>(X,Y,gamma)</tt>	Compute the rbf gaussian kernel between x and y : k x y = exp(-gamma ||x-y||^2).
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L841'>laplacian_kernel</a>(X,Y,gamma)</tt>	Compute the laplacian kernel between x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L875'>cosine_similarity</a>(X,Y,dense_output)</tt>	Compute cosine similarity between samples in x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L923'>additive_chi2_kernel</a>(X,Y)</tt>	Computes the additive chi-squared kernel between observations in x and y the chi-squared kernel is computed between each pair of rows in x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L984'>chi2_kernel</a>(X,Y,gamma)</tt>	Computes the exponential chi-squared kernel x and y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L1046'>distance_metrics</a>()</tt>	Valid metrics for pairwise_distances.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L1072'>_parallel_pairwise</a>(X,Y,func,n_jobs)</tt>	Break the pairwise matrix in n_jobs even slices.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L1094'>_pairwise_callable</a>(X,Y,metric)</tt>	Handle the callable case for pairwise_{distances kernels}.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L1134'>pairwise_distances</a>(X,Y,metric,n_jobs)</tt>	Compute the distance matrix from a vector array x and optional y.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L1272'>kernel_metrics</a>()</tt>	Valid metrics for pairwise_kernels this function simply returns the valid pairwise distance metrics.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/pairwise.py#L1313'>pairwise_kernels</a>(X,Y,metric,filter_params)</tt>	Compute the kernel between arrays x and optional array y.
<tt style='background-color:#E8E8E8;'> metrics._BaseScorer <a href=' /metrics/scorer.py#L69'>_factory_args</a>()</tt>	Return non-default make_scorer arguments for repr.
<tt style='background-color:#E8E8E8;'> metrics._PredictScorer <a href=' /metrics/scorer.py#L75'>__call__</a>(estimator,X,y_true,sample_weight)</tt>	Evaluate predicted target values for x relative to y_true.
<tt style='background-color:#E8E8E8;'> metrics._ProbaScorer <a href=' /metrics/scorer.py#L111'>__call__</a>(clf,X,y,sample_weight)</tt>	Evaluate predicted probabilities for x relative to y_true.
<tt style='background-color:#E8E8E8;'> metrics._ThresholdScorer <a href=' /metrics/scorer.py#L150'>__call__</a>(clf,X,y,sample_weight)</tt>	Evaluate decision function output for x relative to y_true.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/scorer.py#L226'>_passthrough_scorer</a>(estimator)</tt>	Function that wraps estimator score.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/scorer.py#L231'>check_scoring</a>(estimator,scoring,allow_none)</tt>	Determine scorer from user options.
<tt style='background-color:#E8E8E8;'> metrics. <a href=' /metrics/scorer.py#L285'>make_scorer</a>(score_func,greater_is_better,needs_proba,needs_threshold)</tt>	Make a scorer from a performance metric or loss function.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L35'>check_clusterings</a>(labels_true,labels_pred)</tt>	Check that the two clusterings matching 1d integer arrays.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L54'>contingency_matrix</a>(labels_true,labels_pred,eps,sparse)</tt>	Build a contingency matrix describing the relationship between labels.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L113'>adjusted_rand_score</a>(labels_true,labels_pred)</tt>	Rand index adjusted for chance.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L218'>homogeneity_completeness_v_measure</a>(labels_true,labels_pred)</tt>	Compute the homogeneity and completeness and v-measure scores at once.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L292'>homogeneity_score</a>(labels_true,labels_pred)</tt>	Homogeneity metric of a cluster labeling given a ground truth.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L366'>completeness_score</a>(labels_true,labels_pred)</tt>	Completeness metric of a cluster labeling given a ground truth.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L436'>v_measure_score</a>(labels_true,labels_pred)</tt>	V-measure cluster labeling given a ground truth.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L531'>mutual_info_score</a>(labels_true,labels_pred,contingency)</tt>	Mutual information between two clusterings.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L614'>adjusted_mutual_info_score</a>(labels_true,labels_pred)</tt>	Adjusted mutual information between two clusterings.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L710'>normalized_mutual_info_score</a>(labels_true,labels_pred)</tt>	Normalized mutual information between two clusterings.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L790'>fowlkes_mallows_score</a>(labels_true,labels_pred,sparse)</tt>	Measure the similarity of two clusterings of a set of points.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/supervised.py#L862'>entropy</a>(labels)</tt>	Calculates the entropy for a labeling.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/bicluster.py#L11'>_check_rows_and_columns</a>(a,b)</tt>	Unpacks the row and column arrays and checks their shape.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/bicluster.py#L21'>_jaccard</a>(a_rows,a_cols,b_rows,b_cols)</tt>	Jaccard coefficient on the elements of the two biclusters.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/bicluster.py#L32'>_pairwise_similarity</a>(a,b,similarity)</tt>	Computes pairwise similarity matrix.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/bicluster.py#L49'>consensus_score</a>(a,b,similarity)</tt>	The similarity of two sets of biclusters.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/unsupervised.py#L23'>silhouette_score</a>(X,labels,metric,sample_size)</tt>	Compute the mean silhouette coefficient of all samples.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/unsupervised.py#L105'>silhouette_samples</a>(X,labels,metric)</tt>	Compute the silhouette coefficient for each sample.
<tt style='background-color:#E8E8E8;'> metrics.cluster. <a href=' /metrics/cluster/unsupervised.py#L212'>calinski_harabaz_score</a>(X,labels)</tt>	Compute the calinski and harabaz score.
<tt style='background-color:#E8E8E8;'> cross_decomposition. <a href=' /cross_decomposition/pls_.py#L30'>_nipals_twoblocks_inner_loop</a>(X,Y,mode,max_iter)</tt>	Inner loop of the iterative nipals algorithm.
<tt style='background-color:#E8E8E8;'> cross_decomposition. <a href=' /cross_decomposition/pls_.py#L98'>_center_scale_xy</a>(X,Y,scale)</tt>	Center x y and scale if the scale parameter==true.
<tt style='background-color:#E8E8E8;'> cross_decomposition._PLS <a href=' /cross_decomposition/pls_.py#L238'>fit</a>(X,Y)</tt>	Fit model to data.
<tt style='background-color:#E8E8E8;'> cross_decomposition._PLS <a href=' /cross_decomposition/pls_.py#L379'>transform</a>(X,Y,copy)</tt>	Apply the dimension reduction learned on the train data.
<tt style='background-color:#E8E8E8;'> cross_decomposition._PLS <a href=' /cross_decomposition/pls_.py#L417'>predict</a>(X,copy)</tt>	Apply the dimension reduction learned on the train data.
<tt style='background-color:#E8E8E8;'> cross_decomposition._PLS <a href=' /cross_decomposition/pls_.py#L442'>fit_transform</a>(X,y)</tt>	Learn and apply the dimension reduction on the train data.
<tt style='background-color:#E8E8E8;'> cross_decomposition.PLSSVD <a href=' /cross_decomposition/pls_.py#L826'>transform</a>(X,Y)</tt>	Apply the dimension reduction learned on the train data.
<tt style='background-color:#E8E8E8;'> cross_decomposition.PLSSVD <a href=' /cross_decomposition/pls_.py#L840'>fit_transform</a>(X,y)</tt>	Learn and apply the dimension reduction on the train data.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L54'>_handle_zeros_in_scale</a>(scale,copy)</tt>	Makes sure that whenever scale is zero we handle it correctly.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L72'>scale</a>(X,axis,with_mean,with_std)</tt>	Standardize a dataset along any axis center to the mean and component wise scale to unit variance.
<tt style='background-color:#E8E8E8;'> preprocessing.MinMaxScaler <a href=' /preprocessing/data.py#L244'>_reset</a>()</tt>	Reset internal data-dependent state of the scaler if necessary.
<tt style='background-color:#E8E8E8;'> preprocessing.MinMaxScaler <a href=' /preprocessing/data.py#L260'>fit</a>(X,y)</tt>	Compute the minimum and maximum to be used for later scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.MinMaxScaler <a href=' /preprocessing/data.py#L274'>partial_fit</a>(X,y)</tt>	Online computation of min and max on x for later scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.MinMaxScaler <a href=' /preprocessing/data.py#L321'>transform</a>(X)</tt>	Scaling features of x according to feature_range.
<tt style='background-color:#E8E8E8;'> preprocessing.MinMaxScaler <a href=' /preprocessing/data.py#L337'>inverse_transform</a>(X)</tt>	Undo the scaling of x according to feature_range.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L354'>minmax_scale</a>(X,feature_range,axis,copy)</tt>	Transforms features by scaling each feature to a given range.
<tt style='background-color:#E8E8E8;'> preprocessing.StandardScaler <a href=' /preprocessing/data.py#L493'>_reset</a>()</tt>	Reset internal data-dependent state of the scaler if necessary.
<tt style='background-color:#E8E8E8;'> preprocessing.StandardScaler <a href=' /preprocessing/data.py#L507'>fit</a>(X,y)</tt>	Compute the mean and std to be used for later scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.StandardScaler <a href=' /preprocessing/data.py#L523'>partial_fit</a>(X,y)</tt>	Online computation of mean and std on x for later scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.StandardScaler <a href=' /preprocessing/data.py#L590'>transform</a>(X,y,copy)</tt>	Perform standardization by centering and scaling parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.StandardScaler <a href=' /preprocessing/data.py#L618'>inverse_transform</a>(X,copy)</tt>	Scale back the data to the original representation parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.MaxAbsScaler <a href=' /preprocessing/data.py#L693'>_reset</a>()</tt>	Reset internal data-dependent state of the scaler if necessary.
<tt style='background-color:#E8E8E8;'> preprocessing.MaxAbsScaler <a href=' /preprocessing/data.py#L706'>fit</a>(X,y)</tt>	Compute the maximum absolute value to be used for later scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.MaxAbsScaler <a href=' /preprocessing/data.py#L720'>partial_fit</a>(X,y)</tt>	Online computation of max absolute value of x for later scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.MaxAbsScaler <a href=' /preprocessing/data.py#L755'>transform</a>(X,y)</tt>	Scale the data parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.MaxAbsScaler <a href=' /preprocessing/data.py#L773'>inverse_transform</a>(X)</tt>	Scale back the data to the original representation parameters.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L792'>maxabs_scale</a>(X,axis,copy)</tt>	Scale each feature to the [-1 1] range without breaking the sparsity.
<tt style='background-color:#E8E8E8;'> preprocessing.RobustScaler <a href=' /preprocessing/data.py#L920'>_check_array</a>(X,copy)</tt>	Makes sure centering is not enabled for sparse matrices.
<tt style='background-color:#E8E8E8;'> preprocessing.RobustScaler <a href=' /preprocessing/data.py#L932'>fit</a>(X,y)</tt>	Compute the median and quantiles to be used for scaling.
<tt style='background-color:#E8E8E8;'> preprocessing.RobustScaler <a href=' /preprocessing/data.py#L958'>transform</a>(X,y)</tt>	Center and scale the data parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.RobustScaler <a href=' /preprocessing/data.py#L982'>inverse_transform</a>(X)</tt>	Scale back the data to the original representation parameters.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L1007'>robust_scale</a>(X,axis,with_centering,with_scaling)</tt>	Standardize a dataset along any axis center to the median and component wise scale.
<tt style='background-color:#E8E8E8;'> preprocessing.PolynomialFeatures <a href=' /preprocessing/data.py#L1155'>get_feature_names</a>(input_features)</tt>	Return feature names for output features parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.PolynomialFeatures <a href=' /preprocessing/data.py#L1185'>fit</a>(X,y)</tt>	Compute number of output features.
<tt style='background-color:#E8E8E8;'> preprocessing.PolynomialFeatures <a href=' /preprocessing/data.py#L1197'>transform</a>(X,y)</tt>	Transform data to polynomial features parameters.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L1231'>normalize</a>(X,norm,axis,copy)</tt>	Scale input vectors individually to unit norm vector length.
<tt style='background-color:#E8E8E8;'> preprocessing.Normalizer <a href=' /preprocessing/data.py#L1365'>fit</a>(X,y)</tt>	Do nothing and return the estimator unchanged this method is just there to implement the usual api and hence.
<tt style='background-color:#E8E8E8;'> preprocessing.Normalizer <a href=' /preprocessing/data.py#L1374'>transform</a>(X,y,copy)</tt>	Scale each non zero row of x to unit norm parameters.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L1388'>binarize</a>(X,threshold,copy)</tt>	Boolean thresholding of array-like or scipy sparse matrix.
<tt style='background-color:#E8E8E8;'> preprocessing.Binarizer <a href=' /preprocessing/data.py#L1476'>fit</a>(X,y)</tt>	Do nothing and return the estimator unchanged this method is just there to implement the usual api and hence.
<tt style='background-color:#E8E8E8;'> preprocessing.Binarizer <a href=' /preprocessing/data.py#L1485'>transform</a>(X,y,copy)</tt>	Binarize each element of x parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.KernelCenterer <a href=' /preprocessing/data.py#L1511'>fit</a>(K,y)</tt>	Fit kernelcenterer parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.KernelCenterer <a href=' /preprocessing/data.py#L1529'>transform</a>(K,y,copy)</tt>	Center kernel matrix.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L1562'>add_dummy_feature</a>(X,value)</tt>	Augment dataset with an additional dummy feature.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/data.py#L1621'>_transform_selected</a>(X,transform,selected,copy)</tt>	Apply a transform function to portion of selected features parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.OneHotEncoder <a href=' /preprocessing/data.py#L1777'>fit</a>(X,y)</tt>	Fit onehotencoder to x.
<tt style='background-color:#E8E8E8;'> preprocessing.OneHotEncoder <a href=' /preprocessing/data.py#L1792'>_fit_transform</a>(X)</tt>	Assumes x contains only categorical features.
<tt style='background-color:#E8E8E8;'> preprocessing.OneHotEncoder <a href=' /preprocessing/data.py#L1840'>fit_transform</a>(X,y)</tt>	Fit onehotencoder to x then transform x.
<tt style='background-color:#E8E8E8;'> preprocessing.OneHotEncoder <a href=' /preprocessing/data.py#L1889'>transform</a>(X)</tt>	Transform x using one-hot encoding.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/imputation.py#L28'>_get_mask</a>(X,value_to_mask)</tt>	Compute the boolean mask x == missing_values.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/imputation.py#L36'>_most_frequent</a>(array,extra_value,n_repeat)</tt>	Compute the most frequent value in a 1d array extended with [extra_value] * n_repeat where extra_value is assumed to be not part.
<tt style='background-color:#E8E8E8;'> preprocessing.Imputer <a href=' /preprocessing/imputation.py#L126'>fit</a>(X,y)</tt>	Fit the imputer on x.
<tt style='background-color:#E8E8E8;'> preprocessing.Imputer <a href=' /preprocessing/imputation.py#L171'>_sparse_fit</a>(X,strategy,missing_values,axis)</tt>	Fit the transformer on sparse data.
<tt style='background-color:#E8E8E8;'> preprocessing.Imputer <a href=' /preprocessing/imputation.py#L251'>_dense_fit</a>(X,strategy,missing_values,axis)</tt>	Fit the transformer on dense data.
<tt style='background-color:#E8E8E8;'> preprocessing.Imputer <a href=' /preprocessing/imputation.py#L302'>transform</a>(X)</tt>	Impute all missing values in x.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/label.py#L42'>_check_numpy_unicode_bug</a>(labels)</tt>	Check that user is not subject to an old numpy bug fixed in master before 1.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelEncoder <a href=' /preprocessing/label.py#L100'>fit</a>(y)</tt>	Fit label encoder parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelEncoder <a href=' /preprocessing/label.py#L117'>fit_transform</a>(y)</tt>	Fit label encoder and return encoded labels parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelEncoder <a href=' /preprocessing/label.py#L134'>transform</a>(y)</tt>	Transform labels to normalized encoding.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelEncoder <a href=' /preprocessing/label.py#L156'>inverse_transform</a>(y)</tt>	Transform labels back to original encoding.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelBinarizer <a href=' /preprocessing/label.py#L283'>fit</a>(y)</tt>	Fit label binarizer parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelBinarizer <a href=' /preprocessing/label.py#L307'>fit_transform</a>(y)</tt>	Fit label binarizer and transform multi-class labels to binary labels.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelBinarizer <a href=' /preprocessing/label.py#L329'>transform</a>(y)</tt>	Transform multi-class labels to binary labels the output of transform is sometimes referred to by some authors as.
<tt style='background-color:#E8E8E8;'> preprocessing.LabelBinarizer <a href=' /preprocessing/label.py#L360'>inverse_transform</a>(Y,threshold)</tt>	Transform binary labels back to multi-class labels parameters.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/label.py#L411'>label_binarize</a>(y,classes,neg_label,pos_label)</tt>	Binarize labels in a one-vs-all fashion several regression and binary classification algorithms are.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/label.py#L568'>_inverse_binarize_multiclass</a>(y,classes)</tt>	Inverse label binarization transformation for multiclass.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/label.py#L612'>_inverse_binarize_thresholding</a>(y,output_type,classes,threshold)</tt>	Inverse label binarization transformation using thresholding.
<tt style='background-color:#E8E8E8;'> preprocessing.MultiLabelBinarizer <a href=' /preprocessing/label.py#L703'>fit</a>(y)</tt>	Fit the label sets binarizer storing classes_ parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.MultiLabelBinarizer <a href=' /preprocessing/label.py#L726'>fit_transform</a>(y)</tt>	Fit the label sets binarizer and transform the given label sets parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.MultiLabelBinarizer <a href=' /preprocessing/label.py#L767'>transform</a>(y)</tt>	Transform the given label sets parameters.
<tt style='background-color:#E8E8E8;'> preprocessing.MultiLabelBinarizer <a href=' /preprocessing/label.py#L793'>_transform</a>(y,class_mapping)</tt>	Transforms the label sets with a given mapping.
<tt style='background-color:#E8E8E8;'> preprocessing.MultiLabelBinarizer <a href=' /preprocessing/label.py#L817'>inverse_transform</a>(yt)</tt>	Transform the given indicator matrix into label sets parameters.
<tt style='background-color:#E8E8E8;'> preprocessing. <a href=' /preprocessing/_function_transformer.py#L5'>_identity</a>(X)</tt>	The identity function.
<tt style='background-color:#E8E8E8;'> _build_utils. <a href=' /_build_utils/__init__.py#L43'>build_from_c_and_cpp_files</a>(extensions)</tt>	Modify the extensions to build from the c and cpp files.
<tt style='background-color:#E8E8E8;'> _build_utils. <a href=' /_build_utils/__init__.py#L63'>maybe_cythonize_extensions</a>(top_path,config)</tt>	Tweaks for building extensions between release and development mode.
