function	[function_1] estimators within ||| [function_1] [function_2]	count=1
function	build a batch ||| parallel build	count=1
class	list of exception ||| parallel backend	count=1
function	[function_1] binary classifier ||| [function_1] [function_2]	count=1
arg	[arg_1] x y ||| [arg_2] [arg_1]	count=4
function	initialization of ||| initialize	count=2
arg	data ||| data	count=3
function	sample weights by class ||| compute sample	count=1
arg	generate cross-validated ||| cv	count=1
arg	factor in place ||| y code verbose	count=1
function	log probability ||| log multivariate normal	count=1
module	estimator is using ||| core	count=1
arg	[arg_1] <mean_squared_log_error> ||| [arg_2] [arg_1]	count=2
function	compute average [function_1] [function_2] ||| metrics average [function_1] [function_2]	count=2
arg	based on a feature ||| connectivity n_clusters	count=1
module	parameters with the ||| mixture	count=1
class	or ||| multiprocessing backend	count=1
arg	of x ||| x y	count=2
function	the c and ||| c and	count=2
class	data [class] ||| [class]	count=3
function	cosine ||| cosine	count=2
module	a youngs ||| utils	count=1
function	terminal ||| terminal	count=3
arg	estimator and ||| y sample_weight	count=1
module_class	the [class_2] ||| [module_1] [class_2]	count=10
class	density model on the ||| density	count=1
arg	an [arg] into ||| [arg]	count=1
function	to update terminal ||| update terminal	count=2
function	report showing the ||| report	count=1
function	path with coordinate descent ||| path	count=1
function_arg	_fit_coordinate_descent update [arg_2] ||| [function_1] coordinate descent [arg_2]	count=4
arg	and ||| x y classes	count=2
function	[function_1] neighbors for ||| [function_2] [function_1]	count=12
function	return a buffered ||| buffered	count=1
class	for the ||| covariance	count=1
function	[function_1] posterior probability ||| [function_2] [function_1]	count=1
arg	according to [arg_2] ||| [arg_2] [arg_1]	count=6
class	outcomes ||| voting	count=1
arg	the similarity of two ||| a b similarity	count=1
class	sparse format ||| sparse coef	count=2
function	probabilities of possible ||| proba	count=1
function_arg	data [arg_2] ||| [function_1] [arg_2]	count=1
class	the hash depending ||| memorized func	count=1
function	the median ||| median	count=2
function_arg	[function_1] data and ||| [function_1] [arg_2]	count=1
function	inplace row ||| inplace row scale	count=1
function	pairs dataset ||| pairs	count=2
arg	x return leaf indices ||| x	count=1
function	and component wise scale ||| scale	count=2
arg	standardize ||| with_mean with_std	count=1
function	reduced [function_2] ||| [function_2] [function_1]	count=2
function_arg	[function_1] batch_size ||| [arg_2] [function_1]	count=2
function	block checkerboard ||| checkerboard	count=1
arg	to multi-class labels parameters ||| threshold	count=1
function	compute [function_2] ||| [function_1] [function_2]	count=2
arg	threshold ||| estimator importances threshold	count=1
module	folders ||| externals joblib	count=2
arg	svd [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	[function_1] lrd ||| [function_1] [arg_2]	count=2
module	pool ||| externals	count=1
arg	set of samples x ||| x	count=1
arg	routine for validation ||| dtype	count=1
function_arg	fit [arg_2] ||| [arg_2] [function_1]	count=11
function	linkage agglomerative ||| linkage	count=1
arg	inefficient to train all ||| x y classes	count=1
arg	introduced by a random ||| n_samples	count=1
arg	sparse and ||| y	count=1
function	return the query ||| query	count=1
class	gaussian distribution ||| bayesian gaussian	count=2
class	[class_1] gradient ||| [class_2] [class_1]	count=3
function	boolean mask ||| mask	count=2
function	em ||| em	count=1
arg	x and membership ||| x z	count=2
function	elastic net path with ||| path	count=1
arg	w h whose ||| x w h n_components	count=1
function	a name ||| func name	count=1
arg	sorted array of integers ||| tree bin_x left_mask right_mask	count=1
function	[function_1] going up ||| [function_2] [function_1]	count=1
function	binary classifier on ||| binary	count=1
class	uncompressed bytes from the ||| binary zlib	count=1
function_arg	files [arg_2] ||| [function_1] container_path description [arg_2]	count=1
function	[function_1] weiszfeld step ||| [function_1] [function_2]	count=1
function_arg	reachability [function_1] [arg_2] ||| [function_1] [arg_2]	count=9
function	logistic loss and gradient ||| logistic loss and grad	count=1
module	to ||| linear_model	count=1
arg	kernel is computed between [arg_1] [arg_2] ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=1
class	to avoid the ||| memorized func	count=1
function	input ||| val	count=1
arg	x and y ||| x y alpha c	count=1
function	matrix shrunk ||| shrunk	count=1
module_class	[module_1] whether the ||| [module_1] [class_2]	count=4
module	modify ||| _build_utils	count=1
function	people dataset ||| people	count=1
function	return the ||| get	count=1
arg	[arg_1] dense ||| [arg_1] [arg_2]	count=1
module	between ||| metrics	count=3
function	graph of the ||| to graph	count=2
module	run a ||| externals	count=2
function_arg	[function_1] [arg_2] ||| [function_1] container_path description [arg_2]	count=4
class	sparse random projection matrix ||| random projection	count=1
function	the kl [function_2] ||| [function_2] [function_1]	count=4
function	image from all ||| from	count=1
class	for ||| classifier	count=5
function_arg	the neighbors [arg_2] ||| [arg_2] [function_1]	count=1
arg	from ||| size	count=1
arg	target_variables ||| target_variables grid	count=1
arg	given data ||| y	count=1
function_arg	[function_1] multi-class ||| [arg_2] [function_1]	count=4
arg	dataset downloading it if ||| subset data_home download_if_missing random_state	count=1
class	predict ||| decision tree	count=1
arg	the derived class ||| resp	count=1
arg	k x y and ||| x y	count=4
module	list of exception ||| externals joblib	count=1
arg	the derived class ||| x resp	count=1
function	[function_1] embedding ||| [function_1] [function_2]	count=4
arg	estimates for ||| estimator	count=1
class	points in the ||| parameter	count=1
class	oracle approximating shrinkage ||| oas	count=1
function	equal to the average ||| average	count=1
function	wild lfw ||| lfw	count=1
function_arg	seeds [arg_2] ||| [arg_2] [function_1]	count=1
function	directory ||| dir	count=1
arg	[arg_1] vectors ||| [arg_1] [arg_2]	count=1
class	to raw minimum ||| min	count=1
module	to ||| externals joblib	count=11
module	don't store ||| joblib	count=2
class	requested by the ||| backend base	count=1
function	[function_1] from the ||| [function_2] [function_1]	count=2
arg	checking for random ||| n_features	count=1
function	patches of any ||| extract patches	count=1
function	fit the model ||| fit	count=22
class	store the ||| memorized	count=1
class	cache ||| memorized func	count=1
function	[function_1] files ||| [function_1] [function_2]	count=7
function	independent ||| repr	count=1
arg	x return ||| x	count=1
class	format ||| coef mixin	count=1
function	the data home ||| clear data home	count=2
function	the median [function_2] ||| [function_1] [function_2]	count=1
function	[function_1] going up ||| utils gen [function_2] [function_1]	count=1
function	factorization nmf find ||| factorization	count=1
function	train test ||| iter	count=1
function	the directory ||| output dir	count=1
arg	generate a ||| n_samples n_features n_classes n_labels	count=1
module	folders to ||| joblib	count=1
arg	and return encoded labels ||| y	count=1
module	from ||| externals	count=2
module	numpy ||| externals joblib	count=1
arg	in place ||| y code verbose	count=1
function	time controlled by self ||| progress	count=1
class	grid ||| grid	count=4
arg	estimator and ||| y	count=1
function	a binary ||| binary score	count=1
function	error regression loss read ||| error	count=3
module	remove ||| joblib	count=1
arg	for a sparse ||| a	count=1
function_arg	run score function [function_1] [arg_2] features ||| feature_selection base filter [function_1] [arg_2]	count=1
function	classification ||| make classification	count=1
arg	computes the ||| x y alpha	count=2
function	directory in ||| get output dir	count=1
function	used to partition ||| partition	count=1
function	[function_1] gaussian ||| [function_1] [function_2]	count=1
class	classification on ||| base svc	count=2
function	active default [function_2] ||| [function_1] [function_2]	count=1
arg	random sample from a ||| a size	count=1
function_arg	single binary [arg_2] ||| [arg_2] [function_1]	count=4
function	check ||| check params	count=2
function	an ||| shape	count=1
class	the local ||| local	count=1
arg	func ||| func	count=3
function	median of ||| get median	count=1
class	least [class_2] ||| [class_2] [class_1]	count=1
class	compute ||| base multilayer perceptron	count=1
function_arg	[function_1] multi-class labels ||| [arg_2] [function_1]	count=4
function	full covariance ||| full	count=1
function	a covariance ||| covariance	count=1
function_arg	predict class [arg_2] ||| [arg_2] [function_1]	count=3
module	hash depending from ||| externals joblib	count=2
module	dataset is constructed ||| datasets	count=1
function	of this estimator ||| params	count=1
arg	of parameters ||| y estimator parameters	count=2
arg	set of points ||| metric	count=1
function	predict_log_proba of the ||| predict log proba	count=1
function	spherical wishart distribution ||| wishart spherical	count=2
arg	from ||| size replace p	count=1
arg	estimates for ||| x	count=1
function	residues ||| residues	count=1
function_arg	em update [arg_2] ||| [arg_2] [function_1]	count=1
arg	computation ||| output_dir func_name timestamp metadata	count=1
class	count ||| bernoulli nb	count=1
function	creating a class with ||| add	count=1
function	cv ||| check cv	count=1
arg	and dense ||| y sample_weight random_state	count=1
arg	n ||| n	count=4
function	points on the ||| len	count=1
function_arg	[function_1] for mean_shift ||| [function_1] [arg_2]	count=2
class	generative ||| base pca	count=2
function_arg	[function_1] with x ||| [function_1] [arg_2]	count=2
arg	w to ||| w	count=1
module	we don't store ||| externals	count=2
class	k ||| compound	count=1
class	kernel k ||| constant kernel	count=2
function	locally linear embedding ||| locally linear embedding	count=3
function	covariance m ||| covar	count=2
function_arg	a gaussian [arg_2] ||| [function_1] [arg_2]	count=1
arg	cast iterable [arg] to ||| [arg]	count=1
function	get [function_2] ||| [function_2] [function_1]	count=15
function	from the ||| from	count=1
class	matrix ||| sparse	count=1
function	compute decision function ||| decision function	count=4
arg	varies for mono and ||| y	count=1
function	binarization transformation [function_2] ||| [function_2] [function_1]	count=2
function_arg	[function_1] tree ||| [arg_2] [function_1]	count=4
function	sparse random matrix ||| random choice	count=1
function_arg	[function_1] to ||| [arg_2] [function_1]	count=1
function_arg	[function_1] batch_size ||| [function_1] n [arg_2]	count=2
class	the search over parameters ||| base search	count=1
function	partially fit [function_2] ||| [function_1] ovo [function_2]	count=1
arg	computes the ||| metric	count=1
function	read file object ||| read file	count=2
function	[function_1] housing dataset ||| [function_2] [function_1]	count=3
function	linear embedding ||| linear embedding	count=2
arg	given ||| scorer	count=3
function	cluster the result ||| cluster	count=1
function	return a platform ||| shape repr	count=1
arg	from ||| size replace	count=1
arg	each parameter weights and ||| y	count=1
class	best ||| cv	count=5
class	maximum absolute value to ||| max abs	count=1
class	stochastic gradient descent ||| base sgdregressor	count=1
function	precision matrix ||| get precision	count=2
function_arg	[function_1] [arg_2] ||| [function_1] n_samples [arg_2]	count=6
function	active default ||| active	count=1
function	batch and ||| one batch	count=1
class	[class_1] ridge model ||| [class_2] [class_1]	count=2
arg	any axis ||| axis	count=2
module	a platform independent representation ||| utils	count=1
function	random ||| random	count=2
function	for each input data ||| predict	count=1
arg	from sklearn ||| include_meta_estimators include_other type_filter include_dont_test	count=1
function	compute scores ||| score	count=1
arg	of x from ||| x z	count=1
module_class	[module_1] embedding ||| [module_1] [class_2]	count=1
arg	arbitrary python object ||| filename	count=1
arg	the rfe model and ||| x y	count=1
function	print ||| print	count=2
arg	[arg_1] a function ||| [arg_2] [arg_1]	count=2
arg	for a given dataset ||| x y scorer	count=1
arg	x into a ||| x	count=1
function	ovr decision ||| ovr decision	count=2
arg	w h ||| x w h	count=1
function	function of the given ||| function	count=1
module_class	in [class_2] ||| [module_1] [class_2]	count=4
function	for ||| cross val	count=1
function	verbose [function_2] ||| [function_2] [function_1]	count=3
class	an array ||| array wrapper	count=1
function	mask ||| edges weights	count=1
arg	and binary ||| y	count=1
function	the submatrix corresponding ||| get submatrix	count=1
function_arg	[function_1] nmf ||| [function_1] x w [arg_2]	count=2
class	matrix ||| coef mixin	count=1
arg	func to ||| func	count=3
arg	w to minimize ||| x w ht	count=1
class	the ||| memorized	count=2
arg	x for ||| x y	count=1
class	data ||| pca	count=1
arg	estimates for ||| x y	count=1
module	remove too rare or ||| feature_extraction	count=1
function	regression problem with sparse ||| make sparse	count=1
class	hence ||| patch extractor	count=2
function_arg	[function_1] percentiles ||| [arg_2] [function_1]	count=5
function	minimum and [function_2] ||| [function_2] [function_1]	count=1
arg	for a ||| a	count=1
module	test vector ||| core	count=2
class	this wrapper ||| wrapper	count=1
function	transform [function_2] ||| [function_2] [function_1]	count=4
arg	using x y ||| x y	count=1
function	[function_1] divergence ||| [function_2] [function_1]	count=3
module	depending from it ||| externals joblib	count=2
function	for a calibration curve ||| calibration curve	count=1
arg	[arg_1] transformed ||| [arg_2] [arg_1]	count=6
module	this dataset is ||| datasets	count=2
module	hash depending from it ||| externals joblib	count=2
module	folders to ||| externals joblib	count=1
arg	and cv and ||| y	count=1
function	and ||| and	count=9
function	the l1 [function_2] ||| [function_2] [function_1]	count=6
arg	matching pursuit problems ||| x y n_nonzero_coefs	count=1
class	search over ||| search	count=1
arg	data and labels ||| y	count=1
function	smacof algorithm parameters ||| smacof	count=1
class	boost ||| base weight boosting	count=1
function_arg	the covariance [arg_2] ||| [arg_2] [function_1]	count=3
function	lower bound for ||| bound means	count=1
function	return ||| repr	count=1
function	the shortest path ||| shortest path	count=1
function	reconstruct the [function_2] ||| [function_2] [function_1]	count=3
arg	given radius of a ||| radius	count=1
arg	sample_weight ||| y sample_weight	count=1
function	in multiplicative [function_2] ||| [function_1] [function_2]	count=3
arg	n-class ||| n_informative n_redundant	count=1
function	the lfw ||| lfw	count=2
arg	a random ||| n_samples	count=1
function_arg	[function_1] with respect ||| [arg_2] [function_1]	count=5
class	on the grid ||| parameter grid	count=1
class	uncompressed bytes [class_2] ||| [class_2] [class_1]	count=1
class	[class_1] kernel ||| [class_1] [class_2]	count=1
function	similarity ||| similarity	count=2
class	for the ||| empirical	count=1
function	the number of ||| len	count=1
function	the means ||| means	count=1
function_arg	[function_1] a ||| [function_1] [arg_2] b detb n_features	count=3
arg	[arg_1] to ||| [arg_2] [arg_1]	count=2
class	[class_1] regression model ||| [class_1] [class_2]	count=5
function_arg	[function_1] doc_topic_distr ||| [arg_2] [function_1]	count=3
function	the huber loss and ||| huber loss and	count=1
function	maximizer of the reduced ||| arg max reduced	count=1
module	[module] batch ||| [module]	count=3
function	log probabilities within ||| predict log proba	count=1
function	and make sure no ||| non neg array	count=1
class	ridge model ||| ridge	count=1
function	a list of feature ||| feature	count=1
class	signature ||| signature	count=2
function_arg	[function_1] q_ijs ||| [function_1] error [arg_2]	count=4
function	class ||| compute class	count=1
arg	[arg_1] any axis ||| [arg_2] [arg_1]	count=4
function	biclusters ||| consensus score	count=1
function	[function_1] cpp ||| [function_1] [function_2]	count=6
arg	from features or distance ||| y sample_weight	count=1
function	for the given param_grid ||| param iterator	count=1
module	cache folders ||| externals	count=1
function	in multiplicative update ||| multiplicative update w	count=2
arg	accuracy of a classification ||| y_true y_pred	count=1
function	neighbors for points ||| radius neighbors	count=2
arg	the validity of ||| metric p metric_params	count=1
function	shrunk ledoit-wolf ||| ledoit wolf	count=1
class	format ||| sparse	count=1
class	an array using numpy ||| numpy array wrapper	count=1
function	mean [function_2] ||| [function_1] [function_2]	count=11
function	svmlight format this ||| svmlight	count=1
function_arg	[function_1] y and ||| [arg_2] [function_1]	count=2
arg	from module_path/data/data_file_name ||| module_path data_file_name	count=1
arg	different probability thresholds ||| probas_pred pos_label	count=1
function	model fitting method ||| fit	count=1
module	of ||| externals joblib	count=2
function	finds indices in ||| indices	count=1
arg	with x ||| x	count=2
function	absolute error of ||| error	count=1
function_arg	the covariance [arg_2] ||| [function_1] type tied_cv [arg_2]	count=3
class	cf ||| birch	count=1
arg	is inefficient to ||| x y classes	count=1
function	the lfw people ||| lfw people	count=1
arg	generate a ||| n_samples	count=1
class	of the kernel k ||| constant kernel	count=1
arg	build a ||| sample_weight check_input	count=1
function	found ||| line search	count=1
class	boost ||| weight boosting	count=1
arg	function output for x ||| x y sample_weight	count=1
class	calculate approximate ||| latent dirichlet allocation	count=1
class	an array [class_2] ||| [class_2] [class_1]	count=2
class	outlier factor of ||| outlier factor	count=2
function	estimates ||| val predict	count=2
function_arg	[function_1] laplacian matrix ||| [arg_2] [function_1]	count=3
function	seeds ||| get bin seeds	count=2
module	to avoid ||| externals	count=2
function_arg	assumes x ||| transform x	count=1
class	compute ||| base pca	count=2
arg	python object into one ||| filename	count=1
arg	[arg_1] note this ||| [arg_1] [arg_2]	count=2
function	[function_1] of loss ||| [function_2] [function_1]	count=1
function	function the absolute error ||| error	count=1
class	context of the memory ||| memory	count=1
module	depending from it ||| externals	count=2
function	barycenter [function_2] ||| [function_1] kneighbors [function_2]	count=2
function	20 newsgroups ||| 20newsgroups	count=1
class	of ||| backend	count=1
module	metrics should use this ||| metrics	count=1
function	the data ||| data	count=1
class	relative ||| scorer	count=1
function_arg	boolean mask [arg_2] ||| [arg_2] [function_1]	count=2
function	a covariance matrix shrunk ||| shrunk covariance	count=1
arg	y and [arg_2] ||| [arg_2] [arg_1]	count=12
arg	the usual api and ||| x y	count=3
function	by scaling each feature ||| minmax scale	count=1
module	the ||| joblib	count=5
arg	x y as training ||| x y copy_x	count=1
function	a binary ||| binary	count=2
function	sure that ||| check	count=1
function	and compute scores ||| and score	count=2
function	the kl [function_2] ||| [function_1] [function_2]	count=4
arg	transform [arg] to a ||| [arg]	count=1
function	indices in ||| find matching indices	count=1
module	covariance model ||| covariance	count=2
class	training ||| cv	count=1
function_arg	[function_1] on x ||| [function_1] [arg_2]	count=5
function	each ||| val predict	count=2
arg	columns of a matrix ||| columns	count=1
arg	[arg_1] in the ||| [arg_2] [arg_1]	count=2
function	load and [function_2] ||| [function_2] [function_1]	count=3
arg	structure ||| shape n_clusters noise minval	count=1
module	selected returns ||| feature_selection	count=1
arg	of dataset and ||| y	count=1
arg	a nmf model for [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=8
class	force ||| memorized	count=1
arg	x using ||| x y	count=1
function	a list of feature ||| get feature	count=1
class	the gaussian process model ||| gaussian process	count=1
arg	x == missing_values ||| x value_to_mask	count=2
class	the model parameters of ||| base mixture	count=1
class	coefficient matrix to ||| sparse	count=1
function	return staged predictions ||| staged predict	count=1
arg	generate a ||| n_samples n_components n_features n_nonzero_coefs	count=1
class	function and cache result ||| func	count=1
class	voting [class_2] ||| [class_2] [class_1]	count=4
function	coverage error measure ||| coverage error	count=1
function	sizes of training ||| train sizes	count=1
arg	sparse and dense inputs ||| y	count=1
function	error between two ||| error	count=1
class	[class_1] boosting ||| [class_1] [class_2]	count=5
function	to ||| to	count=2
function	low [function_2] ||| [function_1] [function_2]	count=2
class	fit ||| base sgdclassifier	count=3
function	normalized mutual [function_2] ||| [function_2] [function_1]	count=1
function_arg	[function_1] version ||| [function_1] read file [arg_2]	count=2
arg	generate random ||| n_samples random_state	count=2
arg	axis ||| axis	count=2
function	representation ||| shape	count=1
module	don't store the ||| joblib	count=2
function_arg	[function_1] [arg_2] neighborhoods are restricted the ||| [function_1] graph [arg_2] radius	count=14
arg	w to minimize ||| w	count=1
arg	set x y ||| x y	count=5
arg	x from ||| x z	count=1
arg	[arg] it ||| [arg] n_trials	count=1
function	elastic net path with ||| enet path	count=1
function	input data ||| val	count=1
function	neighbors ||| radius neighbors	count=4
function	[function_1] multiclass ||| [function_1] [function_2]	count=1
arg	x with ability to ||| x	count=1
function	the main classification ||| classification	count=1
arg	for [arg] ||| [arg]	count=3
function	the l1 distances between ||| paired manhattan distances	count=1
class	of ||| parallel backend	count=1
function	for each ||| cross val	count=1
function	random matrix ||| random choice csc	count=1
function	a single boost using ||| boost	count=1
function	[function_1] c ||| [function_1] [function_2]	count=3
class	store ||| memory	count=1
arg	data matrix x ||| x	count=1
function_arg	[function_1] for this ||| [function_1] [arg_2]	count=2
function	[function_1] boolean mask ||| [function_1] support [function_2]	count=1
arg	values for ||| x y train	count=2
arg	and dense ||| x y sample_weight	count=1
class	of the kernel k ||| compound kernel	count=1
function	data [function_2] ||| [function_2] [function_1]	count=2
function	compute data ||| get	count=1
function	when ||| repr	count=1
function	wild lfw pairs dataset ||| lfw pairs	count=1
function	[function_1] housing ||| [function_2] [function_1]	count=3
function	cholesky decomposition ||| log det cholesky	count=1
arg	of matrices ||| covariance_type n_features	count=1
class	types to ||| base	count=1
function	[function_1] absolute error ||| [function_2] [function_1]	count=2
module	types to ||| joblib	count=1
arg	version of ||| fobj	count=1
function_arg	kernel x ||| kernel x	count=1
function	online ||| partial fit	count=3
arg	within a given radius ||| x radius	count=1
arg	downloading it if necessary ||| data_home download_if_missing random_state shuffle	count=1
arg	positive-definite ||| covariance_type	count=1
function	a signal ||| signal	count=1
arg	[arg_1] - pred ||| [arg_2] [arg_1]	count=4
class	to avoid the ||| func	count=1
function	initial parameters of the ||| parameters	count=1
class	get ||| selector mixin	count=1
class	arguments ||| memorized func	count=2
function	returns the number ||| len	count=1
arg	zero row of x ||| x	count=1
class	the scaling of ||| scaler	count=1
function	determinant of a wishart ||| wishart	count=1
function	and column [function] of the ||| get [function]	count=1
arg	computes the ||| alpha	count=4
arg	a dense ||| random_state	count=1
class	linear model with passive ||| passive	count=2
function	shrunk on ||| shrunk	count=1
class	of max [class_2] ||| [class_1] [class_2]	count=2
arg	configure a ||| append	count=1
class	hash depending from it ||| func	count=1
module	nothing and ||| feature_extraction	count=1
class	the model parameters ||| base mixture	count=1
class	we don't ||| memory	count=1
class	avoid ||| memory	count=1
function	data to ||| data	count=1
function	or thread pool ||| backend	count=1
function	return a platform independent ||| shape repr	count=1
function	generate train test ||| iter	count=1
class	maximum [class_2] ||| [class_1] [class_2]	count=3
function	median ||| median	count=3
function	objective ||| objective	count=1
function	'l' suffix when ||| shape repr	count=1
class	depending from ||| func	count=1
function	to build a batch ||| build	count=1
function_arg	[function_1] w to ||| [arg_2] [function_1]	count=4
arg	version ||| fobj	count=1
class	model ||| randomized linear model	count=1
arg	target values for x ||| estimator x	count=1
arg	[arg_1] and ||| [arg_2] [arg_1]	count=11
arg	matrix m ||| m k k_skip eigen_solver	count=1
function	reproducibility flips the ||| deterministic vector	count=1
function	mean update ||| mean	count=1
function	two sets of biclusters ||| consensus	count=1
function_arg	cholesky decomposition [arg_2] ||| [arg_2] [function_1]	count=1
function	get the [function_2] ||| [function_1] support [function_2]	count=1
arg	y ||| y	count=24
class	classifier valid parameter ||| classifier	count=1
module	a platform independent ||| utils	count=1
function	sparse random matrix ||| random	count=1
arg	model using x ||| x y	count=1
function	using just nearest ||| nn	count=1
arg	input validation for standard ||| x y accept_sparse dtype	count=1
function_arg	back to [arg_2] ||| [function_1] transform [arg_2]	count=3
class	all transformers ||| feature union	count=2
function	rank matrix with ||| rank matrix	count=1
function_arg	backend factory ||| backend name factory	count=1
class	vectors ||| dummy	count=2
arg	isotropic gaussian ||| centers cluster_std	count=1
function	[function_1] [function_2] for ||| [function_1] [function_2]	count=12
function	from the decision ||| decision	count=1
arg	multi-class labels ||| y threshold	count=1
function	for full ||| full	count=2
arg	the data ||| x	count=2
class	determine the ||| backend base	count=1
function	determine absolute sizes of ||| translate train sizes	count=1
class	which are going ||| multiprocessing backend	count=2
function	iterate ||| iterate	count=1
class	generate train test ||| base shuffle split	count=1
function	get the ||| get	count=6
class	the kernel ridge model ||| kernel ridge	count=1
function	l1 ||| manhattan	count=1
arg	y_true ||| y_true	count=2
module_class	to polynomial ||| preprocessing polynomial	count=1
arg	[arg_1] x ||| [arg_2] w h [arg_1]	count=3
function_arg	[function_1] [arg_2] ||| [function_1] x x [arg_2]	count=22
arg	estimates for each input ||| y	count=1
function_arg	binary [arg_2] ||| [arg_2] [function_1]	count=3
function	normalized [function_2] ||| [function_1] [function_2]	count=2
module	the relationship [module_2] ||| [module_1] [module_2]	count=2
class	types ||| backend base	count=2
function	and maximum ||| max axis	count=1
arg	to compute decisions within ||| estimators_features	count=1
function	of [function] set ||| [function]	count=2
arg	estimator ||| estimator x	count=5
function	lower bound on ||| lower bound	count=1
function	sign of ||| sign	count=1
function	lower bound [function_2] ||| [function_2] [function_1]	count=1
arg	a cross-validated ||| estimator x y cv	count=1
class	-1 [class] ||| local [class]	count=2
module	clustering on the ||| cluster	count=1
arg	an open file object ||| f header_length dtype	count=1
function	predict is invariant of ||| predict	count=1
function	[function_1] feature ||| [function_2] [function_1]	count=3
arg	of x ||| x y copy	count=1
arg	computes the gradient ||| alpha	count=2
function	used in hastie ||| hastie	count=1
arg	of x from y ||| x z reg	count=1
function_arg	[function_1] batch_size elements ||| [arg_2] [function_1]	count=2
arg	cross-validated ||| estimator x y cv	count=2
arg	norm vector length ||| x norm axis	count=1
function	predict based on ||| predict	count=1
function	unique [function] we don't ||| unique [function]	count=1
function	init ||| split init	count=1
arg	columns ||| columns	count=1
function	compute minimum and maximum ||| min max	count=1
function	[function_1] length of ||| [function_2] [function_1]	count=5
function_arg	[function_1] the lrd ||| reachability [function_1] [arg_2]	count=1
function_arg	probabilities for [arg_2] ||| [function_1] [arg_2]	count=4
function	of neighbors ||| radius neighbors	count=2
function	and persist ||| call	count=1
function	compute a logistic regression ||| logistic regression	count=1
function	data home ||| clear data home	count=2
function	[function_1] backed arrays ||| [function_1] [function_2]	count=3
arg	parameter weights and ||| y	count=1
arg	sparse matrix x ||| x	count=1
function	not found and ||| search	count=1
class	array [class_2] ||| [class_2] [class_1]	count=2
function	[function_1] c and ||| [function_2] [function_1]	count=3
class	data ||| base pca	count=2
function	estimates for each ||| cross val predict	count=1
function	long type ||| shape repr	count=1
arg	neighbors ||| neighbors	count=1
arg	set of samples x ||| x y	count=1
arg	with a given mapping ||| class_mapping	count=1
function	introduces an ||| shape repr	count=1
class	more data [class] ||| [class]	count=3
class	string to the file ||| file	count=1
function_arg	directory [arg_2] ||| [function_1] [arg_2]	count=3
function	[function_1] message on ||| [function_2] [function_1]	count=4
function	function for _fit_coordinate_descent update ||| update	count=1
function	of edges for a ||| make edges	count=1
arg	mono and multi-outputs ||| y eps n_alphas	count=1
arg	of observations in x ||| x	count=1
class	undo the scaling of ||| min max scaler	count=1
function_arg	[function_1] structure ||| [function_1] [arg_2]	count=5
function	[function_1] home cache ||| [function_2] [function_1]	count=4
arg	points in x ||| x n_neighbors mode	count=1
function	determination ||| r2	count=1
arg	x for later ||| x	count=1
arg	sparse and ||| x y	count=1
class	[class_1] classifier ||| [class_2] [class_1]	count=4
function	[function_1] random ||| [function_2] [function_1]	count=1
arg	vectors x ||| x	count=1
function_arg	[function_1] multi-class labels ||| [function_1] [arg_2]	count=1
arg	[arg_1] to ||| [arg_1] edges [arg_2]	count=2
function	kernel is [function_2] ||| [function_1] [function_2]	count=1
function_arg	[function_1] squared ||| [function_1] x [arg_2]	count=1
function	report showing the main ||| report	count=1
arg	w ||| w ht	count=1
arg	standardize a dataset along ||| with_centering with_scaling	count=1
function	shortest path length ||| single source shortest path length	count=1
function	generate a grid of ||| grid	count=1
function	return the decision path ||| decision path	count=1
module	input data point ||| core	count=1
function	explained [function_2] ||| [function_2] [function_1]	count=4
arg	data x which should ||| x y	count=1
arg	stderr depending on verbosity ||| msg msg_args	count=1
function_arg	median of data ||| get median data	count=2
function_arg	fit estimator [arg_2] ||| [function_1] transform [arg_2]	count=1
arg	cross-validated estimates for ||| estimator x y cv	count=1
module_class	returns whether the ||| gaussian_process pairwise	count=1
class	depending from ||| memorized	count=1
function	the huber [function_2] ||| [function_1] [function_2]	count=4
arg	x ||| x doc_topic_distr	count=1
function	the wine ||| wine	count=1
function	weighted graph ||| graph	count=4
arg	a ||| a w axis	count=1
function_arg	median [arg_2] ||| [function_1] [arg_2]	count=2
function	in a multilabel format ||| multilabel	count=1
class	[class_1] training data ||| [class_1] [class_2]	count=2
function	in the wild lfw ||| lfw	count=1
class	pool ||| multiprocessing backend	count=1
module	given ||| core	count=1
function	[function] samme ||| [function]	count=2
class	the trained model ||| base multilayer perceptron	count=1
arg	and class probabilities ||| y	count=1
function	estimate class weights ||| compute class	count=1
function_arg	indices in [arg_2] ||| [arg_2] [function_1]	count=3
module	exception ||| externals	count=1
function	the sources [function] to the ||| [function]	count=1
module	train ||| core	count=1
function_arg	[function_1] laplacian ||| [function_1] [arg_2]	count=3
function_arg	[function_1] [arg_2] the ||| [function_1] x [arg_2]	count=1
function	loads data ||| load data	count=1
function	random matrix ||| random	count=1
arg	finds ||| return_distance	count=2
arg	and y ||| y	count=12
function	load output of ||| load output	count=1
arg	[arg_1] == missing_values ||| [arg_1] [arg_2]	count=1
function	generate ||| iter	count=1
function	and return the iris ||| iris	count=1
function	path ||| path	count=6
class	list of exception ||| backend base	count=1
function	[function_1] the gradient ||| [function_1] [function_2]	count=5
function	partially fit ||| partial fit	count=6
arg	of a [arg_1] [arg_2] ||| [arg_2] [arg_1]	count=2
function	mutual ||| mutual	count=4
function	estimates for ||| cross val predict	count=1
function_arg	[function_1] [arg_2] the ||| [function_1] [arg_2]	count=3
arg	and a ||| y	count=1
class	store the ||| memory	count=1
class	polynomial [class_2] ||| [class_1] [class_2]	count=2
function	explained [function_2] ||| [function_1] [function_2]	count=4
module	a size ||| externals	count=1
function_arg	[function_1] dot w ||| [function_1] x [arg_2]	count=1
function	directory in which ||| get output dir	count=1
arg	p_ij ||| desired_perplexity verbose	count=2
class	run in parallel ||| parallel backend	count=1
function	return ||| get	count=3
module	or thread ||| externals joblib	count=1
arg	matrices ||| covariance_type	count=2
class	[class_1] factor ||| [class_2] [class_1]	count=5
function	error regression loss ||| log error	count=1
function	[function_1] linear ||| [function_2] [function_1]	count=3
class	catch and hide warnings ||| warnings	count=1
function	memory text [function] its value ||| memstr [function]	count=1
class	generate ||| base	count=1
module	each input data ||| core	count=1
function	[function_1] update nmf ||| [function_1] [function_2]	count=1
class	process regression ||| process regressor	count=2
arg	[arg_1] to n ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] theta ||| laplace log marginal [function_1] [arg_2]	count=1
function	function to ||| function	count=1
arg	x ||| x z reg	count=1
function	each input data point ||| cross val predict	count=1
class	used for scaling ||| scaler	count=1
arg	for validation and conversion ||| dtype csr_output	count=1
arg	to multi-class labels ||| threshold	count=1
arg	doc_topic_distr ||| doc_topic_distr	count=1
arg	decisions within ||| estimators_features	count=1
function	random matrix given ||| random	count=1
class	convert ||| sparse	count=1
function	random multilabel classification problem ||| make multilabel classification	count=1
arg	for each input data ||| estimator	count=1
class	undo the [class_2] ||| [class_1] [class_2]	count=2
function	the decision path ||| decision path	count=2
function_arg	read [arg_2] ||| [arg_2] [function_1]	count=1
arg	ridge and ||| x y	count=1
arg	set with self ||| x_test y	count=1
function_arg	neighbors for [arg_2] ||| [function_1] graph [arg_2]	count=4
arg	[arg_1] dispatch table ||| [arg_1] [arg_2]	count=1
function	retrieve the leaves of ||| leaves	count=1
arg	the binary ||| y_score average sample_weight	count=1
arg	[arg_1] [arg_2] 1 inlier -1 ||| [arg_1] [arg_2]	count=8
function	[function_1] people dataset ||| [function_2] [function_1]	count=4
arg	based on x and ||| x	count=1
function	mean update and ||| incremental mean	count=1
function	fetch an mldata ||| fetch mldata	count=3
arg	any axis center ||| x axis	count=2
arg	to [arg] return leaf ||| [arg]	count=2
function	a full lars path ||| omp path	count=1
function_arg	[function_1] percentiles of ||| [function_1] x x [arg_2]	count=5
arg	as ||| copy_x	count=1
function	component ||| get covars	count=1
function	median ||| get median	count=1
class	remove cache folders to ||| memory	count=1
function_arg	[function_1] corresponds to ||| [arg_2] [function_1]	count=4
function	points on ||| len	count=1
function	predict if a ||| predict	count=1
function	estimates for ||| cross val	count=1
arg	routine for validation and ||| directed dtype	count=1
function	[function_1] neighbors ||| [function_2] [function_1]	count=12
module	list ||| joblib	count=1
class	parameter ||| parameter	count=1
function	[function_1] and the ||| [function_2] [function_1]	count=4
arg	and configure ||| append random_state	count=2
function	type introduces an ||| repr	count=1
class	passive aggressive algorithm ||| passive aggressive regressor	count=2
class	[class] for the ||| kneighbors [class]	count=1
function	polynomial ||| polynomial	count=1
module	remove cache ||| joblib	count=1
arg	column class distributions ||| classes class_probability random_state	count=1
function	model fitting ||| fit	count=1
function	range approximates the range ||| range	count=1
function	mean ||| incremental mean	count=1
arg	given type in the ||| type	count=1
function_arg	two [arg_2] ||| [function_1] [arg_2]	count=1
function	the california ||| california	count=1
function	gradient ||| gradient	count=1
class	classifier valid parameter keys ||| classifier	count=1
arg	on left-out data ||| x_train y_train x_test y_test	count=1
function	note this implementation is ||| roc	count=1
arg	capture the arguments ||| check_pickle	count=1
function	predict is ||| compute labels predict	count=1
arg	model with x ||| x	count=2
arg	a given radius of ||| x radius	count=1
module	depending ||| externals joblib	count=4
class	for training ||| classifier	count=1
function	compute probabilities of possible ||| proba	count=1
function	[function_1] terminal ||| [function_1] [function_2]	count=2
function	extract the ||| extract	count=1
function_arg	fit x ||| fit x y	count=1
class	label ||| gmmbase	count=1
class	count ||| multinomial nb	count=1
function	not found ||| line search	count=1
arg	keep the ||| root_path bytes_limit	count=1
function	update the ||| update	count=1
arg	binary ||| y_score average	count=1
function	of [function] method no ||| [function]	count=1
function	the california housing dataset ||| fetch california housing	count=1
function	recall is the ||| recall	count=1
function	[function_1] first ||| [function_2] [function_1]	count=1
class	list ||| parallel backend base	count=2
function	names ordered by their ||| names	count=1
function	build a batch of ||| build	count=1
arg	set with self ||| x_test	count=1
module	store the ||| joblib	count=2
function	median [function_2] ||| [function_1] [function_2]	count=6
function	[function] of ||| inplace tanh [function]	count=2
function	[function_1] importances ||| [function_1] [function_2]	count=1
function	leaves of ||| leaves	count=1
class	convert coefficient matrix ||| sparse coef	count=1
class	later scaling ||| scaler	count=1
class	exception types to ||| backend base	count=1
arg	columns of ||| columns	count=1
function	ward ||| ward tree	count=2
function	[function_1] in ||| [function_2] [function_1]	count=3
function	of the reduced likelihood ||| reduced likelihood	count=1
class	generative model ||| base pca	count=1
class	classification ||| svc	count=1
function_arg	[function_1] x ||| [function_1] w [arg_2]	count=1
function	the isotonic regression model ||| isotonic regression	count=1
arg	of x (as ||| x	count=1
function	get the values ||| get	count=1
class	aggressive algorithm ||| aggressive classifier	count=1
function	model parameters ||| fit	count=2
arg	classification task ||| y_true y_score pos_label sample_weight	count=1
function	the number of ||| n	count=2
function_arg	unfitted [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg_1] y and ||| [arg_1] [arg_2]	count=24
class	of the scaler ||| max abs scaler	count=1
function	wishart ||| wishart	count=3
module	to run in ||| externals joblib	count=1
function	the barycenter [function_2] ||| [function_2] [function_1]	count=3
function	california housing ||| fetch california housing	count=2
arg	columns of a ||| columns	count=1
function	the decision functions ||| decision function	count=2
class	with ||| search cv	count=1
arg	computes ||| x y alpha	count=2
class	convert coefficient ||| coef	count=1
function	type introduces an ||| shape repr	count=1
function	simple custom [function] to summarize ||| [function]	count=1
function	[function_1] diagonal ||| [function_2] [function_1]	count=2
arg	and smooth feature occurrences ||| x y	count=2
function	the precision the precision ||| precision	count=1
class	polynomial [class_2] ||| [class_2] [class_1]	count=2
arg	computes the gradient and ||| x y alpha	count=2
arg	y - [arg_2] ||| [arg_1] [arg_2]	count=1
function	huber [function_2] ||| [function_2] [function_1]	count=4
function	[function_1] dependence ||| [function_2] [function_1]	count=1
arg	sparse and dense ||| y	count=1
arg	and smooth feature ||| y	count=2
function	given param_grid ||| param iterator	count=1
arg	and compute ||| x y classes	count=2
class	the gradient [class_2] ||| [class_1] [class_2]	count=2
function	[function_1] strip lines ||| [function_2] [function_1] quoting	count=1
function	spherical ||| spherical	count=3
class	compute the maximum ||| max	count=1
function	compute the boolean mask ||| mask	count=1
arg	with respect ||| activations deltas	count=2
function_arg	fit the [arg_2] ||| [arg_2] [function_1]	count=20
class	the generative model ||| pca	count=1
arg	along any axis ||| x axis	count=2
arg	and a set ||| y	count=1
function	when ||| shape	count=1
arg	according to the given ||| sample_weight	count=2
module	the ||| decomposition	count=1
arg	[arg_1] [arg_2] ||| [arg_1] [arg_2]	count=632
arg	matching pursuit problems ||| n_nonzero_coefs	count=1
class	process or ||| multiprocessing	count=1
module	a platform ||| utils	count=1
arg	in x and y ||| x y sum_over_features	count=1
arg	y_pred ||| y_pred	count=1
class	outlier factor ||| outlier factor	count=2
function	home ||| home	count=1
class	regressor ||| regressor	count=3
function	rand index ||| rand	count=1
class	from ||| func	count=1
class	avoid the hash ||| memorized	count=1
arg	[arg] a ||| [arg]	count=3
arg	generate a ||| n_features	count=1
arg	does not need to ||| y residual	count=1
function	[function_1] c and ||| [function_1] [function_2]	count=3
arg	w to minimize the ||| w	count=1
function	incremental mean and variance ||| incr mean variance	count=1
arg	h whose product ||| h n_components	count=1
arg	w h whose product ||| x w h	count=1
arg	for x using ||| x y	count=1
function	predict based on an ||| predict	count=1
class	the cache for ||| memorized func	count=1
function_arg	[function_1] [arg_2] ||| [function_1] targets [arg_2]	count=1
arg	call ||| args kwargs	count=1
function	for the lfw ||| lfw	count=2
class	don't store ||| memorized func	count=1
function	batch and ||| batch	count=1
function	kl divergence ||| kl divergence	count=2
function	write [function_2] ||| [function_1] [function_2]	count=1
function	estimates for each ||| cross	count=1
module	the relationship [module_2] ||| [module_2] [module_1]	count=2
class	we ||| memorized	count=1
function_arg	loss for [arg_2] ||| [arg_2] [function_1]	count=1
arg	kwargs using a list ||| kwargs	count=1
arg	model according to ||| sample_weight	count=2
arg	of x for ||| x y	count=1
arg	a subcluster from ||| subcluster new_subcluster1 new_subcluster2	count=1
function	insert ||| insert cf	count=1
function	[function_1] and the ||| [function_1] [function_2]	count=4
module	the hash depending from ||| externals	count=2
module	inside a with ||| externals joblib	count=2
function	[function_1] [function_2] ||| [function_1] [function_2]	count=1693
arg	sparse and dense ||| y sample_weight	count=1
arg	a cross-validated ||| y cv	count=1
function	log probabilities within a ||| parallel predict log proba	count=1
function	on ||| fit	count=3
class	convert coefficient matrix ||| coef mixin	count=1
function	[function_1] clustering for ||| [function_1] [function_2]	count=1
arg	perform the ||| responsibilities	count=1
arg	x y [arg_2] ||| [arg_1] [arg_2]	count=6
function	column scaling of ||| column	count=1
module_class	[module_1] [class_2] ||| [module_1] [class_2] vectorizer transform x y	count=2
function	path [function_2] ||| [function_1] [function_2]	count=3
function	the neighbors ||| neighbors	count=1
function	weighted graph of ||| graph	count=4
function_arg	[function_1] with categories ||| [arg_2] [function_1]	count=2
arg	subcluster from ||| subcluster new_subcluster1 new_subcluster2	count=1
function	descent fit ||| fit	count=1
function	[function_1] slices containing ||| [function_1] [function_2]	count=1
arg	samples of [arg_2] ||| [arg_1] [arg_2]	count=1
module	to run a ||| externals	count=1
function	low ||| make low	count=1
class	from it ||| memory	count=1
class	between two covariance estimators ||| covariance	count=1
class	search ||| search cv	count=2
function	factorization ||| non negative factorization	count=2
class	hash depending from ||| memory	count=1
function	the linear [function_2] ||| [function_2] [function_1]	count=2
function_arg	[function_1] of matrices ||| [arg_2] [function_1]	count=3
arg	in x [arg_2] ||| [arg_1] [arg_2]	count=3
class	training data ||| regression	count=1
class	[class_1] features parameters ||| [class_2] [class_1]	count=1
function	locally linear embedding analysis ||| locally linear embedding	count=1
module	an 'l' ||| utils	count=1
function	svd parameters ||| svd	count=1
function	median [function_2] ||| [function_2] [function_1]	count=6
function	coefficient score ||| score	count=1
arg	a classification ||| y_true y_pred	count=1
arg	data and concatenate results ||| y	count=1
arg	the gradient and the ||| y	count=2
function	the score of the ||| score	count=1
arg	each input data ||| x y	count=1
function	[function] segment of ||| [function]	count=3
class	parallel processing this ||| parallel	count=1
function	score of the ||| score	count=1
function	absolute error [function_2] ||| [function_2] divergence [function_1]	count=1
class	training ||| regression	count=1
arg	at x ||| x	count=1
function_arg	[function_1] data in ||| [function_1] zfile file_handle [arg_2]	count=1
function	predict labels for ||| predict	count=1
function	edges for ||| make edges	count=1
arg	[arg] neighborhoods are ||| [arg] radius	count=3
class	the model ||| linear model	count=1
function	the long type ||| shape	count=1
function	suffix when using ||| shape repr	count=1
arg	based on ||| connectivity n_clusters return_distance	count=1
function_arg	[function_1] function func ||| [function_1] [arg_2]	count=1
class	estimator ||| base estimator	count=2
function	regression ||| regression	count=3
module	long ||| utils	count=1
function	mean ||| mean	count=7
arg	given radius ||| radius	count=1
arg	classification task ||| y_true	count=2
arg	the normalized laplacian ||| n_components eigen_solver	count=1
arg	estimator ||| estimator x y classes	count=1
function	full covariance matrices ||| normal density full	count=1
arg	data ||| x y	count=1
arg	matrix ||| k	count=1
arg	set x [arg_2] ||| [arg_1] [arg_2]	count=8
class	types to ||| backend	count=1
arg	generate cross-validated estimates for ||| estimator x y cv	count=1
module	suffix when using the ||| utils	count=1
arg	a ||| a w	count=1
class	test ||| base shuffle split	count=2
function	remove cache folders ||| reduce	count=1
arg	based on a ||| x connectivity n_clusters	count=1
arg	this kernel ||| deep	count=1
function	featureunion ||| union	count=1
function	online computation of ||| partial fit	count=1
class	or thread ||| multiprocessing	count=1
function	the sign of elements ||| sign	count=1
function	function used to build ||| parallel build	count=1
arg	binary classification ||| y_true y_score average sample_weight	count=1
arg	model using x as ||| x	count=2
function	[function_1] covariance ||| [function_2] [function_1]	count=2
arg	computes ||| w x y alpha	count=2
module	under a ||| externals	count=1
arg	beta-divergence of ||| beta	count=1
arg	dataset downloading it ||| subset data_home download_if_missing random_state	count=1
arg	log-det ||| matrix_chol	count=1
class	for parallel processing ||| parallel	count=1
class	gradient boosting ||| gradient boosting	count=4
function	each input data ||| cross val predict	count=1
function	shortest ||| shortest	count=1
function	masks for ||| masks	count=1
function	the mstep ||| do mstep	count=1
function	showing the main classification ||| classification	count=1
arg	x as [arg_2] ||| [arg_1] [arg_2]	count=2
arg	model according to the ||| x y sample_weight	count=2
function	classification ||| classification	count=3
function	[function_1] binary ||| [function_2] [function_1]	count=5
function_arg	range [arg_2] ||| [arg_2] [function_1]	count=1
arg	remove a subcluster ||| subcluster new_subcluster1 new_subcluster2	count=1
class	abort ||| parallel backend base	count=1
class	loss of ||| loss	count=1
function	c in (l1_min_c ||| c	count=1
function	transform binary [function_2] ||| [function_2] [function_1]	count=4
function_arg	range of [arg_2] ||| [function_1] [arg_2]	count=1
arg	and compute scores ||| x y	count=2
function	get feature ||| get feature	count=2
class	it ||| func	count=1
function	that [function] maps ||| bind [function]	count=1
function	on training [function_2] ||| [function_2] [function_1]	count=2
arg	python object into ||| value filename	count=1
arg	a filename ||| filename	count=1
arg	in place ||| code verbose	count=1
function	generate an array with ||| make	count=2
function	absolute sizes of training ||| sizes	count=1
function	an 'l' suffix ||| shape repr	count=1
function	perform mean [function_2] ||| [function_2] [function_1]	count=1
class	list ||| parallel backend	count=1
class	the generative model ||| base	count=1
arg	to the binary classification ||| y_true y_score pos_label	count=1
function	[function_1] and cpp ||| [function_2] [function_1]	count=5
function	laplacian [function_2] ||| [function_2] [function_1]	count=2
module	we ||| joblib	count=2
function	type ||| shape repr	count=1
function_arg	to x ||| transform x	count=1
class	don't store the ||| memorized	count=1
class	train test ||| shuffle split	count=1
arg	x [arg_2] ||| fit [arg_1] [arg_2]	count=1
function	kappa a ||| cohen kappa	count=1
function	update it with the ||| update	count=1
arg	samples of length ||| samples	count=1
function_arg	log-probabilities for [arg_2] ||| [function_1] [arg_2]	count=2
module_class	check if a [module_1] [class_2] ||| [module_1] [class_2]	count=8
arg	the data onto ||| x ridge_alpha	count=1
function	download the [function_2] ||| [function_1] [function_2]	count=3
function	covariance [function_2] ||| [function_2] [function_1]	count=8
function_arg	[function_1] keep the ||| [function_1] [arg_2]	count=2
class	with the best found ||| search cv	count=5
arg	an [arg] into a ||| [arg]	count=1
function	the neighbors within a ||| neighbors	count=1
function	suffix when using the ||| shape	count=1
function_arg	[function_1] n_jobs ||| [arg_2] [function_1]	count=2
function	lfw pairs dataset ||| lfw pairs	count=2
arg	x ||| x check_input	count=1
function	class covariance ||| class cov	count=2
arg	its spectrum spectrum ||| spectrum	count=1
function	make ||| make	count=1
class	data-dependent state [class] if ||| [class]	count=3
class	of exception ||| base	count=1
arg	h whose product ||| h	count=1
function	a single binary ||| predict binary	count=1
arg	a set of points ||| axis metric	count=1
class	maximum absolute value ||| max abs	count=2
function	[function_1] and gradient ||| [function_1] [function_2]	count=3
arg	the case method='lasso' is ||| x y xy gram	count=1
arg	input data point ||| estimator x y	count=1
arg	y [arg_2] ||| [arg_2] [arg_1]	count=7
class	the generative ||| base	count=1
function	matrix shrunk on ||| shrunk	count=1
module	process ||| externals joblib	count=2
arg	loader for the labeled ||| data_home	count=1
arg	of dataset and ||| x y	count=1
function	divergence of p_ijs and ||| divergence	count=1
arg	a cross-validated ||| cv	count=1
function	supports seeking ||| seekable	count=1
arg	weights and ||| x y	count=1
function	the ||| shape	count=2
function_arg	centroids on [arg_2] ||| [function_1] [arg_2]	count=2
function	of init ||| init decision function	count=1
function	data home ||| data home	count=1
module	to be used for ||| preprocessing	count=2
function	a full lars path ||| path	count=1
function_arg	fit [arg_2] ||| [function_1] transform [arg_2]	count=1
module	to avoid ||| externals joblib	count=2
function	compute minimum [function_2] ||| [function_2] [function_1]	count=1
arg	is inefficient ||| x y classes	count=1
function	of the decision functions ||| decision function	count=1
function	the covariance ||| covar matrix to match covariance	count=1
function	requested by the callers ||| effective	count=1
function	edges ||| edges	count=1
function	probabilities ||| proba	count=9
module	the hash ||| externals	count=2
module	estimates for ||| core	count=1
module	compute the ||| neural_network	count=1
module	list of exception ||| externals	count=1
arg	note this ||| sample_weight	count=1
arg	[arg_1] note ||| [arg_2] [arg_1]	count=2
arg	list of regularization parameters ||| pos_class cs	count=1
arg	with self ||| x_test	count=1
class	gaussian ||| gaussian	count=9
function_arg	[function_1] parameters ||| [arg_2] [function_1]	count=2
arg	the mean and ||| y	count=1
function_arg	[function_1] y and ||| [function_1] x [arg_2]	count=1
function	median absolute [function_2] ||| [function_2] [function_1]	count=4
arg	columns of x ||| x	count=1
class	convert coefficient matrix to ||| sparse coef mixin	count=1
function	and the gradient ||| and gradient	count=3
class	fits the shrunk ||| shrunk	count=1
function	for ||| val predict	count=2
function_arg	[function_1] of a ||| [arg_2] [function_1]	count=4
function	logistic ||| logistic	count=5
function	center ||| center scale xy	count=1
function	[function_1] predict ||| [function_1] [function_2]	count=2
function	[function_1] functions ||| [function_2] [function_1]	count=4
function	oracle approximating shrinkage ||| oas	count=1
function	'l' ||| shape repr	count=1
arg	model and ||| x y	count=1
arg	python object ||| value filename	count=1
function_arg	neighbors within [arg_2] ||| [function_1] [arg_2]	count=2
function	read [function_2] ||| [function_1] [function_2]	count=1
arg	is computed between each [arg_1] [arg_2] ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=1
module	for the [module] ||| [module]	count=1
function	shortest path length ||| shortest path length	count=1
function	sign of ||| sign flip	count=1
arg	cross-validated estimates for ||| cv	count=1
function_arg	slices containing [arg_2] ||| [function_1] [arg_2]	count=1
arg	onto ||| x ridge_alpha	count=1
class	[class_1] on ||| [class_2] [class_1]	count=2
arg	point ||| estimator x y	count=1
class	as training ||| orthogonal matching pursuit cv	count=1
class	the gradient ||| base gradient	count=4
function	weighted graph [function_2] ||| [function_2] [function_1]	count=16
function	memmap ||| memmap	count=1
module_class	to be [class_2] ||| [module_1] [class_2]	count=1
arg	mono and multi-outputs ||| x y eps n_alphas	count=1
arg	persist an arbitrary ||| compress protocol	count=1
function	note this implementation ||| roc	count=1
arg	x y ||| x y max_samples	count=1
module	inside a [module_2] ||| [module_1] [module_2]	count=4
function	the leaves ||| leaves	count=1
function	images ||| images	count=1
arg	finds the ||| return_distance	count=2
function	edges for ||| edges	count=1
arg	from features or ||| sample_weight	count=1
module	metrics ||| metrics	count=2
function	[function_1] covariance matrix ||| [function_1] [function_2]	count=2
function	suffix when ||| shape repr	count=1
function_arg	parallel backend [arg_2] ||| [function_1] [arg_2]	count=1
module	coefficient ||| linear_model	count=1
class	of approximate nearest ||| lshforest	count=1
function	clustering ||| clustering	count=1
class	the scaler ||| max scaler	count=1
class	types ||| parallel backend base	count=2
class	dataset ||| random trees	count=1
arg	x for ||| x means covars	count=4
arg	state of ||| state	count=1
function	average path length of ||| average path length	count=1
function	modified weiszfeld [function_2] ||| [function_1] [function_2]	count=1
class	training data ||| cv	count=1
arg	import path as a ||| resolv_alias win_characters	count=1
function	the callable case for ||| callable	count=1
function	perform mean [function_2] ||| [function_1] [function_2]	count=1
function_arg	the training [arg_2] ||| [arg_2] [function_1]	count=10
arg	:ref user guide ||| y_true y_pred	count=3
arg	random sample from a ||| a size replace	count=1
class	search over parameters ||| base search	count=1
function_arg	median of [arg_2] ||| [function_1] [arg_2]	count=2
class	evaluates [class] at ||| [class]	count=1
function	[function_1] feature ||| [function_1] [function_2]	count=3
arg	[arg_1] h whose ||| [arg_1] [arg_2]	count=4
function	back ||| inverse transform	count=4
function	predict is invariant of ||| labels predict	count=1
function_arg	[function_1] x and ||| [function_1] [arg_2]	count=3
arg	[arg_1] the transformed ||| [arg_2] [arg_1]	count=6
function	the logistic [function_2] ||| [function_1] [function_2]	count=4
function	for ||| predict	count=1
arg	generate cross-validated estimates for ||| cv	count=1
arg	on x and y ||| x y	count=1
class	whether the kernel ||| kernel	count=3
function	for updating terminal ||| update terminal	count=1
function	[function_1] divergence of ||| [function_2] [function_1]	count=3
function	compute log probabilities ||| predict log proba	count=1
function	the long type introduces ||| repr	count=1
function	the c [function_2] ||| [function_1] [function_2]	count=3
arg	[arg_1] conversion ||| [arg_2] [arg_1]	count=3
function	of points on the ||| len	count=1
function	determine the number of ||| effective n	count=1
function	in the ||| in	count=1
function	for each ||| val predict	count=1
arg	check that [arg] is ||| [arg]	count=1
arg	estimator and ||| x y	count=1
function	[function_1] the sign ||| [function_2] [function_1]	count=3
function	backed arrays ||| backed	count=1
module	the [module] according to ||| [module]	count=2
function_arg	assumes [arg_2] ||| [function_1] [arg_2]	count=1
function	to predict apply ||| predict	count=2
function_arg	[function_1] downloading it ||| [arg_2] [function_1]	count=3
module	a with ||| externals joblib	count=2
arg	for each ||| y	count=1
function	the shortest [function_2] ||| [function_2] [function_1]	count=2
arg	of equations ||| b damp atol	count=1
function	of cpus ||| cpu count	count=1
function	of biclusters ||| consensus score	count=1
module	clustering on the data ||| cluster	count=1
class	[class_1] squares ||| [class_1] [class_2]	count=1
function	generate a grid ||| grid	count=1
function	load the covertype ||| covtype	count=1
class	the backend ||| backend	count=1
function_arg	[function_1] given dataset ||| [function_1] estimator [arg_2]	count=2
arg	norm vector length ||| x norm	count=1
function	build a ||| build	count=1
arg	training and test ||| y groups	count=6
function	california ||| fetch california	count=1
arg	lrd ||| distances_x neighbors_indices	count=1
function	labels ||| label	count=1
class	[class_1] classifier ||| [class_1] [class_2]	count=4
arg	apply a mask ||| mask	count=1
arg	implement a single ||| iboost x	count=2
function	point ||| cross val	count=1
function	predict_log_proba of ||| predict log proba	count=1
arg	distances ||| distances	count=2
class	patch ||| patch extractor	count=1
function	long type introduces ||| shape	count=1
function_arg	[function_1] to size ||| [function_1] [arg_2]	count=1
function	to the average path ||| average path	count=1
class	of exception types ||| backend	count=1
function	perform mean shift ||| mean shift	count=2
function_arg	[function_1] is meant ||| [function_1] [arg_2]	count=10
function	get feature [function_2] ||| [function_2] [function_1]	count=1
function	of ||| shape	count=1
function_arg	run score function [function_1] [arg_2] the appropriate features ||| feature_selection base filter [function_1] [arg_2]	count=1
arg	from 0 to n ||| n	count=1
class	generate ||| shuffle	count=1
function	all [function_2] ||| [function_2] [function_1]	count=1
arg	vectors individually to unit ||| axis copy	count=1
function	grid of ||| grid	count=1
function	check validity of ||| check params	count=2
function	the depth ||| previous func code	count=1
module	process or thread pool ||| externals	count=1
function	iterate ||| iterate columns	count=2
module	exception ||| joblib	count=1
function	for fit ||| fit	count=1
arg	h ||| h beta_loss	count=1
function	given param_grid ||| get param iterator	count=1
arg	to the binary classification ||| y_true y_score average sample_weight	count=1
function	log of ||| predict log	count=2
function	long ||| shape repr	count=1
function	kl divergence of p_ijs ||| kl divergence	count=1
class	position ||| mds	count=1
function	[function_1] divergence ||| [function_1] [function_2]	count=3
class	density model on ||| kernel density	count=1
function	[function_1] probabilities ||| [function_1] [function_2]	count=4
function	initial parameters ||| parameters	count=1
function	to the average ||| average	count=1
arg	update w ||| x w	count=1
function	l1 ||| paired manhattan	count=1
function	classification problem ||| classification	count=2
arg	matrices w ||| w	count=1
class	labels ||| voting	count=1
function	to assert that ||| check	count=1
arg	returns [arg_2] ||| [arg_1] [arg_2]	count=2
arg	sparse matrix x ||| x dict_type	count=1
function	modified weiszfeld [function_2] ||| [function_2] [function_1]	count=1
function	fit a binary classifier ||| fit binary	count=1
arg	and a set ||| x y	count=1
function	[function_1] stationary ||| [function_2] [function_1]	count=7
function	coordinate [function] ||| [function]	count=3
function	variance ||| variance	count=4
function	of points based on ||| from	count=1
arg	a given test ||| y_test scorer	count=4
function	the score of ||| score	count=3
class	corresponding ||| numpy	count=1
function	global [function_2] ||| [function_2] [function_1]	count=4
class	[class_1] gradient boosting ||| [class_2] [class_1]	count=3
function_arg	vector is [arg_2] ||| [function_1] precision [arg_2]	count=1
function	[function_1] graph of ||| [function_1] kneighbors [function_2]	count=3
function	predict the target of ||| predict	count=1
class	format ||| mixin	count=1
class	the hash depending from ||| func	count=1
function	time it take ||| squeeze time	count=2
function	[function_1] shrunk ||| [function_2] [function_1]	count=4
function	collect ||| collect	count=1
function_arg	[function_1] data ||| [function_1] zfile file_handle [arg_2]	count=1
function	right [function] ||| generate [function]	count=1
arg	usual api and ||| x y	count=3
function	recall ||| recall	count=1
module	convert [module] memory text ||| [module]	count=1
module_class	test [class_2] ||| [module_1] [class_2]	count=4
function	shrunk on the ||| shrunk	count=1
arg	exp(-e v h ||| v	count=1
module	nothing and return the ||| feature_extraction	count=1
function	single boost using the ||| boost	count=1
function	value of the log ||| log	count=1
arg	other and ||| y	count=1
function	found and ||| search	count=1
function_arg	[function_1] [arg_2] neighborhoods are restricted the ||| [function_1] [arg_2]	count=44
arg	set [arg_1] [arg_2] appropriately and checks inputs ||| paired arrays [arg_1] [arg_2]	count=1
arg	evaluate [arg] ||| [arg] n_samples	count=1
module	bytes_limit ||| externals joblib	count=2
function	found and ||| line search	count=1
function	[function] pixel-to-pixel ||| [function]	count=1
function	estimators within a ||| estimators	count=1
function	fit the rfe ||| fit	count=1
function	batch [function_2] ||| [function_1] [function_2]	count=2
function	name ||| name	count=1
function	[function_1] decision ||| [function_2] [function_1]	count=1
function	step ||| step	count=1
function	[function_1] cpp files ||| [function_2] [function_1]	count=6
function	data ||| get	count=1
module	remove cache folders ||| joblib	count=1
class	the maximum likelihood estimator ||| empirical	count=1
function_arg	a single [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	block checkerboard [arg_2] ||| [function_1] [arg_2]	count=3
arg	extensions to ||| extensions	count=1
module	dataset classification ||| datasets	count=1
function_arg	[function_1] keep ||| [function_1] [arg_2]	count=2
function	decision function ||| decision function	count=9
arg	y_[i]) ** 2 ||| sample_weight y_min y_max	count=1
function	barycenter [function_2] ||| [function_1] [function_2]	count=1
function	memmap instance ||| reduce memmap	count=1
function_arg	[function_1] and ||| [function_1] estimator estimator [arg_2]	count=2
arg	cross-validated ||| cv	count=2
class	scaling features of ||| scaler	count=1
module	[module] in ||| [module]	count=3
module	remove cache ||| externals joblib	count=1
module	estimates the minimum covariance ||| covariance	count=1
function	curve auc from ||| auc	count=1
function	project ||| project	count=1
module	or not ||| feature_extraction	count=1
function_arg	[function_1] data parameters ||| [arg_2] [function_1]	count=2
function	absolute error regression ||| absolute error	count=4
function	lars path parameters ||| omp path	count=1
function_arg	training set [arg_2] ||| [function_1] [arg_2]	count=8
function	measure the ||| fowlkes mallows	count=1
class	list ||| parallel	count=1
module	the process ||| externals joblib	count=1
function	given cache [function_2] ||| [function_1] [function_2]	count=1
function	indices in ||| indices	count=1
class	the kernel ||| normalized kernel	count=1
function	low rank matrix with ||| low rank matrix	count=1
function	[function_1] element in ||| [function_2] [function_1]	count=3
arg	[arg] the appropriate ||| x [arg]	count=1
class	[class_1] process ||| [class_2] [class_1]	count=4
arg	for different probability thresholds ||| probas_pred pos_label	count=1
function_arg	the kddcup99 [arg_2] ||| [arg_2] [function_1]	count=2
function	precisions ||| check precisions	count=1
arg	validity ||| metric p metric_params	count=1
class	search ||| search	count=1
function	call wrapped ||| call	count=1
class	computes the ||| empirical covariance	count=1
function	column scaling ||| column	count=1
class	of min ||| min	count=1
function	insert a ||| insert	count=1
function	get the weights ||| get	count=1
class	kernel k ||| pairwise kernel	count=2
arg	matching pursuit ||| n_nonzero_coefs	count=1
function	samples from ||| sample	count=1
class	coefficient matrix to ||| mixin	count=1
arg	matrices ||| covariance_type n_features	count=1
function	[function_1] an mldata ||| [function_1] [function_2]	count=1
function	with a given cache ||| cache	count=1
function	to build a ||| build	count=1
arg	multi-class ||| y threshold	count=1
module	bytes_limit ||| joblib	count=1
class	the hash ||| memorized func	count=1
module_class	[module_1] grid ||| [module_1] parameter [class_2] len	count=2
function	of this ||| params	count=3
arg	a given mapping ||| y class_mapping	count=1
function_arg	this score [arg_2] ||| [arg_2] [function_1]	count=4
function	column ||| column	count=2
function	the sign ||| sign	count=1
arg	cross-validated estimates ||| cv	count=1
arg	data [arg] ||| [arg] w	count=1
arg	tokens ||| tokens	count=1
function_arg	[function_1] x ||| [function_1] diag [arg_2]	count=1
class	train ||| split	count=1
function	from prediction scores note ||| roc	count=1
module	on test ||| core	count=2
class	test ||| shuffle split	count=2
module	a which ||| externals	count=1
function	generate ||| val	count=1
function_arg	of neighbors [arg_2] ||| [function_1] graph [arg_2]	count=4
arg	point ||| y	count=1
arg	[arg_1] matrix ||| [arg_2] [arg_1]	count=1
arg	estimates for ||| y	count=1
function	introduces an 'l' ||| shape repr	count=1
function_arg	log probabilities [arg_2] ||| [arg_2] [function_1]	count=1
arg	a given dataset ||| scorer	count=1
function	terminal regions to median ||| terminal region	count=1
arg	a given dataset split ||| scorer	count=1
module	using ||| linear_model	count=7
class	the file ||| binary zlib file	count=3
arg	to pickler file handle ||| pickler	count=1
function	the submatrix corresponding to ||| submatrix	count=1
function	graph ||| img to graph	count=1
module	the process or ||| externals joblib	count=1
class	types ||| backend	count=1
function	compute minimum and ||| min	count=1
class	density model on ||| density	count=1
arg	data x with ||| x	count=1
function	feature ||| get feature	count=2
function	precision the precision ||| precision	count=1
function_arg	kddcup99 [arg_2] ||| [arg_2] [function_1]	count=2
arg	sparse and dense ||| x y sample_weight	count=1
function	predict the target ||| predict	count=1
arg	validation [arg_2] ||| [arg_2] [arg_1]	count=2
function	determine absolute sizes of ||| sizes	count=1
function	platform independent representation ||| shape	count=1
module	hash depending from it ||| externals	count=2
class	the model ||| base randomized linear model	count=1
function	tolerance which is ||| tolerance	count=1
function	text report [function_2] ||| [function_2] [function_1]	count=2
function	[function_1] first prime ||| [function_2] [function_1]	count=1
function	directory in which ||| output dir	count=1
arg	data and labels ||| x y	count=1
function	update it ||| update	count=1
function	single boost ||| boost	count=1
function	c and [function_2] ||| [function_1] [function_2]	count=2
module	returns ||| gaussian_process	count=20
module	metrics should use ||| metrics	count=1
arg	makes sure that ||| copy	count=1
class	gaussian process model ||| gaussian process	count=1
class	coefficient matrix to ||| sparse coef mixin	count=1
class	don't store the ||| memory	count=1
module	relationship between ||| metrics cluster	count=2
function	distances between the vectors ||| distances	count=2
function	and a name ||| func name	count=1
arg	cross-validated estimates for each ||| cv	count=1
arg	downloading it if necessary ||| data_home download_if_missing random_state	count=1
function	of a single sample ||| sample	count=1
arg	derived class ||| x resp	count=1
class	linear model ||| linear model	count=1
module	reducer function to a ||| externals joblib	count=1
arg	a subcluster from ||| subcluster new_subcluster1	count=1
function	each input data point ||| cross	count=1
function	weiszfeld [function_2] ||| [function_1] [function_2]	count=1
function	can also predict based ||| predict	count=1
class	generate train test ||| shuffle split	count=1
arg	based on ||| x connectivity n_clusters return_distance	count=1
class	we don't store ||| func	count=1
arg	an estimator ||| estimator	count=1
class	validation ||| lib svm	count=1
function	[function_1] strip ||| [function_2] [function_1]	count=3
arg	operation is meant to ||| data_folder_path slice_ color resize	count=1
arg	samples x to ||| x	count=2
arg	gradient and the ||| x y	count=2
function	to dense array ||| densify	count=1
arg	dataset and ||| y	count=1
function_arg	max on x ||| fit x	count=1
class	maximum ||| max	count=1
function	when using ||| repr	count=1
arg	sparse and dense inputs ||| x y	count=1
function	for c in (l1_min_c ||| c	count=1
arg	norm vector length ||| norm	count=1
function	decision function of ||| decision function	count=2
class	classifier valid ||| classifier	count=1
class	model parameters ||| model	count=1
class	[class_1] scaling of ||| [class_2] [class_1]	count=1
module_class	is in the ||| ensemble base	count=1
function	training set according to ||| fit predict	count=1
function	partially fit [function_2] ||| [function_1] [function_2]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] coordinate descent [arg_2]	count=16
function	the log ||| log	count=1
arg	for a given dataset ||| scorer	count=1
class	forest ||| forest	count=2
arg	w to ||| w ht l1_reg	count=1
class	[class_1] found ||| [class_2] [class_1]	count=40
function	kernel between ||| kernel	count=1
arg	test ||| y_test	count=2
class	kernel ||| kernel mixin	count=2
class	found ||| base search	count=2
class	[class_1] classifier valid ||| [class_2] [class_1]	count=4
function	[function_1] mldata ||| [function_1] [function_2]	count=1
arg	than ||| mode	count=2
function	deterministic output from svd ||| svd	count=1
module	the long type introduces ||| utils	count=1
function	graph of neighbors for ||| neighbors graph	count=2
function_arg	np dot [arg_2] ||| [function_1] w [arg_2]	count=1
arg	by its spectrum spectrum ||| spectrum n_samples n_features	count=1
function	optimal batch size ||| compute batch size	count=3
function	samples ||| samples	count=1
arg	subcluster from ||| subcluster	count=1
function	of neighbors for points ||| neighbors	count=2
function	estimates for each ||| val	count=1
function	the cholesky decomposition ||| cholesky	count=1
function	[function_1] of neighbors ||| [function_2] [function_1]	count=16
arg	data ||| y	count=4
module	model using ||| linear_model	count=5
arg	set [arg] ||| [arg]	count=1
arg	and the ||| y	count=2
arg	mean and ||| y	count=1
function	[function_1] binary classifier ||| [function_2] [function_1]	count=1
function	the given param_grid ||| get param iterator	count=1
function	under the model ||| score	count=1
function	reconfigure the ||| configure	count=1
function	[function] set ||| [function]	count=6
module	model ||| decomposition	count=2
function	inverse the ||| inverse	count=1
module	hash depending ||| joblib	count=2
class	linear ||| sgdregressor	count=2
function	file object ||| file	count=2
function	param ||| include self	count=2
arg	a random sample from ||| size	count=1
arg	binary classification ||| y_true y_score pos_label	count=1
arg	1 0 if y ||| y	count=1
class	between two covariance ||| covariance	count=1
function	the curve auc ||| auc score	count=1
function	[function_1] the iris ||| [function_1] [function_2]	count=1
module	are selected ||| feature_selection	count=1
function	generate ||| cross val predict	count=2
function	custom [function] to ||| [function]	count=1
function	compute minimum and maximum ||| min max axis	count=1
arg	and y ||| y gamma	count=2
arg	gradient and the ||| y	count=2
function_arg	[function_1] this kernel ||| [arg_2] [function_1]	count=2
class	labels ||| classifier	count=1
function	[function_1] parameters ||| [function_2] [function_1]	count=6
class	validation ||| base lib svm	count=1
function	sparse ||| make sparse	count=1
function_arg	[function_1] given dataset ||| [arg_2] [function_1]	count=2
class	generate ||| shuffle split	count=2
arg	returns the transformed data ||| w h	count=1
function	message on the ||| msg init	count=1
arg	x to ||| x	count=2
function	set the diagonal ||| set diag	count=3
module	we don't store the ||| joblib	count=2
arg	apply transforms and ||| x y	count=1
function	the lfw [function_2] ||| [function_1] [function_2]	count=8
function	get the weights from ||| get	count=1
arg	[arg_1] y t ||| [arg_2] [arg_1]	count=1
function	estimate model parameters ||| fit	count=1
class	don't store ||| func	count=1
arg	x as [arg_2] ||| [arg_2] [arg_1]	count=2
module	under a size ||| externals joblib	count=1
arg	and perform dimensionality reduction ||| y	count=1
function	the breakdown [function_2] ||| [function_2] [function_1]	count=1
function	to update [function_2] ||| [function_1] [function_2]	count=2
function	finds seeds ||| bin seeds	count=1
class	grid ||| parameter grid	count=1
function	create all the covariance ||| distribute covar matrix to match covariance	count=1
module	type introduces an 'l' ||| utils	count=1
class	for parallel processing this ||| parallel	count=1
function	log probabilities ||| log proba	count=2
module	a list of ||| utils	count=1
function	read up to ||| read	count=1
arg	filename ||| filename	count=1
arg	the gp prior ||| x return_std return_cov	count=1
arg	[arg_1] n-class ||| [arg_1] [arg_2]	count=1
function_arg	[function_1] is ||| [function_1] [arg_2]	count=1
arg	transforms and ||| y sample_weight	count=1
class	an array using ||| array wrapper	count=1
arg	and compute scores ||| y	count=2
function	on the training ||| fit	count=1
class	determine ||| parallel backend	count=1
function	used to compute log ||| log	count=1
function	precision the precision is ||| precision	count=1
arg	for x using the ||| x	count=1
class	not enabled for ||| robust	count=1
function_arg	binary classifier [arg_2] ||| [arg_2] [function_1]	count=2
function	log probability for ||| log multivariate	count=1
module	selected features ||| feature_selection	count=3
class	the hash depending from ||| memory	count=1
arg	mask to edges weighted ||| mask edges weights	count=1
arg	returns n_neighbors of ||| n_neighbors return_distance	count=1
function	each input data ||| cross	count=1
function	of edges for ||| make edges	count=1
arg	vector x ||| x	count=2
class	the voting [class_2] ||| [class_2] [class_1]	count=4
function	[function_1] sample ||| [function_2] [function_1]	count=1
arg	alphas [arg] best ||| [arg]	count=1
arg	clusterings ||| labels_true labels_pred contingency	count=1
function	find the median ||| median	count=1
arg	a for a ||| a	count=1
function	the model and transform ||| transform	count=1
class	store ||| memorized	count=1
module_class	the em algorithm ||| mixture gmmbase	count=1
function_arg	[function_1] sorted array ||| [function_1] [arg_2]	count=2
function	updates terminal regions to ||| terminal	count=1
function_arg	the range [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg_1] by ||| [arg_1] [arg_2]	count=1
function	directory ||| output dir	count=1
function	predict ||| decision function	count=2
arg	case method='lasso' is ||| y xy gram	count=1
function	single sample ||| sample	count=1
class	of the ||| base	count=1
function	data home cache ||| clear data home	count=2
arg	of matrices ||| covariance_type	count=1
function	'l' ||| repr	count=1
function	method for updating terminal ||| update terminal	count=1
function	huber [function_2] ||| [function_1] [function_2]	count=4
function	path with ||| enet path	count=1
function	fit a binary ||| fit binary	count=2
function	[function_1] linear embedding ||| [function_2] [function_1]	count=3
function	matrix factorization nmf ||| factorization	count=1
function	[function_1] the directory ||| [function_1] [function_2]	count=1
class	polynomial ||| polynomial	count=1
module	hash depending from ||| joblib	count=2
arg	validity of ||| x metric p metric_params	count=1
arg	intercept for specified layer ||| layer	count=1
function	multilabel ||| make multilabel	count=1
class	warnings ||| ignore warnings	count=1
function	class [function_2] ||| [function_2] [function_1]	count=3
class	matrix ||| coef	count=1
function	the image from all ||| from	count=1
function	mean squared logarithmic ||| mean squared	count=1
class	inverse ||| agglomeration transform	count=1
arg	each pair [arg] ||| [arg]	count=1
function	the barycenter ||| barycenter	count=1
arg	target variable ||| x y discrete_features	count=2
function	explained variance regression score ||| explained variance	count=1
function	gaussian and label ||| gaussian	count=1
function	fit the model by ||| fit	count=1
module	types to ||| externals joblib	count=1
arg	is ||| y_true	count=1
function_arg	transform the [arg_2] ||| [function_1] [arg_2]	count=3
function_arg	[function_1] matrices from ||| [function_1] type tied_cv [arg_2]	count=4
module	types ||| externals	count=1
arg	exceptions ||| exceptions	count=1
class	test ||| base shuffle	count=1
arg	according to ||| sample_weight	count=4
function	with sparse ||| sparse	count=1
function	return ||| shape repr	count=1
class	documents to [class] matrix ||| [class]	count=1
function	cluster ||| cluster	count=1
function	the lfw people dataset ||| lfw people	count=1
arg	as subfolder names ||| container_path description	count=1
arg	classifier on x ||| x	count=1
class	the ||| covariance	count=1
module	dataset ||| datasets	count=3
function	the median of ||| get median	count=1
function	finds seeds for ||| bin seeds	count=1
class	list of exception ||| parallel backend base	count=1
function	transform on the ||| transform	count=1
arg	and compute scores ||| x y classes	count=2
arg	for a given ||| x y scorer	count=1
function	build a text report ||| report	count=1
function	long type introduces ||| repr	count=1
class	exception types ||| parallel backend base	count=1
function	from ||| from	count=2
function	data point ||| cross	count=1
function	[function_1] and maximum ||| [function_1] [function_2]	count=2
function_arg	check the [arg_2] ||| [arg_2] [function_1]	count=4
function	[function_1] from a ||| [function_2] [function_1]	count=6
module_class	transform [module_1] [class_2] matrix ||| [module_1] [class_2] vectorizer transform x y	count=2
function	can also predict ||| predict	count=1
function	shutdown the process ||| terminate	count=1
function	each input data point ||| val predict	count=1
function	cohen's kappa a ||| kappa	count=1
arg	a set of points ||| metric	count=1
arg	[arg_1] in the ||| [arg_1] [arg_2]	count=2
function	integer indices [function_2] ||| [function_2] [function_1]	count=2
arg	input ||| y	count=1
function	optimal batch ||| compute batch	count=2
class	[class_1] the grid ||| [class_2] [class_1]	count=2
class	to the cache ||| memorized	count=1
class	depending ||| func	count=1
function	path length ||| path length	count=4
class	the file ||| zlib file	count=3
function	folder ||| delete folder	count=2
function	shortest path length ||| source shortest path length	count=1
function	information ||| info	count=2
module	propagation [module] of ||| [module]	count=1
function	model and transform with ||| transform	count=1
function	binary ||| average binary score	count=1
arg	samples in x ||| x y	count=1
function	[function_1] reduced likelihood ||| [function_2] [function_1]	count=2
function	log of [function_2] ||| [function_1] [function_2]	count=2
arg	and compute ||| x y	count=2
function	the wild lfw pairs ||| fetch lfw pairs	count=1
function	[function_1] sign of ||| [function_1] [function_2]	count=2
function	a read ||| read	count=1
class	the cache ||| memorized func	count=1
class	the oracle approximating shrinkage ||| oas	count=1
arg	is positive-definite ||| covariance_type	count=1
function	is not found ||| line search	count=1
function_arg	compressor matching fileobj ||| detect compressor fileobj	count=1
class	the backend ||| parallel backend	count=1
arg	laplacian ||| laplacian	count=1
arg	binary classification ||| y_true	count=2
class	[class_1] process regression ||| [class_1] [class_2]	count=4
arg	computed between each pair [arg_1] [arg_2] ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=1
arg	matrices w [arg_2] ||| [arg_2] [arg_1]	count=4
arg	estimates ||| x y	count=1
function	a ||| shape repr	count=1
function	edges for a ||| make edges	count=1
arg	perform the ||| responsibilities params	count=1
module	memory ||| externals joblib	count=1
function	[function_1] validity ||| [function_1] [function_2]	count=1
function	graph of ||| grid to graph	count=1
function	remove ||| reduce	count=1
class	[class] if necessary ||| [class]	count=6
arg	of csgraph inputs ||| csgraph	count=1
function_arg	[function_1] x w ||| [function_1] [arg_2]	count=1
function	ravel [function] or ||| [function] or	count=1
function	rank matrix with bell-shaped ||| rank matrix	count=1
arg	with respect to coefs ||| n_samples activations deltas	count=1
function	cholesky decomposition of ||| log det cholesky	count=1
function	the long type introduces ||| shape	count=1
arg	non-negative matrices w ||| w	count=1
class	types to ||| parallel backend	count=1
module_class	number of [module_1] [class_2] ||| [module_1] parameter [class_2] len	count=1
class	of max ||| max	count=1
module	process ||| externals	count=1
function	fit a [function_2] ||| [function_1] ovo [function_2]	count=1
function	the precision is ||| precision	count=1
arg	:ref user guide <mean_squared_log_error> ||| y_true y_pred sample_weight multioutput	count=1
module	thread pool ||| externals joblib	count=1
class	get ||| randomized linear model	count=1
function	importances the higher ||| importances	count=2
function	name for the ||| name	count=1
module	types to ||| externals	count=1
module	pickling ||| externals joblib	count=1
arg	corresponds to ||| y_true y_score	count=1
class	model with passive ||| passive	count=2
class	fit ||| multi output estimator	count=1
arg	and returns the labels ||| y	count=1
arg	data point ||| x y	count=1
function	for the california ||| california	count=1
function	function used to fit ||| fit	count=1
function	[function_1] function ||| [function_1] [function_2]	count=23
class	the voting classifier ||| voting classifier	count=2
class	compute ||| base	count=1
function	reduced likelihood [function_2] ||| [function_2] [function_1]	count=5
function	gap ||| gap	count=1
function	an 'l' suffix when ||| shape repr	count=1
function	logarithm of the determinant ||| det	count=1
arg	the [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=2
arg	data point ||| estimator x	count=1
arg	and ||| x y	count=40
function	terminal regions to median ||| terminal	count=1
class	linear [class_2] ||| [class_2] [class_1]	count=2
function	the logistic ||| inplace logistic	count=1
function	factorization nmf ||| negative factorization	count=1
class	the array corresponding ||| numpy array	count=2
function	[function] of ||| wishart log [function]	count=3
function	extracts patches ||| patches	count=1
module	model from data ||| decomposition	count=1
arg	the data [arg] ||| [arg] w	count=1
function	of edges ||| edges	count=1
function	number of cpus ||| cpu count	count=1
class	folders ||| memory	count=1
class	max [class_2] ||| [class_1] [class_2]	count=2
function	image from all of ||| from	count=1
arg	given type [arg_2] ||| [arg_1] [arg_2]	count=1
module_class	[module_1] determinant ||| [module_1] [class_2]	count=1
function_arg	[function_1] version of ||| [function_1] read file [arg_2]	count=2
class	with all sets ||| search cv	count=1
function	incremental mean [function_2] ||| [function_1] [function_2]	count=1
function	mean absolute error ||| mean absolute error	count=3
module	with joblib ||| joblib	count=1
function	update nmf ||| update	count=1
arg	actual fitting performing ||| parameter_iterable	count=1
module	estimate covariance with ||| covariance	count=1
function	make sure that ||| check	count=1
arg	the samples x ||| x	count=5
module_class	[module_1] polynomial ||| [module_1] [class_2]	count=2
arg	data samples in x ||| x y	count=1
function_arg	[function_1] data in ||| [arg_2] [function_1]	count=1
function	[function_1] single binary ||| [function_1] ovo [function_2]	count=2
function	by scaling ||| scale	count=1
function	[function_1] loss ||| [function_2] [function_1]	count=9
class	convert coefficient matrix to ||| coef	count=1
class	convert coefficient ||| sparse coef	count=1
class	generate train ||| base shuffle	count=1
arg	finds ||| n_neighbors return_distance	count=1
arg	dataset and ||| x y	count=1
function	extract the [function_2] ||| [function_2] [function_1]	count=1
function_arg	diagonal of [arg_2] ||| [arg_2] [function_1]	count=3
arg	of a cross-validated ||| y cv	count=1
arg	computes the ||| w x y alpha	count=2
arg	the binary classification task ||| y_true y_score	count=2
function	the [function] ||| [function]	count=13
function	the one-vs-one ||| one vs one	count=1
function	cosine [function_2] ||| [function_1] [function_2]	count=2
arg	of samples x ||| x y sample_weight	count=1
function_arg	row-wise [arg_2] ||| [function_1] x [arg_2]	count=4
function	[function_1] element in ||| [function_1] [function_2]	count=3
function	run fit ||| fit grid	count=4
function	compute the median of ||| median	count=1
function	computes the paired ||| paired	count=1
function	slices [function_2] ||| utils gen [function_2] [function_1]	count=1
arg	the samples x to ||| x	count=2
arg	each input data ||| estimator x y	count=1
module_class	[module_1] with passive ||| [module_1] [class_2]	count=4
function	of [function] ||| score [function]	count=1
arg	squared euclidean ||| squared	count=1
arg	if y [arg_2] ||| [arg_2] [arg_1]	count=1
function	likelihood function ||| likelihood function	count=4
function	for each input data ||| cross val	count=1
class	[class_1] the kernel ||| [class_1] [class_2]	count=1
class	coefficient matrix ||| mixin	count=1
function_arg	[function_1] [arg_2] ||| [function_1] estimator estimator [arg_2]	count=6
arg	validity of ||| metric p metric_params	count=1
module	attempts to retrieve a ||| externals	count=1
function_arg	normalize rows [arg_2] ||| [function_1] [arg_2]	count=1
arg	iterable [arg] to a ||| [arg]	count=1
arg	is meant to be ||| data_folder_path slice_ color resize	count=1
function	minimum ||| min	count=1
function	given format ||| format	count=1
function	case of a logistic ||| logistic	count=1
arg	parameters theta ||| theta	count=1
class	[class_1] ridge regression ||| [class_1] [class_2]	count=1
function	[function_1] [function_2] ||| [function_1] support [function_2]	count=1
function_arg	[function_1] corresponds ||| [function_1] [arg_2]	count=1
class	hash depending from ||| func	count=1
function	first prime [function_2] ||| [function_1] [function_2]	count=3
function	extracts patches of any ||| patches	count=1
function	representation of ||| shape repr	count=1
function	checkerboard ||| checkerboard	count=1
module	and return it ||| externals	count=1
function	coverage error measure compute ||| coverage error	count=1
arg	data ||| estimator x y	count=1
function	predict labels ||| predict	count=1
class	given arguments ||| memorized func	count=1
function	[function_1] first prime ||| [function_1] [function_2]	count=1
class	[class_1] the file ||| [class_1] [class_2]	count=1
function	for full covariance ||| normal density full	count=1
arg	data ||| estimator	count=1
class	gaussian [class_2] ||| [class_2] [class_1]	count=8
arg	estimates for each input ||| estimator x	count=1
arg	elastic net ||| l1_ratio	count=1
function	randomized [function_2] ||| [function_2] [function_1]	count=2
function	the laplacian [function_2] ||| [function_1] [function_2]	count=2
function_arg	finds seeds [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	update [arg_2] ||| [function_1] [arg_2]	count=3
class	best found parameters ||| base search cv	count=4
function_arg	multinomial loss [arg_2] ||| [arg_2] [function_1]	count=3
function	element of numpy ||| element	count=1
class	[class_1] process regression ||| [class_2] [class_1]	count=4
class	the search ||| base search cv	count=1
arg	a subcluster ||| subcluster	count=1
function	estimates for ||| val	count=1
function	kernel ||| kernel	count=2
module	took to [module] batch ||| [module]	count=1
arg	of x for later ||| x y	count=1
module	compute ||| manifold	count=1
class	[class_1] format ||| [class_1] [class_2]	count=2
arg	axis ||| x axis	count=2
arg	eigenvalues and eigenvectors ||| m sigma	count=1
function	number of ||| effective n	count=1
function_arg	diagonal [arg_2] ||| [function_1] [arg_2]	count=2
arg	the function ||| func	count=1
function	cpp [function_2] ||| [function_2] [function_1]	count=1
class	warnings ||| warnings	count=1
function	for each input data ||| cross	count=1
function	element in the specified ||| in	count=1
function	full lars path parameters ||| path	count=1
function_arg	[function_1] a filename ||| [function_1] [arg_2]	count=2
arg	to the normalized laplacian ||| eigen_solver	count=1
arg	and class ||| w x y	count=1
function_arg	[function_1] job ||| [function_1] [arg_2]	count=1
function	sample images for image ||| sample images	count=1
class	the kernel ||| kernel operator	count=1
function	neighbors from ||| neighbors	count=1
arg	and a ||| x y	count=1
function	laplacian [function_2] ||| [function_1] [function_2]	count=2
arg	to data matrix x ||| x	count=1
module	too rare or ||| feature_extraction	count=1
function_arg	text files [arg_2] ||| [function_1] container_path description [arg_2]	count=1
function	the range ||| randomized range finder	count=1
function	[function_1] likelihood function ||| [function_2] [function_1]	count=10
arg	n_components ||| n_components	count=1
function	euclidean or frobenius norm ||| norm	count=1
class	in parallel ||| parallel backend	count=1
arg	first [arg] left ||| [arg]	count=1
arg	for each input ||| estimator x	count=1
arg	[arg_1] python object ||| [arg_2] [arg_1]	count=2
function	a single sample ||| sample	count=1
function	sparse uncorrelated design ||| sparse uncorrelated	count=1
arg	h whose product approximates ||| h	count=1
function	[function_1] matrix shrunk ||| [function_2] [function_1]	count=4
function_arg	on x by ||| fit x y	count=1
function	an array array of ||| array	count=1
class	[class_1] factor of ||| [class_1] [class_2]	count=5
arg	y t ||| y	count=1
function	feature [function] ||| feature [function]	count=6
arg	from a ||| a size replace p	count=1
class	[class] matrix ||| [class]	count=1
arg	:ref user guide <classification_report> ||| y_true y_pred labels target_names	count=1
function	random multilabel [function_2] ||| [function_1] [function_2]	count=2
function_arg	read up [arg_2] ||| [arg_2] [function_1]	count=1
function	parameters ||| parameters	count=1
arg	x from y along ||| x z reg	count=1
module	covariance model according ||| covariance	count=1
arg	set x and returns ||| x y	count=1
arg	job ||| estimators estimators_features	count=1
function	feature names ||| feature names	count=2
arg	input data point ||| estimator x	count=1
arg	pred ||| pred	count=1
function	shortest path ||| source shortest path	count=1
function	function ||| parallel decision function	count=1
function	state ||| state	count=1
function	getter for the ||| get	count=1
function	absolute sizes of training ||| train sizes	count=1
class	convert coefficient matrix ||| sparse coef mixin	count=1
function_arg	[function_1] validity of ||| [function_1] [arg_2]	count=1
arg	and scale the ||| y	count=1
module	avoid the hash depending ||| joblib	count=2
function_arg	[function_1] x ||| [function_1] spherical [arg_2]	count=1
class	data-dependent state [class] ||| [class]	count=3
arg	given autocorrelation parameters theta ||| theta	count=1
class	labels ||| classifier mixin	count=2
arg	distribution ||| mean covar covariance_type	count=1
function_arg	kernel between x ||| kernel x	count=2
function_arg	[function_1] w h ||| [function_1] x [arg_2]	count=1
arg	and ||| y classes	count=2
arg	n_jobs ||| y func n_jobs	count=1
function	cohen's kappa ||| kappa	count=1
module	sequence ||| feature_extraction	count=1
class	decision ||| decision	count=1
arg	is ||| y_true y_pred beta	count=1
function_arg	[function_1] [arg_2] ||| [function_1] n_samples n_features [arg_2]	count=1
arg	w h whose product ||| w h	count=1
arg	samples x to the ||| x	count=2
class	hash depending from it ||| memorized func	count=1
arg	kwargs using ||| kwargs	count=1
class	belongs ||| mean shift	count=1
arg	for each ||| x	count=1
arg	elastic net parameter search ||| y xy l1_ratio	count=1
class	convert coefficient ||| mixin	count=1
function	patches of ||| extract patches	count=1
class	according ||| quadratic discriminant analysis	count=1
function	graph ||| graph	count=7
class	[class_1] distribution ||| [class_2] [class_1]	count=2
arg	from features ||| x y sample_weight	count=1
function	we can also predict ||| predict	count=1
function	for each input data ||| cross val predict	count=1
function	function for the given ||| function	count=1
module	don't ||| joblib	count=2
function_arg	[function_1] structure ||| [arg_2] [function_1]	count=5
function_arg	[function_1] matrices ||| [function_1] type tied_cv [arg_2]	count=4
function	fit a single ||| build trees	count=1
function	a given cache key ||| cache key	count=1
class	the density model on ||| density	count=1
function	multiprocessing ||| if safe multiprocessing	count=1
arg	w [arg_2] ||| [arg_2] [arg_1]	count=5
arg	input ||| estimator x	count=1
function	the one-vs-one multi ||| one vs one	count=1
function	an unfitted ||| unfitted	count=1
arg	regularization ||| pos_class cs	count=1
arg	x which should ||| x	count=1
class	document-term ||| hashing	count=1
module	force ||| externals joblib	count=1
arg	identify uniquely python ||| obj hash_name coerce_mmap	count=1
arg	[arg_1] and y ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=6
arg	[arg_1] and returns ||| [arg_1] [arg_2]	count=4
function	dual gap convergence criterion ||| dual gap	count=1
function	the wild lfw ||| lfw	count=1
function_arg	[function_1] according to ||| [arg_2] [function_1]	count=2
function	[function_1] absolute error ||| [function_1] [function_2]	count=2
function	path parameters ||| path	count=1
arg	given training data and ||| y	count=1
function	[function_1] 1d ||| [function_1] [function_2]	count=1
module	don't store ||| externals joblib	count=2
arg	the lrd of ||| distances_x neighbors_indices	count=1
function	multilabel classification problem ||| make multilabel classification	count=2
function	[function_1] file object ||| [function_1] [function_2]	count=3
class	by the ||| backend base	count=1
function	predict posterior probability of ||| predict proba	count=1
arg	according to [arg_2] ||| [arg_2] y [arg_1]	count=2
arg	arguments of a function ||| function	count=1
arg	data and ||| x y	count=5
arg	membership ||| z	count=1
arg	from ||| sample_weight	count=1
module	with the generative ||| decomposition	count=1
function	the ||| get	count=2
function	class weights ||| compute class	count=1
arg	connectivity matrix ||| x connectivity n_components	count=1
function	trace of np dot ||| trace dot	count=1
module	classification dataset is constructed ||| datasets	count=1
function	compute incremental mean and ||| incr mean	count=1
class	for ||| empirical covariance	count=2
function_arg	probabilities [arg_2] ||| [function_1] distances [arg_2]	count=2
module	separating hyperplane ||| svm	count=1
module	in ||| externals	count=1
function	trace of ||| trace	count=1
arg	the derived ||| x resp	count=1
class	scaler ||| min max scaler	count=1
function	convert ||| ensure	count=1
class	we don't ||| memorized func	count=1
class	search over ||| search cv	count=1
function	online ||| partial	count=3
function	is ||| is	count=7
arg	of this ||| deep	count=2
function	image from ||| from	count=1
function	slices containing ||| batches	count=1
function	in svmlight format ||| svmlight	count=1
function	on ||| predict	count=1
function	cosine [function_2] ||| [function_2] [function_1]	count=2
function	precision matrix with ||| get precision	count=1
function	binary classification ||| binary	count=1
arg	perform the ||| responsibilities params min_covar	count=1
arg	categories ||| categories	count=1
arg	and transforms ||| x y	count=1
class	with the best ||| cv	count=5
class	[class_1] file ||| [class_1] [class_2]	count=1
function	[function_1] [function_2] to ||| [function_2] [function_1]	count=1
class	of exception types to ||| base	count=1
arg	by arpack or randomized ||| svd_solver	count=1
arg	compute decisions within ||| estimators_features x	count=1
class	train test ||| base shuffle	count=1
function_arg	[function_1] and q_ijs ||| [function_1] error [arg_2]	count=4
function	of k-neighbors ||| kneighbors	count=1
arg	x as ||| x	count=3
arg	by a random ||| n_samples eps	count=1
arg	[arg_1] - pred ||| [arg_1] [arg_2]	count=4
arg	does not need to ||| x y residual	count=1
function	factorization nmf ||| non negative factorization	count=1
class	matrix to ||| coef mixin	count=1
module	points [module] the ||| [module]	count=1
function	sparse ||| sparse	count=5
module	to this ||| joblib	count=1
function	build ||| parallel build	count=1
function	based on the ||| from	count=1
function	the cholesky decomposition of ||| cholesky	count=1
function_arg	distances between [arg_2] ||| [arg_2] [function_1]	count=10
function	init ||| init	count=2
function_arg	[function_1] [arg_2] ||| [function_1] fileobject [arg_2]	count=1
function	fit estimator ||| fit	count=1
arg	groups ||| groups	count=1
arg	weights [arg] ||| [arg]	count=3
arg	[arg_1] returns ||| [arg_1] [arg_2]	count=2
function	break the pairwise matrix ||| parallel pairwise	count=1
function	list of feature ||| feature	count=1
function	leaves of the ||| get leaves	count=1
arg	matrices w [arg_2] ||| [arg_1] [arg_2]	count=4
arg	computed between each pair [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
function_arg	training [arg_2] ||| [arg_2] [function_1]	count=10
function	approximates the range of ||| range finder	count=1
function	compute the median of ||| get median	count=1
function	spherical wishart distribution parameters ||| wishart spherical	count=1
arg	validity ||| x metric p metric_params	count=1
function	random ||| random choice	count=1
function_arg	[function_1] x y ||| [function_1] [arg_2]	count=16
function_arg	[function_1] of theta ||| laplace log marginal [function_1] [arg_2]	count=1
function	[function_1] maximum ||| [function_1] [function_2]	count=2
arg	apply a transform ||| transform	count=1
function	of [function] ||| effective n [function]	count=6
function	input data ||| cross val	count=1
arg	w to minimize ||| x w ht l1_reg	count=1
function	log-probabilities for ||| log proba	count=2
arg	set x and ||| x y	count=2
arg	and a set ||| y axis	count=1
arg	transforms and ||| x y	count=1
arg	corresponds to the ||| y_true y_score	count=1
function	finds indices in ||| matching indices	count=1
arg	normalized laplacian ||| eigen_solver	count=1
arg	x from y along ||| x z	count=1
function	predict ||| clusterer compute labels predict	count=1
function	[function_1] cosine ||| [function_2] [function_1]	count=3
class	depending from it ||| memorized	count=1
module	the hash depending from ||| externals joblib	count=2
function	[function_1] the directory ||| [function_2] [function_1]	count=1
function	[function_1] image from ||| [function_2] [function_1]	count=1
function	exception types to ||| get	count=1
function_arg	length [arg_2] ||| [arg_2] [function_1]	count=3
function	returns the submatrix corresponding ||| get submatrix	count=1
arg	using x [arg_2] ||| [arg_2] [arg_1]	count=1
function	parameters of this estimator ||| params	count=1
function	binarize ||| binarize	count=1
function	single binary ||| predict binary	count=1
arg	is inefficient ||| y classes	count=1
arg	norm vector length ||| norm axis	count=1
function_arg	to x using ||| transform x	count=1
arg	of a classification ||| y_true	count=1
function	compute non-negative matrix factorization ||| negative factorization	count=1
function	compute class covariance matrix ||| class cov	count=1
arg	the binary classification ||| y_true y_score average sample_weight	count=1
class	bytes_limit ||| memory	count=1
module_class	the [module_1] [class_2] ||| [module_1] [class_2]	count=2
arg	implement a single ||| iboost x y sample_weight	count=2
function	minimum and [function_2] ||| [function_1] [function_2]	count=1
function	matrix factorization nmf find ||| factorization	count=1
arg	for validation ||| dtype	count=1
function	curve auc ||| auc score	count=1
arg	[arg_1] kwargs using ||| [arg_2] [arg_1]	count=3
function	sample weights by class ||| sample	count=1
function	the lfw ||| fetch lfw	count=2
arg	a given dataset ||| x y scorer	count=1
function	breakdown point ||| breakdown point	count=2
arg	as training data ||| xy	count=1
arg	values ||| x y train	count=2
function	a [function_2] ||| [function_1] [function_2]	count=1
function_arg	[function_1] distribution ||| [function_1] [arg_2]	count=3
function_arg	[function_1] data ||| [function_1] [arg_2]	count=3
function	compute minimum ||| min	count=1
class	kernel matrix ||| kernel	count=1
function	type ||| shape	count=1
function	sets of biclusters ||| consensus score	count=1
function	the kernel is stationary ||| is stationary	count=1
function	binarize labels in a ||| label binarize	count=1
class	cache ||| memorized	count=1
class	passive [class_2] ||| [class_1] [class_2]	count=2
function	estimate sample weights ||| compute sample	count=1
function	paired distances between ||| paired distances	count=2
function	[function_1] information ||| [function_2] [function_1]	count=3
function	disk ||| disk	count=1
function_arg	normalize [arg_2] ||| [arg_2] [function_1]	count=4
arg	corresponds ||| y_true y_score	count=1
function_arg	helper to [arg_2] ||| [function_1] [arg_2]	count=1
function	the precision matrix ||| get precision	count=1
function	strip the ||| strip	count=1
function	data ||| val predict	count=2
arg	and y read more ||| y	count=1
class	of classification ||| calibrated classifier	count=1
function	posterior probability ||| proba	count=1
function_arg	[function_1] structure for ||| [function_1] [arg_2]	count=5
function_arg	[function_1] w h ||| [arg_2] [function_1]	count=1
arg	random sample from a ||| a size replace p	count=1
class	or thread pool ||| multiprocessing backend	count=2
class	for the voting classifier ||| voting classifier	count=1
function	[function] segment ||| [function]	count=3
arg	derived ||| resp	count=1
arg	of a classification ||| y_true y_pred	count=1
function	[function_1] regions ||| [function_1] [function_2]	count=3
module	avoid ||| joblib	count=2
class	with the ||| base	count=1
function	the given param_grid ||| param iterator	count=1
function	ovr ||| ovr	count=1
function_arg	[function_1] a ||| [arg_2] [function_1]	count=6
function	column [function] of the ||| get [function]	count=1
class	binarizer ||| binarizer	count=1
class	get ||| base randomized linear model	count=1
arg	given type ||| type	count=1
function	a wishart ||| wishart	count=1
arg	sparse and dense inputs ||| y sample_weight random_state	count=1
arg	of y and ||| y	count=1
arg	and dense inputs ||| y sample_weight	count=1
function_arg	[function_1] in n_jobs ||| [arg_2] [function_1]	count=3
function	estimate model parameters with ||| fit	count=1
class	list ||| backend base	count=2
class	then return ||| rfe	count=1
arg	given ||| x y scorer	count=1
function	[function_1] stationary ||| [function_1] [function_2]	count=7
arg	set [arg] appropriately and ||| [arg]	count=1
function	log ||| predict log	count=2
arg	of the loss ||| loss	count=1
function	directory in which are ||| dir	count=1
module	classification dataset is ||| datasets	count=1
arg	u ||| u	count=1
module	the process ||| externals	count=1
function	callable case for ||| pairwise callable	count=1
arg	individually to unit ||| axis copy	count=1
function	call with ||| format call	count=1
function	list ||| get	count=1
module_class	covariance [class_2] ||| [module_1] [class_2]	count=4
class	from ||| memorized func	count=1
function	based on ||| from	count=1
arg	estimates for each ||| y	count=1
arg	the loss ||| loss	count=1
module	for each input data ||| core	count=1
class	linear model parameters ||| sgdregressor	count=2
class	max [class_2] ||| [class_2] [class_1]	count=2
class	with the given arguments ||| memorized func	count=1
arg	points in ||| mode	count=1
function	retrieve the leaves ||| leaves	count=1
function	class weights for ||| class	count=1
arg	with self ||| x_test y	count=1
class	the [class] ||| [class]	count=5
function_arg	[function_1] and class ||| [arg_2] [function_1]	count=2
class	whether the kernel ||| stationary kernel mixin	count=1
class	the kernel [class_2] ||| [class_1] [class_2]	count=1
function	the range ||| range	count=1
function_arg	[function_1] x with ||| [function_1] precomp distr [arg_2]	count=1
function	range ||| range	count=1
function_arg	neighbors [arg_2] ||| [function_1] [arg_2]	count=1
arg	note this implementation ||| sample_weight	count=1
function	calculate mean update ||| mean	count=1
arg	capture the ||| check_pickle	count=1
arg	least-squares solution to a ||| a	count=1
function	[function_1] sample images ||| [function_1] [function_2]	count=1
arg	input data ||| estimator x	count=1
function	handle the callable case ||| callable	count=1
function	[function_1] update nmf ||| [function_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] x w [arg_2]	count=2
class	store the ||| func	count=1
arg	output for x ||| x y	count=1
function	terminal ||| terminal region	count=2
function	[function_1] classification ||| [function_1] [function_2]	count=3
module	exception types to ||| externals joblib	count=1
arg	returns n_neighbors ||| x n_neighbors return_distance	count=1
arg	is ||| y_true y_pred	count=1
function	evaluate a score ||| score	count=2
function	sample weights by ||| compute sample	count=1
class	max absolute value of ||| max abs	count=1
class	coefficient matrix ||| sparse coef mixin	count=1
function	[function_1] validity of ||| [function_1] [function_2]	count=1
arg	from source to all ||| graph source	count=1
function_arg	probabilities [arg_2] ||| [function_1] nn [arg_2]	count=1
arg	column class distributions parameters ||| classes class_probability random_state	count=1
function	huber loss [function_2] ||| [function_2] [function_1]	count=3
arg	data parameters ||| y sample_weight	count=1
function	with sparse [function_2] ||| [function_1] [function_2]	count=1
function	[function_1] slices containing ||| [function_2] [function_1]	count=1
class	train test ||| shuffle	count=1
function	text report showing ||| report	count=1
arg	include_self ||| x include_self	count=1
arg	derivatives with respect to ||| activations deltas	count=1
class	using the gaussian process ||| gaussian process	count=1
class	of the scaler ||| min max scaler	count=1
arg	transforms features ||| feature_range axis copy	count=1
function	of ||| shape repr	count=1
arg	list of regularization ||| x y pos_class cs	count=1
function	generate names ||| name	count=1
arg	linear system of equations ||| b damp atol	count=1
function	names from ||| names	count=1
function	of the logistic ||| logistic	count=1
class	to avoid the hash ||| memory	count=1
function_arg	[function_1] lrd of ||| [arg_2] [function_1]	count=3
function	approximates the range ||| range	count=1
function	an 'l' suffix when ||| shape	count=1
arg	is meant ||| index_file_path data_folder_path slice_ color	count=1
function_arg	mask [arg_2] ||| [arg_2] [function_1]	count=2
function	graph of neighbors ||| radius neighbors graph	count=6
function_arg	covariance [arg_2] ||| [arg_2] [function_1]	count=3
function	descent fit is ||| fit	count=1
function	graph of k-neighbors ||| kneighbors graph	count=1
class	the mixture parameters ||| bayesian gaussian mixture	count=1
arg	of compute_labels ||| name clusterer	count=1
module	when using the ||| utils	count=1
function	wild lfw pairs ||| fetch lfw pairs	count=2
module	a which this ||| externals	count=1
function	'l' suffix ||| shape	count=1
function	partially fit [function_2] ||| [function_2] [function_1]	count=2
arg	matrix ||| n_components affinity	count=1
function	callable case for pairwise_{distances ||| pairwise callable	count=1
function	[function_1] wishart ||| [function_2] [function_1]	count=2
arg	and conversion [arg_2] ||| [arg_2] [arg_1]	count=2
function	[function_1] iris ||| [function_1] [function_2]	count=1
function	each input ||| val predict	count=1
class	[class_1] training data ||| [class_2] [class_1]	count=2
class	which ||| backend	count=1
function_arg	[function_1] a job ||| [function_1] [arg_2]	count=2
function	fit [function_2] ||| [function_2] [function_1]	count=4
arg	the given data x ||| x y	count=1
module	the relationship ||| cluster	count=1
arg	the mean and ||| x y	count=1
class	found parameters ||| base search	count=2
module	list of ||| joblib	count=1
function	kl [function_2] ||| [function_2] [function_1]	count=4
function_arg	probabilities [arg_2] ||| [function_1] nn distances neighbors [arg_2]	count=2
function	barycenter weighted [function_2] ||| [function_1] kneighbors [function_2]	count=2
function	california housing dataset from ||| california housing	count=1
function	to build ||| build	count=2
function	for [function] ||| silhouette [function]	count=1
function	iris ||| iris	count=1
arg	given dataset ||| scorer	count=1
function	evaluate the ||| score samples	count=1
arg	x ||| x	count=181
class	hash ||| memorized func	count=1
class	density model on the ||| kernel density	count=1
arg	in x ||| x y	count=1
function	path parameters ||| omp path	count=1
arg	p_ij [arg_2] ||| [arg_2] [arg_1]	count=3
function_arg	[function_1] [arg_2] ||| [function_1] binarize [arg_2]	count=4
function	build a ||| parallel build	count=1
function	estimates for each input ||| cross	count=1
arg	validation [arg_2] ||| [arg_1] [arg_2]	count=2
class	we don't store ||| memory	count=1
function_arg	seeds for [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	[function_1] [arg_2] restricted the points at ||| [function_1] graph [arg_2]	count=12
function	[function_1] transform ||| [function_2] [function_1]	count=1
function	covariance ||| match covariance	count=1
function	dispatch ||| dispatch	count=1
arg	than ||| mode metric	count=1
arg	generate a ||| n_samples n_features n_classes	count=1
arg	gradient and ||| y	count=2
module	the [module] ||| [module]	count=17
class	gaussian [class_2] ||| [class_1] [class_2]	count=6
class	whether the file ||| binary zlib file	count=2
class	perform dbscan ||| dbscan	count=1
arg	for each input ||| x y	count=1
function	[function_1] for multiclass ||| [function_2] [function_1]	count=1
function	probabilities ||| probabilities	count=2
function	embedding analysis on the ||| embedding	count=1
function	sizes of training subsets ||| train sizes	count=1
arg	data onto ||| x ridge_alpha	count=1
arg	[arg_1] returns the ||| [arg_1] [arg_2]	count=2
class	the deviance ||| deviance	count=1
function_arg	[function_1] [arg_2] ||| [function_1] error [arg_2]	count=16
arg	on x and membership ||| x z	count=1
arg	n_packs ||| n_packs n_samples	count=1
arg	y as training data ||| y	count=2
class	gaussian process [class_2] ||| [class_1] [class_2]	count=4
module	a ||| externals	count=16
function	names for ||| name	count=1
function_arg	[function_1] version ||| [arg_2] [function_1]	count=2
function_arg	[function_1] doc_topic_distr ||| [function_1] x [arg_2]	count=3
arg	x parameters ||| x n_neighbors	count=2
arg	values ||| y train	count=2
function_arg	density [arg_2] ||| [arg_2] [function_1]	count=2
arg	from features or ||| y sample_weight	count=1
function	[function_1] likelihood function ||| [function_1] [function_2]	count=10
function	display the process of ||| print	count=1
function	mean and variance ||| incr mean variance	count=3
module	long type ||| utils	count=1
module	[module_1] with ||| [module_1] [module_2]	count=4
class	creates ||| base spectral	count=1
arg	y - ||| y	count=1
function	shortest path ||| shortest path	count=1
function	return the directory ||| dir	count=1
class	points in [class_2] ||| [class_2] [class_1]	count=1
arg	the validity of ||| x metric p metric_params	count=1
function_arg	accept precomputed [arg_2] ||| [function_1] x [arg_2]	count=1
function	random multilabel classification ||| make multilabel classification	count=2
arg	of a cross-validated ||| x y cv	count=1
module	an 'l' suffix when ||| utils	count=1
arg	x (as bigger is ||| x	count=1
function	[function_1] functions of ||| [function_2] [function_1]	count=4
function	[function] have ||| preprocess [function]	count=1
class	std ||| standard	count=1
function	huber loss ||| huber loss	count=2
arg	for each input ||| y	count=1
module_class	[module_1] embedding ||| [module_1] locally linear [class_2]	count=1
function	[function_1] this ||| [function_2] [function_1]	count=3
function	the average path length ||| average path length	count=1
arg	filters the ||| func ignore_lst	count=1
class	apply affinity [class] clustering ||| affinity [class]	count=1
arg	update h ||| w h	count=1
arg	given data [arg_2] ||| [arg_2] [arg_1]	count=2
function	regions ||| regions	count=1
arg	matching pursuit problems ||| y n_nonzero_coefs	count=1
arg	returns the ||| w	count=1
function	train test indices ||| indices	count=1
function	graph ||| to graph	count=2
function	integer indices ||| indices	count=1
arg	from source ||| graph source	count=1
function	check to make sure ||| check	count=1
arg	accuracy of a classification ||| y_true y_pred labels sample_weight	count=1
class	center ||| robust scaler	count=2
arg	perform ||| x responsibilities	count=1
arg	data onto the ||| ridge_alpha	count=1
function	compute average [function] ||| average [function]	count=3
class	process or thread ||| multiprocessing backend	count=1
function	shrunk ||| shrunk	count=1
module	of exception types ||| externals	count=1
function	used for later ||| fit	count=1
arg	on x [arg_2] ||| [arg_2] [arg_1]	count=1
class	for the ||| empirical covariance	count=1
arg	function to ||| function	count=1
function	the precisions ||| precisions	count=1
function	update terminal ||| update terminal	count=2
arg	csgraph inputs ||| csgraph	count=1
module	long type introduces an ||| utils	count=1
module	return ||| utils	count=1
arg	the given estimator ||| estimator	count=1
class	convert ||| sparse coef mixin	count=1
function	net path with ||| path	count=1
arg	decorator used to capture ||| check_pickle	count=1
class	of possible outcomes ||| voting	count=1
function	[function_1] step ||| [function_2] [function_1]	count=2
function	[function_1] divergence of ||| [function_1] [function_2]	count=3
function	[function_1] terminal regions ||| [function_1] [function_2]	count=2
function	[function_1] of this ||| [function_2] [function_1]	count=3
arg	for each input ||| x	count=1
function	multiprocessing ||| multiprocessing	count=1
function	used to build ||| build	count=1
function	number of points ||| len	count=1
function_arg	loss [arg_2] ||| [function_1] [arg_2]	count=3
function	jaccard similarity coefficient score ||| score	count=1
arg	orthogonal matching pursuit step ||| x y n_nonzero_coefs tol	count=1
function	m step for diagonal ||| diag	count=1
function_arg	kddcup99 dataset [arg_2] ||| [function_1] [arg_2]	count=3
function	training ||| fit predict	count=1
function	"news" format strip the ||| strip newsgroup	count=1
function_arg	[function_1] model and ||| [arg_2] [function_1]	count=1
function	compute mean and variance ||| mean variance	count=1
function	generate names for ||| name	count=1
function_arg	[function_1] values ||| [arg_2] [function_1]	count=4
function	binary and ||| binary	count=1
function	global clustering for ||| global clustering	count=2
function	estimates ||| predict	count=1
function	to fit ||| fit	count=1
function	on the training set ||| fit	count=1
module	or thread pool ||| joblib	count=1
class	file ||| file	count=4
class	the kernel ||| normalized kernel mixin	count=1
function	[function_1] sign ||| [function_1] [function_2]	count=2
function	factorization ||| negative factorization	count=2
function	covariance [function_2] ||| [function_1] mstep [function_2]	count=2
function	grid [function_2] ||| [function_2] [function_1]	count=1
function	reproducibility flips the sign ||| deterministic vector sign	count=1
function	estimates the shrunk ledoit-wolf ||| ledoit wolf shrinkage	count=1
function	grid of [function_2] ||| [function_1] [function_2]	count=2
arg	[arg_1] as ||| [arg_2] [arg_1]	count=4
function	sample [function_2] ||| [function_1] [function_2]	count=4
function	return the decision ||| decision	count=1
function	neighbors within a ||| neighbors	count=1
function	compute ||| score	count=2
arg	lrd the lrd of ||| distances_x neighbors_indices	count=1
function	coefficient of determination regression ||| r2	count=1
function	samples ||| decision function	count=2
arg	routine for validation ||| directed dtype	count=1
arg	classification ||| y_true y_score pos_label sample_weight	count=1
arg	sparse and ||| y sample_weight random_state	count=1
function	also predict ||| predict	count=1
arg	a given radius ||| radius	count=1
arg	samples of length dimensions ||| samples dimensions rng	count=1
function	first prime element in ||| prime in	count=1
arg	axix ||| last_mean last_var	count=1
module	type introduces an ||| utils	count=1
module	independent ||| utils	count=1
class	regressor from ||| regressor	count=2
function	names and a name ||| get func name	count=1
module	avoid the ||| externals joblib	count=2
function	the laplacian kernel ||| laplacian kernel	count=2
class	with randomly drawn ||| randomized search cv	count=1
function	dimension of a ||| dimension	count=1
function	evaluate ||| call	count=1
class	[class_1] ridge model ||| [class_1] [class_2]	count=2
class	with the generative model ||| base pca	count=1
class	fit ||| regression cv	count=1
class	ridge regression ||| ridge classifier	count=1
arg	data point ||| x	count=1
function	and [function_2] ||| [function_1] [function_2]	count=12
class	the best ||| cv	count=5
arg	normalized laplacian ||| n_components eigen_solver	count=1
function	[function_1] size ||| [function_1] [function_2]	count=3
arg	in n_jobs ||| y func n_jobs	count=1
function	the time ||| time	count=1
function	the sigmoid ||| sigmoid	count=1
module	covariance model according to ||| covariance	count=1
arg	squared euclidean norm ||| squared	count=1
function	compute log probabilities within ||| predict log proba	count=1
function	loss and [function_2] ||| [function_1] [function_2]	count=2
arg	remove a subcluster ||| subcluster new_subcluster1	count=1
function	submatrix corresponding to ||| submatrix	count=1
arg	data to [arg_2] ||| [arg_2] [arg_1]	count=1
arg	eigenvalues and eigenvectors of ||| m sigma	count=1
function	infers the dimension of ||| dimension	count=1
arg	generate cross-validated estimates for ||| x y cv	count=1
arg	the :ref user guide ||| y_true y_pred	count=3
class	or thread ||| multiprocessing backend	count=1
arg	[arg_1] [arg_2] ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=3
function	later ||| fit	count=1
function_arg	computing truncated [arg_2] ||| [function_1] [arg_2]	count=2
arg	to a large sparse ||| a	count=1
arg	[arg_1] [arg_2] the appropriate features ||| [arg_1] [arg_2]	count=2
class	regression model we can ||| regressor	count=1
function	[function] parameters ||| [function]	count=2
class	sparse components ||| sparse pca	count=1
function	[function_1] probabilities ||| [function_2] [function_1]	count=4
arg	dot w h ||| w h	count=2
module_class	[module_1] em ||| [module_1] [class_2]	count=6
class	exception ||| parallel backend base	count=2
function	insert ||| insert	count=1
function	[function] between ||| build [function]	count=3
arg	in sorted array ||| tree bin_x left_mask right_mask	count=1
class	regression model ||| regressor	count=1
arg	and ||| y sample_weight	count=4
function	the shortest path length ||| single source shortest path length	count=1
class	local ||| local	count=1
function_arg	an unfitted [arg_2] ||| [arg_2] [function_1]	count=1
function	apply the derivative ||| derivative	count=1
function	multilabel classification ||| make multilabel classification	count=2
arg	generate a ||| n_samples n_features	count=3
function	list of feature ||| get feature	count=1
arg	solution to a ||| a	count=1
class	coefficient matrix to ||| coef	count=1
function	absolute sizes of ||| translate train sizes	count=1
class	compute ||| multilayer perceptron	count=1
class	with passive aggressive algorithm ||| passive aggressive regressor	count=1
function	[function_1] point ||| [function_2] [function_1]	count=3
class	backend and ||| backend base	count=1
function	centers [function] have ||| preprocess [function]	count=1
function	smacof algorithm ||| smacof	count=1
arg	and scale the ||| x y	count=1
function_arg	[function_1] estimator ||| [function_1] [arg_2]	count=18
function	seeds for ||| get bin seeds	count=1
function	using ||| shape repr	count=1
class	data-dependent state [class] if necessary ||| [class]	count=3
arg	[arg_1] conversion of ||| [arg_1] [arg_2]	count=3
arg	input ||| x	count=1
function	mean [function_2] ||| [function_2] [function_1]	count=12
module	to this ||| externals joblib	count=1
function	compute ||| compute log	count=1
function	the bound ||| bound	count=1
function	average [function_2] ||| [function_2] [function_1]	count=3
arg	dictionary factor in ||| dictionary	count=1
arg	is meant to ||| data_folder_path slice_ color resize	count=1
arg	remove a subcluster from ||| subcluster new_subcluster1 new_subcluster2	count=1
module	when using ||| utils	count=1
class	passive aggressive algorithm ||| passive aggressive classifier	count=2
class	using ||| factor	count=1
function	full lars path ||| omp path	count=1
class	calibrated ||| calibrated classifier cv	count=1
function	independent representation ||| shape	count=1
function_arg	[function_1] of x ||| [arg_2] [function_1]	count=9
function	sizes of training subsets ||| translate train sizes	count=1
arg	autocorrelation parameters theta ||| theta	count=1
function	computes the barycenter weighted ||| barycenter	count=1
function	the number ||| len	count=1
function	of [function] ||| [function]	count=2
arg	the data and ||| x y	count=1
class	by the ||| base	count=1
arg	output for x ||| x y sample_weight	count=1
module	from it ||| externals	count=2
arg	eigenvalue decomposition ||| value norm_laplacian	count=1
function_arg	of [function_1] [arg_2] ||| [function_1] [arg_2]	count=6
function	cholesky decomposition ||| cholesky	count=2
function_arg	[function_1] this ||| [function_1] [arg_2]	count=6
function_arg	[function_1] x ||| [function_1] graph [arg_2] radius	count=2
module	closest cluster each sample ||| cluster	count=1
class	force the execution of ||| memorized	count=1
arg	the elastic net optimization ||| l1_ratio	count=1
function	this score ||| score	count=1
function	sources [function] to the ||| [function]	count=1
function	range of ||| range	count=1
function	negative ||| negative	count=2
arg	data in the ||| data compress	count=2
arg	for an estimator ||| estimator	count=1
arg	in x into ||| x	count=1
function	[function_1] number of ||| [function_1] [function_2]	count=2
arg	given radius of ||| x radius	count=1
arg	[arg] using trained ||| [arg]	count=3
arg	the validity ||| metric p metric_params	count=1
arg	threshold ||| importances threshold	count=1
class	outlier ||| outlier	count=2
function	modified [function_2] ||| [function_1] [function_2]	count=2
arg	of the derived ||| x resp	count=1
class	affinity [class] clustering ||| affinity [class]	count=1
class	to avoid ||| memorized	count=1
function	lfw [function_2] ||| [function_2] [function_1]	count=12
class	the kernel ||| kernel mixin	count=2
arg	meant ||| index_file_path data_folder_path slice_ color	count=1
function_arg	[function_1] mean_shift ||| [arg_2] [function_1]	count=2
function	training set according to ||| fit	count=1
function	strip ||| strip	count=2
class	label [class_2] ||| [class_1] [class_2]	count=1
arg	sparse and dense inputs ||| y sample_weight	count=1
function	for full ||| normal density full	count=1
arg	for 1 iteration ||| total_samples batch_update parallel	count=1
function	used to build ||| parallel build	count=1
function_arg	density [arg_2] ||| reachability [function_1] [arg_2]	count=2
function_arg	[function_1] and ||| [function_1] predict [arg_2]	count=1
function	error regression ||| log error	count=1
arg	returns first [arg] left and ||| [arg]	count=1
function_arg	[function_1] fileobj ||| [function_1] [arg_2]	count=1
arg	of p_ijs and q_ijs ||| params p neighbors degrees_of_freedom	count=1
module	to [module] ||| [module]	count=1
arg	the binary classification task ||| y_true y_score average sample_weight	count=1
function	log probability ||| log multivariate normal density	count=1
function	in the specified ||| in	count=1
function	check x format and ||| check	count=1
function	[function_1] mldata ||| [function_2] [function_1]	count=1
arg	[arg_1] y_true ||| [arg_2] [arg_1]	count=2
class	coefficient matrix to ||| sparse coef	count=1
class	the search ||| search cv	count=1
function_arg	[function_1] and apply ||| [function_1] x [arg_2]	count=1
function	make sure no ||| non neg array	count=1
function	error [function_2] ||| [function_2] divergence [function_1]	count=1
arg	given args and kwargs ||| args kwargs	count=1
class	with ||| cv	count=1
function	[function_1] regions ||| [function_2] [function_1]	count=3
class	regression model we ||| regressor	count=1
function	sparse uncorrelated design ||| make sparse uncorrelated	count=2
class	and hide warnings ||| ignore warnings	count=1
function	laplacian kernel between ||| laplacian kernel	count=2
class	matrix of patch ||| patch extractor	count=1
function	[function_1] this estimator ||| [function_2] [function_1]	count=1
arg	and then the ||| y	count=1
arg	csgraph ||| csgraph directed	count=1
function	leaves ||| leaves	count=1
module	long type introduces ||| utils	count=1
module_class	the em ||| mixture gmmbase	count=1
module	file as a ||| externals	count=1
function	training set ||| fit predict	count=1
function	the dimension of a ||| dimension	count=1
class	[class_1] the scaling ||| [class_1] [class_2]	count=1
function	check [function_2] ||| [function_2] [function_1]	count=3
function_arg	[function_1] dictionary factor ||| [function_1] [arg_2]	count=1
arg	filters [arg_2] ||| [arg_2] [arg_1]	count=5
function	sign ||| sign flip	count=1
function	a grid of ||| grid	count=1
function	update it with ||| update	count=1
function	suffix ||| repr	count=1
arg	[arg_1] configure a ||| [arg_2] [arg_1]	count=2
function	not found and raise ||| search	count=1
function	fetch [function_2] ||| [function_1] [function_2]	count=1
function_arg	of loss [arg_2] ||| [arg_2] [function_1]	count=3
class	[class_1] format ||| [class_2] [class_1]	count=2
class	from ||| memory	count=1
arg	p_ij from distances ||| distances desired_perplexity verbose	count=3
arg	downloading it if ||| subset data_home download_if_missing random_state	count=1
function	with ||| with	count=3
function_arg	[function_1] on ||| [arg_2] [function_1]	count=2
class	the ||| gaussian mixture	count=1
function	and a name ||| get func name	count=1
function	[function_1] decision function ||| [function_1] [function_2]	count=1
module_class	transform [module_1] [class_2] ||| [module_1] [class_2] vectorizer transform x y	count=2
function_arg	[function_1] call ||| [function_1] called str function_name [arg_2]	count=1
function	squared [function_2] ||| [function_1] [function_2]	count=1
arg	of the data onto ||| ridge_alpha	count=1
function	at each stage ||| staged	count=3
function	compute the gradient ||| compute	count=1
arg	with x [arg] the dimensionality ||| x [arg]	count=1
arg	the median and ||| x y	count=1
function	new ndarray with aligned ||| aligned	count=1
function	median absolute ||| median absolute	count=2
function	directory in which ||| dir	count=1
arg	the elastic net ||| l1_ratio	count=1
arg	returns ||| w	count=1
arg	test [arg] ||| [arg]	count=3
class	store ||| memorized func	count=1
function	each input ||| cross	count=1
arg	sample from ||| size replace	count=1
function	compute the l1 ||| manhattan	count=1
class	[class_1] factor ||| [class_1] [class_2]	count=5
class	cache for ||| memorized func	count=1
class	format ||| sparse coef	count=1
function	[function] jaccard ||| jaccard similarity [function]	count=3
function_arg	estimators [arg_2] ||| [function_1] [arg_2]	count=2
module	decorator to ||| utils	count=1
class	of exception types to ||| parallel backend	count=1
function	[function_1] breast ||| [function_1] [function_2]	count=1
function	callable case ||| pairwise callable	count=1
arg	of theta ||| theta eval_gradient	count=1
function	for full ||| density full	count=1
arg	loader for ||| subset data_home	count=1
function	terminal ||| update terminal	count=1
function	training set according ||| fit	count=1
function	data ||| cross val predict	count=2
function	sample images for ||| sample images	count=2
arg	0 if y - ||| y	count=1
function	absolute error ||| absolute error	count=4
function	function used to partition ||| partition	count=1
function_arg	[function_1] the validity ||| [arg_2] [function_1]	count=1
function	the residues ||| residues	count=1
function	fit for ||| fit	count=1
function	gaussian and label samples ||| gaussian	count=1
module	retrieve a [module_2] ||| [module_1] [module_2]	count=2
function	approximates the range of ||| randomized range finder	count=1
arg	[arg_1] <mean_absolute_error> ||| [arg_2] [arg_1]	count=2
arg	the validity of the ||| metric p metric_params	count=1
function	[function_1] maximum ||| [function_2] [function_1]	count=2
class	to avoid the ||| memory	count=1
module	the process or thread ||| externals joblib	count=1
function	each input data point ||| val	count=1
function_arg	[function_1] classification ||| [arg_2] [function_1]	count=1
arg	n_packs ||| n_packs	count=1
function	for the lfw ||| fetch lfw	count=2
function	output of transform is ||| transform	count=1
arg	x parameters ||| x n_neighbors reg	count=1
function	incremental mean and ||| incr mean	count=1
arg	each ||| y	count=1
function	matrix factorization ||| non negative factorization	count=1
arg	and dense ||| y	count=1
function	sample weights ||| compute sample	count=1
module	features are selected ||| feature_selection	count=1
function_arg	pairs dataset [arg_2] ||| [arg_2] [function_1]	count=1
function	tokens ||| word ngrams	count=1
class	list of exception types ||| parallel backend	count=1
function	[function_1] weiszfeld ||| [function_1] [function_2]	count=1
arg	based on a feature ||| x connectivity n_clusters	count=1
arg	in n_jobs even slices ||| y func n_jobs	count=1
function	[function_1] the sign ||| [function_1] [function_2]	count=3
module	hash depending ||| externals joblib	count=2
function	the absolute error of ||| error	count=1
arg	[arg_1] transformed data ||| [arg_1] [arg_2]	count=6
function	compute class ||| class	count=1
function	job ||| parallel	count=1
function	[function_1] [function_2] of the ||| [function_1] [function_2]	count=2
function	[function_1] kl ||| [function_2] [function_1]	count=2
function	a logistic ||| logistic	count=2
function_arg	maximum [arg_2] ||| [arg_2] [function_1]	count=1
function	download the [function_2] ||| [function_2] [function_1]	count=3
arg	of parameters ||| parameters	count=2
class	to avoid ||| memorized func	count=1
arg	in place using strides ||| arr patch_shape extraction_step	count=1
function	compute decision [function_2] ||| [function_2] [function_1]	count=4
function	linear assignment problem using ||| linear assignment	count=1
module	decision tree ||| tree	count=1
function	make ||| make estimator	count=1
function	introduces ||| shape repr	count=1
arg	[arg_1] classification task ||| [arg_2] [arg_1]	count=8
function_arg	people dataset [arg_2] ||| [function_1] [arg_2]	count=1
arg	laplacian matrix and ||| laplacian	count=1
arg	data x ||| x doc_topic_distr sub_sampling	count=1
function	inplace row scaling ||| inplace row scale	count=1
module_class	[module_1] [class_2] ||| [module_1] [class_2]	count=94
function	absolute error regression loss ||| absolute error	count=2
function	compute the decision function ||| decision function	count=1
function	to partition ||| partition	count=1
arg	for each ||| estimator x y	count=1
module	estimator is ||| core	count=1
function	update ||| update dict	count=1
class	[class_1] encoder ||| [class_1] [class_2]	count=1
module	propagation [module] of data ||| [module]	count=1
function	add an ||| add	count=1
module	the [module] in ||| [module]	count=1
arg	generate ||| n_samples	count=2
function	the cholesky decomposition of ||| det cholesky	count=1
arg	a large sparse linear ||| a	count=1
function_arg	[function_1] for x ||| [function_1] [arg_2]	count=7
function	a platform independent ||| shape repr	count=1
function_arg	[function_1] in x ||| [function_1] [arg_2]	count=8
function	[function_1] thresholding ||| [function_1] [function_2]	count=1
function	a locally [function_2] ||| [function_2] [function_1]	count=5
arg	[arg_1] as ||| [arg_1] [arg_2]	count=4
function_arg	parameters of [arg_2] ||| [function_1] [arg_2]	count=3
class	hierarchical ||| feature agglomeration	count=1
function_arg	[function_1] size ||| [function_1] [arg_2]	count=1
function	introduces an ||| repr	count=1
function	for full covariance ||| full	count=1
function	two ||| cc	count=1
function_arg	function of x ||| function x	count=8
arg	up to size ||| size	count=1
arg	target_variables ||| target_variables grid x	count=1
function	and transform ||| transform	count=1
function	all estimators ||| all estimators	count=2
function	lower bound for the ||| bound	count=1
function_arg	[function_1] the laplacian ||| [arg_2] [function_1]	count=3
function_arg	update the [arg_2] ||| [function_1] [arg_2]	count=3
function_arg	[function_1] nmf ||| [arg_2] [function_1]	count=2
arg	set [arg_1] [arg_2] appropriately and checks inputs ||| [arg_1] [arg_2]	count=1
arg	k x ||| x	count=4
function	transform on ||| transform	count=1
function	returns [function] the ensemble ||| [function]	count=1
arg	the given args and ||| args	count=1
class	fit ||| lars ic	count=1
function	main classification ||| classification	count=1
function	covariance ||| covar	count=2
arg	the dense dictionary factor ||| dictionary y	count=1
function	approximates the range ||| randomized range finder	count=1
function	is [function] ||| check [function] probabilistic	count=1
function	jobs that ||| jobs	count=2
function	for each ||| cross val predict	count=1
function	fit on the ||| fit	count=1
function_arg	truncated [arg_2] ||| [arg_2] [function_1]	count=2
class	matrix for label ||| label	count=1
function	[function_1] error ||| [function_2] [function_1]	count=4
function	long type ||| shape	count=1
class	spectral ||| spectral	count=1
class	whether the kernel ||| pairwise kernel	count=3
arg	- y_[i]) ** 2 ||| sample_weight y_min y_max	count=1
arg	mono and ||| x y	count=1
class	the ||| parallel backend base	count=1
function	[function_1] the wine ||| [function_1] [function_2]	count=1
function	stationary ||| stationary	count=5
module	based on ||| neighbors	count=1
class	to an array ||| quadratic discriminant	count=1
function	svmlight format ||| svmlight	count=1
arg	loader for ||| data_home download_if_missing	count=2
function_arg	[function_1] problem ||| [function_1] n_samples n_features [arg_2]	count=1
function	[function_1] distances between ||| [function_2] [function_1]	count=12
class	of the kernel ||| kernel mixin	count=1
function	for ||| cross	count=1
module	with the generative model ||| decomposition	count=1
function	images for image manipulation ||| images	count=1
module	store ||| externals joblib	count=4
function	[function_1] covariance matrix ||| [function_2] [function_1]	count=2
function	[function_1] [function_2] ||| utils [function_2] [function_1]	count=1
function_arg	write [arg_2] ||| [function_1] zfile file_handle [arg_2]	count=5
class	of the local outlier ||| local outlier	count=1
function	the data home cache ||| clear data home	count=1
arg	suited for eigenvalue decomposition ||| value norm_laplacian	count=1
arg	according to the ||| y sample_weight	count=2
function	the directory in which ||| dir	count=1
arg	[arg_1] conversion of ||| [arg_2] [arg_1]	count=3
arg	given data x ||| x y	count=2
function	batch and dispatch ||| dispatch one batch	count=1
function	compute class [function_2] ||| [function_2] [function_1]	count=2
class	em algorithm and ||| gmmbase	count=1
arg	of u such that ||| u	count=1
arg	model according to the ||| sample_weight	count=2
function	type introduces an 'l' ||| shape	count=1
function	the logistic [function_2] ||| [function_2] [function_1]	count=4
module	and a ||| utils	count=1
function	[function_1] first ||| [function_1] [function_2] line func_code	count=1
class	in ||| one	count=1
function	[function_1] kernel between ||| [function_2] [function_1]	count=3
function	[1] and breiman [2] ||| make friedman3	count=1
function	[function_1] dependence ||| [function_1] [function_2]	count=1
class	of exception types ||| backend base	count=1
arg	each input data point ||| estimator x y	count=1
arg	y as training ||| y	count=2
function	from the training ||| fit	count=6
function_arg	[function_1] y and ||| [function_1] targets [arg_2]	count=1
function	point ||| point	count=1
arg	dictionary factor ||| dictionary y	count=1
class	binarizer parameters ||| binarizer	count=1
arg	function ||| func	count=1
module	platform independent representation ||| utils	count=1
function	[function_1] kl ||| [function_2] divergence [function_1]	count=2
module	suffix when using ||| utils	count=1
function	class_weight ||| targets	count=1
function	compute log [function_2] ||| [function_2] [function_1]	count=2
class	exception ||| parallel	count=1
function	[function_1] embedding ||| [function_2] [function_1]	count=4
function	inplace column scaling ||| inplace column scale	count=1
function	cohen's kappa ||| cohen kappa	count=1
function	estimates for ||| val predict	count=1
function	[function_1] and variance ||| [function_1] [function_2] n_past mu var x	count=1
arg	filters ||| ignore_lst	count=1
function	to a sparse ||| sparse	count=1
arg	axis center to the ||| x axis	count=2
arg	on x [arg_2] ||| [arg_1] [arg_2]	count=1
class	product ||| projection	count=1
function	all the covariance ||| covar matrix to match covariance	count=1
arg	percentiles ||| percentiles grid_resolution	count=1
function	a spherical ||| spherical	count=1
function_arg	partition estimators [arg_2] ||| [function_1] [arg_2]	count=1
function	extract the first ||| extract first	count=1
arg	of x from y ||| x z	count=1
function	sizes of training ||| translate train sizes	count=1
arg	multi-class labels parameters ||| y threshold	count=1
class	pool ||| backend	count=1
function	samples from [function_2] ||| [function_2] [function_1]	count=1
function_arg	vector is [arg_2] ||| [arg_2] [function_1]	count=1
arg	2d square and ||| tol raise_warning raise_exception	count=1
function	build a [function_2] ||| [function_1] [function_2]	count=1
class	search over parameters ||| search cv	count=1
module	to run in parallel ||| externals joblib	count=1
function_arg	[function_1] data x ||| [arg_2] [function_1]	count=2
arg	in n_jobs ||| func n_jobs	count=1
function_arg	model for the data [function_1] [arg_2] ||| [function_1] [arg_2]	count=5
arg	edges weighted ||| edges	count=1
function	curve auc ||| auc	count=2
function_arg	training set x ||| fit x	count=8
class	vectors ||| dummy regressor	count=2
class	convert coefficient ||| sparse	count=1
arg	[arg_1] configure ||| [arg_2] [arg_1]	count=2
arg	[arg_1] y and ||| [arg_2] [arg_1]	count=24
class	[class_1] regression model ||| [class_2] [class_1]	count=5
module	exception types ||| joblib	count=1
function	point ||| val predict	count=2
arg	subset of dataset and ||| y	count=1
arg	from ||| x y sample_weight	count=1
class	the local outlier factor ||| local outlier factor	count=1
function	is the time ||| time	count=1
function_arg	[function_1] version of ||| [arg_2] [function_1]	count=2
function	compressor matching ||| detect compressor	count=1
function	[function_1] directory ||| [function_1] [function_2]	count=1
class	to ||| parallel	count=1
arg	between x and y ||| x y	count=1
class	[class] if ||| [class]	count=6
arg	the vectors in x ||| x	count=3
function	[function_1] transform with ||| [function_2] [function_1]	count=1
arg	given [arg_2] ||| [arg_2] [arg_1]	count=4
class	linear [class_2] ||| [class_1] [class_2]	count=2
module	list ||| externals	count=1
function	lfw pairs dataset ||| fetch lfw pairs	count=4
arg	estimates ||| estimator	count=1
class	all transformers ||| union	count=2
arg	orthogonal matching pursuit step ||| y n_nonzero_coefs tol	count=1
function	compute the number of ||| compute n	count=1
arg	used to capture the ||| check_pickle	count=1
function	the diagonal of ||| diag	count=1
arg	binary classification task ||| y_true y_score pos_label sample_weight	count=1
arg	on [arg_2] ||| [arg_2] [arg_1]	count=2
arg	sparse and dense ||| y sample_weight random_state	count=1
class	coefficient ||| sparse coef mixin	count=1
function	"news" format [function_2] ||| [function_2] [function_1]	count=12
class	regressor from the ||| regressor	count=2
function	compute the boolean mask ||| get mask	count=1
arg	according to ||| x y sample_weight	count=2
function	[function_1] np dot ||| [function_2] [function_1]	count=1
module	process or thread ||| externals joblib	count=1
function_arg	[function_1] and q_ijs ||| [function_1] [arg_2]	count=4
class	process or thread pool ||| multiprocessing backend	count=2
arg	in n_jobs even ||| func n_jobs	count=1
function	input ||| cross	count=1
function	[function_1] an mldata ||| [function_2] [function_1]	count=1
function_arg	[function_1] the lrd ||| [arg_2] [function_1]	count=3
function_arg	np dot [arg_2] ||| [function_1] [arg_2]	count=4
arg	matching pursuit problems ||| x y n_nonzero_coefs tol	count=1
function	finds seeds ||| get bin seeds	count=1
function	dummy ||| dummy	count=1
module	a reliable ||| externals joblib	count=2
class	file ||| binary zlib file	count=3
function	x format check ||| check	count=1
arg	data point ||| y	count=1
arg	w to ||| x w	count=1
function	matrix ||| inplace	count=1
function	[function_1] k-neighbors ||| [function_2] [function_1]	count=4
arg	[arg] to the ||| [arg]	count=4
function	log probabilities ||| parallel predict log proba	count=1
function	write the [function_2] ||| [function_1] [function_2]	count=2
class	[class_1] aggressive algorithm ||| [class_2] [class_1]	count=8
arg	elastic net optimization function ||| l1_ratio	count=1
function	predict_log_proba ||| predict log proba	count=3
function	log ||| log	count=10
arg	training data and parameters ||| x y	count=5
arg	function func with ||| func	count=1
arg	threshold value ||| estimator importances threshold	count=1
arg	given dataset ||| x y scorer	count=1
function	an array array ||| array	count=1
arg	each ||| estimator x y	count=1
function_arg	[function_1] multi-class labels ||| [function_1] transform [arg_2]	count=3
arg	note this implementation is ||| sample_weight	count=1
module_class	[module_1] [class_2] ||| [module_1] min cov [class_2]	count=3
arg	observations in x ||| x	count=1
function	compute decision ||| decision	count=2
module	cache folders to ||| externals joblib	count=1
module	object ||| externals	count=1
function	the linear ||| linear	count=1
function_arg	[function_1] [arg_2] restricted the points at ||| [function_1] [arg_2]	count=60
class	hide warnings ||| ignore warnings	count=1
function	compute the weighted ||| weighted	count=1
function	[function_1] pairs ||| [function_1] [function_2]	count=8
function_arg	files with [arg_2] ||| [arg_2] [function_1]	count=2
class	of the kernel k ||| pairwise kernel	count=1
function_arg	update for [arg_2] ||| [arg_2] [function_1]	count=1
class	the scaler ||| min max scaler	count=1
function	batch ||| batch	count=3
arg	kernel k [arg] ||| [arg]	count=1
arg	of a ||| a	count=2
function	online computation ||| partial	count=2
function	calibration curve ||| calibration curve	count=2
arg	and binary classification algorithms ||| y	count=1
arg	set [arg] appropriately ||| [arg]	count=1
module	[module] function ||| [module]	count=1
function	data covariance ||| covariance	count=1
module	a byte string ||| externals	count=1
class	two covariance ||| covariance	count=1
function	compute the laplacian ||| laplacian	count=1
function_arg	[function_1] for x ||| [function_1] predict [arg_2]	count=2
function	negative value in an ||| negative	count=1
function	returns the bound ||| bound	count=1
class	with the given arguments ||| func	count=2
function	score ||| score	count=15
function_arg	[function_1] [arg_2] ||| [function_1] spherical [arg_2]	count=3
function	data precision matrix ||| get precision	count=1
function_arg	pairwise matrix [arg_2] ||| [function_1] [arg_2]	count=3
module	an ||| utils	count=1
function	extract the [function_2] ||| [function_1] [function_2] line func_code	count=1
function	subclusters ||| subclusters	count=1
class	or ||| multiprocessing	count=1
function	a single binary ||| binary	count=4
function	loss ||| loss	count=6
arg	onto the ||| x ridge_alpha	count=1
class	forest to ||| forest	count=1
class	the given arguments ||| func	count=2
function_arg	predict [arg_2] ||| [function_1] estimator [arg_2]	count=8
function_arg	[function_1] x by ||| [function_1] [arg_2]	count=5
function	load sample [function_2] ||| [function_1] [function_2]	count=4
module	callers ||| externals joblib	count=1
function	gaussian and label ||| make gaussian	count=1
class	the loss of ||| loss	count=1
arg	by its spectrum spectrum ||| spectrum n_samples	count=1
function	predict ||| decision	count=1
function	helper ||| parallel helper	count=1
function	[function_1] [function_2] ||| [function_2] [function_1] quoting	count=4
function	a read [function_2] ||| [function_1] [function_2]	count=1
arg	2 voxels [arg] connected ||| n_x n_y n_z [arg]	count=1
function	[function_1] reduced likelihood ||| [function_1] [function_2]	count=2
function	perform ||| predict	count=1
function	number of [function] ||| effective n [function]	count=6
class	to the file ||| zlib file	count=1
class	getter for the ||| empirical covariance	count=1
function	patches of ||| patches	count=1
module	return a platform ||| utils	count=1
function_arg	[function_1] of data ||| [arg_2] [function_1]	count=3
arg	new ||| make_default	count=1
function	of edges for ||| edges	count=1
function	transform the data ||| transform	count=1
class	from it ||| memorized func	count=1
arg	of test vectors x ||| x	count=1
function	transform the ||| transform	count=2
module	platform independent representation of ||| utils	count=1
class	hash depending from ||| memorized func	count=1
module_class	returns whether ||| gaussian_process pairwise	count=1
function	each ||| cross val predict	count=2
module	a byte ||| externals joblib	count=1
function_arg	[function_1] multi-class ||| [function_1] transform [arg_2]	count=3
function	estimates for each input ||| cross val predict	count=1
class	sparse ||| sparse	count=2
arg	x for a ||| x means	count=2
class	in bytes_limit ||| memory	count=1
function	calculate mean ||| incremental mean	count=1
function	an 'l' suffix ||| shape	count=1
arg	x parameters ||| x	count=2
function	[function_1] mutual ||| [function_1] [function_2]	count=1
class	catch and hide warnings ||| ignore warnings	count=1
class	for later scaling ||| scaler	count=1
class	[class_1] scaling ||| [class_2] [class_1]	count=1
class	whether [class_2] ||| [class_1] [class_2]	count=1
module	a which this function ||| externals joblib	count=1
class	the array [class_2] ||| [class_2] [class_1]	count=2
function	find ||| find	count=1
function	adjusted ||| adjusted	count=1
function	[function_1] directory ||| [function_2] [function_1]	count=1
module_class	[module_1] wrapper ||| [module_1] [class_2]	count=1
class	the ||| base mixture	count=1
function_arg	[function_1] [arg_2] ||| [function_1] x [arg_2]	count=26
function	extracts patches of ||| extract patches	count=1
function	under the curve auc ||| auc	count=2
function_arg	[function_1] classification ||| [function_1] [arg_2]	count=1
module	a decision tree ||| tree	count=1
arg	the other and transforms ||| y	count=1
function	maximizer [function_2] ||| [function_1] [function_2]	count=3
function	log of ||| log	count=3
module	from ||| externals joblib	count=5
arg	parameters ||| estimator parameters	count=2
arg	subcluster from ||| subcluster new_subcluster1	count=1
function_arg	path length [arg_2] ||| [arg_2] [function_1]	count=3
function	[function_1] error regression ||| [function_1] [function_2]	count=4
arg	computes the [arg_2] ||| [arg_2] [arg_1]	count=8
function_arg	[function_1] estimator and ||| [function_1] transform [arg_2]	count=1
function	type introduces ||| shape	count=1
arg	x into a matrix ||| x	count=1
function	[function_1] the diagonal ||| [function_2] [function_1]	count=1
function	representation of ||| repr	count=1
class	to the cache ||| memorized func	count=1
function	minimum [function_2] ||| [function_2] [function_1]	count=1
function	of init ||| init	count=1
function	the gradient of loss ||| loss grad	count=1
function	maximizer ||| arg max	count=1
arg	apply a transform ||| x transform	count=1
function	[function_1] classification problem ||| [function_2] [function_1]	count=3
arg	connectivity [arg_2] ||| [arg_1] [arg_2]	count=1
arg	data [arg_2] ||| [arg_1] [arg_2]	count=5
function	clear all ||| clear	count=1
arg	connectivity ||| connectivity	count=1
arg	python object into one ||| value filename	count=1
function	calibration ||| calibration	count=2
function_arg	[function_1] n ||| utils [function_1] slices [arg_2]	count=1
module	introduces an 'l' ||| utils	count=1
function_arg	single [arg_2] ||| [function_1] [arg_2]	count=1
class	remove cache ||| memory	count=1
arg	data onto the ||| x ridge_alpha	count=1
function	predict based ||| predict	count=1
function	number of ||| n	count=3
module_class	is [module_1] [class_2] ||| [module_1] [class_2]	count=2
arg	u such that ||| u	count=1
module	of exception types to ||| externals joblib	count=1
function	the shortest ||| shortest	count=1
function	type suitable ||| int	count=1
function	inplace row scaling of ||| inplace row scale	count=1
module	hash ||| externals	count=2
function	[function_1] names from ||| [function_1] [function_2]	count=2
arg	the dispatch table ||| reduce_func	count=1
function	a gaussian ||| gaussian	count=1
arg	one-vs-all fashion several regression ||| classes neg_label pos_label	count=1
function	[function_1] of loss ||| [function_1] [function_2]	count=1
class	the [class] ||| base [class]	count=1
module_class	[module_1] is worthy ||| [module_1] [class_2]	count=2
function	[1] and breiman [2] ||| friedman3	count=1
arg	k x [arg_2] ||| [arg_2] [arg_1]	count=8
arg	x and y ||| x y	count=15
function	recall the recall ||| recall	count=1
function	[function_1] cluster ||| [function_1] [function_2]	count=1
arg	[arg] later ||| [arg]	count=1
function	updating terminal ||| terminal	count=1
function_arg	[function_1] p_ij ||| [function_1] distances [arg_2]	count=2
function	[function_1] sparse ||| [function_2] [function_1]	count=1
arg	model according to ||| x y sample_weight	count=2
function	get number of ||| get n	count=2
class	scaling features ||| scaler	count=1
function	of ||| get	count=1
arg	any axis ||| x axis	count=2
function	[function_1] kernel between ||| [function_1] [function_2]	count=3
class	model ||| base randomized linear model	count=1
function	compute log probabilities ||| log proba	count=2
class	of the gradient boosting ||| base gradient boosting	count=1
function	sample ||| compute sample	count=1
function_arg	write [arg_2] ||| [arg_2] [function_1]	count=5
function	repr ||| repr	count=2
arg	[arg_1] length dimensions ||| [arg_2] [arg_1]	count=1
module	thread ||| joblib	count=1
arg	[arg] the appropriate ||| [arg]	count=1
arg	matrices w h whose ||| w h	count=1
module	avoid the ||| joblib	count=2
function	class weights ||| class	count=1
arg	standardize a ||| with_mean with_std	count=1
arg	for points in x ||| x	count=2
function	[function_1] it take ||| [function_2] [function_1]	count=8
class	trained model ||| base multilayer perceptron	count=1
arg	accuracy of a classification ||| y_true y_pred labels	count=1
class	embedding ||| embedding	count=1
function	number ||| n	count=1
arg	the dense dictionary factor ||| dictionary	count=1
class	the position of ||| mds	count=1
arg	y [arg_2] ||| [arg_1] [arg_2]	count=7
function	check according to li ||| check	count=1
function	housing dataset from statlib ||| housing	count=1
function_arg	[function_1] filename ||| [function_1] [arg_2]	count=3
function	trace [function_2] ||| [function_2] [function_1]	count=1
class	numpy ||| numpy	count=1
function	[function_1] [function_2] ||| [function_2] divergence [function_1]	count=9
class	types to ||| backend base	count=1
module	data ||| decomposition	count=2
arg	x ||| x y	count=26
function_arg	the directory corresponding ||| func dir mkdir	count=1
arg	and then ||| x y	count=1
function	the 20 newsgroups data ||| 20newsgroups	count=1
class	we don't store the ||| memorized	count=1
module	parallel ||| externals joblib	count=2
arg	x according to the ||| x	count=1
function	the training set ||| fit predict	count=1
function	the iris ||| iris	count=1
function	platform independent representation ||| shape repr	count=1
function	predict using the ||| predict	count=2
function	decision functions of ||| decision function	count=2
arg	within a job ||| estimators estimators_features x	count=1
function	for each input ||| val	count=1
function	for each input ||| predict	count=1
module	the process ||| joblib	count=1
class	local outlier [class_2] ||| [class_1] [class_2]	count=2
function	and dot ||| beta divergence	count=1
function	the diagonal of the ||| diag	count=1
function	retrieve the leaves of ||| get leaves	count=1
module	biclusters ||| metrics cluster	count=1
function	[function_1] mutual ||| [function_2] [function_1]	count=1
function	load ||| load	count=8
function	a score ||| score	count=2
module	cluster each sample in ||| cluster	count=1
class	[class_1] ridge regression ||| [class_2] [class_1]	count=1
function	check x format check ||| check	count=1
module	dataset is ||| datasets	count=1
arg	verbose ||| verbose	count=1
function	logistic ||| inplace logistic	count=1
module	getter for the ||| covariance	count=1
function	a diagonal ||| diag	count=1
function	download ||| download	count=1
function	a locally linear embedding ||| locally linear embedding	count=1
arg	memory is inefficient ||| x y classes	count=1
class	absolute value to be ||| abs	count=1
arg	categories as subfolder names ||| container_path description categories load_content	count=1
class	avoid ||| memorized func	count=1
arg	training and test set ||| y groups	count=6
function_arg	[function_1] x ||| [function_1] precomp distr [arg_2]	count=1
function	for _fit_coordinate_descent update ||| update	count=1
function_arg	loads data [arg_2] ||| [arg_2] [function_1]	count=1
arg	and transforms the ||| x y	count=1
function	of the breakdown point ||| breakdown point	count=1
arg	non-negative matrices w h ||| x w h n_components	count=1
function	depth ||| check previous func code	count=1
arg	generate ||| estimator x	count=1
function	a locally [function_2] ||| [function_1] [function_2]	count=5
function	the weighted graph of ||| graph	count=3
arg	and smooth ||| y	count=2
arg	w [arg_2] ||| [arg_1] [arg_2]	count=5
function	global ||| global	count=1
module	do nothing and ||| feature_extraction	count=1
arg	if y - ||| y	count=1
arg	to y_true ||| y_true sample_weight	count=2
arg	connectivity ||| x connectivity	count=1
function	from svd ||| svd	count=1
arg	orthogonal matching pursuit ||| y n_nonzero_coefs tol	count=1
class	encoder parameters ||| encoder	count=1
function	sparse random matrix ||| random choice csc	count=1
arg	estimates for ||| estimator x	count=1
arg	capture ||| check_pickle	count=1
function	gradient of loss ||| loss	count=1
function	full lars path ||| path	count=1
function	exceptions ||| assert raise message	count=1
module	the hash depending ||| externals	count=2
arg	filters the [arg_2] ||| [arg_2] [arg_1]	count=5
arg	x and y read ||| x y	count=1
arg	dtype of x ||| x	count=1
class	compute data ||| base	count=1
function_arg	[function_1] x ||| [arg_2] [function_1]	count=94
class	of exception types ||| parallel backend	count=1
arg	random ||| n_features	count=1
function	suffix ||| shape	count=1
arg	the model using x ||| x y	count=1
arg	each input ||| estimator x	count=1
class	input ||| sgd	count=1
arg	p_ijs and q_ijs ||| params p neighbors degrees_of_freedom	count=1
function	in ||| in	count=1
arg	given radius of a ||| x radius	count=1
arg	for ||| x	count=1
function_arg	the directory [arg_2] ||| [function_1] [arg_2]	count=3
arg	from [arg_2] ||| [arg_2] [arg_1]	count=2
arg	inefficient to ||| x y classes	count=1
function	with coordinate [function] ||| [function]	count=3
arg	row of x ||| x	count=1
function	embedding analysis on ||| embedding	count=1
function	estimators ||| estimators	count=2
function	and transform with ||| transform	count=1
function_arg	[function_1] of compute_labels ||| [function_1] [arg_2]	count=1
class	types to ||| parallel backend base	count=1
module	to a ||| externals	count=1
function	depth ||| previous func code	count=1
arg	training data and ||| x y	count=2
function	name for ||| func name	count=1
function_arg	[function_1] values for ||| [function_1] estimator [arg_2]	count=4
function	estimates the shrunk ledoit-wolf ||| ledoit wolf	count=1
class	of max [class_2] ||| [class_2] [class_1]	count=2
function	partial [function_2] ||| [function_2] [function_1]	count=1
arg	continuous target variable ||| x y discrete_features n_neighbors	count=1
arg	[arg] the ||| x [arg]	count=3
arg	[arg_1] and conversion ||| [arg_1] [arg_2]	count=3
arg	[arg_1] multi-outputs ||| [arg_2] [arg_1]	count=5
function	average [function_2] ||| [function_1] [function_2]	count=3
class	embedding space ||| embedding	count=1
arg	computes the ||| y alpha	count=2
function	[function_1] variance ||| [function_2] [function_1]	count=7
arg	[arg_1] [arg_2] ||| [arg_1] l1_ratio [arg_2]	count=4
function	the c and cpp ||| c and cpp	count=1
function_arg	[function_1] given radius ||| [function_1] [arg_2]	count=2
function_arg	[function_1] dictionary ||| [function_1] [arg_2]	count=1
function	c and [function_2] ||| [function_2] [function_1]	count=2
function	sparse random ||| random choice	count=1
function	each input data point ||| cross val	count=1
function	length is not found ||| search	count=1
function	rand index adjusted for ||| adjusted rand	count=1
arg	generate isotropic gaussian ||| n_samples n_features centers cluster_std	count=1
class	polynomial features ||| polynomial features	count=2
class	from it ||| func	count=1
function_arg	[function_1] theta ||| laplace [function_1] [arg_2]	count=1
arg	inefficient to train all ||| y classes	count=1
function_arg	compressor matching [arg_2] ||| [arg_2] [function_1]	count=1
function	used to build a ||| build	count=1
arg	memory is inefficient ||| classes	count=1
function	for a calibration ||| calibration	count=1
function	log probability for ||| log multivariate normal density	count=1
function	independent ||| shape	count=1
arg	of x for ||| x	count=1
class	the gradient [class_2] ||| [class_2] [class_1]	count=2
function_arg	write the [arg_2] ||| [arg_2] [function_1]	count=5
function	update ||| update	count=12
arg	the model with x ||| x	count=2
function	representation of ||| shape	count=1
arg	dense dictionary factor in ||| dictionary y	count=1
arg	whether y ||| y	count=1
class	function and cache ||| func	count=1
function	be used for later ||| fit	count=1
arg	for data x ||| x	count=2
function_arg	divergence [arg_2] ||| [arg_2] [function_1]	count=1
function	housing dataset from ||| housing	count=1
class	process of the parallel ||| parallel	count=1
function	perplexity for data ||| perplexity	count=2
class	[class_1] classifier valid ||| [class_1] [class_2]	count=4
arg	inefficient ||| y classes	count=1
arg	w to ||| x w ht l1_reg	count=1
arg	dictionary factor ||| dictionary	count=1
class	the backend ||| parallel backend base	count=1
function	parameters of ||| params	count=4
function	iterate over ||| iter	count=2
function	lfw people dataset this ||| lfw people	count=1
arg	convert string beta_loss ||| beta_loss	count=1
function	compute ||| get	count=1
function	number of ||| len	count=1
function	fit the model with ||| fit transform	count=1
arg	on x and y ||| x y alpha	count=1
function	youngs and ||| and	count=1
function	of init ||| init decision	count=1
class	class ||| boosting classifier	count=2
module_class	[module_1] em algorithm ||| [module_1] [class_2]	count=8
arg	each input data point ||| estimator	count=1
class	process or thread ||| multiprocessing	count=1
arg	and cv and ||| x y	count=1
class	of ||| parallel backend base	count=2
class	process or ||| backend	count=1
function	binary ||| average binary	count=1
module	each input ||| core	count=1
module_class	to [class_2] ||| [module_1] [class_2]	count=8
function	long type introduces an ||| shape repr	count=1
function	check initial parameters ||| check parameters	count=1
function_arg	[function_1] with respect ||| [function_1] layer [arg_2]	count=5
arg	for ridge and ||| x y	count=1
arg	the value of verbose ||| verbose	count=1
arg	in data ||| data	count=1
class	with ||| base	count=1
function	each ||| cross val	count=1
arg	[arg_1] n-class ||| [arg_2] [arg_1]	count=1
module	a cluster ||| cluster	count=1
function	a name for the ||| name	count=1
function	from ||| fit	count=1
arg	x using ||| x	count=2
function	measure the similarity of ||| fowlkes mallows	count=1
function	c ||| c	count=2
function_arg	laplacian kernel [arg_2] ||| [arg_2] [function_1]	count=2
function_arg	[function_1] of parameters ||| [arg_2] [function_1]	count=2
arg	x and returns ||| x y	count=2
arg	regression and cv and ||| x y	count=1
module_class	[module_1] the kernel ||| [module_1] [class_2]	count=6
class	the model ||| model	count=1
function	check [function_2] ||| [function_1] [function_2]	count=3
function_arg	the training [arg_2] ||| bagging [function_1] [arg_2]	count=2
function	a name for ||| name	count=1
module	list of exception ||| joblib	count=1
arg	when memory is inefficient ||| x y classes	count=1
module	when ||| utils	count=1
function	list of edges for ||| make edges	count=1
arg	a random n-class ||| n_informative n_redundant	count=1
function_arg	[function_1] compute_labels ||| [function_1] [arg_2]	count=1
function	function code and the ||| func code	count=1
function_arg	[function_1] corresponding ||| [function_1] [arg_2]	count=3
arg	for validation [arg_2] ||| [arg_2] [arg_1]	count=2
arg	[arg] appropriately ||| [arg]	count=1
function_arg	truncated svd ||| truncated x n_components	count=1
function	platform independent representation of ||| shape repr	count=1
class	kernel ||| stationary kernel mixin	count=1
function	call with the ||| call	count=1
module_class	linear model [class_2] ||| [module_1] [class_2]	count=4
arg	other and transforms ||| y	count=1
function	scale back ||| inverse transform	count=2
module	to avoid the ||| externals joblib	count=2
function_arg	[function_1] using x ||| [function_1] [arg_2]	count=3
arg	random sample from ||| size	count=1
module	with joblib dump ||| joblib	count=1
function	compute mean [function_2] ||| [function_1] [function_2]	count=1
module_class	returns [class_2] ||| [module_1] [class_2]	count=18
function_arg	and [arg_2] ||| [function_1] x [arg_2]	count=2
module_class	[module_1] scaling ||| [module_1] [class_2]	count=1
function_arg	[function_1] 1 iteration ||| [function_1] [arg_2]	count=2
function	validation ||| validate	count=1
function	for each ||| cross	count=1
arg	regression and cv and ||| y	count=1
function	the time it take ||| squeeze time	count=1
function	determine absolute sizes ||| sizes	count=1
function	the absolute error ||| error	count=1
arg	generate [arg_2] ||| [arg_1] [arg_2]	count=3
function	tolerance which is independent ||| tolerance	count=1
function	the maximizer of the ||| arg max	count=1
class	em ||| latent dirichlet allocation	count=1
function	a calibration ||| calibration	count=1
arg	[arg] the dimensionality ||| x [arg]	count=1
function_arg	run score function [function_1] [arg_2] ||| [function_1] [arg_2]	count=3
arg	used to capture ||| check_pickle	count=1
function	optimal [function_2] ||| [function_2] [function_1]	count=2
function	function of the ||| function	count=1
arg	generate random ||| n_samples	count=1
function_arg	write the [arg_2] ||| [function_1] zfile file_handle [arg_2]	count=5
function	for full covariance matrices ||| multivariate normal density full	count=1
function	return the directory ||| get output dir	count=1
function_arg	determine the number of [function_1] [arg_2] ||| [function_1] [arg_2]	count=1
arg	estimates for each ||| x	count=1
class	the scaler ||| scaler	count=3
function	return probability estimates ||| predict proba	count=1
function_arg	[function_1] between x ||| [arg_2] [function_1]	count=4
class	lad ||| least absolute error	count=1
function	[function] data ||| [function]	count=1
function	fit is on ||| fit	count=1
class	thread pool ||| multiprocessing	count=1
function	[function_1] in-place ||| [function_1] [function_2]	count=1
class	process or ||| multiprocessing backend	count=1
function	[function_1] home ||| [function_2] [function_1]	count=4
class	backend ||| parallel backend	count=1
function	reduction for memmap ||| memmap	count=1
function	isotropic [function] ||| [function]	count=3
class	k ||| white	count=1
module	a byte string ||| externals joblib	count=1
function	shuffle ||| shuffle	count=1
function	right fileobject ||| fileobject	count=1
function	normalize ||| scale normalize	count=1
function	binarization transformation for multiclass ||| binarize multiclass	count=1
class	voting ||| voting	count=1
class	the grid ||| parameter grid	count=1
class	list of exception types ||| backend	count=1
function_arg	finds indices [arg_2] ||| [arg_2] [function_1]	count=2
class	compute the deviance ||| deviance	count=1
arg	reduce x ||| x	count=2
class	avoid ||| func	count=1
function	initial parameters of ||| parameters	count=1
function	cpus ||| cpu count	count=1
function	finds indices ||| matching indices	count=1
arg	data and concatenate ||| y	count=1
function_arg	the median [arg_2] ||| [arg_2] [function_1]	count=2
class	the gaussian process ||| gaussian process	count=2
arg	a classification ||| y_true y_pred labels	count=1
function	[function] the ||| [function]	count=3
arg	dictionary ||| dictionary	count=1
class	[class_1] training ||| [class_2] [class_1]	count=2
function	predict apply ||| predict	count=2
function_arg	[function_1] n_jobs even ||| [function_1] [arg_2]	count=2
function	compute decision function of ||| decision function	count=2
function	a covariance matrix ||| covariance	count=1
arg	0 if y ||| y	count=1
function	the average path ||| average path	count=2
function	huber loss and the ||| huber loss and	count=1
arg	[arg_1] and the ||| [arg_2] [arg_1]	count=4
function	download [function_2] ||| [function_1] [function_2]	count=2
arg	to [arg] return ||| [arg]	count=2
arg	x by scaling rows ||| x	count=1
arg	spectrum spectrum ||| spectrum	count=1
arg	h whose ||| h n_components	count=1
function	samples from a ||| sample	count=1
function	net path ||| enet path	count=1
arg	data in ||| data compress	count=2
function	updating terminal ||| update terminal	count=1
class	local outlier factor of ||| local outlier factor	count=1
class	model ||| linear model	count=1
function_arg	likelihood [arg_2] ||| laplace log marginal [function_1] [arg_2]	count=1
arg	different probability thresholds note ||| probas_pred pos_label sample_weight	count=1
arg	model using x y ||| x y sample_weight	count=1
function	classification problem ||| make classification	count=1
function	rand index ||| rand score	count=1
function	hash ||| hash	count=1
class	types ||| parallel	count=1
class	apply ||| analysis	count=2
class	parallel ||| parallel	count=3
arg	tree ||| tree	count=1
function	list of edges ||| edges	count=1
function	sets of biclusters ||| consensus	count=1
function	for c in ||| c	count=1
arg	dot w [arg_2] ||| [arg_2] [arg_1]	count=1
function	fit a [function_2] ||| [function_2] [function_1]	count=6
function	[function] for ||| barycenter [function]	count=1
arg	y is of ||| y	count=1
function	[function_1] parameters for ||| [function_1] [function_2]	count=1
function	curve auc from prediction ||| auc score	count=1
function	first blank line ||| header	count=1
function_arg	transform [arg_2] ||| [arg_2] [function_1]	count=5
function	data [function_2] ||| [function_1] [function_2]	count=2
function	transform with ||| transform	count=1
function	paired ||| paired	count=2
arg	array is [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	indices [arg_2] ||| [function_1] [arg_2]	count=2
function	as the maximizer of ||| arg max	count=1
function	likelihood function for ||| likelihood function	count=2
class	classifier from the ||| classifier	count=1
function	given cache ||| cache	count=1
function	seeds for ||| seeds	count=1
function_arg	[function_1] corresponding to ||| [arg_2] [function_1]	count=3
function	gaussian random ||| gaussian random	count=2
function	exception in an unfitted ||| estimators unfitted	count=1
arg	operation is meant ||| index_file_path data_folder_path slice_ color	count=1
function	matrix cells ||| covers	count=1
arg	the binary classification task ||| y_true y_score average	count=1
arg	create a base ||| meta	count=2
module	to unit ||| preprocessing	count=1
class	using the gaussian ||| gaussian	count=1
function	boost using the ||| boost	count=1
function_arg	vector [arg_2] ||| [function_1] precision [arg_2]	count=1
function	the data [function_2] ||| [function_1] [function_2]	count=2
function	[function_1] density lrd ||| [function_2] [function_1]	count=1
function	data covariance with ||| covariance	count=2
arg	inefficient ||| classes	count=1
function	patches ||| extract patches	count=1
class	mlp loss function and ||| multilayer perceptron	count=1
function_arg	[function_1] the percentiles ||| [arg_2] [function_1]	count=6
function_arg	[function_1] n ||| [arg_2] [function_1]	count=1
function_arg	run score function [function_1] [arg_2] the appropriate features ||| [function_1] [arg_2]	count=1
function	[function_1] labels ||| [function_2] [function_1]	count=2
arg	parameters ||| x y estimator parameters	count=2
class	[class_1] k ||| [class_2] [class_1]	count=24
function	representation ||| repr	count=1
function	the callable case ||| pairwise callable	count=1
class	classification ||| classifier	count=2
function	row ||| row	count=2
class	the weighted log probabilities ||| base mixture	count=1
function	iterator over estimators in ||| iter	count=1
function	reduced likelihood function ||| reduced likelihood function	count=5
function	names for ||| names	count=1
arg	data and ||| y sample_weight	count=1
function	[function] between each ||| build [function]	count=3
arg	calculates a ||| emp_cov shrinkage	count=1
arg	point ||| x	count=1
arg	each input data point ||| x	count=1
module_class	[module_1] [class_2] matrix ||| [module_1] [class_2]	count=2
function	transform with the ||| transform	count=1
function	[function_1] validity ||| [function_2] [function_1]	count=1
function_arg	[function_1] and ||| [arg_2] [function_1]	count=13
function	[function_1] key ||| [function_2] [function_1]	count=3
class	the ||| empirical covariance	count=2
function	type suitable for ||| int	count=1
function	from [function_2] ||| [function_1] [function_2]	count=4
class	multitaskelasticnet ||| multi task elastic net	count=1
class	trained model parameters ||| multilayer perceptron	count=1
function	strip lines beginning ||| strip	count=1
arg	using x ||| x	count=4
function_arg	[function_1] from module_path/data/data_file_name ||| [function_1] [arg_2]	count=2
class	the density model ||| kernel density	count=1
arg	generate ||| n_samples n_components	count=1
function	reconstruct [function_2] ||| [function_1] [function_2]	count=2
arg	sample_weight ||| sample_weight	count=2
function	of feature [function_2] ||| [function_2] [function_1]	count=1
arg	[arg] and ||| [arg]	count=3
class	exception types ||| backend base	count=1
function	the california ||| fetch california	count=1
function	wishart distribution parameters ||| wishart	count=1
arg	of u ||| u	count=1
arg	stacklevel ||| stacklevel	count=1
function	the kddcup99 dataset ||| brute kddcup99	count=1
arg	estimates for each input ||| x y	count=1
module	input data ||| core	count=1
function	[function_1] shift ||| [function_1] [function_2]	count=2
function	compute non-negative matrix factorization ||| non negative factorization	count=1
class	of exception types ||| parallel	count=1
function_arg	parameters for [arg_2] ||| [arg_2] [function_1]	count=1
arg	of x i ||| x	count=1
function	one-vs-one multi ||| one vs one	count=1
arg	its spectrum spectrum ||| spectrum n_samples	count=1
function	in svmlight format this ||| svmlight	count=1
arg	mean_shift ||| x bin_size min_bin_freq	count=1
arg	in x according ||| x	count=1
function	[function_1] in the ||| [function_1] [function_2]	count=3
class	train test ||| base shuffle split	count=1
function	leaves of the ||| leaves	count=1
arg	update h ||| h	count=1
function	fit for one ||| fit	count=1
function	binarization transformation ||| binarize	count=2
function_arg	transform x ||| transform x y	count=1
function_arg	[function_1] values for ||| [arg_2] [function_1]	count=4
function	[function_1] of k-neighbors ||| [function_2] [function_1]	count=4
function	maximizer of ||| arg max	count=1
function	[function_1] function ||| [function_2] [function_1]	count=23
function	each boosting iteration ||| staged	count=1
arg	values for a given ||| y train	count=2
function	count ||| count	count=2
function	[function_1] svd parameters ||| [function_2] [function_1]	count=1
function	[function_1] clustering ||| [function_1] [function_2]	count=1
function	svmlight format this function ||| svmlight	count=1
function	warnings ||| warnings	count=1
arg	is the ||| y_true y_pred beta labels	count=1
function	strip the headers by ||| strip	count=1
arg	for a given ||| scorer	count=1
module	step using ||| linear_model	count=1
function	compute scores for a ||| score	count=1
arg	to the binary ||| y_score	count=1
function	breakdown ||| breakdown	count=1
class	as ||| orthogonal matching pursuit	count=2
function	apply ||| transform	count=1
function	an 'l' suffix when ||| repr	count=1
class	the hash depending from ||| memorized func	count=1
module	this classification dataset is ||| datasets	count=1
function	precision ||| precision	count=2
arg	[arg_1] [arg_2] ||| fit [arg_1] [arg_2]	count=1
class	local outlier [class_2] ||| [class_2] [class_1]	count=2
arg	and then the underlying ||| y	count=1
function	prediction scores note this ||| roc	count=1
function	[function_1] from the ||| [function_1] [function_2]	count=2
arg	a large ||| a	count=1
module	points in ||| manifold	count=1
arg	x y and get ||| x y	count=1
class	train ||| base	count=1
arg	x [arg_2] ||| paired arrays [arg_1] [arg_2]	count=1
module	distance [module] ||| [module]	count=3
function	callable case ||| callable	count=1
function	weighted ||| weighted	count=1
function	and dispatch them ||| dispatch one	count=1
function	model ||| fit	count=8
class	format ||| coef	count=2
module_class	[module_1] this wrapper ||| [module_1] [class_2]	count=1
arg	generate a ||| n_samples n_components n_features	count=1
class	getter for ||| empirical covariance	count=1
class	class ||| classifier	count=6
arg	parallel n_jobs ||| n_jobs	count=1
class	local ||| local outlier factor	count=1
function	[function_1] backed arrays ||| [function_2] [function_1]	count=3
function	c in ||| c	count=1
function	net path with coordinate ||| enet path	count=1
arg	the percentiles ||| percentiles grid_resolution	count=1
class	the density model on ||| kernel density	count=1
function_arg	get parameters [arg_2] ||| [arg_2] [function_1]	count=4
function	call transform on ||| transform	count=1
class	determinant ||| det	count=1
class	the hash depending from ||| memorized	count=1
function	[function] x ||| [function]	count=1
arg	cast iterable [arg] to a ||| [arg]	count=1
function_arg	fit [arg_2] ||| [function_1] predict [arg_2]	count=1
function	loss [function_2] ||| [function_1] [function_2]	count=5
function	of edges for a ||| edges	count=1
function_arg	[function_1] [arg_2] ||| [function_1] binarize y [arg_2]	count=1
function	compute minimum [function_2] ||| [function_1] [function_2]	count=1
function_arg	row-wise [arg_2] ||| [arg_2] [function_1]	count=5
function_arg	directory [arg_2] ||| [arg_2] [function_1]	count=3
function	in multiplicative update nmf ||| multiplicative update h	count=1
function	[function_1] size ||| [function_2] [function_1]	count=3
function	with aligned memory ||| aligned	count=1
function_arg	from a [arg_2] ||| [function_1] fileobject [arg_2]	count=1
function	set [function_2] ||| [function_2] [function_1]	count=6
module	cache ||| externals	count=1
arg	from source to all ||| source cutoff	count=1
function	for memmap backed arrays ||| memmap backed	count=1
function	of exception ||| get	count=1
class	run ||| grid	count=1
function	at each stage for ||| staged	count=3
function	and persist the ||| call	count=1
arg	transform ||| transform	count=1
class	the linear model ||| linear model	count=1
module	the hash depending ||| externals joblib	count=2
function	an 'l' ||| shape	count=1
module	datasets ||| datasets	count=1
function_arg	[function_1] validity ||| [arg_2] [function_1]	count=1
arg	function [arg] ||| func [arg]	count=2
arg	persist ||| compress protocol	count=1
function	the recall ||| recall	count=1
function	fit linear model ||| fit	count=5
arg	packed_parameters ||| packed_parameters	count=1
class	to avoid the hash ||| memorized	count=1
function	component wise scale ||| scale	count=2
module_class	[module_1] scaling ||| [module_1] robust [class_2]	count=1
module_class	to this [class_2] ||| [module_1] [class_2]	count=1
arg	and returns [arg_2] ||| [arg_1] [arg_2]	count=2
class	to avoid the hash ||| func	count=1
arg	samples in x ||| x	count=3
function	this estimator ||| params	count=1
class	string to the file ||| binary zlib file	count=1
function_arg	[function_1] for x ||| [function_1] predict proba [arg_2]	count=1
function	and dispatch ||| dispatch	count=1
module	a new ndarray ||| utils	count=1
function	compute the gradient of ||| compute	count=1
function	precision is the ratio ||| precision	count=1
arg	[arg] number ||| [arg]	count=1
class	[class_1] corresponding ||| [class_2] [class_1]	count=4
module	[module] in dot ||| [module]	count=2
function	cholesky decomposition of ||| det cholesky	count=1
class	the ||| backend	count=1
function	absolute sizes ||| translate train sizes	count=1
function	[function_1] the wine ||| [function_2] [function_1]	count=1
function	neighbors within a ||| radius neighbors	count=1
module	the hash depending ||| joblib	count=2
module	depending ||| externals	count=2
arg	values ||| train	count=2
class	generate train test ||| base shuffle	count=1
function	data ||| transform	count=1
function	signal ||| signal	count=1
function	[function_1] single binary ||| [function_1] [function_2]	count=3
arg	each input data point ||| x y	count=1
arg	y as ||| y xy	count=2
module	of a cluster ||| cluster	count=1
arg	axis center ||| axis	count=2
arg	zero row of x ||| x y	count=1
arg	and conversion ||| csr_output	count=1
class	generate train ||| shuffle split	count=1
arg	and dense inputs ||| x y sample_weight random_state	count=1
arg	job ||| estimators estimators_features x	count=1
arg	training data and y ||| y	count=2
module	or ||| externals	count=1
function	median absolute error regression ||| median absolute error	count=1
module_class	to this [class_2] ||| [module_1] numpy array [class_2]	count=1
module	types ||| joblib	count=1
function	skip test ||| skip	count=1
arg	training and test ||| x y groups	count=6
arg	the beta-divergence ||| beta	count=1
function	memmap [function_2] ||| [function_2] [function_1]	count=1
function	generate an [function_2] ||| [function_2] [function_1]	count=1
arg	w h ||| x w h n_components	count=1
function	mostly low ||| low	count=1
function_arg	[function_1] x for ||| [arg_2] [function_1]	count=3
function	the shrunk ledoit-wolf ||| ledoit wolf shrinkage	count=1
module_class	on test [class_2] ||| [module_1] [class_2]	count=2
function	by computing truncated ||| truncated	count=1
arg	state of the estimator ||| state	count=1
arg	estimates ||| x	count=1
arg	of regularization ||| pos_class cs	count=1
function	path ||| omp path	count=1
class	ridge regression ||| ridge gcv	count=1
function	load the kddcup99 ||| fetch brute kddcup99	count=1
function	shortest ||| source shortest	count=1
module	convert ||| linear_model	count=1
function	compute ||| compute log det	count=1
function	code ||| get func code	count=1
module_class	returns whether [class_2] ||| [module_1] [class_2]	count=6
function	from a ||| read	count=1
function	predict is invariant ||| labels predict	count=1
class	as training ||| isotonic regression	count=2
arg	squared euclidean [arg_2] ||| [arg_2] [arg_1]	count=2
arg	persist an ||| compress protocol	count=1
function	absolute [function_2] ||| [function_2] [function_1]	count=8
function	determinant matrix ||| fast mcd	count=1
function	the first prime ||| prime	count=1
function	a name ||| get func name	count=1
class	least squares ||| least squares error	count=2
function	random matrix given ||| random choice	count=1
function	lfw [function_2] ||| [function_1] [function_2]	count=12
arg	local structure is retained ||| x_embedded n_neighbors precomputed	count=1
class	[class_1] fastmcd algorithm ||| [class_2] [class_1]	count=2
function	binarize labels in ||| label binarize	count=2
arg	the laplacian matrix ||| laplacian	count=1
module	over ||| feature_selection	count=1
function_arg	a binary [arg_2] ||| [function_1] [arg_2]	count=2
arg	x y as ||| x y	count=4
function	the logistic ||| logistic	count=3
arg	x ||| x n_neighbors	count=2
function	images for ||| images	count=1
function	return a platform ||| shape	count=1
class	to ||| sparse coef mixin	count=1
arg	[arg_1] dense ||| [arg_2] [arg_1]	count=1
function	backend ||| backend	count=2
arg	of csgraph ||| csgraph directed	count=1
module_class	[module_1] determinant with ||| [module_1] min cov [class_2]	count=1
function	[function_1] svd ||| [function_1] [function_2]	count=1
function	kappa a ||| kappa	count=1
arg	training and test set ||| x y groups	count=6
arg	elastic net parameter search ||| xy l1_ratio	count=1
arg	a mask [arg_2] ||| [arg_1] edges [arg_2]	count=1
function	type introduces an ||| shape	count=1
function	"news" format strip ||| strip newsgroup quoting	count=1
function_arg	[function_1] the percentiles ||| [function_1] x x [arg_2]	count=6
arg	x and y ||| x y alpha	count=1
function	[function_1] and transform ||| [function_1] [function_2]	count=1
class	for training data ||| classifier	count=1
function	[function_1] cosine ||| [function_1] [function_2]	count=3
arg	values for x ||| x	count=1
function	fit [function_2] ||| [function_1] [function_2]	count=3
function	is [function_2] ||| [function_1] [function_2]	count=6
function	predict if ||| predict	count=1
arg	x [arg] the ||| x [arg]	count=2
module	paired distance [module] ||| [module]	count=3
function	housing ||| housing	count=1
function	log probabilities within ||| parallel predict log proba	count=1
function	indices [function_2] ||| [function_2] [function_1]	count=2
module_class	points into [class_2] ||| [module_1] [class_2]	count=2
function	number ||| len	count=1
function	paired cosine distances between ||| paired cosine distances	count=1
function	long ||| shape	count=1
arg	does not need ||| tree x y residual	count=1
function	mean update ||| incremental mean	count=1
function_arg	clustering on [arg_2] ||| [function_1] [arg_2]	count=2
module	depending from ||| externals	count=2
function	[function_1] parameters ||| [function_1] [function_2]	count=6
function	of feature ||| get feature	count=1
arg	x y ||| x y sample_weight	count=9
module	the process or thread ||| externals	count=1
class	process ||| multiprocessing backend	count=1
arg	[arg] to ||| [arg]	count=4
function	build from the c ||| build from c	count=1
function	to build a ||| parallel build	count=1
arg	given dataset split ||| scorer	count=1
class	as [class_2] ||| [class_1] [class_2]	count=4
function	training set ||| fit	count=5
function	a diagonal model ||| diag	count=1
class	the trained model ||| multilayer perceptron	count=1
function	the log of ||| log	count=1
arg	[arg_1] vectors ||| [arg_2] [arg_1]	count=1
class	run in parallel ||| parallel	count=1
arg	the normalized laplacian ||| eigen_solver	count=1
function	[function_1] people dataset ||| [function_1] [function_2]	count=4
function	mean absolute [function_2] ||| [function_1] [function_2]	count=4
function	log-likelihood of ||| score	count=1
function	predict apply predict_proba ||| predict	count=2
function_arg	run score function [function_1] [arg_2] appropriate features ||| [function_1] [arg_2]	count=1
arg	y ||| y max_samples	count=1
arg	tree ||| tree forest x y	count=1
function	arrays ||| arrays	count=1
class	avoid the ||| func	count=1
function	return the shortest path ||| source shortest path	count=1
arg	dot w [arg_2] ||| [arg_1] [arg_2]	count=1
function	the decision [function_2] ||| [function_2] [function_1]	count=9
function	return a tolerance which ||| tolerance	count=1
function_arg	kernel between [arg_2] ||| [arg_2] [function_1]	count=2
arg	a filename ||| fileobj filename	count=1
function	of the data ||| data	count=1
function	masks ||| masks	count=1
class	the hash depending ||| memorized	count=1
function	perform a locally ||| locally	count=1
function	under ||| score	count=1
function	a class with ||| add	count=1
class	is worthy enough to ||| cfsubcluster	count=1
function	partially [function_2] ||| [function_2] [function_1]	count=7
function	load the kddcup99 dataset ||| brute kddcup99	count=1
function	l1 distances between ||| paired manhattan distances	count=2
function	the directory in ||| dir	count=1
arg	generate cross-validated ||| y cv	count=1
class	rfe ||| rfe	count=1
function	matrix factorization ||| factorization	count=1
function	modified [function_2] ||| [function_2] [function_1]	count=2
class	test ||| shuffle	count=1
arg	and dense inputs ||| y	count=1
function	items to delete to ||| items to delete	count=1
function_arg	[function_1] [arg_2] ||| [function_1] nn [arg_2]	count=2
class	as [class_2] ||| [class_2] [class_1]	count=4
arg	for each input data ||| estimator x y	count=1
function	the long type ||| repr	count=1
function	[function_1] names for ||| [function_1] [function_2]	count=2
module	hash depending ||| externals	count=2
function	types ||| get	count=1
function	a binary ||| average binary score	count=1
function	a binary classifier ||| binary	count=1
function_arg	[function_1] x as ||| [function_1] [arg_2]	count=2
function_arg	the residues [arg_2] ||| [arg_2] [function_1]	count=2
arg	mask ||| mask	count=1
class	coefficient matrix ||| coef mixin	count=1
function	[function_1] in-place ||| [function_2] [function_1]	count=1
function	number of samples ||| samples	count=1
function	the covariance ||| covariance	count=1
class	to ||| sparse coef	count=1
function	score for a fit ||| fit	count=1
arg	transforms and ||| y	count=1
arg	scale if the scale ||| scale	count=1
function	independent representation ||| repr	count=1
function	the leaves of ||| get leaves	count=1
function	wild lfw [function_2] ||| [function_1] [function_2]	count=4
function	weighted graph of neighbors ||| radius neighbors graph	count=2
function	loading for the lfw ||| lfw	count=2
arg	for each input data ||| estimator x	count=1
function	class weights for ||| compute class	count=1
class	points in ||| parameter	count=1
arg	[arg_1] returns the ||| [arg_2] [arg_1]	count=2
arg	lrd the lrd ||| distances_x neighbors_indices	count=1
class	k ||| constant	count=1
arg	compute the mean and ||| y	count=1
arg	[arg] neighborhoods ||| [arg] radius	count=3
function	a tolerance which is ||| tolerance	count=1
function	shortest [function_2] ||| [function_1] [function_2]	count=2
arg	and dense inputs ||| x y	count=1
class	for label ||| label	count=1
arg	[arg] 1 ||| x [arg]	count=1
function_arg	[function_1] q_ijs ||| [function_1] [arg_2]	count=4
class	coefficient matrix ||| sparse	count=1
module	[module_1] between ||| [module_2] [module_1]	count=2
function	return the shortest path ||| shortest path	count=1
module	function to a ||| externals joblib	count=1
function	object that [function] maps the ||| bind [function]	count=1
arg	[arg_1] and returns ||| [arg_2] [arg_1]	count=4
arg	subcluster ||| subcluster new_subcluster1 new_subcluster2	count=1
class	position ||| binary zlib	count=2
arg	to pickler ||| pickler	count=1
function_arg	np dot x ||| dot x	count=1
function	the laplacian kernel between ||| laplacian kernel	count=1
function_arg	the diagonal [arg_2] ||| [arg_2] [function_1]	count=2
arg	zipped pickle ||| target_dir cache_path	count=1
class	uncompressed bytes from ||| binary zlib	count=1
function	oracle approximating shrinkage algorithm ||| oas	count=1
arg	data parameters ||| y	count=1
module	the minimum covariance ||| covariance	count=1
class	read value from ||| result	count=1
function	precision ap from ||| precision	count=1
function	[function_1] c ||| [function_2] [function_1]	count=3
class	factor ||| factor	count=1
arg	parallel n_jobs is ||| n_jobs	count=1
function	[function_1] function of ||| [function_2] [function_1]	count=5
arg	with n_zeros for ||| n_zeros	count=1
function_arg	[function_1] is positive-definite ||| [function_1] precision [arg_2]	count=1
function	and cpp files ||| and cpp files	count=3
function	median across axis 0 ||| median axis 0	count=1
class	maximum likelihood estimator ||| empirical	count=1
function	rand index [function_2] ||| [function_2] [function_1]	count=4
arg	descent the elastic net ||| l1_ratio	count=1
function	write [function_2] ||| [function_2] [function_1]	count=1
class	of the scaler ||| abs scaler	count=1
module	run a ||| externals joblib	count=1
class	backend ||| backend	count=1
arg	update h ||| x w h beta_loss	count=1
function	with aligned ||| aligned	count=1
class	search ||| base search cv	count=2
function	"news" format strip ||| strip newsgroup	count=3
module	return the ||| externals joblib	count=6
arg	y as training data ||| y copy_x	count=1
arg	cross-validated ||| x y cv	count=2
function	centroids on ||| fit	count=1
arg	local structure is retained ||| x x_embedded n_neighbors precomputed	count=1
function_arg	to [arg_2] ||| [function_1] [arg_2]	count=4
function	download the ||| download	count=1
arg	k ||| k	count=1
arg	y as training data ||| y xy	count=1
function	estimates for each ||| predict	count=1
function_arg	[function_1] p_ij from ||| [arg_2] [function_1]	count=4
function_arg	fit [arg_2] ||| [function_1] and predict [arg_2]	count=1
function	[function_1] weiszfeld ||| [function_2] [function_1]	count=1
arg	compute the median and ||| y	count=1
arg	a given ||| y scorer	count=1
function	log-marginal [function] ||| log marginal [function]	count=1
function	calibration [function_2] ||| [function_1] [function_2]	count=1
class	the ||| multiprocessing backend	count=1
function	fit the model and ||| fit	count=1
function	output of transform ||| transform	count=1
function	to build from the ||| build from	count=1
arg	median and ||| y	count=1
class	to ||| memorized func	count=1
function	loss for ||| loss	count=2
class	the cache for the ||| memorized	count=1
function	bytes_limit ||| reduce	count=1
function	probabilities [function_2] ||| [function_2] predict [function_1]	count=2
arg	x for a ||| x means covars	count=4
arg	if y - pred ||| y pred	count=1
arg	and configure a copy ||| append random_state	count=1
class	common ||| vectorizer	count=1
function	function for ||| function	count=1
function	covariance ||| covariance	count=3
function_arg	mask [arg_2] ||| [function_1] mask [arg_2]	count=1
class	linear model ||| sgdregressor	count=2
class	of exception types ||| base	count=1
arg	and the ||| x y	count=2
arg	estimates ||| y	count=1
arg	the binary classification ||| y_true y_score pos_label	count=1
function	images for image ||| images	count=1
module	point ||| core	count=1
arg	[arg_1] transformed ||| [arg_1] [arg_2]	count=6
function	the l1 ||| manhattan	count=1
arg	the case method='lasso' is ||| xy gram	count=1
function	terminal [function_2] ||| [function_2] [function_1]	count=1
function	verbose [function_2] ||| [function_1] [function_2]	count=3
module	getter ||| covariance	count=1
function	the lfw [function_2] ||| [function_2] [function_1]	count=8
function	squared logarithmic error regression ||| squared log error	count=1
function	each ||| val	count=1
function	the long ||| shape repr	count=1
function	return the directory in ||| get output dir	count=1
arg	for a [arg] ||| [arg]	count=2
arg	downloading it ||| subset data_home download_if_missing random_state	count=1
class	bicluster ||| bicluster mixin	count=2
function	#1240 [function] can't ||| [function]	count=1
function	directory ||| get output dir	count=1
class	maximum [class_2] ||| [class_2] [class_1]	count=3
function_arg	binary [arg_2] ||| [function_1] [arg_2]	count=2
arg	arrays ||| arrays	count=1
function	blobs for clustering ||| make blobs	count=1
function_arg	function [arg_2] ||| [arg_2] [function_1]	count=5
class	[class] for ||| kneighbors [class]	count=1
function_arg	divergence [arg_2] ||| [function_1] error [arg_2]	count=1
function	[function_1] people ||| [function_2] [function_1]	count=4
arg	to capture ||| check_pickle	count=1
arg	data x ||| x	count=2
function	factorization nmf find ||| negative factorization	count=1
arg	a random ||| n_samples eps	count=1
function	custom [function] to summarize ||| [function]	count=1
function	reconstruct [function_2] ||| [function_2] [function_1]	count=2
function	batch and dispatch them ||| dispatch one batch	count=1
arg	vectors ||| vectors n_clusters	count=1
function	mostly low [function_2] ||| [function_1] [function_2]	count=2
function	random matrix ||| random choice	count=1
arg	of the laplacian ||| laplacian	count=1
function	returns [function] ||| [function]	count=3
class	array corresponding ||| numpy array	count=2
arg	as training data ||| copy_x	count=1
function	shutdown ||| terminate	count=1
function	[function_1] [function_2] for ||| [function_2] [function_1]	count=8
function	and cluster the ||| and cluster	count=2
function	dense array format ||| densify	count=1
function	[function_1] output ||| [function_2] [function_1]	count=1
function_arg	[function_1] dot w ||| [arg_2] [function_1]	count=1
function	generate an [function_2] ||| [function_1] [function_2]	count=1
function	jobs that can ||| jobs	count=2
class	process [class_2] ||| [class_2] [class_1]	count=4
function	people dataset this operation ||| people	count=1
function_arg	[function_1] p_ij from ||| [function_1] distances [arg_2]	count=2
function	nugget ||| nugget	count=1
function	run fit on the ||| fit	count=1
class	set ||| linear model	count=1
function_arg	predict is [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg_1] w ||| [arg_2] [arg_1]	count=2
arg	onto the ||| ridge_alpha	count=1
function	predict class ||| predict	count=1
arg	for x using ||| x	count=1
function	the directory in which ||| output dir	count=1
arg	value in data ||| data	count=1
arg	and returns the transformed ||| y w h	count=1
function	feature ||| feature	count=6
function	the kddcup99 dataset ||| kddcup99	count=1
function_arg	[function_1] is the ||| [function_1] [arg_2]	count=1
function	contingency matrix describing ||| contingency matrix	count=1
arg	according to x y ||| x y sample_weight	count=2
function	global [function_2] ||| [function_1] [function_2]	count=4
function	the covariance ||| match covariance	count=1
function	in hastie ||| make hastie	count=1
arg	validity of the input ||| metric p metric_params	count=1
function_arg	perplexity [arg_2] ||| [arg_2] [function_1]	count=3
arg	of length dimensions ||| dimensions	count=1
function	or [function] numpy ||| column or [function]	count=1
arg	x and returns the ||| x y	count=1
function	call predict on ||| predict	count=1
function	[function_1] sample images ||| [function_2] [function_1]	count=1
function	neighbors for points ||| neighbors	count=2
function	and the ||| and	count=1
function	maximum ||| max axis	count=2
arg	and perform dimensionality ||| y	count=1
module	to unit variance ||| preprocessing	count=1
class	coefficient ||| coef mixin	count=1
function	a list of edges ||| make edges	count=1
arg	matrices w h ||| x w h n_components	count=1
function	set the [function_2] ||| [function_2] [function_1]	count=7
function	dispatch them ||| dispatch one	count=1
arg	[arg_1] for a ||| [arg_1] [arg_2]	count=2
function	[function_1] home ||| [function_1] [function_2]	count=4
function	the centroids on ||| fit	count=1
function	platform independent representation of ||| repr	count=1
class	[class_1] found parameters ||| [class_2] [class_1]	count=16
function	callers ||| effective	count=2
function	is stationary ||| is stationary	count=10
arg	of the derived class ||| x resp	count=1
function_arg	mldata [arg_2] ||| [arg_2] [function_1]	count=1
class	[class_1] file ||| [class_2] [class_1]	count=1
function	and right [function] all ||| generate [function]	count=1
function	column [function] of ||| get [function]	count=1
arg	a mask to ||| mask edges weights	count=1
class	we don't ||| func	count=1
module	exception types ||| externals joblib	count=1
arg	generate cross-validated ||| x y cv	count=1
module	selected ||| feature_selection	count=1
class	gradient [class_2] ||| [class_1] [class_2]	count=2
arg	loader for the ||| data_home	count=2
class	hash depending from it ||| memory	count=1
arg	implement a single ||| iboost	count=2
function	infers the dimension ||| dimension	count=1
function	[function_1] reduced ||| [function_1] [function_2]	count=2
module	remove cache folders to ||| joblib	count=1
class	signature from ||| signature	count=1
function_arg	gaussian [arg_2] ||| [arg_2] [function_1]	count=1
function	distances between ||| distances	count=5
function	thread pool ||| backend	count=1
function	reconstruct ||| reconstruct	count=1
function_arg	and [arg_2] ||| regressor sample [function_1] [arg_2] random_state	count=1
arg	[arg_1] a ||| [arg_2] [arg_1]	count=8
function_arg	text files [arg_2] ||| [arg_2] [function_1]	count=2
class	[class] for the ||| radius neighbors [class]	count=1
function	build from ||| build from	count=2
class	[class_1] outlier factor ||| [class_2] [class_1]	count=4
arg	data x with ability ||| x	count=1
class	regression target ||| regressor	count=1
arg	remove a subcluster from ||| subcluster	count=1
function	for the california ||| fetch california	count=1
arg	perform ||| responsibilities params min_covar	count=1
function	kernel is [function_2] ||| [function_2] [function_1]	count=1
module	avoid the hash depending ||| externals	count=2
function	[function_1] scores note ||| [function_2] [function_1]	count=2
arg	n_jobs even ||| n_jobs	count=1
function	[function_1] estimators ||| [function_2] [function_1]	count=5
arg	each parameter weights and ||| x y	count=1
class	process or thread pool ||| multiprocessing	count=1
function	the shortest ||| source shortest	count=1
arg	a mask ||| mask	count=1
function	covariance matrix shrunk ||| shrunk covariance	count=3
function	classifier ||| classifier	count=1
function	likelihood [function_2] ||| [function_1] [function_2]	count=5
module	of exception ||| joblib	count=1
function	the l1 distances between ||| manhattan distances	count=1
class	list of ||| backend	count=1
function	'l' suffix ||| shape repr	count=1
arg	unit norm vector length ||| norm axis copy	count=1
function	cholesky decomposition ||| det cholesky	count=1
class	gradient [class_2] ||| [class_2] [class_1]	count=2
class	generate ||| base shuffle split	count=2
arg	the transformed ||| h	count=1
class	with passive [class_2] ||| [class_2] [class_1]	count=2
function	non-negative matrix factorization nmf ||| factorization	count=1
class	multi-class targets using underlying ||| output code	count=1
class	whether the kernel ||| kernel operator	count=1
function	derivative ||| derivative	count=1
function	long type ||| repr	count=1
function	return [function_2] ||| [function_2] [function_1]	count=3
function	build from [function_2] ||| [function_1] [function_2]	count=4
function	[function_1] block checkerboard ||| [function_2] [function_1]	count=1
class	process regression model we ||| process regressor	count=1
arg	[arg_1] of x ||| [arg_2] [arg_1]	count=5
function	a job ||| parallel	count=1
arg	standardize a ||| with_centering with_scaling	count=1
function_arg	[function_1] to multi-class ||| [function_1] [arg_2]	count=1
module	of exception types ||| externals joblib	count=1
function	to fit a single ||| trees	count=1
module	of ||| externals	count=1
module	the closest cluster ||| cluster	count=1
function	[function_1] curve ||| [function_1] [function_2]	count=4
function_arg	[function_1] and concatenate ||| [arg_2] [function_1]	count=1
arg	for mono and multi-outputs ||| x y eps n_alphas	count=1
arg	and y ||| y alpha	count=1
function	load sample images ||| load sample images	count=3
arg	generate ||| n_samples n_components n_features	count=1
arg	for data x with ||| x	count=1
function	covariance matrix ||| covariance	count=1
module	returns whether ||| gaussian_process	count=3
module	returns ||| core	count=1
function	curve auc from prediction ||| auc	count=1
arg	for mono and ||| y	count=1
function	the log-likelihood ||| score	count=1
arg	curve of width ||| effective_rank tail_strength	count=1
arg	meant ||| data_folder_path slice_ color resize	count=1
function_arg	[function_1] [arg_2] neighborhoods are restricted the ||| [function_1] [arg_2] radius	count=30
class	of exception ||| backend	count=1
function	reproducibility flips [function_2] ||| [function_2] [function_1]	count=3
function	dispatch them ||| dispatch	count=1
class	[class_1] training ||| [class_1] [class_2]	count=2
function	format check x ||| check	count=1
arg	samples x ||| x	count=6
function	register ||| register	count=1
function	download the 20 newsgroups ||| download 20newsgroups	count=1
function	data ||| predict	count=1
arg	a random sample from ||| size replace p	count=1
arg	sparse and dense inputs ||| x y sample_weight	count=1
arg	from distances ||| distances	count=2
function	slices ||| slices	count=1
module	rare or ||| feature_extraction	count=1
arg	between jobs ||| n_estimators n_jobs	count=1
function_arg	residues [arg_2] ||| [arg_2] [function_1]	count=2
function	input data point ||| val predict	count=1
arg	the binary classification task ||| y_true y_score pos_label	count=1
function	verbose ||| verbose	count=2
class	the parallel ||| parallel	count=1
function	the pairwise matrix in ||| pairwise	count=1
class	[class_1] the scaling ||| [class_2] [class_1]	count=1
function	[function_1] wine ||| [function_1] [function_2]	count=1
arg	stacklevel is the ||| stacklevel	count=1
function	is a ||| is	count=1
arg	length dimensions ||| dimensions	count=1
function	sigmoid ||| sigmoid	count=2
class	the voting [class_2] ||| [class_1] [class_2]	count=4
function	the covariance ||| matrix to match covariance	count=1
function	finds indices in ||| find matching indices	count=1
function	[function_1] labels back ||| [function_2] [function_1]	count=2
module	of ||| joblib	count=1
function	logistic loss [function_2] ||| [function_2] [function_1]	count=2
class	fits the graphlasso ||| graph lasso cv	count=1
function	a tolerance which ||| tolerance	count=1
arg	and then the underlying ||| x y	count=1
function	laplacian kernel ||| laplacian kernel	count=2
function	a fit ||| fit	count=1
function_arg	[function_1] svd ||| [arg_2] [function_1]	count=5
function	report [function_2] ||| [function_2] [function_1]	count=2
class	generative ||| pca	count=1
module	we don't store ||| joblib	count=2
arg	x [arg] the dimensionality ||| x [arg]	count=1
function	call ||| format call	count=1
function	[function_1] variance ||| [function_1] [function_2]	count=6
arg	a mask [arg_2] ||| [arg_1] [arg_2]	count=1
arg	using x as training ||| x	count=2
function	estimates ||| val	count=1
module	from it ||| externals joblib	count=2
arg	classification task ||| y_true y_score	count=1
arg	corresponding to ||| mkdir	count=1
function	folders to ||| reduce	count=1
arg	y_prob ||| y_prob	count=1
function	given cache key ||| cache key	count=2
function_arg	back to [arg_2] ||| [arg_2] [function_1]	count=3
arg	for a [arg_1] [arg_2] ||| [arg_2] [arg_1]	count=4
function_arg	an mldata [arg_2] ||| [function_1] [arg_2]	count=1
function	an unfitted ||| estimators unfitted	count=1
arg	gp prior ||| return_std return_cov	count=1
arg	squared euclidean norm of ||| squared	count=1
arg	to the binary classification ||| y_true y_score average	count=1
function_arg	max [function_1] [arg_2] later ||| [function_1] [arg_2]	count=2
function_arg	transform x ||| transform x	count=1
arg	[arg_1] [arg_2] ||| [arg_2] [arg_1]	count=240
function	corresponding to test sets ||| test	count=1
function	clustering on ||| fit predict	count=1
function	a list of edges ||| edges	count=1
class	linear ||| base sgdregressor	count=2
function	k-neighbors ||| kneighbors	count=1
function	finds seeds for ||| seeds	count=1
function	the one-vs-one multi class ||| one vs one	count=1
module	the ||| neural_network	count=1
arg	compute the beta-divergence ||| beta	count=1
arg	values for a ||| y train	count=2
function	california ||| california	count=1
class	process regression model ||| process regressor	count=2
function	descent fit is on ||| fit	count=1
arg	or sparse matrix x ||| x dict_type	count=1
class	[class_1] boosting ||| [class_2] [class_1]	count=5
function	partially fit a ||| partial fit	count=4
arg	x y ||| x y	count=29
function	mean and ||| incr mean	count=1
module	under a ||| externals joblib	count=1
function	binary ||| binary score	count=1
arg	and ||| x y sample_weight	count=3
class	the ||| bayesian gaussian mixture	count=1
function	name for the ||| get func name	count=1
class	list of ||| backend base	count=1
function	generate ||| cross	count=1
arg	y is of a ||| y	count=1
function_arg	the neighbors [arg_2] ||| [function_1] [arg_2]	count=1
function	estimate class weights for ||| class	count=1
function	going up ||| even	count=1
arg	vector ||| w	count=1
function	the neighbors ||| radius neighbors	count=1
function	mean and [function_2] ||| [function_1] [function_2]	count=2
module	dataset regression ||| datasets	count=1
function	[function_1] thresholding ||| [function_2] [function_1]	count=1
function	neighbors ||| neighbors	count=4
arg	y and get ||| y	count=1
function_arg	data [arg_2] ||| [arg_2] [function_1]	count=1
function	guts of [function] method no ||| [function]	count=1
function	suffix when using the ||| repr	count=1
class	model ||| model	count=2
arg	data to ||| data	count=1
function	a fully connected graph ||| graph	count=1
module	remove cache folders to ||| externals	count=1
function	compute log ||| log	count=2
function	fit the ||| fit	count=23
arg	of x according ||| x	count=1
module_class	returns whether the ||| gaussian_process dot product	count=1
class	features ||| features	count=1
function	read up ||| read	count=1
function	scale back the data ||| inverse transform	count=2
function	barycenter weighted graph ||| barycenter kneighbors graph	count=2
module	independent representation of ||| utils	count=1
class	the cache ||| memorized	count=1
arg	for ||| means covars	count=2
arg	perform ||| responsibilities params	count=1
function	symmetric ||| symmetric	count=1
function_arg	[function_1] multi-class ||| [function_1] [arg_2]	count=1
module	relationship [module_2] ||| [module_2] [module_1]	count=2
function	sources [function] to ||| [function]	count=1
arg	any axis center to ||| axis	count=2
function_arg	[function_1] lrd ||| [arg_2] [function_1]	count=3
function	precisions ||| precisions	count=2
module	for ||| covariance	count=1
function	indices ||| iter indices	count=1
class	of the [class_2] ||| [class_1] [class_2]	count=2
arg	turn [arg] into ||| [arg]	count=1
function	the lfw people dataset ||| fetch lfw people	count=1
class	quantiles ||| robust	count=1
arg	input validation ||| accept_sparse dtype	count=1
function	a platform independent ||| repr	count=1
class	the process ||| backend	count=1
function	absolute error ||| error	count=1
module	representation ||| utils	count=1
function	row scaling ||| row	count=2
function	x ||| x predict	count=1
function	load sample ||| load sample	count=2
function	labels back ||| inverse	count=1
function	create all the covariance ||| to match covariance	count=1
class	of the memory ||| memory	count=1
function_arg	files [arg_2] ||| [arg_2] [function_1]	count=2
function	a random multilabel ||| multilabel	count=1
arg	beta-divergence of [arg_2] ||| [arg_2] [arg_1]	count=1
arg	and returns the ||| y	count=1
function	reduced likelihood ||| reduced likelihood	count=3
function	found and raise ||| line search	count=1
function	dummy feature ||| dummy feature	count=2
arg	to multi-class labels ||| y threshold	count=1
arg	optionally its gradient ||| eval_gradient	count=11
function	build ||| build	count=2
arg	this ||| deep	count=3
function	row-wise ||| row norms	count=1
function_arg	[function_1] and ||| [function_1] x [arg_2]	count=2
module	platform independent ||| utils	count=1
class	found ||| search	count=5
function_arg	[function_1] and compute ||| [function_1] estimator estimator [arg_2]	count=2
function	for the one-vs-one multi ||| one vs one	count=1
class	the kernel k ||| constant kernel	count=2
function	sparse random matrix given ||| random	count=1
class	array ||| array	count=1
function	break the pairwise matrix ||| pairwise	count=1
class	for ||| covariance	count=1
function	ability to accept precomputed ||| precomp distr	count=1
function	[function_1] probability estimates ||| [function_1] [function_2]	count=2
function	introduces ||| repr	count=1
module	list of ||| externals	count=1
class	compute data ||| base pca	count=1
function	loading for the lfw ||| fetch lfw	count=2
arg	a ||| a	count=8
function	indices ||| generate indices	count=1
function	of edges ||| make edges	count=1
module	matrix ||| linear_model	count=1
arg	matching pursuit ||| y n_nonzero_coefs tol	count=1
function	name for ||| name	count=1
function	predict is invariant ||| predict	count=1
arg	a given radius of ||| radius	count=1
class	randomly drawn ||| randomized search cv	count=1
function	multinomial [function_2] ||| [function_1] [function_2]	count=1
arg	generate ||| estimator x y	count=1
arg	x [arg] ||| x [arg]	count=2
function_arg	[function_1] percentiles of ||| [arg_2] [function_1]	count=5
function	the lfw people ||| fetch lfw people	count=2
arg	the binary classification task ||| y_true	count=1
arg	corresponding derivatives with respect ||| activations deltas	count=1
arg	average ||| average	count=1
function	decision function to ||| decision function	count=2
module_class	[module_1] for scaling ||| [module_1] robust [class_2]	count=1
function	binary classification threshold ||| binary	count=1
function	fully connected graph ||| graph	count=1
function	[function_1] squared logarithmic ||| [function_1] [function_2]	count=1
function_arg	seeds [arg_2] ||| [function_1] [arg_2]	count=1
arg	binary classification task ||| y_true y_score	count=2
function	load and return the ||| load	count=5
function	list of edges ||| make edges	count=1
arg	validation and [arg_2] ||| [arg_2] [arg_1]	count=2
arg	of this kernel ||| deep	count=1
function	[function_1] batch ||| [function_2] [function_1]	count=1
function	compute the laplacian kernel ||| laplacian kernel	count=1
function	lower bound for the ||| bound means	count=1
function_arg	[function_1] lrd of ||| reachability [function_1] [arg_2]	count=1
class	local ||| outlier factor	count=1
arg	and scale the data ||| x y	count=1
arg	generate ||| x	count=1
module	using ||| utils	count=1
arg	of a classification ||| y_true y_pred labels	count=1
function	compute labels ||| labels	count=1
arg	for mono and ||| x y	count=1
module	the hash depending from ||| joblib	count=2
function	return a platform ||| repr	count=1
function	[function_1] of this ||| [function_1] [function_2]	count=3
function_arg	[function_1] from sklearn ||| [function_1] [arg_2]	count=2
arg	to multi-class ||| threshold	count=1
function_arg	[function_1] neighbors ||| [arg_2] [function_1]	count=1
class	don't ||| memorized	count=1
function	by scaling each ||| minmax scale	count=1
function	memmap backed arrays ||| memmap backed	count=2
function	timestamp when pickling ||| reduce	count=2
function	[function_1] message on ||| [function_1] [function_2]	count=4
module	cache folders ||| joblib	count=1
module	remove ||| externals joblib	count=2
class	cache for the function ||| memorized func	count=1
module	list of exception types ||| externals joblib	count=1
arg	[arg] appropriately and ||| [arg]	count=1
function	that [function] maps the ||| bind [function]	count=1
function	return feature ||| get feature	count=2
class	of exception types to ||| backend	count=1
arg	[arg_1] length dimensions ||| [arg_1] [arg_2]	count=1
arg	the given parameter ||| estimator parameter	count=1
function	concentration parameter ||| concentration	count=1
function	transform is ||| transform	count=1
function	[function_1] patches ||| [function_1] [function_2]	count=3
arg	gp prior ||| x return_std return_cov	count=1
arg	ridge and ||| y	count=1
class	train ||| shuffle split	count=2
function	for c ||| c	count=1
function	the directory in which ||| get output dir	count=1
function	labels ||| labels	count=1
function_arg	single binary [arg_2] ||| [function_1] [arg_2]	count=4
function	[function_1] likelihood ||| [function_2] [function_1]	count=10
function	error regression loss read ||| log error	count=1
function	factorization nmf find ||| non negative factorization	count=1
function	for memmap ||| memmap	count=1
arg	multi-class ||| threshold	count=1
module	to a ||| externals joblib	count=1
arg	from source to ||| graph source	count=1
function	evaluates the reduced likelihood ||| reduced likelihood	count=1
arg	structure for biclustering ||| shape n_clusters noise minval	count=1
class	getter for ||| covariance	count=1
arg	within a job ||| estimators estimators_features	count=1
function_arg	probabilities [arg_2] ||| [arg_2] [function_1]	count=10
arg	tree ||| tree forest x	count=1
arg	[arg] number of ||| [arg]	count=1
arg	from features or ||| x y sample_weight	count=1
function	generates integer indices ||| indices	count=1
module	an 'l' suffix ||| utils	count=1
function	get parameters ||| get params	count=10
function_arg	laplacian kernel [arg_2] ||| [function_1] [arg_2]	count=2
function	generate ||| predict	count=1
class	list of exception types ||| parallel backend base	count=1
class	is worthy ||| cfsubcluster	count=1
arg	n_jobs even ||| func n_jobs	count=1
module	to the [module] ||| [module]	count=3
function	median absolute [function_2] ||| [function_1] [function_2]	count=4
function	wishart distribution ||| wishart	count=2
arg	and then the ||| x y	count=1
arg	compute the mean and ||| x y	count=1
function	the california [function_2] ||| [function_2] [function_1]	count=4
function_arg	em update [arg_2] ||| [function_1] [arg_2]	count=1
function	dense array ||| densify	count=1
class	the kernel ||| stationary kernel mixin	count=1
function	from all of ||| from	count=1
arg	y ||| y sample_weight	count=5
arg	the data onto the ||| x ridge_alpha	count=1
function	for species ||| fetch species	count=1
arg	and transforms ||| y	count=1
function	range of ||| range finder	count=1
class	covered ||| state	count=1
arg	to x return leaf ||| x	count=1
module	a with block ||| externals joblib	count=2
function	the sources [function] to ||| [function]	count=1
function_arg	[function_1] with x ||| [arg_2] [function_1]	count=2
arg	other and ||| x y	count=1
arg	the data in ||| data compress	count=2
arg	with stochastic gradient descent ||| coef_init intercept_init	count=1
function	clustering for the subclusters ||| clustering	count=1
function	em update ||| em step	count=1
module	the closest cluster each ||| cluster	count=1
arg	[arg_1] y ||| [arg_1] [arg_2]	count=24
arg	job ||| estimators estimators_features x n_classes	count=1
arg	binary classification ||| y_true y_score	count=2
module	on ||| core	count=2
function	estimates for each ||| cross val	count=1
function	input ||| cross val predict	count=2
arg	draw randomly sampled ||| random_state bootstrap n_population n_samples	count=1
function	the data home ||| data home	count=1
function	mldata ||| mldata	count=1
arg	makes ||| x copy	count=1
function	getter ||| get	count=1
arg	given dataset split ||| y scorer	count=1
class	min ||| min	count=1
function	a text report showing ||| report	count=1
arg	dense dictionary factor ||| dictionary y	count=1
function	the curve auc from ||| auc	count=1
arg	input data ||| estimator x y	count=1
function	run [function_2] ||| [function_2] [function_1]	count=4
arg	laplacian matrix and convert ||| laplacian	count=1
function	assignment problem using the ||| assignment	count=1
function	blobs for ||| make blobs	count=1
function	compute non-negative matrix factorization ||| factorization	count=1
function	kddcup99 ||| kddcup99	count=1
function	return number of samples ||| samples	count=1
function_arg	checkerboard [arg_2] ||| [function_1] [arg_2]	count=3
function_arg	[function_1] and ||| [function_1] inertia precompute dense [arg_2]	count=1
class	the backend ||| backend base	count=1
function	spherical wishart ||| wishart spherical	count=2
function	create all the covariance ||| covar matrix to match covariance	count=1
class	computes the position ||| mds	count=1
arg	meant to be cached ||| index_file_path data_folder_path slice_ color	count=1
function	logistic regression ||| logistic regression path	count=2
class	computes the position of ||| mds	count=1
arg	values for ||| y train	count=2
arg	the gradient and ||| w x y	count=2
arg	from features ||| y sample_weight	count=1
arg	for ||| estimator x	count=1
arg	x according to feature_range ||| x	count=1
function_arg	[function_1] [arg_2] ||| bagging [function_1] [arg_2]	count=20
class	boost ||| ada boost classifier	count=2
function	reconstruct the image ||| reconstruct	count=1
function_arg	normalize x by ||| scale normalize x	count=1
class	generate train ||| base	count=1
module	of points [module] the ||| [module]	count=1
function	the state ||| state	count=1
class	the search over parameters ||| search	count=1
function	a binary classifier on ||| binary	count=1
arg	filters the [arg_2] ||| [arg_1] [arg_2]	count=5
function	sizes ||| translate train sizes	count=1
function	of the data home ||| data home	count=1
arg	from source ||| source	count=1
function	[function_1] images for ||| [function_2] [function_1]	count=2
arg	model to x ||| x y	count=1
arg	of points ||| metric	count=1
function	svmlight ||| svmlight	count=1
module	store ||| externals	count=2
class	matrix to ||| mixin	count=1
function	cluster the ||| cluster	count=1
function_arg	[function_1] and y_prob ||| [arg_2] [function_1]	count=1
function	the precision ||| precision	count=1
class	depending from ||| memorized func	count=1
function	estimates for each input ||| val predict	count=1
function	[function_1] the reduced ||| [function_1] [function_2]	count=3
arg	from source ||| source cutoff	count=1
arg	x for later ||| x y	count=1
arg	generate ||| n_samples n_features	count=5
function_arg	centroids on x ||| fit x	count=1
module	cache ||| joblib	count=1
arg	array is [arg_2] ||| [arg_1] [arg_2]	count=1
function_arg	run score function [function_1] [arg_2] features ||| [function_1] [arg_2]	count=1
class	leaf ||| decision tree	count=1
function	remove cache folders to ||| reduce	count=1
function	normalize ||| normalize	count=1
function	the median ||| get median	count=1
function_arg	normalize x ||| scale normalize x	count=1
class	the gaussian process regression ||| gaussian process regressor	count=1
function	samples ||| decision	count=1
module	a size ||| externals joblib	count=1
arg	sparse and ||| y sample_weight	count=1
function	20 newsgroups data ||| 20newsgroups	count=1
function	validity ||| params	count=1
class	can be different from ||| calibrated classifier	count=1
function	apply trees ||| apply	count=1
arg	[arg_1] multi-outputs ||| [arg_1] [arg_2]	count=1
function	of transform is sometimes ||| transform	count=1
arg	and ||| x y axis	count=1
function	[function_1] loss ||| [function_1] [function_2]	count=9
class	with the generative model ||| pca	count=1
arg	a given [arg_2] ||| [arg_2] [arg_1]	count=4
arg	v ||| v	count=1
arg	dimensions ||| dimensions rng	count=1
function	absolute [function_2] ||| [function_1] [function_2]	count=8
class	target ||| regressor	count=2
arg	points ||| axis metric	count=1
function	[function_1] posterior probability ||| [function_1] [function_2]	count=1
function_arg	[function_1] set x ||| [arg_2] [function_1]	count=12
arg	case method='lasso' is : ||| x y xy gram	count=1
function_arg	[function_1] [arg_2] ||| [function_1] y [arg_2]	count=1
module	convert coefficient matrix to ||| linear_model	count=1
class	kernel k ||| compound kernel	count=2
function	the barycenter [function_2] ||| [function_1] kneighbors [function_2]	count=2
function	x ||| fit transform	count=1
arg	a mask [arg_2] ||| [arg_2] [arg_1]	count=2
function	is [function_2] ||| [function_2] [function_1]	count=6
arg	according to ||| y sample_weight	count=2
arg	w ||| w ht l1_reg	count=1
function	[function_1] and transform ||| [function_2] [function_1]	count=1
function	report ||| report	count=1
class	avoid the hash depending ||| memorized func	count=1
function	random multilabel classification ||| multilabel classification	count=1
function	[function_1] variance ||| [function_1] [function_2] n_past mu var x	count=1
function	compute log probabilities of ||| log proba	count=1
module	input ||| core	count=1
arg	[arg] the ||| [arg]	count=1
function	perplexity ||| perplexity	count=2
class	linear model parameters ||| base sgdregressor	count=2
function	transform on the estimator ||| transform	count=1
arg	of regularization parameters ||| x y pos_class cs	count=1
function	the feature [function] ||| feature [function]	count=6
module	don't store ||| externals	count=2
function	the california housing dataset ||| california housing	count=1
function	compute [function_1] [function_2] ||| metrics [function_1] [function_2]	count=2
arg	self ||| x_test y	count=1
function	data ||| data	count=3
function	array with block checkerboard ||| checkerboard	count=1
class	the gradient boosting ||| base gradient boosting	count=6
function	and component wise scale ||| robust scale	count=1
function_arg	on [arg_2] ||| [arg_2] [function_1]	count=13
function	estimate sample ||| compute sample	count=1
class	scaler ||| max scaler	count=1
function	vector ||| positivity	count=1
function_arg	score [arg_2] ||| [arg_2] [function_1]	count=6
arg	continuous target variable ||| discrete_features n_neighbors	count=1
function	[function_1] batch ||| [function_1] [function_2]	count=1
function	kddcup99 ||| brute kddcup99	count=1
arg	cross-validated estimates ||| x y cv	count=1
module	to run a ||| externals joblib	count=1
arg	[arg] 1 inlier ||| x [arg]	count=1
arg	workaround python 2 limitations ||| obj methodname	count=1
arg	the derived ||| resp	count=1
function	linear [function_2] ||| [function_1] [function_2]	count=6
function	create all the covariance ||| matrix to match covariance	count=1
arg	each input ||| y	count=1
function	for each input ||| cross val	count=1
arg	[arg_1] <mean_squared_log_error> ||| [arg_1] [arg_2]	count=2
function_arg	backend [arg_2] ||| [function_1] [arg_2]	count=1
arg	gram ||| gram	count=1
arg	for ||| means	count=2
arg	significance of a cross-validated ||| estimator x y cv	count=1
class	whether the kernel ||| stationary kernel	count=1
function	gaussian ||| make gaussian	count=1
arg	[arg_1] kwargs ||| [arg_2] [arg_1]	count=3
arg	[arg_1] and y ||| [arg_2] [arg_1]	count=30
function	set the parameters of ||| set	count=4
arg	[arg_1] of csgraph ||| [arg_2] dtype [arg_1]	count=2
module	in bytes_limit ||| externals joblib	count=1
arg	func to be run ||| func	count=3
arg	the data and concatenate ||| y	count=1
class	[class_1] gradient ||| [class_1] [class_2]	count=3
function	the range of ||| randomized range finder	count=1
function	graph of the ||| img to graph	count=1
arg	and a set of ||| y	count=1
arg	structure for ||| shape n_clusters noise minval	count=1
function	barycenter ||| barycenter	count=1
arg	y as training ||| y xy	count=2
arg	for a ||| means	count=2
function	c and cpp files ||| c and cpp files	count=1
function	contingency matrix describing the ||| contingency matrix	count=1
arg	x as training ||| x	count=2
function	[function_1] single binary ||| [function_2] [function_1]	count=5
function	and variance ||| variance	count=3
function_arg	boolean mask [arg_2] ||| [function_1] [arg_2]	count=2
function	ledoit-wolf ||| ledoit wolf	count=2
function	[function_1] cluster ||| [function_2] [function_1]	count=1
function	people dataset this ||| people	count=1
arg	sum_h exp(-e v ||| v	count=1
arg	is meant to ||| index_file_path data_folder_path slice_ color	count=1
function_arg	[function_1] on ||| [function_1] x [arg_2]	count=2
arg	data onto ||| ridge_alpha	count=1
function	set ||| set	count=6
function	wise scale ||| scale	count=2
function	[function_1] diagonal ||| [function_1] mstep [function_2]	count=1
module	relationship [module_2] ||| [module_1] [module_2]	count=2
class	the kernel [class_2] ||| [class_2] [class_1]	count=9
function	the shrunk ledoit-wolf ||| ledoit wolf	count=1
arg	binary classification task ||| y_true y_score pos_label	count=1
arg	and train_size ||| train_size	count=1
arg	threshold ||| threshold	count=1
function_arg	[function_1] to ||| [function_1] mask edges [arg_2]	count=1
arg	based on a feature ||| connectivity n_clusters return_distance	count=1
function	curve auc [function_2] ||| [function_2] [function_1]	count=2
function_arg	and dot [arg_2] ||| [arg_2] [function_1]	count=2
arg	is inefficient to ||| y classes	count=1
function	predict [function_2] ||| [function_2] [function_1]	count=3
class	of exception ||| parallel backend	count=1
arg	the beta-divergence [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	[function_1] between jobs ||| [arg_2] [function_1]	count=5
class	generates ||| repeated splits	count=1
arg	routine for validation and ||| dtype	count=1
arg	loader for the ||| data_home download_if_missing	count=1
arg	each sample in x ||| x	count=1
arg	each ||| estimator	count=1
class	propagation ||| propagation	count=1
class	scaling of ||| scaler	count=1
function	[function_1] using thresholding ||| [function_1] [function_2]	count=1
class	search over ||| base search	count=1
function	the first prime element ||| prime	count=1
function	'l' suffix ||| repr	count=1
class	classification [class_2] ||| [class_2] [class_1]	count=2
function	random multilabel ||| multilabel	count=1
class	em algorithm ||| gmmbase	count=3
arg	[arg] appropriately ||| x [arg]	count=1
arg	subsets and validate 'train_sizes' ||| train_sizes n_max_training_samples	count=1
function	the range ||| randomized range	count=1
arg	data in the given ||| data compress	count=1
module	generate ||| core	count=2
arg	check if y ||| y	count=1
function	home cache ||| home	count=1
arg	generate cross-validated estimates ||| estimator x y cv	count=1
class	[class] of ||| grid [class]	count=1
function	patches of any n-dimensional ||| extract patches	count=1
arg	rows of u such ||| u	count=1
arg	configure a copy of ||| append	count=1
function	[function_1] for full ||| [function_1] mstep [function_2]	count=1
arg	i ||| i data	count=1
arg	is inefficient to train ||| x y classes	count=1
function	class [function_2] ||| [function_1] [function_2]	count=3
module	'l' ||| utils	count=1
arg	configure ||| append	count=1
arg	model according to the ||| y sample_weight	count=2
function	data precision matrix with ||| get precision	count=1
function	[function_1] function of ||| [function_1] [function_2]	count=5
arg	discrete [arg_2] ||| [arg_2] [arg_1]	count=2
function	the kddcup99 ||| brute kddcup99	count=1
function	spherical [function_2] ||| [function_2] [function_1]	count=6
arg	returns the [arg_2] ||| [arg_2] [arg_1]	count=2
arg	w h ||| w h	count=3
function	factorization nmf find two ||| negative factorization	count=1
function	[function_1] parameters for ||| [function_2] [function_1]	count=1
function	generative model ||| get	count=1
function	csgraph ||| validate graph	count=1
function	the covariance ||| distribute covar matrix to match covariance	count=1
arg	place ||| code verbose	count=1
function	covariance matrix ||| cov	count=1
function	negative value ||| negative	count=1
function	scores note this implementation ||| roc	count=1
module	tree ||| tree	count=1
function	with the ||| get	count=1
class	which [class_2] ||| [class_2] [class_1]	count=2
function	updates terminal regions ||| terminal	count=1
class	[class_1] the grid ||| [class_1] [class_2]	count=2
arg	computes ||| metric	count=1
arg	[arg_1] y as ||| [arg_2] [arg_1]	count=4
arg	filters [arg_2] ||| [arg_1] [arg_2]	count=5
function_arg	labels back [arg_2] ||| [arg_2] [function_1]	count=3
function	of the decision ||| decision	count=1
function	exceptions ||| raise message	count=1
class	naive bayes classifier ||| discrete nb	count=1
function	when using ||| shape repr	count=1
module	embedding space ||| manifold	count=1
class	the ||| func	count=2
function_arg	random matrix [arg_2] ||| [function_1] n_samples [arg_2]	count=1
arg	the dense dictionary ||| dictionary y	count=1
function	full ||| density full	count=2
function	the long type ||| shape repr	count=1
function	range ||| randomized range	count=1
arg	each input data point ||| estimator x	count=1
function	all [function_2] ||| [function_1] [function_2]	count=1
function	jaccard [function] coefficient defined ||| jaccard [function]	count=1
module	the hash ||| externals joblib	count=2
function	fetch an ||| fetch	count=1
function	trace of [function_2] ||| [function_2] [function_1]	count=1
function	training [function_2] ||| [function_2] [function_1]	count=2
function	[function_1] path ||| [function_1] [function_2]	count=10
arg	the data ||| y	count=1
function	[function_1] block checkerboard ||| [function_1] [function_2]	count=1
function	build from [function_2] ||| [function_2] [function_1]	count=4
function	right fileobject [function_2] ||| [function_2] [function_1]	count=2
arg	is inefficient to train ||| y classes	count=1
arg	and ||| x	count=3
function	to be captured ||| get exceptions	count=1
class	two covariance estimators ||| covariance	count=1
function	a single ||| trees	count=1
module	retrieve a ||| externals	count=1
arg	and class probabilities ||| w x y	count=1
function	load the kddcup99 ||| kddcup99	count=1
function	the barycenter weighted ||| barycenter	count=1
function	each input ||| val	count=1
function	lars path ||| omp path	count=1
module	a ||| externals joblib	count=19
arg	problem ||| n_informative n_targets	count=1
function	mask ||| mask edges weights	count=1
class	get ||| linear model	count=1
arg	on ||| n_components	count=1
function	[function_1] [function_2] ||| [function_1] [function_2] n_past mu var x	count=2
arg	the given data ||| y	count=1
class	the search over ||| search cv	count=1
arg	given type [arg_2] ||| [arg_2] [arg_1]	count=1
module	cluster each ||| cluster	count=1
function	partition [function_2] ||| [function_2] [function_1]	count=1
function	probabilities for each sample ||| samples	count=1
function	a name for the ||| func name	count=1
arg	sample from ||| size	count=1
arg	run in parallel n_jobs ||| n_jobs	count=1
function	determination regression ||| r2	count=1
arg	of data [arg_2] ||| [arg_1] [arg_2]	count=1
class	the array ||| array	count=1
function	row scaling of ||| row	count=1
class	to ||| parallel backend base	count=2
function	[function_1] from all ||| [function_1] [function_2]	count=1
module	estimates ||| core	count=1
function_arg	[function_1] squared euclidean ||| [function_1] x [arg_2]	count=1
arg	[arg_1] in ||| [arg_2] [arg_1]	count=2
function	for each ||| val	count=1
function	[function_1] housing dataset ||| [function_1] [function_2]	count=3
class	[class_1] outlier ||| [class_1] [class_2]	count=4
function_arg	a single [arg_2] ||| [function_1] [arg_2]	count=1
function	logistic loss ||| logistic loss	count=4
module	kernel k ||| gaussian_process	count=1
class	we don't store the ||| memory	count=1
class	the hash ||| memorized	count=1
arg	features ||| x features	count=1
function	weighted graph of neighbors ||| neighbors graph	count=2
function	from training ||| fit	count=1
function	suffix when using the ||| shape repr	count=1
arg	input data ||| y	count=1
arg	x as a ||| x y	count=1
function_arg	[function_1] y_prob ||| metrics check [function_1] probabilistic predictions y_true [arg_2]	count=1
function	[function_1] parameters of ||| [function_2] [function_1]	count=4
module	process or ||| joblib	count=1
function	[function_1] based on ||| [function_2] [function_1]	count=2
function	the laplacian ||| laplacian	count=1
class	avoid the ||| memory	count=1
function	probabilities [function_2] ||| [function_2] [function_1]	count=2
arg	from source to ||| graph source cutoff	count=1
function	mean squared logarithmic error ||| mean squared log error	count=1
arg	sample from a ||| a size	count=1
class	local [class_2] ||| [class_2] [class_1]	count=3
arg	this operation is meant ||| index_file_path data_folder_path slice_ color	count=1
function	of determination ||| r2	count=1
arg	beta-divergence [arg_2] ||| [arg_2] w h [arg_1]	count=1
arg	by ||| y	count=1
function	[function_1] output ||| [function_1] [function_2]	count=1
function	partial [function_2] ||| [function_1] [function_2]	count=1
arg	approximation of the ||| n_samples n_subsamples	count=1
arg	and y ||| y alpha c	count=1
class	avoid the hash depending ||| func	count=1
class	the trained model parameters ||| multilayer perceptron	count=1
arg	of the derived class ||| resp	count=1
class	determinant with the ||| det	count=1
function_arg	[function_1] of matrices ||| [function_1] matrix_chol [arg_2]	count=3
function	run fit ||| fit	count=1
arg	[arg_1] and y ||| paired arrays [arg_1] [arg_2]	count=1
function	assumes ||| transform	count=1
function	precision matrix with the ||| precision	count=1
module	a which this ||| externals joblib	count=1
arg	similarity of two ||| a b similarity	count=1
arg	if y ||| y	count=2
arg	with respect ||| n_samples activations deltas	count=1
arg	each input ||| x	count=1
function_arg	[function_1] in x ||| [function_1] graph [arg_2] radius	count=4
module	depending ||| joblib	count=2
function_arg	fit the [arg_2] ||| [function_1] x [arg_2]	count=1
arg	w h whose ||| w h n_components	count=1
arg	the data ||| data	count=1
arg	for a sparse matrix ||| a	count=1
class	in pipeline after transforms ||| pipeline	count=1
arg	test_size and train_size at ||| test_size train_size	count=1
class	the [class_1] [class_2] ||| [class_1] [class_2]	count=4
module	avoid ||| externals joblib	count=4
class	cache ||| memory	count=1
arg	according to the ||| sample_weight	count=2
module	covariance estimator read ||| covariance	count=1
arg	x ||| x z	count=1
arg	values for x ||| estimator x	count=1
class	the hierarchical ||| agglomerative	count=1
function	covariance ||| matrix to match covariance	count=1
function	decision [function_2] ||| [function_2] [function_1]	count=14
arg	a subcluster from ||| subcluster	count=1
arg	if the given estimator ||| estimator	count=1
module	returns whether the ||| gaussian_process	count=3
function	loss and the ||| loss and	count=2
class	polynomial features parameters ||| polynomial features	count=2
function	for memmap [function_2] ||| [function_2] [function_1]	count=1
class	the grid ||| grid	count=3
function	false positives per binary ||| binary clf curve	count=1
class	an array ||| quadratic discriminant	count=1
module	closest cluster each ||| cluster	count=1
function	values of the basic ||| initial	count=1
function	coverage ||| coverage	count=1
function	score on the given ||| score	count=1
arg	samples of ||| samples	count=1
function_arg	[function_1] [arg_2] ||| [function_1] nn distances neighbors [arg_2]	count=4
function	precision matrix with the ||| get precision	count=1
function	global clustering ||| global clustering	count=2
function	free energy f ||| free energy	count=1
function_arg	from [arg_2] ||| [arg_2] [function_1]	count=1
function	text [function] its ||| memstr [function]	count=1
function	the shortest path ||| source shortest path	count=1
arg	[arg_1] the transformed ||| [arg_1] [arg_2]	count=6
function	binarization transformation using thresholding ||| binarize thresholding	count=1
arg	makes sure that whenever ||| copy	count=1
function	[function_1] update ||| [function_2] [function_1]	count=2
arg	csgraph inputs ||| csgraph directed	count=1
arg	the dense dictionary ||| dictionary	count=1
arg	parameters ||| x compute_sources	count=1
arg	features ||| features	count=1
function	[function_1] path length ||| [function_1] [function_2]	count=7
function_arg	regression [arg_2] ||| [arg_2] [function_1]	count=1
function	full covariance matrices ||| full	count=1
arg	unit norm vector length ||| x norm axis copy	count=1
function	estimates for each input ||| val	count=1
function	used to fit ||| fit	count=1
function	classification used in hastie ||| hastie	count=1
arg	binary classification task ||| y_true y_score average sample_weight	count=1
function	set [function_2] ||| [function_1] [function_2]	count=6
arg	place ||| y code verbose	count=1
function	the reduced likelihood function ||| reduced likelihood function	count=2
function	estimates for each input ||| predict	count=1
function	using a single binary ||| predict binary	count=1
module	extract ||| externals joblib	count=1
function	[function_1] [function_2] algorithm ||| [function_1] [function_2]	count=2
class	the search over ||| search	count=1
class	train ||| shuffle	count=1
function	[function] to ||| gen [function]	count=1
arg	n_jobs is the is ||| n_jobs	count=1
function	[function_1] from all ||| [function_2] [function_1]	count=1
function	theta as the maximizer ||| arg max	count=1
module	datasets in ||| datasets	count=1
class	the position of the ||| mds	count=1
function	return a ||| shape repr	count=1
function	and ||| y	count=1
class	backend ||| parallel backend base	count=1
arg	matrices w h ||| w h	count=1
function_arg	median [arg_2] ||| [arg_2] [function_1]	count=2
arg	for x ||| x y	count=1
function	the range of ||| range finder	count=1
class	signature from the ||| signature	count=1
function	for updating terminal ||| terminal	count=1
class	loss ||| loss	count=1
function_arg	indices in [arg_2] ||| [function_1] [arg_2]	count=3
arg	compute [arg] it ||| [arg] n_trials	count=1
arg	for mono and multi-outputs ||| y eps n_alphas	count=1
arg	filename ||| fileobj filename	count=1
arg	x as ||| x y iter_offset	count=1
function	data home cache ||| data home	count=1
function	estimates for ||| predict	count=1
function	estimators within a job ||| estimators	count=1
arg	each input ||| estimator x y	count=1
arg	vectors ||| vectors	count=1
function	[function_1] regression ||| [function_2] [function_1]	count=3
module	and return the content ||| externals joblib	count=1
function	call with the ||| format call	count=1
arg	x i ||| x	count=1
function	20 newsgroups data and ||| 20newsgroups	count=1
function	found and raise an ||| search	count=1
function	[function_1] [function_2] line information from the ||| [function_1] [function_2]	count=1
function	x format check x ||| check	count=1
arg	truncated ||| n_components n_oversamples n_iter	count=1
function_arg	[function_1] corresponds ||| [arg_2] [function_1]	count=4
function_arg	one set [arg_2] ||| [function_1] [arg_2]	count=2
module	depending from ||| joblib	count=2
module_class	covariance [class_2] ||| [module_1] min [class_2]	count=1
function	return feature names for ||| get feature names	count=1
function	for full covariance matrices ||| full	count=1
arg	and class ||| x y	count=1
function	matrix in-place ||| inplace swap row	count=2
function	run ||| grid	count=2
function	compute probabilities ||| proba	count=2
arg	loader ||| data_home download_if_missing	count=2
function	the parameters of this ||| params	count=3
arg	to the normalized laplacian ||| n_components eigen_solver	count=1
arg	the data and ||| y	count=1
class	abort ||| backend base	count=1
function	likelihood ||| likelihood	count=3
function	estimators within ||| estimators	count=1
function	is not found and ||| line search	count=1
class	of the [class_2] ||| [class_2] [class_1]	count=2
module_class	transform [module_1] [class_2] ||| [module_1] [class_2]	count=2
function	indices in ||| matching indices	count=1
function	for the lfw people ||| fetch lfw people	count=1
function	the polynomial ||| polynomial	count=1
function	breakdown [function_2] ||| [function_1] [function_2]	count=1
function	1d ||| 1d	count=1
function	step for full ||| full	count=1
function_arg	log-probabilities [arg_2] ||| [arg_2] [function_1]	count=2
arg	the data x which ||| x y	count=1
function	ward ||| ward	count=1
function	update ||| update w	count=2
arg	from source ||| graph source cutoff	count=1
function_arg	compute scores [arg_2] ||| [function_1] estimator [arg_2]	count=2
function	for full ||| multivariate normal density full	count=1
arg	any axis center ||| axis	count=2
module	inside a with block ||| externals joblib	count=1
function_arg	[function_1] and y_prob ||| metrics check [function_1] probabilistic predictions y_true [arg_2]	count=1
function	long type introduces an ||| repr	count=1
function	length is not found ||| line search	count=1
class	[class_1] outlier ||| [class_2] [class_1]	count=4
arg	data x ||| x y	count=6
class	then ||| transformer	count=1
function	predict labels for data ||| predict	count=1
arg	the model with x ||| x y	count=2
function	extracts patches ||| extract patches	count=1
arg	features ||| features feature_names	count=1
function	a platform independent representation ||| repr	count=1
function	probability estimates ||| proba	count=2
function	functions of the ||| function	count=1
function_arg	[function_1] corresponds to ||| [function_1] [arg_2]	count=1
arg	sample in x ||| x	count=1
arg	with respect to each ||| activations deltas	count=1
module_class	on test vectors ||| core dummy regressor	count=1
function	get the [function_2] ||| [function_1] [function_2]	count=4
function	nans ||| clean nans	count=1
function	fit ||| fit	count=92
arg	the laplacian matrix and ||| laplacian	count=1
function	unique [function] we ||| unique [function]	count=1
arg	dataset along any axis ||| axis	count=2
arg	for each ||| estimator x	count=1
function	of the determinant ||| det	count=1
arg	and scale ||| x y	count=1
class	k ||| pairwise	count=1
module	compute ||| decomposition	count=1
function_arg	clustering on x ||| fit predict x	count=1
arg	samples ||| samples	count=1
class	types ||| base	count=1
arg	to the binary classification ||| y_true y_score	count=2
arg	as ||| xy	count=1
function	[function_1] kl divergence ||| [function_2] [function_1]	count=4
arg	array [arg_2] ||| [arg_1] [arg_2]	count=1
arg	import path as ||| resolv_alias win_characters	count=1
arg	the data [arg] ||| [arg]	count=2
function	barycenter weighted ||| barycenter	count=1
arg	matrix x ||| x dict_type	count=1
arg	with respect to ||| activations deltas	count=2
module	don't ||| externals joblib	count=4
function_arg	from x ||| fit x y	count=1
arg	[arg_1] target variable ||| [arg_2] [arg_1]	count=4
arg	features ||| x features feature_names	count=1
arg	[arg_1] pred ||| [arg_1] [arg_2]	count=3
arg	classification task ||| y_true y_score pos_label	count=1
function	each input data ||| cross val	count=1
module	perform classification on test ||| core	count=1
function	two sets of biclusters ||| consensus score	count=1
class	it ||| memorized func	count=1
function	predict the closest ||| predict	count=1
function	number of points on ||| len	count=1
arg	p_ij [arg_2] ||| [arg_2] neighbors [arg_1]	count=1
class	position of ||| mds	count=1
function	similarity coefficient score the ||| score	count=1
function	kappa ||| cohen kappa	count=1
function	[function_1] batch size ||| [function_2] [function_1]	count=1
arg	the model according to ||| x y sample_weight	count=2
function_arg	[function_1] of this ||| [function_1] [arg_2]	count=4
module_class	points into [class_2] ||| [module_1] locally linear [class_2]	count=2
module	folders ||| externals	count=1
function	loss and [function_2] ||| [function_2] [function_1]	count=2
arg	data and ||| y	count=5
module	a full distance matrix ||| cluster	count=1
arg	kernel k x ||| x	count=4
function	centers [function] ||| preprocess [function]	count=1
function	file ||| file	count=1
function	compute the score ||| score	count=2
function	type introduces an 'l' ||| shape repr	count=1
function	generate train test indices ||| iter indices	count=1
function	fit linear model with ||| fit	count=3
function	net path with ||| enet path	count=1
function	[function_1] full ||| [function_2] [function_1]	count=1
arg	factory ||| name factory	count=1
arg	matrix m ||| m k k_skip	count=1
arg	random ||| n_samples eps	count=1
arg	the training set x ||| x	count=1
function	pairs dataset this ||| pairs	count=2
arg	memory is inefficient to ||| x y classes	count=1
module	the [module] according ||| [module]	count=2
function	from [function_2] ||| [function_2] [function_1]	count=4
arg	data x which ||| x y	count=2
arg	from features or distance ||| x y sample_weight	count=1
function_arg	of [function_1] [arg_2] ||| bagging [function_1] [arg_2]	count=6
function	by computing full svd ||| full	count=1
arg	a sparse matrix ||| a	count=1
class	belongs to ||| mean shift	count=1
arg	and dense ||| y sample_weight	count=1
arg	individually to unit ||| copy	count=1
class	kernel k ||| white kernel	count=2
arg	average a ||| y_score average	count=1
function	kddcup99 dataset ||| brute kddcup99	count=1
function	component wise scale ||| robust scale	count=1
function_arg	check [arg_2] ||| [arg_2] [function_1]	count=3
arg	returns the transformed ||| w h	count=3
arg	x ||| x dict_type	count=1
arg	[arg_1] and conversion ||| [arg_2] [arg_1]	count=3
class	function evaluates [class] at ||| [class]	count=1
function	estimate mutual ||| mutual	count=2
module_class	using [class_2] ||| [module_1] [class_2]	count=12
class	list of exception ||| parallel	count=1
class	we ||| func	count=1
arg	sample_weight ||| x y sample_weight	count=1
function_arg	[function_1] lrd ||| reachability [function_1] [arg_2]	count=1
class	the search over ||| base search cv	count=1
function	compute incremental mean and ||| mean	count=1
arg	decisions within ||| estimators_features x	count=1
arg	and y is float32 ||| y	count=1
arg	size ||| size	count=2
class	matrix ||| sparse coef	count=1
function	the average [function_2] ||| [function_1] [function_2]	count=3
function	fit ||| fit transform	count=3
module_class	[module_1] is ||| [module_1] [class_2]	count=2
function	binarization transformation using ||| binarize	count=1
arg	training data and ||| y	count=2
function	boolean mask ||| get mask	count=1
function	net path ||| path	count=1
class	depending from it ||| memorized func	count=1
arg	based on a ||| connectivity n_clusters	count=1
module_class	[module_1] whether ||| [module_1] [class_2]	count=4
function	all the covariance ||| match covariance	count=1
function	[function_1] cluster the ||| [function_1] [function_2]	count=1
function	the weighted ||| weighted	count=1
function_arg	fit the [arg_2] ||| [function_1] [arg_2]	count=19
function	curve auc using ||| auc	count=1
arg	[arg_1] in ||| [arg_1] [arg_2]	count=2
function_arg	[function_1] continuous ||| [arg_2] [function_1]	count=1
function	the precision matrix ||| precision	count=1
function	[function_1] density ||| [function_2] [function_1]	count=1
arg	of a cross-validated ||| estimator x y cv	count=1
function	range of ||| randomized range finder	count=1
module	return a ||| utils	count=1
function	each input data point ||| predict	count=1
arg	median and ||| x y	count=1
class	outlier on the ||| outlier	count=1
function	median absolute error ||| median absolute error	count=3
class	generate train test ||| base	count=1
function	log-probabilities ||| log proba	count=3
function	it take ||| squeeze	count=1
module	given file as a ||| externals	count=1
module	the relationship between labels ||| metrics cluster	count=1
function	the data home cache ||| data home	count=1
arg	and compute scores ||| y classes	count=2
function	compute decision [function_2] ||| [function_1] [function_2]	count=4
arg	restricted to the binary ||| y_score average sample_weight	count=1
function	compute joint probabilities ||| joint probabilities	count=4
arg	x y [arg_2] ||| [arg_2] [arg_1]	count=6
function	get the [function_2] ||| [function_2] [function_1]	count=5
function_arg	update [arg_2] ||| [function_1] coordinate descent [arg_2]	count=4
function	using a single binary ||| binary	count=1
function	text files ||| files	count=1
arg	and smooth feature ||| x y	count=2
function	covariance ||| cov	count=1
arg	values for a given ||| x y train	count=2
arg	compute the beta-divergence of ||| beta	count=1
function_arg	binary [arg_2] ||| metrics check [function_1] probabilistic predictions y_true [arg_2]	count=1
function	graph [function_2] ||| [function_2] [function_1]	count=16
module_class	[module_1] embedding space ||| [module_1] locally linear [class_2]	count=1
module	pool ||| externals joblib	count=2
arg	and scaling ||| x y	count=1
arg	first [arg] left and ||| [arg]	count=1
function	elastic net path ||| path	count=1
class	determine [class_2] ||| [class_1] [class_2]	count=1
function	compute the centroids on ||| fit	count=1
function	for the concentration parameter ||| concentration	count=1
function_arg	[function_1] and ||| [function_1] transform [arg_2]	count=1
arg	matrices from a ||| covariance_type	count=1
function	the shortest ||| single source shortest	count=1
module	covariance estimator read more ||| covariance	count=1
class	on the grid ||| grid	count=1
arg	function ||| function	count=2
function	species ||| fetch species	count=1
function	[function_1] sign ||| [function_2] [function_1]	count=2
function	the first ||| first	count=1
class	a document-term ||| hashing	count=1
function	with block checkerboard ||| checkerboard	count=1
function	of the logistic ||| inplace logistic	count=1
function_arg	parameters [arg_2] ||| [arg_2] [function_1]	count=4
function	and compute scores for ||| and score	count=1
function	representation ||| shape repr	count=1
function	null ||| null	count=1
function	dimension of a dataset ||| dimension	count=1
function	all the covariance ||| to match covariance	count=1
function	introduces an 'l' ||| repr	count=1
function	scale back the ||| inverse transform	count=2
function	directory in ||| output dir	count=1
function	precision ap ||| precision	count=1
function	feature names from ||| feature names	count=2
arg	[arg_1] distances ||| [arg_2] [arg_1]	count=3
function_arg	[function_1] dense dictionary ||| [arg_2] [function_1]	count=1
arg	the other and ||| x y	count=1
function	content of the data ||| data	count=1
arg	inefficient to train ||| y classes	count=1
module	clustering algorithm ||| cluster	count=1
function	feature [function_2] ||| [function_2] [function_1]	count=5
class	function and ||| func	count=1
function	check x format ||| check	count=1
function	shortest path [function_2] ||| [function_2] [function_1]	count=1
arg	a given dataset split ||| y scorer	count=1
class	is ||| cfsubcluster	count=1
function	indicating which features are ||| support	count=1
function	func ||| apply async	count=3
arg	<classification_report> ||| labels target_names	count=1
arg	and y ||| y sum_over_features size_threshold	count=1
function	get parameters for ||| get params	count=2
function	class covariance matrix ||| class cov	count=2
arg	with given gradients ||| grads	count=1
class	the hash depending ||| memory	count=1
function	logistic [function_2] ||| [function_1] [function_2]	count=5
function	extracts patches of any ||| extract patches	count=1
function	[function_1] for multiclass ||| [function_1] [function_2]	count=1
function_arg	of neighbors [arg_2] ||| [function_1] graph [arg_2] radius	count=2
function	across axis 0 ||| axis 0	count=1
function	hastie ||| hastie	count=1
function_arg	patches [arg_2] ||| [arg_2] [function_1]	count=1
function	update ||| step	count=1
arg	binary [arg_2] ||| [arg_2] [arg_1]	count=4
function_arg	predict [arg_2] ||| [arg_2] [function_1]	count=9
function	the shortest path length ||| source shortest path length	count=1
function	the pairwise matrix ||| parallel pairwise	count=1
class	depending from it ||| func	count=1
function	[function_1] cpp ||| [function_2] [function_1]	count=6
arg	system of equations ||| b damp atol	count=1
function	task ||| recall curve	count=1
module	closest cluster ||| cluster	count=1
function	for the ||| get	count=1
arg	laplacian matrix ||| laplacian	count=1
function	the generative model ||| get	count=1
arg	validation and conversion of ||| directed dtype csr_output	count=1
arg	categories [arg_2] ||| [arg_2] [arg_1]	count=2
function	read [function_2] ||| [function_2] [function_1]	count=1
class	it ||| memorized	count=1
arg	x y and ||| x y	count=25
function	compute mean [function_2] ||| [function_2] [function_1]	count=1
function	fit a ||| fit	count=5
arg	continuous [arg_2] ||| [arg_2] [arg_1]	count=2
function	compute online [function] of ||| [function] mean	count=1
function	[function_1] functions ||| [function_1] [function_2]	count=4
arg	cross-validated estimates for each ||| x y cv	count=1
function	in-place ||| swap row	count=2
function	leaves of ||| get leaves	count=1
function	update the dense ||| update dict	count=1
function_arg	[function_1] y_prob ||| [arg_2] [function_1]	count=2
function_arg	max [function_1] [arg_2] ||| [function_1] [arg_2]	count=4
arg	dense dictionary factor ||| dictionary	count=1
function	types to ||| get	count=1
function	[function_1] names for ||| [function_2] [function_1]	count=2
function_arg	x [arg_2] ||| [arg_2] [function_1]	count=8
function	scale ||| scale	count=2
function	[function_1] strip the ||| [function_2] [function_1]	count=2
arg	percentiles of ||| percentiles grid_resolution	count=1
module	'l' suffix ||| utils	count=1
function	estimate [function] parameters ||| [function]	count=1
function	issue #1240 [function] can't ||| [function]	count=1
arg	b ||| b	count=1
class	to [class] ||| [class]	count=1
function	fetch an [function_2] ||| [function_1] [function_2]	count=1
arg	conversion of [arg_2] ||| [arg_2] dtype [arg_1]	count=1
function	edges ||| make edges	count=1
function	for each sample ||| samples	count=1
arg	stacklevel is ||| stacklevel	count=1
function	ndarray with aligned memory ||| aligned	count=1
arg	finds the ||| x n_neighbors return_distance	count=1
function	'l' suffix when ||| repr	count=1
class	graphlasso ||| graph lasso cv	count=2
function	sign of elements of ||| sign	count=1
function_arg	eval [arg_2] ||| [arg_2] [function_1]	count=3
arg	[arg_1] test ||| [arg_2] [arg_1]	count=12
class	[class_1] process ||| [class_1] [class_2]	count=4
function	solve the linear ||| linear	count=1
function	shortest [function_2] ||| [function_2] [function_1]	count=2
function	a platform independent representation ||| shape repr	count=1
arg	memory is inefficient to ||| classes	count=1
function	one-vs-one ||| one vs one	count=1
arg	and returns [arg_2] ||| [arg_2] [arg_1]	count=2
class	with ||| pca	count=1
function	the callers ||| effective	count=1
function	get the parameters of ||| get	count=1
function	prediction scores this score ||| score	count=1
function	name for the ||| func name	count=1
function	cholesky decomposition ||| cholesky omp	count=1
arg	in n_jobs even ||| n_jobs	count=1
arg	validity of the input ||| x metric p metric_params	count=1
arg	columns of a matrix ||| x columns	count=1
function	update ||| update h	count=2
function	finds indices ||| find matching indices	count=1
module	generative ||| decomposition	count=1
class	thread pool and ||| multiprocessing backend	count=1
arg	in x ||| x	count=12
function	for ||| get	count=1
function	density lrd ||| density	count=1
class	deviance ||| deviance	count=1
function	in multiplicative [function_2] ||| [function_2] [function_1]	count=3
function_arg	distances between x ||| distances x	count=2
class	state [class] ||| [class]	count=3
arg	[arg] apply the ||| [arg]	count=1
arg	and return encoded ||| y	count=1
function	[function_1] svd parameters ||| [function_1] [function_2]	count=1
class	to the file ||| file	count=1
function	c and cpp ||| c and cpp	count=3
class	of the cf ||| birch	count=1
function	check the ||| check	count=1
function	predict [function_2] ||| [function_1] [function_2]	count=3
class	return whether the file ||| zlib file	count=2
function	call with the given ||| call	count=1
function	log [function_2] ||| [function_2] [function_1]	count=4
function	the weighted graph ||| graph	count=3
arg	generate a random n-class ||| n_samples n_features n_informative n_redundant	count=1
class	convert ||| coef mixin	count=1
function_arg	log-probabilities for [arg_2] ||| [arg_2] [function_1]	count=2
arg	actual fitting performing the ||| y parameter_iterable	count=1
arg	and returns ||| y w	count=2
function_arg	[function_1] keep the ||| [arg_2] [function_1]	count=2
function	[function_1] graph of ||| [function_2] [function_1]	count=3
function	[function_1] squared logarithmic ||| [function_2] [function_1]	count=1
function	[function_1] estimators ||| [function_1] [function_2]	count=5
class	with stochastic gradient descent ||| base sgdregressor	count=1
function_arg	[function_1] n_jobs ||| [function_1] [arg_2]	count=2
arg	along an axis on ||| axis	count=1
arg	n_jobs even slices ||| x y func n_jobs	count=1
function	init ||| init decision function	count=2
class	best found ||| base search cv	count=4
module	in ||| ensemble	count=4
function	index of the leaf ||| apply	count=1
function	updates terminal regions to ||| terminal region	count=1
arg	with respect to ||| n_samples activations deltas	count=1
function	squared logarithmic ||| squared log	count=1
function	the training set ||| fit	count=5
arg	[arg_1] note ||| [arg_1] [arg_2]	count=2
function	element of numpy array ||| element	count=1
module	are selected returns ||| feature_selection	count=1
function	generate the ||| make	count=3
function	[function_1] file object ||| [function_2] [function_1]	count=3
function	average ||| average	count=1
function	locally [function_2] ||| [function_2] [function_1]	count=5
function	grid of alpha values ||| alpha grid	count=1
module	remove cache folders ||| externals joblib	count=1
arg	a filename ||| filename mmap_mode	count=1
function_arg	and [arg_2] ||| [arg_2] [function_1]	count=3
arg	columns of a ||| x columns	count=1
function	of the kl divergence ||| kl divergence	count=1
arg	update h ||| x w h	count=1
function	binarization transformation [function_2] ||| [function_1] [function_2]	count=2
class	whether the file ||| file	count=2
function	sample [function_2] ||| [function_2] [function_1]	count=4
class	density model ||| kernel density	count=1
arg	input data ||| x y	count=1
function	abort ||| abort	count=1
arg	computes ||| alpha	count=4
class	fastmcd algorithm ||| cov	count=1
function	state of ||| state	count=1
arg	generate ||| n_samples n_features n_classes n_labels	count=1
class	determinant with [class_2] ||| [class_2] [class_1]	count=2
class	inlier -1 [class] ||| local [class]	count=2
function	from the [function_2] ||| [function_2] [function_1]	count=4
function	a multinomial ||| multinomial	count=1
function_arg	[function_1] [arg_2] ||| [function_1] precomp distr [arg_2]	count=9
function	insert a ||| insert cf	count=1
function	kernel is ||| is	count=1
arg	of x (as bigger ||| x	count=1
function_arg	perplexity for [arg_2] ||| [function_1] precomp distr [arg_2]	count=3
arg	generate a [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] for mean_shift ||| [arg_2] [function_1]	count=2
arg	of width ||| effective_rank tail_strength	count=1
function_arg	update the [arg_2] ||| [arg_2] [function_1]	count=3
function	[function] propagation ||| [function]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] zfile file_handle [arg_2]	count=10
class	with the generative ||| base	count=1
class	the cache for the ||| memorized func	count=1
function	assert that ||| check	count=1
module	under a size limit ||| externals joblib	count=1
class	evaluates [class] ||| [class]	count=1
function	set the parameters ||| set	count=4
function	input ||| predict	count=1
class	requested by the ||| base	count=1
arg	classes param ||| classes	count=1
function_arg	kernel [arg_2] ||| [function_1] [arg_2]	count=4
function	iterator over ||| iter	count=1
function_arg	[function_1] percentiles ||| [function_1] x x [arg_2]	count=5
function	return the path of ||| get	count=1
function	non-negative matrix factorization ||| negative factorization	count=1
function	of loss ||| loss	count=1
arg	descriptors of a ||| a	count=1
class	the [class_2] ||| [class_1] [class_2]	count=4
class	linear model ||| base sgdregressor	count=2
function	the cholesky decomposition ||| det cholesky	count=1
arg	list of regularization ||| y pos_class cs	count=1
arg	n_jobs even slices ||| func n_jobs	count=1
function_arg	on [arg_2] ||| feature_selection base filter [function_1] [arg_2]	count=6
arg	apply ||| affinity	count=1
arg	when memory is inefficient ||| classes	count=1
function	one-vs-one multi class ||| one vs one	count=1
function	estimate class weights ||| class	count=1
arg	compute [arg] ||| [arg] n_trials	count=1
module	we ||| externals	count=2
function	gradient of loss ||| loss grad	count=1
class	gaussian process regression model ||| gaussian process regressor	count=1
function	vectors for reproducibility flips ||| deterministic vector	count=1
function_arg	computing truncated svd ||| truncated x n_components	count=1
function	locally ||| locally	count=1
arg	argument checking for random ||| n_features	count=1
function_arg	function of [arg_2] ||| [function_1] [arg_2]	count=4
function	computing truncated ||| truncated	count=1
class	to ||| func	count=1
class	found parameters ||| search	count=2
function_arg	the training [arg_2] ||| [function_1] [arg_2]	count=8
function	strip lines ||| strip	count=1
function	a name for ||| get func name	count=1
function	the wild lfw ||| fetch lfw	count=1
arg	and returns ||| y	count=1
arg	x and ||| x	count=1
function_arg	[function_1] problem ||| [arg_2] [function_1]	count=1
function	an 'l' ||| shape repr	count=1
function_arg	[function_1] x and ||| [arg_2] [function_1]	count=3
function	the kl divergence of ||| kl divergence	count=1
module	if there ||| utils	count=1
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2] average sample_weight	count=20
function	curve auc from ||| auc score	count=1
function	case of a multinomial ||| multinomial	count=1
module_class	[module_1] kernel ||| [module_1] [class_2]	count=6
arg	x with ability ||| x	count=1
module	covariance matrix ||| covariance	count=2
function_arg	[function_1] and ||| decomposition nmf [function_1] x [arg_2]	count=1
function	and a name for ||| func name	count=1
arg	h whose product approximates ||| h n_components	count=1
function_arg	[function_1] x ||| [function_1] predict [arg_2]	count=2
arg	finds the ||| n_neighbors return_distance	count=1
class	absolute value of ||| abs	count=1
arg	for x ||| x y sample_weight	count=1
function	when using ||| shape	count=1
arg	standardize ||| with_centering with_scaling	count=1
function	maximizer of the ||| arg max	count=1
class	best [class_2] ||| [class_2] [class_1]	count=14
function	and breiman [2] ||| make friedman3	count=1
arg	x according ||| x	count=2
function	energy ||| energy	count=1
class	compute the minimum ||| min	count=1
function	back the ||| inverse transform	count=2
class	compute the loss ||| loss	count=1
function	[function_1] embedding analysis ||| [function_1] [function_2]	count=4
function	calibration [function_2] ||| [function_2] [function_1]	count=1
function_arg	assumes [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	[function_1] downloading it ||| [function_1] [arg_2]	count=3
function_arg	[function_1] [arg_2] ||| [function_1] precision [arg_2]	count=2
class	list ||| backend	count=1
function	to build ||| parallel build	count=1
arg	p_ij from ||| desired_perplexity verbose	count=2
class	em ||| gmmbase	count=1
function	row scaling of a ||| row	count=1
function	seeds for ||| bin seeds	count=1
function	of feature ||| feature	count=1
function_arg	validation of [arg_2] ||| [function_1] targets [arg_2]	count=1
function	the directory ||| get output dir	count=1
arg	provided ||| n_components	count=1
class	hash depending ||| memorized	count=1
function	from all ||| from	count=1
function	types to be captured ||| exceptions	count=1
function	strip the headers ||| strip	count=1
class	state [class] if ||| [class]	count=3
function	data ||| cross val	count=1
function	text report showing the ||| report	count=1
function_arg	perplexity for [arg_2] ||| [function_1] [arg_2]	count=1
function	[function_1] adjusted for ||| [function_2] [function_1]	count=2
class	trained model ||| multilayer perceptron	count=1
function	the function code and ||| func code	count=1
arg	the data onto ||| ridge_alpha	count=1
function	and breiman [2] ||| friedman3	count=1
function	of neighbors for points ||| radius neighbors	count=2
function_arg	[function_1] to size ||| [arg_2] [function_1]	count=1
function	data point ||| cross val predict	count=1
arg	in x into a ||| x	count=1
class	list of ||| base	count=1
class	undo the [class_2] ||| [class_2] [class_1]	count=2
function	validation of ||| validate	count=1
function	sign of elements ||| sign flip	count=1
function_arg	[function_1] is meant ||| [arg_2] [function_1]	count=10
function	the null ||| null	count=1
module_class	[module_1] this wrapper ||| [module_1] numpy array [class_2]	count=1
arg	y as ||| y	count=2
arg	the given parameter ||| parameter	count=1
class	sparse [class_2] ||| [class_1] [class_2]	count=1
arg	multi-class labels ||| threshold	count=1
function	for the means ||| means	count=1
function	the timestamp when pickling ||| reduce	count=2
function	parameters of this ||| params	count=3
function_arg	[function_1] factory ||| [arg_2] [function_1]	count=2
function	the breakdown point ||| breakdown point	count=2
arg	parallel n_jobs is the ||| n_jobs	count=1
function	skip test if ||| check skip	count=1
class	the rfe ||| rfe	count=1
function	check according ||| check	count=1
arg	[arg_1] [arg_2] ||| [arg_2] neighbors [arg_1]	count=2
arg	that [arg] is ||| [arg]	count=1
function_arg	loss [arg_2] ||| [function_1] layer [arg_2]	count=3
arg	the other and transforms ||| x y	count=1
function	class with ||| add	count=1
arg	classification ||| y_true y_pred	count=1
function	"news" format [function_2] ||| [function_2] [function_1] quoting	count=4
arg	computes the gradient and ||| y alpha	count=2
function	the range ||| range finder	count=1
function	[function_1] classification problem ||| [function_1] [function_2]	count=3
class	factor of ||| factor	count=1
arg	between x [arg_2] ||| [arg_2] [arg_1]	count=1
function	on ||| fit predict	count=1
arg	learn and ||| x y	count=1
function_arg	fit [arg_2] ||| [function_1] [arg_2]	count=8
function	shutdown the ||| terminate	count=1
function	to compute log probabilities ||| parallel predict log proba	count=1
function	compute the l1 ||| paired manhattan	count=1
function	smacof ||| smacof	count=2
function	[function_1] point ||| [function_1] [function_2]	count=3
arg	algorithms ||| x n_components init eps	count=1
function	return [function_2] ||| [function_1] [function_2]	count=3
arg	of x ||| x z reg	count=1
function	the huber loss ||| huber loss	count=2
arg	points ||| metric	count=1
class	the ||| base pca	count=2
function	absolute sizes of ||| train sizes	count=1
class	sparse [class_2] ||| [class_2] [class_1]	count=1
class	number of [class] ||| parallel [class]	count=1
module	return the number of ||| externals joblib	count=3
arg	random sample from ||| size replace p	count=1
function	[function_1] for full ||| [function_2] [function_1]	count=1
module	datasets in the ||| datasets	count=1
class	the ||| memorized func	count=2
function	[function_1] mutual information ||| [function_2] [function_1]	count=1
arg	version of a ||| fobj	count=1
function	[function_1] error ||| [function_1] [function_2]	count=4
class	lsi ||| truncated svd	count=1
function	a single ||| build trees	count=1
module	the process or ||| joblib	count=1
function	inplace column scaling of ||| inplace column scale	count=1
arg	of a cross-validated ||| cv	count=1
function	message on ||| msg init	count=2
arg	generate cross-validated estimates ||| x y cv	count=1
function	of the leaf ||| apply	count=1
function	free parameters ||| parameters	count=1
module	took to [module] ||| [module]	count=1
arg	a classification ||| y_true y_pred labels sample_weight	count=1
function	call predict_log_proba on ||| predict log proba	count=1
arg	to unit ||| copy	count=1
class	the sparse components ||| sparse pca	count=1
function	for reproducibility flips the ||| deterministic vector	count=1
function	[function_1] discrete ||| [function_2] [function_1]	count=2
function	[function_1] shift ||| [function_2] [function_1]	count=2
module	covariance with ||| covariance	count=1
module	of a cluster ||| metrics cluster	count=1
arg	within a job ||| estimators estimators_features x n_classes	count=1
function	class ||| class	count=3
function	call predict_log_proba on the ||| predict log proba	count=1
arg	orthogonal matching pursuit ||| n_nonzero_coefs	count=1
arg	a given ||| x y scorer	count=1
function_arg	[function_1] categories ||| [function_1] container_path description [arg_2]	count=2
arg	intercept for specified layer ||| layer n_samples	count=1
arg	generate cross-validated estimates ||| y cv	count=1
function	updates terminal regions ||| terminal region	count=1
arg	and class probabilities ||| x y	count=1
arg	matrix for x using ||| x y	count=1
function	dummy [function_2] ||| [function_2] [function_1]	count=1
arg	subcluster ||| subcluster	count=1
function_arg	[function_1] and compute ||| [function_1] fit estimator estimator [arg_2]	count=1
function	fit a multi-class ||| fit	count=1
function	single boost using ||| boost	count=1
class	whether the ||| pairwise	count=1
function	exponential ||| exponential	count=1
function	point ||| predict	count=1
function	compute ||| compute	count=7
function	matrix factorization nmf ||| non negative factorization	count=1
function	update terminal regions ||| update terminal regions	count=3
module_class	[module_1] wrapper ||| [module_1] numpy array [class_2]	count=1
class	format ||| sparse coef mixin	count=1
function	list of exception types ||| get	count=1
function_arg	[function_1] filename ||| [function_1] fileobject [arg_2]	count=1
function_arg	fit x ||| fit transform x	count=1
class	[class_1] regression ||| [class_2] [class_1]	count=5
arg	based on ||| x connectivity n_clusters	count=1
class	the best found ||| base search cv	count=4
function	element of ||| element	count=1
class	k-neighbors ||| kneighbors mixin	count=1
arg	x for ||| x means	count=2
class	matrix to ||| coef	count=1
function	calculate mean update ||| incremental mean	count=1
function	column scaling of a ||| column	count=1
arg	given radius ||| x radius	count=1
function_arg	log-marginal [function_1] [arg_2] ||| laplace log marginal [function_1] [arg_2]	count=2
function_arg	[function_1] data parameters ||| [function_1] [arg_2]	count=2
function	divergence of ||| divergence	count=1
arg	or regression value ||| check_input	count=1
class	in parallel ||| parallel	count=1
module	for the ||| covariance	count=1
function	find the null ||| null	count=1
arg	a job ||| estimators estimators_features x	count=1
function	one set ||| point	count=2
arg	input ||| estimator x y	count=1
arg	w h whose product ||| x w h n_components	count=1
class	the best [class_2] ||| [class_2] [class_1]	count=14
class	[class_1] features ||| [class_1] [class_2]	count=1
arg	h ||| w h beta_loss	count=1
function_arg	the kddcup99 [arg_2] ||| [function_1] [arg_2]	count=2
function	minimum and ||| min	count=1
arg	n_jobs even ||| x y func n_jobs	count=1
arg	and then ||| y	count=1
function	callable case for pairwise_{distances ||| callable	count=1
function	maximizer of [function_2] ||| [function_2] [function_1]	count=3
function	calculate mean update and ||| mean	count=1
arg	from a ||| a size	count=1
arg	list of regularization ||| pos_class cs	count=1
arg	significance of a cross-validated ||| y cv	count=1
function	sizes of ||| train sizes	count=1
module_class	[module_1] [class_2] matrix ||| [module_1] [class_2] vectorizer transform x y	count=2
function	used to partition estimators ||| partition estimators	count=1
function	[function_1] compute scores ||| [function_2] [function_1]	count=1
class	signature from the given ||| signature	count=1
function_arg	predict class [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg_1] a dense ||| [arg_2] [arg_1]	count=1
module_class	returns whether ||| gaussian_process dot product	count=1
function	[function_1] strip ||| [function_2] [function_1] quoting	count=1
class	kernel ||| stationary kernel	count=1
function	skip test if ||| skip	count=1
function	code ||| func code	count=1
function	an mldata ||| mldata	count=1
arg	and apply ||| y	count=2
arg	from ||| y sample_weight	count=1
function	blobs for ||| blobs	count=1
module	embedding space parameters ||| manifold	count=1
arg	and dense inputs ||| x y sample_weight	count=1
module	ordered array [module] unique ||| [module]	count=1
function	a given cache ||| cache	count=1
module	in bytes_limit ||| externals	count=1
function	name ||| func name	count=1
function	fit on ||| fit	count=1
arg	a subcluster ||| subcluster new_subcluster1	count=1
arg	of x from ||| x	count=1
class	hash depending ||| memorized func	count=1
function	l1 distances between ||| manhattan distances	count=2
function	[function_1] fit a ||| [function_2] [function_1]	count=2
function	matrix shrunk on the ||| shrunk	count=1
arg	row of x ||| x y	count=1
function	[function_1] people ||| [function_1] [function_2]	count=4
module	process or ||| externals joblib	count=1
class	determinant ||| cov det	count=1
arg	for each input ||| estimator x y	count=1
function	linear embedding analysis ||| linear embedding	count=2
class	we don't store ||| memorized	count=1
function_arg	from [arg_2] ||| [function_1] [arg_2]	count=1
function	first prime ||| prime	count=1
arg	sorted array of ||| tree bin_x left_mask right_mask	count=1
arg	generate a random ||| n_samples n_features n_classes	count=1
arg	of x and y ||| x y	count=1
function	determine absolute sizes ||| translate train sizes	count=1
module	clustering ||| cluster	count=9
function_arg	[function_1] tree ||| [function_1] [arg_2]	count=4
function_arg	kddcup99 [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	[function_1] x ||| feature_selection base filter [function_1] [arg_2]	count=1
arg	y as ||| y copy_x	count=2
arg	as training ||| copy_x	count=1
arg	of x ||| x z	count=1
arg	classes param logic estimators ||| classes	count=1
arg	with respect to coefs ||| activations deltas	count=1
arg	row of x ||| x y copy	count=1
function_arg	the median [arg_2] ||| [function_1] [arg_2]	count=2
class	check ||| latent dirichlet allocation	count=1
function	approximates the range ||| randomized range	count=1
function	a contingency matrix describing ||| contingency matrix	count=1
module	convert [module] memory ||| [module]	count=1
function	find the [function_2] ||| [function_1] [function_2]	count=5
function	low ||| low	count=1
function	the submatrix corresponding to ||| get submatrix	count=1
function	slices [function_2] ||| [function_2] [function_1]	count=2
module	computes a ||| utils	count=1
module_class	to be [class_2] ||| [module_1] robust [class_2]	count=1
arg	remove a subcluster ||| subcluster	count=1
function	an ||| repr	count=1
arg	dataset along any axis ||| x axis	count=2
function	helper function to ||| helper	count=1
function	predict on ||| predict	count=1
function	read the ||| read	count=2
function_arg	[function_1] in x ||| [function_1] [arg_2] radius	count=8
module	under a size limit ||| externals	count=1
class	[class_1] model ||| [class_2] [class_1]	count=1
class	the local outlier ||| local outlier	count=2
function	the cholesky decomposition ||| log det cholesky	count=1
module	or thread ||| joblib	count=1
function_arg	[function_1] w to ||| [function_1] coordinate descent [arg_2]	count=4
class	train ||| base shuffle split	count=2
function	sparse random ||| random	count=1
function	the boolean mask ||| get mask	count=1
function	build from the ||| build from	count=2
arg	<mean_squared_log_error> ||| sample_weight multioutput	count=1
arg	according to the ||| x y sample_weight	count=2
module_class	number [module_1] [class_2] ||| [module_1] [class_2]	count=1
function	key ||| key	count=1
arg	case method='lasso' is : ||| xy gram	count=1
arg	dense dictionary ||| dictionary y	count=1
class	to avoid the ||| memorized	count=1
arg	data ||| estimator x	count=1
function	prediction of init ||| init	count=1
arg	set [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=4
function	compute the sigmoid ||| sigmoid	count=1
arg	each input data ||| y	count=1
module	it ||| joblib	count=2
function_arg	directory corresponding ||| func dir mkdir	count=1
function	return the wine ||| wine	count=1
function	indices ||| matching indices	count=1
class	wrapped [class] ||| memorized [class]	count=3
function	get the directory ||| get func dir	count=3
arg	list of regularization parameters ||| x y pos_class cs	count=1
function	binary labels back to ||| inverse	count=1
arg	m ||| m	count=1
arg	inefficient to ||| classes	count=1
function	such that for c ||| c	count=1
class	to sparse format ||| sparse coef	count=2
arg	gram matrix ||| gram	count=1
function	return the shortest ||| shortest	count=1
function	kl [function_2] ||| [function_1] [function_2]	count=4
module_class	[module_1] determinant ||| [module_1] min cov [class_2]	count=1
arg	the other and ||| y	count=1
module	or ||| externals joblib	count=2
arg	using x [arg_2] ||| [arg_1] [arg_2]	count=1
arg	w to minimize the ||| x w	count=1
function	dependence ||| dependence	count=1
function	with the generative model ||| get	count=1
function	of [function] method ||| [function]	count=1
module	estimator ||| core	count=2
arg	generate a mostly ||| n_samples n_features	count=1
function	compute probabilities of ||| proba	count=2
function	a [function] ||| load [function]	count=2
function_arg	all estimators [arg_2] ||| [arg_2] [function_1]	count=1
function	and the [function_2] ||| [function_2] [function_1]	count=1
arg	and ||| y sample_weight random_state	count=1
module	get a list of ||| utils	count=1
arg	multi-outputs ||| eps	count=1
function_arg	[function_1] p_ij ||| [function_1] nn distances neighbors [arg_2]	count=2
module	samples in ||| svm	count=1
function	[function_1] in ||| [function_1] [function_2]	count=3
arg	update h ||| h beta_loss	count=1
arg	p_ij from [arg_2] ||| [arg_2] neighbors [arg_1]	count=1
arg	if fileobj ||| fileobj	count=1
function	trace ||| trace	count=1
class	to bicluster ||| bicluster	count=1
arg	and [arg_2] ||| [arg_1] [arg_2]	count=4
function	helper to ||| helper	count=1
function	online computation ||| partial fit	count=1
function	each ||| cross	count=1
arg	each input ||| x y	count=1
class	data ||| base	count=1
function	display the process ||| print	count=1
arg	in x and y ||| x y	count=4
module	to avoid the ||| externals	count=2
function	get feature [function_2] ||| [function_1] [function_2]	count=1
module	remove cache folders ||| externals	count=1
arg	x with ||| x	count=1
function_arg	[function_1] is ||| [arg_2] [function_1]	count=1
function	platform ||| shape	count=1
function	independent representation ||| shape repr	count=1
arg	with a given mapping ||| y class_mapping	count=1
function_arg	[function_1] corresponds ||| [function_1] [arg_2] average sample_weight	count=5
arg	norm of x ||| x	count=1
function	iterate over the ||| iter	count=1
function_arg	[function_1] matrices ||| [function_1] matrix_chol [arg_2]	count=2
function	lfw ||| fetch lfw	count=3
arg	a job ||| estimators estimators_features	count=1
function	return the breast ||| breast	count=1
arg	x ||| estimator x	count=1
class	undo [class_2] ||| [class_1] [class_2]	count=2
class	exception types to ||| parallel backend base	count=1
function	[function_1] boolean mask ||| [function_2] [function_1]	count=1
function	shortest path ||| single source shortest path	count=1
function	[function] of the ||| [function]	count=2
arg	validation and ||| directed dtype	count=1
arg	for x ||| estimator x	count=1
function	[function_1] [function_2] of ||| [function_1] [function_2]	count=2
module	read ||| externals joblib	count=1
arg	classes param logic ||| classes	count=1
arg	n_jobs ||| func n_jobs	count=1
function	to predict apply predict_proba ||| predict	count=2
class	the backend and ||| backend base	count=1
function	partially [function_2] ||| [function_1] [function_2]	count=7
arg	update w ||| w	count=1
function	update nmf ||| update h	count=1
arg	as a zipped pickle ||| target_dir cache_path	count=1
function_arg	binary classifier [arg_2] ||| [function_1] [arg_2]	count=2
arg	the binary classification ||| y_true y_score	count=2
function_arg	[function_1] laplacian matrix ||| [function_1] [arg_2]	count=3
arg	x and [arg_2] ||| [arg_2] [arg_1]	count=5
class	covariance estimators ||| covariance	count=1
function	transform is sometimes ||| transform	count=1
class	the calibrated ||| calibrated classifier cv	count=1
class	estimator with the best ||| cv	count=5
module	for each input ||| core	count=1
function	for full covariance matrices ||| density full	count=1
module	don't store the ||| externals joblib	count=2
function	for each ||| predict	count=1
function	em update for ||| em step	count=1
arg	data set with self ||| x_test y	count=1
arg	[arg_1] for ||| [arg_2] [arg_1]	count=2
arg	average a ||| average	count=1
function	np dot ||| dot	count=2
function	text [function] its value ||| memstr [function]	count=1
function_arg	[function_1] matrices from ||| [arg_2] [function_1]	count=4
arg	func to be ||| func	count=3
module	a [module_2] ||| [module_1] [module_2]	count=6
function	the dimension of ||| dimension	count=1
class	search over parameters ||| base search cv	count=1
function	get the values used ||| get	count=1
function	absolute sizes of ||| sizes	count=1
class	the voting ||| voting	count=1
module	estimator is using a ||| core	count=1
arg	classification ||| y_true y_score	count=2
arg	data to [arg_2] ||| [arg_1] [arg_2]	count=1
arg	place using strides ||| arr patch_shape extraction_step	count=1
module	between labels ||| metrics	count=1
arg	samples x ||| x y	count=1
function	the ||| repr	count=2
function	when using the ||| repr	count=1
function	directory in which are ||| get output dir	count=1
function_arg	update [arg_2] ||| [function_1] x w [arg_2]	count=1
module_class	test vectors ||| core dummy regressor	count=1
function_arg	[function_1] on x ||| [arg_2] [function_1]	count=5
function	a calibration [function_2] ||| [function_2] [function_1]	count=1
function	sample from the decision ||| decision	count=1
class	fit ||| skewed chi2sampler	count=1
arg	meant to be ||| data_folder_path slice_ color resize	count=1
arg	x y as training ||| x y	count=2
class	memory ||| memory	count=1
arg	data and concatenate ||| x y	count=1
arg	input validation for ||| y accept_sparse dtype	count=1
arg	x using the ||| x	count=2
function	simple custom [function] to ||| [function]	count=1
function_arg	[function_1] p_ij from ||| [function_1] nn distances neighbors [arg_2]	count=2
function	cpp files ||| cpp files	count=2
class	exception ||| parallel backend	count=1
arg	training set x and ||| x y	count=1
function	leaf ||| apply	count=1
function	log probability for ||| log multivariate normal	count=1
function	first [function_2] ||| [function_1] [function_2]	count=1
function	centers [function] have mean ||| preprocess [function]	count=1
arg	the binary [arg_2] ||| [arg_2] [arg_1]	count=4
function	log-likelihood ||| score	count=1
function	huber ||| huber	count=1
function	in bytes_limit ||| reduce	count=1
function	[function_1] pairs ||| [function_2] [function_1]	count=8
function	full ||| normal density full	count=2
function	back the data ||| inverse transform	count=2
class	not enabled ||| robust	count=1
arg	points in x parameters ||| x n_neighbors mode	count=1
module	relationship ||| cluster	count=1
arg	y and [arg_2] ||| [arg_1] [arg_2]	count=12
function	the paired cosine ||| paired cosine	count=2
function	as the maximizer ||| arg max	count=1
arg	loader for ||| data_home	count=3
function	the sign of ||| sign flip	count=1
function	turn [function] into a ||| [function]	count=1
arg	generate ||| y	count=1
function	make cache size fit ||| size	count=1
arg	[arg_1] [arg_2] ||| [arg_1] edges [arg_2]	count=2
function	pairwise matrix in ||| pairwise	count=1
function	negative value in ||| negative	count=1
class	hash ||| func	count=1
class	compute data ||| pca	count=1
function_arg	a gaussian [arg_2] ||| [arg_2] [function_1]	count=1
function	reconstruct the ||| reconstruct	count=1
function	for ||| val	count=1
function	the score on ||| score	count=1
function	non-negative matrix factorization ||| factorization	count=1
arg	the usual api and ||| y	count=3
arg	x and returns the ||| x y w	count=1
arg	estimates for each ||| estimator x	count=1
arg	generate a [arg_2] ||| [arg_1] [arg_2]	count=2
function	for each input ||| cross	count=1
function	report showing [function_2] ||| [function_2] [function_1]	count=2
function	get ||| get	count=16
function_arg	[function_1] for this ||| [arg_2] [function_1]	count=2
function_arg	is [function_1] [arg_2] ||| metrics check [function_1] probabilistic predictions y_true [arg_2]	count=2
function	randomized svd ||| randomized svd	count=2
function	generate ||| make	count=5
arg	a given mapping ||| class_mapping	count=1
function	graph of ||| to graph	count=2
function	generate ||| cross val	count=1
arg	set x ||| x	count=5
arg	connectivity matrix ||| connectivity n_components	count=1
class	linear model parameters ||| linear model	count=1
function	for the precisions ||| precisions	count=1
function	full covariance ||| normal density full	count=1
function	check the estimator ||| estimator	count=3
arg	subset of dataset and ||| x y	count=1
function	the right fileobject from ||| read fileobject	count=1
function	check a ||| check	count=1
class	to the file ||| binary zlib file	count=1
arg	h ||| x w h	count=1
module	or ||| feature_extraction	count=2
class	find ||| hungarian state	count=1
arg	actual fitting performing the ||| x y parameter_iterable	count=1
function	svd ||| svd	count=2
arg	barycenter weights [arg] ||| [arg]	count=3
class	the generative ||| pca	count=1
function	in ||| reduce	count=1
function	not found and ||| line search	count=1
function	problem with sparse ||| sparse	count=1
function	updates terminal ||| terminal region	count=1
function	submatrix corresponding ||| get submatrix	count=1
arg	and ||| random_state	count=1
function_arg	eval function func ||| eval func	count=1
module	it ||| externals	count=2
arg	inefficient to ||| y classes	count=1
function	function for the ||| function	count=1
function	a random multilabel classification ||| multilabel classification	count=1
function	calculate mean ||| mean	count=1
function_arg	[function_1] [arg_2] and ||| [function_1] [arg_2]	count=2
module	thread pool ||| joblib	count=1
function_arg	[function_1] x w ||| [arg_2] [function_1]	count=1
class	on ||| base	count=1
arg	[arg_1] y t ||| [arg_1] [arg_2]	count=1
arg	and concatenate ||| x y	count=1
arg	is meant ||| data_folder_path slice_ color resize	count=1
arg	and return that ||| y	count=1
function	to dense array format ||| densify	count=1
class	boosting ||| boosting	count=2
function_arg	[function_1] is positive-definite ||| [arg_2] [function_1]	count=1
arg	x and y ||| x y gamma	count=4
function	[function_1] function to ||| [function_2] [function_1]	count=1
function	score of the underlying ||| score	count=1
function	compute elastic net path ||| enet path	count=1
function_arg	[function_1] x ||| [function_1] [arg_2] radius	count=6
function	of estimators within a ||| estimators	count=1
arg	x by scaling ||| x	count=1
function	data ||| val	count=1
arg	with x [arg] ||| x [arg]	count=1
function	[function_1] the kl ||| [function_2] [function_1]	count=3
function	neighbors from the ||| neighbors	count=1
arg	corresponding to the ||| mkdir	count=1
module	retrieve a reliable ||| externals joblib	count=2
function	with sparse uncorrelated design ||| sparse uncorrelated	count=1
class	pipeline after transforms ||| pipeline	count=1
function	[function_1] pairs dataset ||| [function_2] [function_1]	count=8
function	barycenter weighted [function_2] ||| [function_1] [function_2]	count=1
arg	a function ||| function	count=1
class	computes the ||| empirical	count=2
arg	tree ||| tree forest	count=1
arg	given dataset ||| y scorer	count=1
class	least [class_2] ||| [class_1] [class_2]	count=1
function	estimates ||| cross val	count=1
function	dimension ||| dimension	count=1
function	the recall is the ||| recall	count=1
class	the generative model ||| base pca	count=1
function	locally linear [function_2] ||| [function_2] [function_1]	count=4
class	the search over parameters ||| base search cv	count=1
function	return the directory ||| output dir	count=1
function	and right [function] ||| generate [function]	count=1
function	was opened for writing ||| writable	count=1
function	contain a partial ||| partial	count=1
class	coefficient matrix ||| coef	count=1
function	call ||| call	count=3
class	voting classifier ||| voting classifier	count=2
arg	to multi-class labels parameters ||| y threshold	count=1
function	[function_1] wine ||| [function_2] [function_1]	count=1
function	memmap instance to reopen ||| memmap	count=1
arg	[arg_1] [arg_2] ||| [arg_2] y [arg_1]	count=2
arg	function func ||| func	count=1
class	with the ||| base pca	count=1
class	hash depending from it ||| memorized	count=1
class	outlyingness ||| outlier detection mixin	count=1
class	then ||| transformer mixin	count=1
function	x ||| decision function	count=2
arg	to compute decisions within ||| estimators_features x	count=1
class	get ||| voting classifier	count=1
arg	n_jobs ||| n_jobs	count=3
arg	extensions ||| extensions	count=1
function_arg	compute labels [arg_2] ||| [arg_2] [function_1]	count=1
module	with block ||| joblib	count=1
function	weiszfeld [function_2] ||| [function_2] [function_1]	count=1
function	multiclass ||| multiclass	count=1
arg	memory is inefficient ||| y classes	count=1
function	the pairwise matrix ||| pairwise	count=1
function	compute the decision ||| decision	count=1
class	centering ||| scaler	count=1
function	scale ||| robust scale	count=2
arg	validation and conversion of ||| dtype csr_output	count=1
function	the l1 [function_2] ||| [function_1] [function_2]	count=6
function	graph ||| grid to graph	count=1
function	axis ||| axis	count=1
arg	other and transforms the ||| x y	count=1
class	of max absolute value ||| max abs	count=1
function_arg	diagonal of [arg_2] ||| [function_1] [arg_2]	count=3
function	slices [function_2] ||| utils [function_2] [function_1]	count=1
function	the shortest path ||| single source shortest path	count=1
function	mean and [function_2] ||| [function_1] [function_2] n_past mu var x	count=1
function	feature importances ||| get feature importances	count=2
arg	matrix x ||| x	count=2
arg	gradient of the loss ||| loss	count=1
function	for multiclass ||| multiclass	count=1
function	memmap instance to ||| memmap	count=1
function	graph of the ||| graph	count=2
function	fit is ||| fit	count=1
function	to be captured ||| exceptions	count=1
function	call predict on the ||| predict	count=1
arg	w to minimize the ||| w ht l1_reg	count=1
module	fit the [module] ||| [module]	count=1
arg	for validation and ||| dtype	count=1
module	list of ||| externals joblib	count=1
arg	w ||| x w	count=3
function	evaluate ||| score samples	count=2
function_arg	normalize rows [arg_2] ||| [arg_2] [function_1]	count=1
arg	generate ||| n_features	count=1
arg	data and ||| x y sample_weight	count=1
function	generate train test indices ||| indices	count=1
class	from it ||| memorized	count=1
arg	of x [arg_2] ||| [arg_2] [arg_1]	count=3
function	error [function_2] ||| [function_2] [function_1]	count=9
class	passive ||| passive	count=2
function	element ||| element	count=1
module	compute ||| utils	count=1
function	type ||| repr	count=1
arg	svd [arg_2] ||| [arg_1] [arg_2]	count=1
arg	if dtype of x ||| x	count=1
function	generate train ||| iter	count=1
function	log probabilities ||| predict log proba	count=1
function	compute data covariance ||| covariance	count=1
module	hash depending from ||| externals	count=2
function_arg	density lrd [arg_2] ||| [arg_2] [function_1]	count=3
function	[function_1] for diagonal ||| [function_1] mstep [function_2]	count=1
function	and predict ||| and predict	count=4
function_arg	labels back [arg_2] ||| [function_1] transform [arg_2]	count=3
class	fit ||| output estimator	count=1
class	squares ||| squares	count=1
arg	generate a ||| n_samples n_components	count=1
class	as training data ||| orthogonal matching pursuit cv	count=1
function	unfitted ||| estimators unfitted	count=2
arg	is inefficient to train ||| classes	count=1
class	of the kernel k ||| white kernel	count=1
module	cache folders to ||| joblib	count=1
function_arg	update [arg_2] ||| [arg_2] [function_1]	count=8
arg	for each ||| x y	count=1
arg	for specified layer ||| layer n_samples	count=1
class	convert coefficient ||| sparse coef mixin	count=1
function	size ||| size	count=2
function	the curve auc from ||| auc score	count=1
arg	according to x ||| x y sample_weight	count=2
function	sparse [function_2] ||| [function_2] [function_1]	count=1
function	linear ||| linear	count=2
function	california housing dataset from ||| fetch california housing	count=1
arg	regularization parameters ||| pos_class cs	count=1
function	cache ||| cache	count=1
function	data precision matrix ||| precision	count=1
arg	input validation for standard ||| y accept_sparse dtype	count=1
function	prediction of init ||| init decision	count=1
function	variance regression score ||| variance	count=1
function	huber loss and ||| huber loss and	count=3
class	max absolute value ||| max abs	count=2
function	[function_1] the c ||| [function_2] [function_1]	count=3
class	list of ||| parallel backend	count=1
arg	matrices w h whose ||| x w h n_components	count=1
function_arg	[function_1] laplacian ||| [arg_2] [function_1]	count=3
function	make cache size fit ||| reduce size	count=1
function_arg	[function_1] a filename ||| [arg_2] [function_1]	count=2
module	matrix to ||| linear_model	count=1
arg	kwargs ||| kwargs	count=1
function	fit the [function_2] ||| [function_1] [function_2]	count=3
arg	log-det of the ||| matrix_chol	count=1
function_arg	[function_1] job ||| [arg_2] [function_1]	count=1
arg	and y ||| y sum_over_features	count=1
arg	width ||| effective_rank tail_strength	count=1
arg	spectrum spectrum ||| spectrum n_samples n_features	count=1
arg	of the derived ||| resp	count=1
arg	beta-divergence ||| beta	count=1
function	for a fit ||| fit	count=1
function	the concentration parameter ||| concentration	count=1
function	range approximates the range ||| randomized range finder	count=1
arg	of csgraph inputs ||| csgraph directed	count=1
arg	does not need ||| y residual	count=1
class	backend and ||| parallel backend base	count=1
arg	to the binary ||| y_score average sample_weight	count=1
arg	[arg_1] for x ||| [arg_2] [arg_1]	count=4
arg	invariant of compute_labels ||| name clusterer	count=1
class	depending ||| memorized	count=1
arg	[arg_1] x ||| [arg_2] [arg_1]	count=31
function	found and raise an ||| line search	count=1
function	california housing dataset ||| fetch california housing	count=2
function	with sparse ||| make sparse	count=1
function	[function_1] breast ||| [function_2] [function_1]	count=1
function	the lfw pairs dataset ||| lfw pairs	count=1
arg	is ||| precision_ alpha	count=1
arg	to x ||| x	count=2
function	all ||| all	count=1
function	the current ||| tell	count=1
class	with the ||| pca	count=1
function	and return the breast ||| breast	count=1
function	of the data home ||| clear data home	count=1
function	computes the weighted graph ||| graph	count=3
arg	the [arg] ||| [arg]	count=2
function	the sample ||| sample	count=1
function_arg	read up [arg_2] ||| [function_1] [arg_2]	count=1
class	to ||| coef	count=1
class	local outlier factor ||| local outlier factor	count=3
function	approximates the range of ||| randomized range	count=1
arg	arbitrary python object into ||| value filename	count=1
module_class	[module_1] [class_2] ||| [module_1] min [class_2]	count=1
module	suffix when ||| utils	count=1
module	each ||| core	count=1
function	the output of transform ||| transform	count=1
class	gaussian process [class_2] ||| [class_2] [class_1]	count=4
arg	to the data ||| y	count=1
function	fetch [function_2] ||| [function_2] [function_1]	count=1
function	approximates the range ||| range finder	count=1
arg	binary classification ||| y_true y_score average	count=1
function	class versus all others ||| multiclass	count=1
function	california housing dataset ||| california housing	count=1
function	call with the given ||| format call	count=1
function	the long ||| shape	count=1
class	constructs signature from ||| signature	count=1
class	to [class] matrix ||| [class]	count=1
function	compute prediction of init ||| init decision function	count=1
function	length ||| length	count=2
arg	model and ||| y	count=1
module	of ||| utils	count=3
function	returns the score ||| score	count=2
module_class	to [class_2] ||| [module_1] numpy array [class_2]	count=1
function	covariance ||| distribute covar matrix to match covariance	count=1
function_arg	[function_1] and ||| [function_1] fit estimator estimator [arg_2]	count=1
arg	validity of the ||| x metric p metric_params	count=1
function	returns the huber loss ||| huber loss	count=1
function	first and ||| first and	count=2
module	'l' suffix when ||| utils	count=1
arg	[arg_1] csgraph inputs ||| [arg_2] dtype [arg_1]	count=2
arg	values for a ||| train	count=2
function	build a batch ||| build	count=1
function	predict is invariant ||| compute labels predict	count=1
arg	estimates ||| estimator x	count=1
arg	[arg_1] <classification_report> ||| [arg_2] [arg_1]	count=2
arg	x according to ||| x	count=2
function	input ||| val predict	count=2
class	the gaussian ||| gaussian	count=2
function	estimates ||| cross val predict	count=2
arg	in x [arg_2] ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=1
class	the gaussian [class_2] ||| [class_1] [class_2]	count=5
function	fitted model ||| fit	count=1
class	run ||| grid search	count=1
module	covariance estimator ||| covariance	count=1
class	least squares ||| least squares	count=1
arg	w ||| x w ht	count=1
class	leaf ||| base decision tree	count=1
function	computes the graph ||| graph	count=1
function	discrete ||| discrete	count=1
class	we don't store ||| memorized func	count=1
function	barycenter [function_2] ||| [function_2] [function_1]	count=3
function	the cholesky decomposition of ||| log det cholesky	count=1
arg	of parameters ||| x y estimator parameters	count=2
function_arg	[function_1] [arg_2] ||| [function_1] inertia precompute dense [arg_2]	count=1
function	normalized mutual ||| normalized mutual	count=2
function	a calibration [function_2] ||| [function_1] [function_2]	count=1
class	the maximum absolute value ||| max abs	count=1
function	float32 then dtype ||| dtype	count=1
function_arg	[function_1] according to ||| [function_1] [arg_2]	count=2
class	the file ||| file	count=4
arg	is ||| precision_	count=1
class	regression target ||| boosting regressor	count=1
module	file as a ||| externals joblib	count=1
arg	and perform ||| y	count=1
function	[function_1] patches ||| [function_2] [function_1]	count=3
arg	to compute [arg] it ||| [arg] n_trials	count=1
arg	the data x ||| x y	count=2
function	the image from ||| from	count=1
class	classification ||| calibrated classifier	count=1
module	cache folders ||| externals joblib	count=1
class	function evaluates [class] ||| [class]	count=1
function	also predict based ||| predict	count=1
module	for ||| core	count=1
function	number of estimators in ||| len	count=1
arg	estimates for each ||| x y	count=1
module	introduces ||| utils	count=1
function	matrix ||| matrix	count=5
arg	batch_size ||| batch_size	count=1
class	computes ||| empirical	count=2
function	the directory in ||| output dir	count=1
arg	include_self ||| include_self	count=1
function	compute the score of ||| score	count=2
function	with ||| add	count=1
function	[function_1] [function_2] algorithm ||| [function_1] [function_2] iboost x y sample_weight	count=2
arg	the rfe model and ||| y	count=1
class	kernel ridge model ||| kernel ridge	count=2
function	task ||| precision recall curve	count=1
function	from ||| read	count=1
function_arg	neighbors for [arg_2] ||| [arg_2] [function_1]	count=6
arg	operation is meant to ||| index_file_path data_folder_path slice_ color	count=1
module	generative model ||| decomposition	count=1
function	returns the submatrix corresponding ||| submatrix	count=1
arg	[arg_1] returns ||| [arg_2] [arg_1]	count=2
arg	turn [arg] into a ||| [arg]	count=1
function	to compute log ||| log	count=1
arg	with x ||| x y	count=2
class	uncompressed bytes [class_2] ||| [class_1] [class_2]	count=1
arg	along an axis on ||| x axis	count=1
function_arg	unfitted [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	[function_1] with categories ||| [function_1] container_path description [arg_2]	count=2
module	process or thread ||| joblib	count=1
class	matrix to ||| sparse coef mixin	count=1
function	the estimator ||| estimator	count=3
function	non-negative matrix factorization nmf ||| non negative factorization	count=1
class	don't store the ||| func	count=1
function	[function_1] sparse ||| [function_1] [function_2]	count=1
function	a lower bound on ||| lower bound	count=1
function_arg	distances between [arg_2] ||| [function_1] [arg_2]	count=10
function	fit a single binary ||| fit binary	count=2
arg	generate a random ||| n_samples n_features n_classes n_labels	count=1
function	classification used in hastie ||| make hastie	count=1
function_arg	training [arg_2] ||| [function_1] [arg_2]	count=8
arg	along any axis center ||| axis	count=2
class	the scaler ||| standard scaler	count=1
arg	w h whose ||| x w h	count=1
arg	of samples x ||| x	count=1
arg	computes [arg_2] ||| [arg_2] [arg_1]	count=8
function	load and ||| load	count=5
function	random multilabel classification problem ||| multilabel classification	count=1
function_arg	[function_1] x y ||| [arg_2] [function_1]	count=24
arg	model for the data [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=16
class	the maximum [class_2] ||| [class_2] [class_1]	count=3
function	data point ||| val predict	count=1
arg	matrix [arg_2] ||| [arg_2] [arg_1]	count=2
function	patches of any n-dimensional ||| patches	count=1
module	the generative ||| decomposition	count=1
function_arg	_fit_coordinate_descent update [arg_2] ||| [arg_2] [function_1]	count=4
function	[function_1] uncorrelated design ||| [function_2] [function_1]	count=4
function	items ||| items	count=1
function	the callable case ||| callable	count=1
arg	given parameter ||| estimator parameter	count=1
module	train test ||| core	count=1
class	the mixture parameters ||| gaussian mixture	count=1
arg	mean and ||| x y	count=1
arg	w to minimize the ||| x w ht l1_reg	count=1
class	the best found parameters ||| search cv	count=2
arg	object ||| to_write filename	count=1
function	array [function] ||| check is [function]	count=1
arg	orthogonal matching pursuit step ||| n_nonzero_coefs	count=1
function	full ||| full	count=2
function	return the directory in ||| output dir	count=1
function	incremental mean and ||| mean	count=1
module	parameters ||| core	count=8
class	[class_1] gradient boosting ||| [class_1] [class_2]	count=3
function	graph of ||| img to graph	count=1
function_arg	[function_1] data and ||| [arg_2] [function_1]	count=1
function	load and return ||| load	count=5
module	of exception ||| externals joblib	count=1
function	squared logarithmic error ||| squared log error	count=1
class	with the fastmcd algorithm ||| cov	count=1
function	a buffered ||| buffered	count=1
function	decision [function_2] ||| [function_1] [function_2]	count=14
class	the process or ||| multiprocessing backend	count=1
function	of points on ||| len	count=1
arg	truncated ||| m n_components n_oversamples n_iter	count=1
arg	x [arg_2] ||| [arg_1] [arg_2]	count=78
arg	is 2d square and ||| tol raise_warning raise_exception	count=1
arg	and a set of ||| x y	count=1
function	normalized mutual [function_2] ||| [function_1] [function_2]	count=1
function	average [function] ||| average [function]	count=3
arg	a sparse ||| a	count=1
function	model ||| get	count=1
function	density lrd the ||| density	count=1
arg	perform ||| responsibilities	count=1
function	a locally linear ||| locally linear	count=2
function	[function_1] and maximum ||| [function_2] [function_1]	count=2
function	the breast ||| breast	count=1
class	for parallel ||| parallel	count=1
function_arg	loss for [arg_2] ||| [function_1] [arg_2]	count=1
module	the long type ||| utils	count=1
function	[function_1] number ||| [function_1] [function_2]	count=1
function	compute joint [function_2] ||| [function_2] [function_1]	count=2
function	california housing ||| california housing	count=1
function	a read [function_2] ||| [function_2] [function_1]	count=1
function	suffix when ||| shape	count=1
function	vector is ||| positivity	count=1
arg	filename ||| filename mmap_mode	count=1
arg	n_jobs even slices ||| y func n_jobs	count=1
arg	x y ||| x y max_samples max_depth	count=1
arg	cross-validated estimates ||| estimator x y cv	count=1
function	to predict ||| predict	count=2
function	partially ||| partial	count=4
class	scaler ||| abs scaler	count=1
function	[function_1] backend ||| [function_2] [function_1]	count=2
module	list of exception types ||| joblib	count=1
function	the median [function_2] ||| [function_2] [function_1]	count=1
arg	x ||| x y sample_weight	count=2
arg	and dense ||| x y	count=1
module	estimates for each ||| core	count=1
function	the linear [function_2] ||| [function_1] [function_2]	count=2
arg	nicely formatted statement displaying ||| args kwargs object_name	count=1
function	suffix when using ||| repr	count=1
module	pool ||| joblib	count=1
module	dataset is constructed by ||| datasets	count=1
arg	[arg_1] classification ||| [arg_2] [arg_1]	count=8
function_arg	[function_1] structure for ||| [arg_2] [function_1]	count=5
function	full lars path parameters ||| omp path	count=1
function	return ||| shape	count=1
function	buffered ||| buffered	count=1
class	avoid the hash ||| func	count=1
class	with the [class] ||| [class]	count=1
arg	x and [arg_2] ||| [arg_1] [arg_2]	count=5
class	store the ||| memorized func	count=1
function_arg	neighbors [arg_2] ||| [function_1] graph [arg_2]	count=4
arg	x and y ||| x y dense_output	count=2
function	and the [function_2] ||| [function_1] [function_2]	count=1
class	of the mixture parameters ||| gaussian mixture	count=1
arg	in x and y ||| x y dense_output	count=1
function	pairs dataset this operation ||| pairs	count=1
class	not enabled for sparse ||| robust	count=1
module	the process or thread ||| joblib	count=1
function	low rank matrix with ||| make low rank matrix	count=1
function_arg	log-marginal [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
arg	makes ||| copy	count=2
function	[function_1] likelihood ||| [function_1] [function_2]	count=10
arg	and ||| w x y	count=3
arg	with x [arg] the ||| x [arg]	count=1
module	list of exception types ||| externals	count=1
arg	identify uniquely python objects ||| obj hash_name coerce_mmap	count=1
function	return the current ||| tell	count=1
arg	compute decisions within ||| estimators_features	count=1
class	hash depending from ||| memorized	count=1
module	process or thread pool ||| externals joblib	count=1
function_arg	[function_1] function func ||| [arg_2] [function_1]	count=1
module	the relationship between ||| metrics cluster	count=2
function	check validity of parameters ||| check params	count=1
function	[function_1] fit a ||| [function_1] [function_2]	count=2
function	test ||| iter	count=1
function	density ||| density	count=2
arg	<mean_absolute_error> ||| sample_weight multioutput	count=1
class	exception types to ||| parallel	count=1
function	[function_1] decision ||| [function_1] [function_2]	count=1
class	workers requested by the ||| base	count=1
module_class	the test vectors ||| core dummy	count=1
function	ovr decision [function_2] ||| [function_2] [function_1]	count=1
function	the determinant ||| det	count=1
arg	[rouseeuw1984]_ aiming at computing ||| n_support remaining_iterations initial_estimates	count=1
class	the scaler ||| abs scaler	count=1
function_arg	neighbors for [arg_2] ||| [function_1] graph [arg_2] radius	count=2
function	[function_1] and ||| [function_1] [function_2]	count=13
module	[module_1] [module_2] ||| [module_2] [module_1]	count=8
function	reduced likelihood function for ||| reduced likelihood function	count=1
function	predict posterior probability ||| predict proba	count=2
function_arg	finds indices [arg_2] ||| [function_1] [arg_2]	count=2
function	barycenter weighted [function_2] ||| [function_2] [function_1]	count=3
function	extracts patches of ||| patches	count=1
function	inverse ||| inverse	count=4
class	gaussian process ||| gaussian process	count=2
class	scaling ||| scaler	count=6
arg	meant to ||| index_file_path data_folder_path slice_ color	count=1
class	the hierarchical ||| feature agglomeration	count=1
class	getter for the ||| covariance	count=1
function_arg	[function_1] [arg_2] ||| [function_1] mask [arg_2]	count=1
class	the process or ||| multiprocessing	count=1
function_arg	neighbors [arg_2] ||| [arg_2] [function_1]	count=7
arg	a given ||| scorer	count=3
arg	[arg_1] dimensions ||| [arg_1] [arg_2]	count=1
function	[function_1] length ||| [function_1] [function_2]	count=9
function	add ||| add	count=1
function	diagonal of ||| diag	count=5
function	the leaf ||| apply	count=1
function	of a read ||| read	count=1
arg	state of the ||| state	count=1
function	estimate model ||| fit	count=3
arg	corresponding ||| mkdir	count=1
module	folders to ||| externals	count=1
arg	onto ||| ridge_alpha	count=1
class	position of the ||| mds	count=1
class	don't ||| func	count=1
arg	the median and ||| y	count=1
class	hyperparameters ||| kernel	count=1
function	return the directory in ||| dir	count=1
function	compute scores for ||| score	count=1
function_arg	range [arg_2] ||| [function_1] [arg_2]	count=1
class	list of ||| parallel backend base	count=1
function	mean and ||| mean	count=3
arg	the gradient and ||| y	count=2
module	to a function ||| externals	count=1
arg	[arg_1] isotropic gaussian ||| [arg_1] [arg_2]	count=1
function_arg	neighbors within [arg_2] ||| [arg_2] [function_1]	count=2
function	the lfw pairs ||| fetch lfw pairs	count=2
function_arg	range of [arg_2] ||| [arg_2] [function_1]	count=1
arg	column class distributions parameters ||| classes class_probability	count=1
arg	axis center to ||| x axis	count=2
class	the process or thread ||| multiprocessing	count=1
class	label ||| label	count=2
function	r^2 coefficient of determination ||| r2	count=1
function	output from svd ||| svd	count=1
class	class ||| gradient boosting classifier	count=2
arg	[arg] appropriately and ||| x [arg]	count=1
module	data ||| core	count=1
arg	axis center ||| x axis	count=2
function	lower bound [function_2] ||| [function_1] [function_2]	count=1
class	avoid the hash ||| memory	count=1
function_arg	binary and [arg_2] ||| metrics check [function_1] probabilistic predictions y_true [arg_2]	count=1
function_arg	kl divergence [arg_2] ||| [function_1] error [arg_2]	count=1
function	[function_1] diagonal of ||| [function_2] [function_1]	count=1
class	return whether the file ||| file	count=2
function	[function_1] terminal regions ||| [function_2] [function_1]	count=2
module	bytes_limit ||| externals	count=1
function_arg	[function_1] from source ||| [function_1] [arg_2]	count=5
function	[function_1] step ||| [function_1] [function_2]	count=2
class	given arguments ||| func	count=2
class	from the file ||| file	count=1
arg	for eigenvalue decomposition ||| value norm_laplacian	count=1
function	squared ||| squared	count=2
function	the sign of ||| sign	count=1
function	kddcup99 dataset ||| kddcup99	count=1
function	kappa ||| kappa	count=1
function	a ||| make	count=1
arg	from source to ||| source cutoff	count=1
arg	in sorted array of ||| tree bin_x left_mask right_mask	count=1
function	a random multilabel ||| make multilabel	count=1
function_arg	and dot [arg_2] ||| [function_1] x [arg_2]	count=2
arg	computes the gradient and ||| w x y alpha	count=2
class	[class_1] regression ||| [class_1] [class_2]	count=5
class	to ||| base	count=1
function	coefficient score the ||| score	count=1
function	linear embedding analysis on ||| linear embedding	count=1
class	scaler ||| standard scaler	count=1
function	[function_1] similarity ||| [function_2] [function_1]	count=1
arg	for a ||| means covars	count=2
arg	from source to ||| source	count=1
function	projection p only changes ||| johnson lindenstrauss min dim	count=1
function	samples from [function_2] ||| [function_1] [function_2]	count=1
function	the diagonal ||| diag	count=1
function	compute binary ||| binary	count=1
function	[function_1] loss and ||| [function_1] [function_2]	count=5
function	init ||| init decision	count=1
class	[class_1] model parameters ||| [class_1] [class_2]	count=1
arg	dense ||| random_state	count=1
function	directory in ||| dir	count=1
module	array of [module] vectors ||| [module]	count=1
arg	and y_prob ||| y_prob	count=1
arg	continuous ||| y n_neighbors	count=1
function	under the curve auc ||| auc score	count=1
arg	input data point ||| x y	count=1
function	and cpp [function_2] ||| [function_1] [function_2]	count=1
function	predict using ||| predict	count=3
function	[function_1] terminal ||| [function_2] [function_1]	count=2
arg	[arg_1] dispatch table ||| [arg_2] [arg_1]	count=1
arg	h ||| h n_components	count=1
function	incremental mean and variance ||| mean variance	count=1
module	execution only a ||| externals joblib	count=1
class	squares ||| squares error	count=1
function	return a platform independent ||| repr	count=1
class	with all sets ||| cv	count=1
function	of a wishart ||| wishart	count=1
arg	varies for mono and ||| x y	count=1
function	back to ||| inverse	count=1
arg	rfe model and ||| y	count=1
module	to ||| joblib	count=8
class	the gaussian [class_2] ||| [class_2] [class_1]	count=5
function_arg	centroids on [arg_2] ||| [arg_2] [function_1]	count=2
function	independent representation of ||| shape repr	count=1
class	of exception ||| parallel backend base	count=1
class	we ||| memorized func	count=1
arg	observations in x according ||| x	count=1
module	a byte string to ||| externals joblib	count=1
arg	x return leaf ||| x	count=1
function	range ||| range finder	count=1
function	in multiplicative update ||| multiplicative update h	count=2
arg	for validation [arg_2] ||| [arg_1] [arg_2]	count=2
function_arg	[function_1] categories ||| [arg_2] [function_1]	count=2
class	[class] at ||| [class]	count=2
module	to avoid the hash ||| joblib	count=2
module	for [module] ||| [module]	count=1
function	the boolean mask ||| mask	count=2
function	a logistic regression ||| logistic regression path	count=2
function_arg	[function_1] [arg_2] ||| laplace [function_1] [arg_2]	count=1
function	to build [function_2] ||| [function_1] [function_2]	count=6
function	sample images ||| sample images	count=2
arg	copy of y ||| y	count=1
arg	after the other and ||| y	count=1
class	of exception types to ||| parallel backend base	count=1
function	the decision [function_2] ||| [function_1] [function_2]	count=9
function	slices going up ||| even slices	count=1
class	cache for ||| memorized	count=1
function_arg	[function_1] parameters ||| [function_1] [arg_2]	count=2
class	with ||| base pca	count=2
arg	of points ||| axis metric	count=1
function	the log-likelihood of a ||| score	count=1
arg	input data point ||| y	count=1
arg	and returns the ||| y w	count=2
function_arg	[function_1] of a ||| [function_1] [arg_2]	count=4
function_arg	one set [arg_2] ||| [arg_2] [function_1]	count=2
function	the leaves of the ||| get leaves	count=1
function	or jaccard [function] coefficient ||| jaccard [function]	count=1
function	when ||| shape repr	count=1
function	to delete to ||| to delete	count=1
function	and a name for ||| name	count=1
function	helper function ||| helper	count=1
arg	similarity of ||| a b similarity	count=1
arg	set x y ||| x y sample_weight	count=7
function_arg	[function_1] x with ||| [arg_2] [function_1]	count=1
function	calculate mean update and ||| incremental mean	count=1
arg	ensemble to [arg] return leaf ||| [arg]	count=2
function	the huber [function_2] ||| [function_2] [function_1]	count=4
function	kddcup99 dataset ||| fetch brute kddcup99	count=1
arg	random sample from ||| size replace	count=1
arg	y as training ||| y copy_x	count=2
function_arg	[function_1] p_ij ||| [arg_2] [function_1]	count=4
arg	samples [arg_2] ||| [arg_1] [arg_2]	count=1
function	shift ||| shift	count=1
class	the search over ||| base search	count=1
arg	input data ||| estimator	count=1
arg	that will be extracted ||| i_h i_w p_h p_w	count=1
arg	values for a ||| x y train	count=2
function_arg	slices containing [arg_2] ||| [arg_2] [function_1]	count=5
function	[function_1] covariance ||| [function_1] [function_2]	count=2
arg	loader ||| data_home	count=3
class	actually run in parallel ||| parallel backend	count=1
function_arg	subsets incrementally [arg_2] ||| [function_1] fit estimator estimator [arg_2]	count=3
arg	binary classification task ||| y_true	count=1
arg	generate a dense ||| n_features random_state	count=3
function	of the breakdown ||| breakdown	count=1
function	[function] all hash ||| generate [function]	count=1
arg	is ||| y_true y_pred beta labels	count=1
function	the paired distances between ||| paired distances	count=1
module	nothing ||| feature_extraction	count=1
function	samples ||| predict	count=1
function	this is the time ||| time	count=1
arg	cv and ||| x y	count=1
function	likelihood function for the ||| likelihood function	count=1
arg	:ref user guide <mean_absolute_error> ||| y_true y_pred sample_weight multioutput	count=1
class	test ||| base	count=1
class	pool ||| multiprocessing	count=1
module	format ||| linear_model	count=1
function	'l' suffix when using ||| shape	count=1
function	return a ||| shape	count=1
function	embedding ||| embedding	count=1
function	on sparse ||| sparse	count=1
arg	[arg_1] pred ||| [arg_2] [arg_1]	count=3
function	from the training set ||| fit	count=4
function	a reference ||| and shelve	count=1
arg	regularization parameters ||| x y pos_class cs	count=1
function	locally linear [function_2] ||| [function_1] [function_2]	count=4
function	used to build a ||| parallel build	count=1
class	hierarchical ||| agglomerative	count=1
function	[function] line ||| extract [function]	count=1
arg	estimates for ||| estimator x y	count=1
function_arg	[function_1] estimator ||| [function_1] and predict [arg_2]	count=1
arg	beta-divergence [arg_2] ||| [arg_2] [arg_1]	count=1
arg	generate ||| estimator	count=1
module	exception ||| externals joblib	count=2
function	length of ||| length	count=1
class	of the scaler ||| max scaler	count=1
arg	estimator ||| name estimator	count=1
arg	a classification ||| y_true	count=1
function	[function_1] transform with ||| [function_1] [function_2]	count=1
function_arg	median of [arg_2] ||| [arg_2] [function_1]	count=2
class	don't store ||| memorized	count=1
function	with the generative ||| get	count=1
function	of samples ||| samples	count=1
arg	of x for later ||| x	count=1
function	and dispatch ||| dispatch one	count=1
class	absolute value ||| abs	count=2
class	model ||| pca	count=1
function_arg	[function_1] data ||| [arg_2] [function_1]	count=4
function	platform independent ||| shape repr	count=1
function	to ||| get	count=1
function	return feature [function_2] ||| [function_1] [function_2]	count=2
function	the maximizer of ||| arg max	count=1
class	undo [class_2] ||| [class_2] [class_1]	count=2
arg	classification ||| y_true y_score pos_label	count=1
function_arg	kl divergence [arg_2] ||| [arg_2] [function_1]	count=1
class	back ||| label binarizer	count=1
arg	threshold value ||| threshold	count=1
function_arg	[function_1] to multi-class ||| [function_1] transform [arg_2]	count=2
function	data point ||| predict	count=1
arg	according to the given ||| y sample_weight	count=2
module	the ||| utils	count=2
class	collect ||| voting classifier	count=1
function	of points ||| len	count=1
class	as ||| isotonic	count=1
function	call transform ||| transform	count=1
function	recall is the ratio ||| recall	count=1
arg	[arg] apply ||| [arg]	count=1
function	number of [function_2] ||| [function_2] [function_1]	count=1
function	for full covariance ||| multivariate normal density full	count=1
function	accept precomputed ||| precomp distr	count=1
arg	zero row of x ||| x y copy	count=1
function	compute the polynomial ||| polynomial	count=1
class	getter ||| empirical	count=1
arg	binary ||| y_score	count=1
class	the points in the ||| parameter	count=1
function	right fileobject from a ||| read fileobject	count=1
arg	theta ||| theta	count=2
arg	inefficient to train ||| x y classes	count=1
arg	model using x y ||| x y	count=1
arg	introduced by a random ||| n_samples eps	count=1
class	encoder ||| encoder	count=2
function	[function_1] [function_2] numpy array else raises ||| [function_1] [function_2]	count=2
function	ndarray with aligned ||| aligned	count=1
arg	n_jobs is the ||| n_jobs	count=2
arg	theta ||| theta eval_gradient	count=1
function	not found and raise ||| line search	count=1
arg	w h ||| w h n_components	count=1
function	cosine distances between ||| cosine distances	count=2
function	all the covariance ||| distribute covar matrix to match covariance	count=1
arg	[arg_1] from distances ||| [arg_2] [arg_1]	count=3
function	updates terminal ||| terminal	count=1
function	of determination regression ||| r2	count=1
class	the kernel k ||| compound kernel	count=2
function	loss ||| loss grad	count=1
function	weiszfeld ||| weiszfeld	count=1
function	for diagonal ||| diag	count=1
module_class	[module_1] grid ||| [module_1] [class_2]	count=2
function	update for ||| step	count=1
class	the generative ||| base pca	count=1
function_arg	reachability [function_1] [arg_2] ||| reachability [function_1] [arg_2]	count=9
arg	threshold value ||| importances threshold	count=1
class	make ||| base ensemble	count=1
module	depending from it ||| joblib	count=2
module	remove cache folders to ||| externals joblib	count=1
function	[function_1] the breast ||| [function_1] [function_2]	count=1
class	of the kernel ||| normalized kernel mixin	count=1
function	find the first prime ||| find prime	count=1
arg	data x ||| x doc_topic_distr	count=1
function	samples in x ||| predict	count=1
function	estimators from the training ||| fit	count=2
function	to fit a single ||| build trees	count=1
function	build a [function_2] ||| [function_2] [function_1]	count=1
function	update terminal [function_2] ||| [function_1] [function_2]	count=1
function	dimension of ||| dimension	count=1
arg	[arg_1] for ||| [arg_1] [arg_2]	count=2
arg	matrix for x using ||| x	count=1
arg	largest k singular values/vectors ||| k ncv tol	count=1
function	to accept precomputed ||| precomp distr	count=1
function_arg	log-probabilities for x ||| log proba x	count=4
function	distributions for the means ||| means	count=1
function_arg	check [arg_2] ||| [function_1] [arg_2]	count=3
arg	[rouseeuw1984]_ aiming at computing ||| x n_support remaining_iterations initial_estimates	count=1
arg	and a ||| x y axis	count=1
arg	weights and ||| y	count=1
module	execution only ||| externals joblib	count=1
arg	[arg] neighborhoods are ||| [arg] radius mode	count=3
function	getter for ||| get	count=1
arg	with stochastic gradient descent ||| x y coef_init intercept_init	count=1
module	cluster each sample ||| cluster	count=1
function_arg	computing truncated [arg_2] ||| [arg_2] [function_1]	count=2
arg	in x [arg_2] ||| [arg_2] [arg_1]	count=4
arg	y - pred ||| y pred	count=3
function_arg	parameters [arg_2] ||| [function_1] [arg_2]	count=4
function	the decision ||| decision	count=4
class	of the parallel ||| parallel	count=1
function	the breakdown [function_2] ||| [function_1] [function_2]	count=1
arg	matrix ||| k k_skip eigen_solver	count=1
function	the range of ||| randomized range	count=1
arg	a subcluster ||| subcluster new_subcluster1 new_subcluster2	count=1
arg	samples of [arg_2] ||| [arg_2] [arg_1]	count=1
arg	input validation for standard ||| accept_sparse dtype	count=1
module	metrics read more ||| metrics	count=1
function	error of [function_2] ||| [function_2] [function_1]	count=9
arg	output for x ||| x	count=1
function	to partition estimators ||| partition estimators	count=2
arg	usual api and ||| y	count=3
function	iterator over estimators ||| iter	count=1
class	model ||| base	count=1
arg	values for a given ||| train	count=2
class	the ||| pca	count=1
class	of exception types to ||| parallel	count=1
function	locally linear ||| locally linear	count=2
function	[function_1] diagonal ||| [function_1] [function_2]	count=1
function	list of edges for ||| edges	count=1
arg	continuous ||| x y n_neighbors	count=1
function	the decision function of ||| decision function	count=1
function	[function_1] information ||| [function_1] [function_2]	count=3
class	don't ||| memory	count=1
arg	data and y ||| y	count=2
class	matrix to ||| sparse coef	count=1
module	linear model ||| linear_model	count=2
function	uncorrelated design ||| uncorrelated	count=1
function	predict is ||| clusterer compute labels predict	count=1
class	using numpy ||| numpy	count=1
class	multi-class targets ||| output code	count=1
class	folders to ||| memory	count=1
arg	downloading it if necessary ||| subset data_home download_if_missing random_state	count=1
class	the points in ||| parameter	count=1
function	bytes ||| bytes	count=2
arg	a transform ||| transform	count=1
function_arg	from a [arg_2] ||| [arg_2] [function_1]	count=1
arg	of regularization parameters ||| pos_class cs	count=1
function	memmap instance to reopen ||| reduce memmap	count=1
function	when using the ||| shape	count=1
function	the logistic loss ||| logistic loss	count=4
function	data ||| cross	count=1
arg	spectrum spectrum ||| spectrum n_samples	count=1
arg	matrix m ||| m k	count=1
function_arg	[function_1] the data ||| [function_1] x [arg_2]	count=1
class	undo the ||| min max	count=1
function	[function_1] strip lines ||| [function_2] [function_1]	count=1
function	terminal regions ||| terminal region	count=1
function_arg	model for the data [function_1] [arg_2] ||| decomposition nmf [function_1] x [arg_2]	count=5
function	[function] line information ||| extract [function]	count=1
function_arg	compute scores [arg_2] ||| [arg_2] [function_1]	count=2
arg	[arg_1] as training ||| [arg_2] [arg_1]	count=4
arg	case method='lasso' is ||| xy gram	count=1
class	avoid the ||| memorized func	count=1
arg	and class ||| y	count=1
function	transform data ||| transform	count=1
function	wild lfw [function_2] ||| [function_2] [function_1]	count=4
class	it ||| memory	count=1
function_arg	compute labels [arg_2] ||| [function_1] inertia precompute dense [arg_2]	count=1
function	point ||| cross val predict	count=2
function_arg	and maximum [arg_2] ||| [function_1] [arg_2]	count=1
function	shape ||| shape	count=1
function	task ||| curve	count=1
function	set the [function_2] ||| [function_1] [function_2]	count=7
function	by scaling ||| minmax scale	count=1
function_arg	[function_1] this ||| [arg_2] [function_1]	count=6
arg	transformed data ||| h	count=1
function	train test indices ||| iter indices	count=1
arg	connectivity [arg_2] ||| [arg_2] [arg_1]	count=1
function	precision is ||| precision	count=1
arg	within a given radius ||| radius	count=1
arg	of x ||| x	count=16
arg	estimates for each input ||| estimator	count=1
module_class	[module_1] the ||| [module_1] [class_2]	count=2
function	linkage agglomerative ||| linkage tree	count=1
function	compute gaussian log-density at ||| log multivariate normal density	count=2
arg	solution to a large ||| a	count=1
arg	for a given ||| y scorer	count=1
function	the right fileobject ||| fileobject	count=1
function_arg	probabilities for x ||| proba x	count=8
arg	[arg_1] as training ||| [arg_1] [arg_2]	count=4
function	for full covariance ||| density full	count=1
function	trace of [function_2] ||| [function_1] [function_2]	count=1
class	[class_1] aggressive algorithm ||| [class_1] [class_2]	count=8
module	of a ||| utils	count=1
function	the state of ||| state	count=1
arg	classes ||| classes	count=1
class	possible outcomes ||| voting	count=1
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2] y	count=2
arg	given ||| y scorer	count=1
function	return the iris ||| iris	count=1
function_arg	block checkerboard [arg_2] ||| [arg_2] [function_1]	count=3
arg	configure a copy ||| append	count=1
function_arg	subsets incrementally [arg_2] ||| [arg_2] [function_1]	count=3
class	backend and ||| backend	count=1
function	first ||| first	count=2
class	[class] of ||| [class]	count=2
function	for the lfw pairs ||| lfw pairs	count=1
function	the kl ||| kl	count=1
function	compute mean ||| mean	count=1
function	current ||| tell	count=1
module_class	cluster [class_2] ||| [module_1] [class_2]	count=8
module	with ||| decomposition	count=1
function_arg	training set [arg_2] ||| [arg_2] [function_1]	count=8
arg	compute_labels ||| name clusterer	count=1
function_arg	[function_1] fileobj ||| [arg_2] [function_1]	count=1
function	[function_1] fit ||| [function_1] [function_2]	count=3
arg	alphas [arg] best alpha ||| [arg]	count=1
module	avoid the ||| externals	count=2
arg	random ||| n_samples	count=1
function	each sample ||| samples	count=3
arg	binary ||| y_score average sample_weight	count=1
function	range ||| randomized range finder	count=1
arg	to unit ||| axis copy	count=1
class	the process or thread ||| backend	count=1
arg	of the loss is ||| loss	count=1
class	mlp loss ||| multilayer perceptron	count=1
module	generate train ||| core	count=1
function	kernel is stationary ||| is stationary	count=2
arg	non-negative matrices w h ||| w h	count=1
module	exception types to ||| externals	count=1
function	[function_1] kernel ||| [function_1] [function_2]	count=3
class	of [class] ||| parallel [class]	count=1
arg	the beta-divergence of ||| beta	count=1
arg	the binary ||| y_score	count=1
class	the minimum ||| min	count=1
class	kernel [class_2] ||| [class_1] [class_2]	count=2
function_arg	two [arg_2] ||| [arg_2] [function_1]	count=1
module	of exception types ||| joblib	count=1
function_arg	[function_1] x using ||| [function_1] [arg_2]	count=1
function	[function_1] transform ||| [function_1] [function_2]	count=1
class	coefficient ||| coef	count=1
function	and persist the output ||| call	count=1
function_arg	this score [arg_2] ||| [function_1] [arg_2] average sample_weight	count=4
module	from it ||| joblib	count=2
class	print ||| base mixture	count=2
function	text report ||| report	count=1
function	function code and ||| func code	count=1
arg	[arg_1] and ||| [arg_1] [arg_2]	count=5
arg	[arg] neighborhoods ||| [arg] radius mode	count=3
arg	y - [arg_2] ||| [arg_2] [arg_1]	count=1
module	process or ||| externals	count=1
function	normalized ||| normalized	count=1
arg	lrd of ||| distances_x neighbors_indices	count=1
arg	a given dataset ||| y scorer	count=1
function	terminal [function_2] ||| [function_1] [function_2]	count=1
function	shrunk ledoit-wolf ||| ledoit wolf shrinkage	count=1
arg	for each input data ||| x	count=1
function	fit ||| fit parameter	count=2
arg	of theta ||| theta	count=1
function	the pairwise matrix in ||| parallel pairwise	count=1
arg	w h whose product ||| w h n_components	count=1
arg	of csgraph ||| csgraph	count=1
arg	validation and conversion ||| directed dtype csr_output	count=3
class	label [class_2] ||| [class_2] [class_1]	count=1
arg	derivatives with respect ||| activations deltas	count=1
function	memmap ||| mmap	count=1
function	the recall is ||| recall	count=1
class	thread ||| multiprocessing	count=1
function_arg	log probabilities [arg_2] ||| [function_1] [arg_2]	count=1
module	exception types to ||| joblib	count=1
function	for each input ||| val predict	count=1
function	the recall the recall ||| recall	count=1
function	[function_1] full ||| [function_1] mstep [function_2]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] n [arg_2]	count=8
module	[module_1] between ||| [module_1] [module_2]	count=2
class	underlying estimators should be ||| one vs one classifier	count=1
class	of the kernel ||| kernel	count=5
function	l1-penalized ||| graph lasso	count=1
function	scorer ||| scorer	count=1
function	of neighbors for ||| radius neighbors	count=2
arg	of rows in x ||| x	count=1
function	determine absolute sizes ||| train sizes	count=1
function	[function_1] labels in ||| [function_2] [function_1]	count=2
function_arg	[function_1] in n_jobs ||| [function_1] [arg_2]	count=3
function	[function_1] pairs dataset ||| [function_1] [function_2]	count=8
function	the median of ||| median	count=1
function	by the callers ||| effective	count=1
class	for ||| boosting classifier	count=1
class	computes ||| empirical covariance	count=1
arg	sparse and dense ||| x y	count=1
arg	in the ||| compress	count=1
function_arg	[function_1] of theta ||| [arg_2] [function_1]	count=1
function	predict on the ||| predict	count=1
function	load and [function_2] ||| [function_1] [function_2]	count=3
arg	and smooth ||| x y	count=2
arg	values for ||| train	count=2
class	with passive ||| passive	count=4
function_arg	[function_1] x for ||| [function_1] diag [arg_2]	count=1
arg	x which should contain ||| x	count=1
arg	x from ||| x	count=1
arg	of the data ||| x	count=2
class	to ||| selector mixin	count=1
arg	based on a ||| x connectivity n_clusters return_distance	count=1
function	cpp ||| cpp	count=1
class	passive [class_2] ||| [class_2] [class_1]	count=2
function	the neighbors within ||| radius neighbors	count=1
function	full covariance matrices ||| multivariate normal density full	count=1
function	factorization ||| factorization	count=1
arg	with categories [arg_2] ||| [arg_2] [arg_1]	count=2
function	error of the ||| error	count=1
function	return a platform independent ||| shape	count=1
arg	x y as training ||| x y xy	count=1
arg	p ||| p	count=1
function	partition ||| partition	count=1
arg	kwargs using a ||| kwargs	count=1
function	for the precision matrix ||| get precision	count=1
arg	given args and ||| args	count=1
function	[function_1] sign of ||| [function_2] [function_1]	count=2
arg	estimates for each input ||| estimator x y	count=1
arg	dot w ||| w	count=1
function	log probabilities of ||| log proba	count=2
class	boost ||| boost classifier	count=2
module	hash ||| externals joblib	count=4
function	load [function_2] ||| [function_1] [function_2]	count=9
class	depending ||| memorized func	count=1
function	importances the higher the ||| importances	count=2
function	terminal regions ||| terminal	count=1
arg	to a large ||| a	count=1
arg	[arg_1] [arg_2] ||| [arg_2] dtype [arg_1]	count=6
arg	pictures of famous people ||| funneled resize	count=1
function	batch size ||| batch size	count=4
class	avoid the ||| memorized	count=1
arg	[arg_1] csgraph inputs ||| [arg_2] [arg_1]	count=2
module	transform a [module] of documents ||| [module]	count=1
function_arg	maximum [arg_2] ||| [function_1] [arg_2]	count=1
function	fit on the estimator ||| fit	count=1
function	seeds ||| bin seeds	count=2
class	regression ||| regressor	count=1
arg	compute decisions within a ||| estimators_features x	count=1
function_arg	divergence of [arg_2] ||| [function_1] error [arg_2]	count=1
function	for the given param_grid ||| get param iterator	count=1
function	[function_1] concentration parameter ||| [function_1] [function_2]	count=1
arg	h ||| w h	count=1
function	path with coordinate ||| enet path	count=1
arg	each input data ||| estimator x	count=1
arg	on x and ||| x	count=1
function	used in hastie ||| make hastie	count=1
class	the kernel k ||| pairwise kernel	count=2
class	whether ||| pairwise	count=1
function	precision is the ||| precision	count=1
module	or thread pool ||| externals joblib	count=1
function	reconstruct the image from ||| reconstruct from	count=1
arg	the binary classification ||| y_true y_score pos_label sample_weight	count=1
function	compute data precision matrix ||| get precision	count=1
function	generate an ||| make	count=2
function	[function] function ||| [function]	count=2
function	curve auc using the ||| auc	count=1
function	dispatch ||| dispatch one	count=1
function	[function_1] concentration parameter ||| [function_2] [function_1]	count=1
function	maximizer of [function_2] ||| [function_1] [function_2]	count=3
function	partition estimators ||| partition estimators	count=2
arg	x from ||| x z reg	count=1
module	and a youngs ||| utils	count=1
function	boolean mask [function_2] ||| [function_2] [function_1]	count=6
function	find the [function_2] ||| [function_2] [function_1]	count=5
function	write ||| write	count=4
arg	from source to all ||| graph source cutoff	count=1
class	computation of min ||| min	count=1
arg	given radius of ||| radius	count=1
class	[class_1] features ||| [class_2] [class_1]	count=1
function	call with ||| call	count=1
function_arg	[function_1] this kernel ||| [function_1] [arg_2]	count=2
arg	for ||| y	count=1
arg	each input ||| estimator	count=1
function_arg	[function_1] in x ||| [arg_2] [function_1]	count=20
arg	[arg_1] == missing_values ||| [arg_2] [arg_1]	count=1
function	exception ||| get	count=1
arg	compute the median and ||| x y	count=1
class	generative model ||| pca	count=1
function_arg	parameters of [arg_2] ||| [arg_2] [function_1]	count=3
function	a [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] for diagonal ||| [function_2] [function_1]	count=1
function	types to be captured ||| get exceptions	count=1
function_arg	[function_1] size ||| [arg_2] [function_1]	count=1
module	return a platform independent ||| utils	count=1
function	feature names for ||| feature names	count=2
arg	the model according to ||| y sample_weight	count=2
function	predict is invariant ||| clusterer compute labels predict	count=1
function	model and transform ||| transform	count=1
function	a logistic [function_2] ||| [function_2] [function_1]	count=1
module_class	number of [module_1] [class_2] ||| [module_1] [class_2]	count=1
arg	estimator ||| estimator	count=8
function	that ||| check	count=1
class	update ||| base optimizer	count=1
class	thread pool ||| backend	count=1
function	mean squared logarithmic ||| mean squared log	count=2
arg	of regularization ||| x y pos_class cs	count=1
function	ovr decision [function_2] ||| [function_1] [function_2]	count=1
class	the given arguments ||| memorized func	count=1
function	multinomial loss ||| multinomial loss	count=2
function	range approximates the range ||| randomized range	count=1
function	x ||| inverse transform	count=1
function_arg	[function_1] squared euclidean ||| [arg_2] [function_1]	count=1
arg	the laplacian ||| laplacian	count=1
function	and [function_2] ||| [function_2] [function_1]	count=12
class	convert ||| coef	count=1
arg	the gradient and ||| x y	count=2
arg	along any axis ||| axis	count=2
function	thresholding ||| thresholding	count=1
arg	x using the model ||| x	count=1
function_arg	function [arg_2] ||| [function_1] called str function_name [arg_2]	count=1
arg	the transformed data ||| h	count=1
function_arg	[function_1] sorted array ||| [arg_2] [function_1]	count=2
class	distribution ||| bayesian	count=1
function_arg	the range [arg_2] ||| [arg_2] [function_1]	count=1
class	process ||| backend	count=1
function	[function_1] in the ||| [function_2] [function_1]	count=3
class	exception ||| backend	count=1
arg	regularization ||| x y pos_class cs	count=1
module	to avoid the ||| joblib	count=2
arg	restricted to the binary ||| y_score	count=1
function	[function_1] images ||| [function_1] [function_2]	count=2
function	fit the model using ||| fit	count=3
function	'l' suffix when using ||| repr	count=1
arg	and the ||| w x y	count=2
function	[function_1] and variance ||| [function_2] [function_1]	count=6
class	of exception types ||| parallel backend base	count=1
module	a new ndarray with ||| utils	count=1
function	check initial parameters of ||| check parameters	count=1
function	estimator ||| estimator	count=3
module	neighbors ||| neighbors	count=1
function_arg	files with [arg_2] ||| [function_1] container_path description [arg_2]	count=1
function	object that [function] maps ||| bind [function]	count=1
function	function ||| function	count=13
module	independent representation ||| utils	count=1
class	getter for the ||| empirical	count=1
arg	points in x ||| x	count=2
arg	1 iteration ||| total_samples batch_update parallel	count=1
arg	sorted array ||| tree bin_x left_mask right_mask	count=1
function	compute the [function_2] ||| [function_2] [function_1]	count=3
function_arg	perplexity [arg_2] ||| [function_1] precomp distr [arg_2]	count=2
class	of ||| base	count=1
arg	pickler file ||| pickler	count=1
function	estimate sample weights ||| sample	count=1
class	covariance ||| covariance	count=1
function	train ||| iter	count=1
function	test indices ||| iter indices	count=1
function	using ||| repr	count=1
arg	and a set of ||| x y axis	count=1
arg	and compute ||| y	count=2
module	store the ||| externals	count=2
arg	validate 'train_sizes' ||| train_sizes n_max_training_samples	count=1
function	jobs that can actually ||| jobs	count=2
arg	[arg_1] membership ||| [arg_1] [arg_2]	count=3
arg	estimator ||| estimator x y i	count=1
function	the huber ||| huber	count=1
function_arg	an mldata [arg_2] ||| [arg_2] [function_1]	count=1
arg	input data point ||| estimator	count=1
function_arg	transform the [arg_2] ||| [arg_2] [function_1]	count=3
function	a grid ||| grid	count=1
function	kddcup99 ||| fetch brute kddcup99	count=1
arg	rows in x ||| x	count=1
function	recall is ||| recall	count=1
function	in an unfitted ||| unfitted	count=1
module	a sparse ||| utils	count=1
arg	and columns of x ||| x	count=1
arg	approximation ||| n_samples n_subsamples	count=1
arg	estimates for each ||| estimator x y	count=1
class	of the scaler ||| scaler	count=3
class	relative ||| predict scorer	count=2
arg	elastic net parameter search ||| x y xy l1_ratio	count=1
function	a random multilabel classification ||| make multilabel classification	count=1
class	kernel ||| normalized kernel mixin	count=1
module	or ||| joblib	count=1
arg	object ||| filename	count=1
function	compute joint ||| joint	count=2
arg	w to minimize ||| w ht	count=1
function	[function_1] random ||| [function_1] [function_2]	count=1
function	using the ||| repr	count=1
function_arg	partition estimators [arg_2] ||| [arg_2] [function_1]	count=1
function	a ||| repr	count=1
arg	using the gp prior ||| x return_std return_cov	count=1
function_arg	check the [arg_2] ||| [function_1] [arg_2]	count=4
function	divergence ||| divergence	count=1
class	the kernel ||| kernel	count=15
arg	the beta-divergence [arg_2] ||| [arg_2] w h [arg_1]	count=1
arg	point ||| estimator	count=1
function	handle ||| handle	count=1
function	leaves ||| get leaves	count=1
arg	of regularization parameters ||| y pos_class cs	count=1
arg	meant to be cached ||| data_folder_path slice_ color resize	count=1
arg	x into ||| x	count=1
class	list ||| base	count=1
function	center ||| center	count=1
function	mean absolute error regression ||| mean absolute error	count=1
function	[function_1] gaussian ||| [function_2] [function_1]	count=1
function	indices ||| indices	count=5
function	fit a [function_2] ||| [function_1] [function_2]	count=5
function	predict the ||| predict	count=4
function	estimate class ||| compute class	count=1
function	and cpp [function_2] ||| [function_2] [function_1]	count=1
class	thread pool ||| multiprocessing backend	count=2
arg	x and y ||| x y sum_over_features size_threshold	count=1
function	covariance m [function_2] ||| [function_1] mstep [function_2]	count=2
arg	and dense inputs ||| y sample_weight random_state	count=1
arg	non-negative matrices w ||| x w	count=1
function	[function_1] path ||| [function_2] [function_1]	count=10
class	train ||| base shuffle	count=1
function	display the ||| print	count=1
class	the maximum [class_2] ||| [class_1] [class_2]	count=3
function	type introduces ||| shape repr	count=1
class	the local [class_2] ||| [class_1] [class_2]	count=3
module	'l' suffix when using ||| utils	count=1
arg	truncated ||| n_oversamples n_iter	count=1
function	normalize rows and ||| normalize	count=1
function	introduces an 'l' suffix ||| repr	count=1
arg	[arg_1] random n-class ||| [arg_1] [arg_2]	count=1
arg	or regression value for ||| check_input	count=1
arg	in parallel n_jobs ||| n_jobs	count=1
function	gaussian and ||| gaussian	count=1
function	binarization transformation for ||| binarize	count=1
function	note this ||| roc	count=1
function	on training subsets incrementally ||| incremental fit	count=1
class	the weighted ||| base mixture	count=1
function	error ||| error	count=6
class	as training data ||| isotonic regression	count=2
arg	matching pursuit problems ||| y n_nonzero_coefs tol	count=1
arg	in ||| compress	count=1
arg	two non-negative matrices w ||| x w	count=1
arg	using x ||| x y	count=1
arg	x y t ||| x y	count=2
arg	the binary classification ||| y_true y_score average	count=1
function	[function_1] np dot ||| [function_1] [function_2]	count=1
class	of the kernel ||| normalized kernel	count=1
arg	given estimator ||| estimator	count=1
module_class	[module_1] [class_2] ||| [module_1] robust [class_2]	count=4
function	a calibration curve ||| calibration curve	count=2
function	online [function] of ||| [function] mean	count=1
arg	cv and ||| y	count=1
function_arg	[function_1] given ||| [function_1] estimator [arg_2]	count=2
function	code ||| code	count=2
arg	of x from y ||| x	count=1
function	explained ||| explained	count=1
class	is worthy enough ||| cfsubcluster	count=1
class	the maximum ||| max	count=1
arg	w ||| w	count=5
function_arg	[function_1] the lrd ||| [function_1] [arg_2]	count=2
function_arg	[function_1] [arg_2] ||| [function_1] mask edges [arg_2]	count=1
class	the kernel ||| stationary kernel	count=1
function_arg	np dot [arg_2] ||| [arg_2] [function_1]	count=5
arg	the data [arg_2] ||| [arg_1] [arg_2]	count=4
function	the reduced likelihood ||| reduced likelihood	count=4
function	average path ||| average path	count=2
class	graph matrix for label ||| label	count=1
function	sign of elements of ||| sign flip	count=1
arg	to the binary classification ||| y_true	count=2
arg	and y is ||| y	count=1
arg	python object into ||| filename	count=1
function_arg	density lrd [arg_2] ||| reachability [function_1] [arg_2]	count=3
arg	or sparse matrix x ||| x	count=1
function_arg	[function_1] x ||| [function_1] predict proba [arg_2]	count=1
class	determinant [class_2] ||| [class_2] [class_1]	count=2
class	voting classifier valid parameter ||| voting classifier	count=1
function	and a name ||| name	count=1
arg	sparse matrix ||| accept_sparse dtype	count=1
function	array-like or scipy ||| binarize	count=1
class	remove cache folders ||| memory	count=1
function	a locally ||| locally	count=1
function	print verbose ||| print verbose	count=2
function_arg	boolean mask x ||| get mask x	count=1
function	a platform ||| repr	count=1
arg	other and transforms the ||| y	count=1
class	outlier on the ||| outlier factor	count=1
arg	for each input data ||| x y	count=1
arg	n_components ||| array n_components	count=1
module	inside a ||| externals	count=1
function	in-place ||| swap	count=1
function	maximum ||| max	count=1
module	problem this dataset is ||| datasets	count=1
function	check that ||| check	count=3
class	fit ||| lars cv	count=1
class	shutdown ||| multiprocessing backend	count=1
arg	target values for x ||| x	count=1
function	long ||| repr	count=1
class	thread ||| backend	count=1
function	wild lfw ||| fetch lfw	count=1
function_arg	[function_1] [arg_2] ||| [function_1] and predict [arg_2]	count=1
function_arg	files with [arg_2] ||| [function_1] [arg_2]	count=1
arg	in parallel n_jobs is ||| n_jobs	count=1
class	the trained ||| multilayer perceptron	count=1
module	in ||| joblib	count=1
class	[class] of samples ||| [class]	count=2
arg	training data and parameters ||| y	count=5
class	cache for the function ||| memorized	count=1
module	buffered ||| externals joblib	count=1
function	all the covariance ||| matrix to match covariance	count=1
class	the weighted log ||| base mixture	count=1
function_arg	on x ||| fit predict x	count=1
function	a platform independent ||| shape	count=1
function	the training set according ||| fit predict	count=1
function	guts of [function] method ||| [function]	count=1
class	don't store ||| memory	count=1
function_arg	based on [arg_2] ||| [arg_2] [function_1]	count=2
function	independent representation of ||| repr	count=1
function	input ||| cross val	count=1
function	posterior probability of ||| proba	count=1
arg	== missing_values ||| value_to_mask	count=1
function	and false positives per ||| clf curve	count=1
function	versus all others ||| multiclass	count=1
module	to avoid ||| joblib	count=2
function	adjusted for ||| adjusted	count=1
class	a matrix of patch ||| patch extractor	count=1
function	to ||| reduce	count=1
function	the lfw pairs dataset ||| fetch lfw pairs	count=1
function_arg	pairwise matrix [arg_2] ||| [arg_2] [function_1]	count=3
function	training ||| fit	count=9
class	whether ||| dot product	count=1
class	generate train test ||| split	count=1
function	optimal [function_2] ||| [function_1] [function_2]	count=2
arg	apply transforms and ||| y	count=1
function_arg	[function_1] from source ||| [arg_2] [function_1]	count=5
function	isotonic regression model : ||| isotonic regression	count=1
arg	returns n_neighbors ||| n_neighbors return_distance	count=1
function	init ||| shuffle split init	count=1
class	detects ||| one class svm	count=1
function	[function_1] cpp files ||| [function_1] [function_2]	count=6
function	of exception types ||| get	count=1
arg	n_jobs is ||| n_jobs	count=2
class	exception ||| base	count=1
function_arg	[function_1] x by ||| [arg_2] [function_1]	count=5
arg	between x and y ||| x y gamma	count=1
class	naive bayes ||| nb	count=1
function	each input ||| predict	count=1
arg	for ||| estimator	count=1
function	of the cholesky decomposition ||| log det cholesky	count=1
function	fetch ||| fetch	count=1
class	to ||| backend base	count=2
function	names ||| names	count=2
function	wild lfw pairs ||| lfw pairs	count=1
arg	model with x ||| x y	count=2
arg	array ||| array	count=2
class	coefficient ||| sparse	count=1
arg	and conversion [arg_2] ||| [arg_2] dtype [arg_1]	count=2
function_arg	[function_1] of data ||| [function_1] [arg_2]	count=3
arg	loader for the ||| subset data_home	count=1
class	cache folders ||| memory	count=1
function	compute a logistic regression ||| logistic regression path	count=1
arg	gradient and the ||| w x y	count=2
module	points into ||| manifold	count=1
arg	bell-shaped curve of width ||| effective_rank tail_strength	count=1
function	the depth ||| check previous func code	count=1
arg	learn and ||| y	count=1
class	minimum ||| min	count=3
arg	transforms and ||| x y sample_weight	count=1
function	estimates ||| cross	count=1
module	we ||| externals joblib	count=4
function	format check x format ||| check	count=1
module	we don't store ||| externals joblib	count=2
function	strip lines beginning with ||| strip	count=1
function	the data [function_2] ||| [function_2] [function_1]	count=2
arg	corresponds to the area ||| y_true y_score	count=1
arg	of regularization ||| y pos_class cs	count=1
arg	writes an [arg] into a ||| [arg]	count=1
function	return the feature ||| feature	count=1
arg	a random sample from ||| size replace	count=1
function	text files with ||| files	count=1
function_arg	parameters for this ||| params deep	count=2
function	for memmap [function_2] ||| [function_1] [function_2]	count=1
module	a byte string to ||| externals	count=1
arg	for 1 iteration ||| x total_samples batch_update parallel	count=1
function	the log-likelihood of ||| score	count=1
class	decision ||| gradient boosting classifier	count=1
module	[module] the ||| [module]	count=3
arg	of the samples x ||| x	count=5
function	the kernel is ||| is	count=1
function_arg	path length [arg_2] ||| [function_1] [arg_2]	count=3
function	the average ||| average	count=1
class	to ||| mixin	count=1
arg	batch_size elements from ||| batch_size	count=1
function_arg	diagonal [arg_2] ||| [arg_2] [function_1]	count=2
function	fit the [function_2] ||| [function_2] [function_1]	count=3
function	problem with sparse ||| make sparse	count=1
function	print verbose [function_2] ||| [function_1] [function_2]	count=3
class	don't store the ||| memorized func	count=1
module	transform a [module] of ||| [module]	count=1
function	lfw pairs ||| lfw pairs	count=2
function	[function_1] the c ||| [function_1] [function_2]	count=3
function	lfw ||| lfw	count=3
function	l1 [function_2] ||| [function_2] [function_1]	count=6
arg	regularization ||| y pos_class cs	count=1
function	input data ||| cross	count=1
arg	unit ||| copy	count=1
class	outlier [class_2] ||| [class_1] [class_2]	count=2
function	platform ||| repr	count=1
class	or thread pool ||| multiprocessing	count=1
function	false positives per ||| clf curve	count=1
arg	specified layer ||| layer n_samples	count=1
arg	sample from a ||| a size replace	count=1
function	introduces an 'l' suffix ||| shape	count=1
arg	[arg_1] h whose ||| [arg_2] [arg_1]	count=4
function	consistent ||| consistent	count=1
arg	- pred ||| pred	count=1
arg	matrices from ||| covariance_type	count=1
function	gaussian ||| gaussian	count=3
module	do nothing ||| feature_extraction	count=1
function	transform binary labels back ||| inverse transform	count=1
function	mutual information ||| mutual info	count=4
function	log probability ||| log	count=1
function	batch of estimators within ||| estimators	count=1
function	breast ||| breast	count=1
function	compute data covariance with ||| covariance	count=2
arg	[arg_1] of csgraph ||| [arg_2] [arg_1]	count=2
function	[function_1] key ||| [function_1] [function_2]	count=3
function	not found ||| search	count=1
function	log probability for full ||| log multivariate normal density full	count=1
class	determinant with ||| det	count=1
function	one-vs-one multi class libsvm ||| one vs one	count=1
function	reference ||| and shelve	count=1
module	exception types ||| externals	count=1
function	cosine similarity ||| cosine similarity	count=2
function	[function_1] based on ||| [function_1] [function_2]	count=2
function	build a batch of ||| parallel build	count=1
module	coefficient matrix ||| linear_model	count=1
arg	[arg_1] distances ||| [arg_2] neighbors [arg_1]	count=1
arg	continuous target variable ||| y discrete_features n_neighbors	count=1
function	probabilities of ||| proba	count=3
arg	in n_jobs even slices ||| func n_jobs	count=1
arg	non-negative matrices w h ||| x w h	count=1
function	variance regression ||| variance	count=1
function	found ||| search	count=1
arg	discrete ||| n_neighbors	count=1
function_arg	[function_1] x ||| bagging [function_1] [arg_2]	count=8
module	avoid ||| externals	count=2
class	determine the ||| parallel backend base	count=2
arg	and scaling ||| y	count=1
arg	w to minimize the ||| x w ht	count=1
function	a ||| shape	count=1
function	[function_1] the reduced ||| [function_2] [function_1]	count=3
arg	according to the given ||| x y sample_weight	count=2
function	breakdown [function_2] ||| [function_2] [function_1]	count=1
class	absolute value to ||| abs	count=1
class	the process ||| multiprocessing backend	count=1
arg	in x according to ||| x	count=1
class	avoid the hash ||| memorized func	count=1
module	hash ||| joblib	count=2
function	[function_1] images for ||| [function_1] [function_2]	count=2
function	the time [function_2] ||| [function_2] [function_1]	count=2
function	curve ||| curve	count=1
arg	between x ||| x	count=1
function_arg	perplexity for [arg_2] ||| [arg_2] [function_1]	count=4
arg	of samples x ||| x y	count=1
arg	computes an orthonormal ||| size n_iter power_iteration_normalizer	count=1
module	[module_1] with block ||| [module_1] [module_2]	count=4
arg	input data point ||| x	count=1
function	[function_1] [function_2] ||| [function_2] predict [function_1]	count=2
function	[function_1] similarity ||| [function_1] [function_2]	count=1
class	classifier ||| classifier	count=4
arg	y_[i]) ** 2 ||| y sample_weight y_min y_max	count=1
function	sign of elements ||| sign	count=1
function	load the kddcup99 ||| brute kddcup99	count=1
function	mutual [function_2] ||| [function_2] [function_1]	count=2
function	[function_1] using thresholding ||| [function_2] [function_1]	count=1
class	underlying ||| one vs one classifier	count=1
class	optimal ||| auto batching mixin	count=1
arg	[arg_1] for a ||| [arg_2] [arg_1]	count=4
arg	shuffled copy of y ||| y	count=1
module	to avoid the hash ||| externals joblib	count=2
function	point ||| val	count=1
function	number of patches ||| n patches	count=2
function	regression ||| regression path	count=2
arg	decisions within a job ||| estimators_features	count=1
class	search over ||| base search cv	count=1
function	[function_1] loss and ||| [function_2] [function_1]	count=5
function	compute the residues ||| residues	count=1
function	spherical model ||| spherical	count=1
class	[class_1] absolute value ||| [class_1] [class_2]	count=6
class	of the local ||| local	count=1
function	download [function_2] ||| [function_2] [function_1]	count=2
arg	[arg_1] x which ||| [arg_2] [arg_1]	count=8
arg	[arg_1] membership ||| [arg_2] [arg_1]	count=3
function	[function_1] files ||| [function_2] [function_1]	count=7
function	shortest path [function_2] ||| [function_1] [function_2]	count=1
class	parallel processing this method ||| parallel	count=1
class	the target ||| regressor	count=2
arg	v h ||| v	count=1
class	whether the file ||| zlib file	count=2
class	voting [class_2] ||| [class_1] [class_2]	count=4
function	fetch an [function_2] ||| [function_2] [function_1]	count=1
class	[class_1] the ||| [class_1] [class_2]	count=1
function	covariance ||| covar matrix to match covariance	count=1
module	[module_1] between labels ||| [module_1] [module_2]	count=2
function	loss [function_2] ||| [function_2] [function_1]	count=5
class	in ||| memory	count=1
class	from ||| memorized	count=1
arg	for each input ||| estimator	count=1
function	the covariance ||| to match covariance	count=1
function	probabilities for a calibration ||| calibration	count=1
class	remove ||| memory	count=1
arg	and ||| y axis	count=1
function	the first blank line ||| header	count=1
module_class	[module_1] [class_2] ||| [module_1] locally linear [class_2]	count=2
arg	cross-validated estimates ||| y cv	count=1
function	input data point ||| cross	count=1
function	minimum [function_2] ||| [function_1] [function_2]	count=1
arg	perform the ||| x responsibilities params min_covar	count=1
function	[function_1] a gaussian ||| [function_1] [function_2]	count=1
arg	x and y is ||| x y	count=1
function	[function_1] names ||| [function_2] [function_1]	count=2
arg	filters the ||| ignore_lst	count=1
module	using the ||| utils	count=1
function	california [function_2] ||| [function_1] [function_2]	count=4
arg	point ||| x y	count=1
arg	for mean_shift ||| x bin_size min_bin_freq	count=1
arg	calculates ||| emp_cov shrinkage	count=1
function	graph of ||| graph	count=6
function	when using the ||| shape repr	count=1
arg	model to x ||| x	count=1
class	max ||| max	count=1
class	with the generative ||| pca	count=1
function	on the training ||| fit predict	count=1
function	mean ||| incr mean	count=1
function	compute average [function_1] [function_2] ||| [function_1] [function_2]	count=2
function	sparse random ||| random choice csc	count=1
function_arg	[function_1] and compute ||| [arg_2] [function_1]	count=3
function_arg	neighbors [arg_2] ||| [function_1] graph [arg_2] radius	count=2
arg	given dataset split ||| x y scorer	count=1
class	getter for ||| empirical	count=1
function	[function_1] decision function ||| [function_2] [function_1]	count=1
arg	nmf model for the [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=8
class	convert coefficient matrix ||| mixin	count=1
class	fits a minimum ||| min	count=1
function	mean shift ||| mean shift	count=2
function	the dimension ||| dimension	count=1
function_arg	[function_1] x ||| [function_1] [arg_2]	count=70
arg	and dense ||| x y sample_weight random_state	count=1
class	wrapped function ||| func	count=1
arg	derived class ||| resp	count=1
class	backend ||| backend base	count=1
function	gaussian and ||| make gaussian	count=1
class	with passive aggressive algorithm ||| passive aggressive classifier	count=1
function	determine the number of ||| n	count=1
function	read ||| read	count=6
function_arg	[function_1] corresponds to ||| [function_1] [arg_2] average sample_weight	count=5
function	random ||| random choice csc	count=1
function	[function_1] binary classification ||| [function_2] [function_1]	count=4
arg	derived ||| x resp	count=1
arg	ensure that x ||| x	count=1
arg	conversion of ||| csr_output	count=1
function_arg	on x ||| fit x	count=1
function_arg	the directory [arg_2] ||| [arg_2] [function_1]	count=3
module	thread ||| externals joblib	count=2
arg	[arg_1] random n-class ||| [arg_2] [arg_1]	count=1
arg	for random ||| n_features	count=1
function	function used to build ||| build	count=1
function	output ||| output	count=1
arg	capture the arguments of ||| check_pickle	count=1
module	for each ||| core	count=1
function	the maximizer [function_2] ||| [function_2] [function_1]	count=3
arg	the value in data ||| data	count=1
arg	samples x ||| x y sample_weight	count=1
function_arg	[function_1] and returns ||| [arg_2] [function_1]	count=1
arg	x w ||| w x	count=2
function	build [function_2] ||| [function_2] [function_1]	count=6
arg	connectivity matrix ||| x connectivity n_components affinity	count=1
arg	inefficient to train ||| classes	count=1
function	compute prediction of init ||| init	count=1
class	of ||| backend base	count=2
arg	parameters ||| parameters	count=2
function	absolute error of the ||| error	count=1
arg	sparse and ||| x y sample_weight	count=1
module	of exception ||| externals	count=1
function	decision ||| decision	count=8
module	we don't ||| joblib	count=2
class	list of ||| parallel	count=1
class	return the kernel ||| kernel	count=4
function	the paired ||| paired	count=2
function	samples from a gaussian ||| sample gaussian	count=1
function	the precision is the ||| precision	count=1
function	the kddcup99 ||| kddcup99	count=1
function	lfw people ||| fetch lfw people	count=2
function	also predict based on ||| predict	count=1
arg	with new iteration ||| j est	count=1
arg	significance of a cross-validated ||| x y cv	count=1
class	convert coefficient matrix to ||| sparse coef	count=1
arg	state ||| state	count=1
function	generate ||| val predict	count=2
function_arg	length [arg_2] ||| [function_1] [arg_2]	count=3
arg	nmf ||| h	count=1
arg	two non-negative matrices w ||| w	count=1
function	returns the number of ||| len	count=1
module	each input data point ||| core	count=1
module	store the ||| externals joblib	count=2
function	the leaves ||| get leaves	count=1
class	types to ||| parallel	count=1
function	the neighbors within a ||| radius neighbors	count=1
class	points in [class_2] ||| [class_1] [class_2]	count=1
function	platform ||| shape repr	count=1
arg	x by ||| x	count=1
arg	decisions within a ||| estimators_features	count=1
function	matrix factorization nmf find ||| non negative factorization	count=1
arg	on x and y ||| x y alpha c	count=1
arg	of a function ||| function	count=1
module	a [module] of ||| [module]	count=1
module	return the [module] ||| [module]	count=1
function	items [function_2] ||| [function_2] [function_1]	count=1
module	given file as a ||| externals joblib	count=1
arg	loader for the labeled ||| subset data_home	count=1
function_arg	[function_1] factory ||| [function_1] [arg_2]	count=2
function	labels back to ||| inverse	count=1
function	[function_1] computing truncated ||| [function_2] [function_1]	count=1
module_class	[module_1] determinant with ||| [module_1] [class_2]	count=1
class	gaussian naive bayes ||| gaussian nb	count=2
function	[function_1] reduced ||| [function_2] [function_1]	count=2
function	optimal batch [function_2] ||| [function_1] [function_2]	count=1
class	backend and ||| parallel backend	count=1
arg	each input data ||| x	count=1
function	compute the median ||| median	count=1
module	to ||| preprocessing	count=4
arg	dimensions ||| dimensions	count=1
module	process or thread ||| externals	count=1
function	global clustering for the ||| global clustering	count=1
function	precisions parameters of ||| precisions	count=1
function	fit the ||| fit transform	count=1
function	data point ||| val	count=1
function_arg	[function_1] distribution ||| [arg_2] [function_1]	count=3
function	right fileobject from ||| read fileobject	count=1
class	product with ||| projection	count=1
arg	n_jobs even slices ||| n_jobs	count=1
function	partial dependence ||| partial dependence	count=2
arg	on a given test ||| y_test scorer	count=2
function	used by parallel inside ||| parallel	count=1
function	precisions parameters of the ||| precisions	count=1
function	a spherical model ||| spherical	count=1
arg	a filename ||| fileobj filename mmap_mode	count=1
function	[function_1] probabilities of ||| [function_2] [function_1]	count=2
module	list ||| externals joblib	count=2
function	lower bound on model ||| lower bound	count=1
arg	x and returns ||| x y w	count=1
function	lars path ||| path	count=1
function	input data ||| predict	count=1
arg	w to ||| w ht	count=1
function_arg	normalize [arg_2] ||| [function_1] [arg_2]	count=4
function	computes the graph laplacian ||| graph	count=1
function	[function_1] shrunk on ||| [function_2] [function_1]	count=4
function_arg	helper to [arg_2] ||| [arg_2] [function_1]	count=1
module	covariance ||| covariance	count=7
function	[function_1] svd ||| [function_2] [function_1]	count=1
function	in multiplicative update nmf ||| multiplicative update	count=1
class	the hash depending ||| func	count=1
function	the score ||| score	count=5
function	score on ||| score	count=1
arg	mono and ||| y	count=1
function	of estimators within ||| estimators	count=1
arg	axis center to ||| axis	count=2
arg	on x ||| x	count=1
function_arg	likelihood [arg_2] ||| [arg_2] [function_1]	count=1
function	kl ||| kl	count=1
function	compute the ||| compute	count=2
arg	of the data onto ||| x ridge_alpha	count=1
class	[class_1] scaling of ||| [class_1] [class_2]	count=1
arg	for specified layer ||| layer	count=1
arg	factory ||| factory	count=1
function	update [function_2] ||| [function_2] [function_1]	count=2
function	name ||| get func name	count=1
function	c [function_2] ||| [function_1] [function_2]	count=3
arg	squared ||| squared	count=1
function	non-negative matrix factorization ||| non negative factorization	count=1
function	estimate sample ||| sample	count=1
function_arg	[function_1] a ||| [function_1] [arg_2]	count=3
function	range approximates the range ||| range finder	count=1
arg	input validation for ||| accept_sparse dtype	count=1
arg	makes sure ||| copy	count=1
function	predict is invariant of ||| clusterer compute labels predict	count=1
arg	h ||| x w h beta_loss	count=1
arg	is inefficient ||| classes	count=1
function	weighted graph of k-neighbors ||| kneighbors graph	count=1
function	the array [function] ||| check is [function]	count=1
module	to a file ||| externals joblib	count=1
function	decision function of the ||| decision function	count=1
function_arg	[function_1] compute_labels ||| [arg_2] [function_1]	count=1
function	suffix when ||| repr	count=1
class	chunking it into mini-batches ||| mini batch kmeans	count=1
function	names and a name ||| func name	count=1
function	using thresholding ||| thresholding	count=1
arg	[arg] using ||| [arg]	count=3
arg	on left-out data for ||| x_train y_train x_test y_test	count=1
arg	similarity of two sets ||| a b similarity	count=1
function	transform binary labels ||| transform	count=1
arg	computes an orthonormal matrix ||| size n_iter power_iteration_normalizer	count=1
class	the voting classifier valid ||| voting classifier	count=1
arg	of x from ||| x z reg	count=1
class	underlying estimators ||| one vs one classifier	count=1
arg	the validity ||| x metric p metric_params	count=1
function	loads data ||| data	count=1
module	the ||| externals joblib	count=10
function_arg	[function_1] corresponding ||| [arg_2] [function_1]	count=3
function	timestamp when pickling to ||| reduce	count=2
module	full distance matrix ||| cluster	count=1
function	[function_1] classification ||| [function_2] [function_1]	count=5
function	factorization nmf find two ||| factorization	count=1
arg	set of samples x ||| x y sample_weight	count=1
class	coefficient matrix to ||| coef mixin	count=1
function_arg	divergence of [arg_2] ||| [arg_2] [function_1]	count=1
class	list of exception types ||| parallel	count=1
arg	perform ||| x responsibilities params	count=1
class	[class_1] factor of ||| [class_2] [class_1]	count=5
arg	for a given dataset ||| y scorer	count=1
class	whether the [class_2] ||| [class_1] [class_2]	count=1
function	breiman [2] ||| make friedman3	count=1
class	outlier ||| outlier factor	count=1
arg	to capture the ||| check_pickle	count=1
function	rand index adjusted for ||| adjusted rand score	count=1
module	generate train test ||| core	count=1
arg	x [arg_2] ||| [arg_2] [arg_1]	count=83
function	the long type introduces ||| shape repr	count=1
arg	[arg_1] and binary ||| [arg_2] [arg_1]	count=2
function	input data ||| val predict	count=1
class	whether [class_2] ||| [class_2] [class_1]	count=1
module	metrics should ||| metrics	count=1
function	precision ap from prediction ||| precision	count=1
function	run fit on ||| fit	count=1
function	log-likelihood of a ||| score	count=1
arg	for ||| x y	count=1
arg	arbitrary python object ||| value filename	count=1
function	and return the wine ||| wine	count=1
class	to ||| parallel backend	count=1
arg	sparse and ||| x y sample_weight random_state	count=1
function	hastie ||| make hastie	count=1
function	random multilabel [function_2] ||| [function_2] [function_1]	count=2
arg	returns the [arg_2] ||| [arg_1] [arg_2]	count=2
function_arg	[function_1] a given ||| [arg_2] [function_1]	count=2
function	lower bound for ||| bound	count=1
arg	standardize a dataset ||| with_mean with_std	count=1
arg	i ||| i	count=1
class	with the best found ||| base search cv	count=2
class	function ||| func	count=2
function	matrix factorization nmf ||| negative factorization	count=1
arg	regularization parameters ||| y pos_class cs	count=1
arg	q_ijs ||| params p neighbors degrees_of_freedom	count=1
arg	like d ||| d	count=1
module	from ||| joblib	count=2
function	items [function_2] ||| [function_1] [function_2]	count=1
function	params ||| params	count=1
class	the memory ||| memory	count=1
function	logistic [function_2] ||| [function_2] [function_1]	count=5
module_class	[module_1] embedding space ||| [module_1] [class_2]	count=1
class	the ||| multiprocessing	count=1
function	logistic loss [function_2] ||| [function_1] [function_2]	count=2
arg	set x [arg_2] ||| [arg_2] [arg_1]	count=8
class	init ||| base gradient boosting	count=1
function	[function_1] home cache ||| [function_1] [function_2]	count=4
function	compute the [function_2] ||| [function_1] [function_2]	count=3
function	long type introduces ||| shape repr	count=1
function	#1240 [function] can't be ||| [function]	count=1
function	sample weights ||| sample	count=1
function	return the path ||| get	count=1
function	neighbors within ||| neighbors	count=1
function_arg	seeds for [arg_2] ||| [arg_2] [function_1]	count=1
function	compute a logistic ||| logistic	count=1
function_arg	likelihood of [arg_2] ||| laplace log marginal [function_1] [arg_2]	count=1
function	the training ||| fit	count=7
arg	factor in place ||| code verbose	count=1
arg	matching pursuit ||| x y n_nonzero_coefs tol	count=1
function	a logistic regression ||| logistic regression	count=1
arg	kernel is computed between [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
function	parameters ||| params	count=5
function_arg	[function_1] [arg_2] ||| [function_1] layer [arg_2]	count=15
class	of classification ||| classifier	count=1
function	a platform ||| shape repr	count=1
arg	csgraph ||| csgraph	count=1
function	isotonic regression model ||| isotonic regression	count=1
function	the training ||| fit predict	count=1
module	the process or ||| externals	count=1
function_arg	[function_1] w ||| [function_1] coordinate descent [arg_2]	count=4
function_arg	[function_1] n_jobs even ||| [arg_2] [function_1]	count=2
arg	the model according to ||| sample_weight	count=2
arg	generate ||| x y	count=1
module_class	covariance [class_2] ||| [module_1] min cov [class_2]	count=3
function	the kddcup99 ||| fetch brute kddcup99	count=1
class	multi-class targets using ||| output code classifier	count=1
function	turn [function] into ||| [function]	count=1
function	the c ||| c	count=1
function	submatrix corresponding ||| submatrix	count=1
class	depending ||| memory	count=1
function	first prime element ||| prime	count=1
function	measure ||| fowlkes mallows	count=1
function_arg	[function_1] a job ||| [arg_2] [function_1]	count=2
function	is float32 then dtype ||| dtype	count=1
arg	inefficient ||| x y classes	count=1
class	compute the loss of ||| loss	count=1
function	sample from ||| sample	count=2
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2] b detb n_features	count=3
function	computes the paired cosine ||| paired cosine	count=1
function	binary labels back ||| inverse	count=1
function	the shortest path length ||| shortest path length	count=1
function	optimal batch [function_2] ||| [function_2] [function_1]	count=1
function	suffix ||| shape repr	count=1
class	with passive [class_2] ||| [class_1] [class_2]	count=2
arg	schedule ||| callback	count=3
arg	computes y ||| y	count=1
function	"news" format strip lines ||| strip newsgroup	count=1
arg	to size ||| size	count=1
function	and a name for ||| get func name	count=1
module	node ||| cluster	count=1
arg	given column class distributions ||| classes class_probability	count=1
function	functions ||| function	count=1
arg	y and ||| y	count=14
function	gram ||| gram omp	count=1
function_arg	mask [arg_2] ||| [function_1] mask edges [arg_2]	count=1
arg	the data [arg_2] ||| [arg_2] [arg_1]	count=12
arg	loss is ||| loss	count=1
class	convert coefficient matrix to ||| mixin	count=1
function	the sign of elements ||| sign flip	count=1
class	convert ||| sparse coef	count=1
function	compute incremental mean ||| mean	count=1
arg	standardize a dataset ||| with_centering with_scaling	count=1
function_arg	indices [arg_2] ||| [arg_2] [function_1]	count=2
function	cohen's kappa a ||| cohen kappa	count=1
function_arg	[function_1] corresponding to ||| [function_1] [arg_2]	count=3
arg	p_ij from [arg_2] ||| [arg_2] [arg_1]	count=3
class	[class_1] features parameters ||| [class_1] [class_2]	count=1
function	get feature names from ||| get feature names	count=1
arg	x ||| x y copy	count=1
arg	along any axis center ||| x axis	count=2
function	error ||| log error	count=1
function	[function_1] weighted graph ||| [function_1] kneighbors [function_2]	count=3
class	label encoder ||| label encoder	count=2
arg	data and parameters ||| y	count=5
arg	based on a ||| connectivity n_clusters return_distance	count=1
function_arg	[function_1] [arg_2] ||| [function_1] [arg_2]	count=1808
class	approximate nearest ||| lshforest	count=1
function_arg	[function_1] n ||| [function_1] [arg_2]	count=2
arg	vectors in x ||| x	count=3
arg	matrix ||| k k_skip	count=1
function	jaccard [function] coefficient ||| jaccard [function]	count=1
function	[function_1] this estimator ||| [function_1] [function_2]	count=1
function_arg	[function_1] the data ||| [arg_2] [function_1]	count=2
arg	for x using the ||| x y	count=1
function	to build [function_2] ||| [function_2] [function_1]	count=6
arg	function output for x ||| x y	count=1
class	whether the ||| dot product	count=1
function	log of the determinant ||| log	count=1
function_arg	finds seeds [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] function for ||| [function_1] [function_2]	count=5
arg	x for ||| x	count=2
module	this dataset is described ||| datasets	count=2
function	cpp [function_2] ||| [function_1] [function_2]	count=1
class	hash depending ||| memory	count=1
function	[function_1] from ||| [function_1] [function_2]	count=3
class	[class_1] outlier factor ||| [class_1] [class_2]	count=4
arg	generate cross-validated estimates ||| cv	count=1
function_arg	[function_1] and ||| [function_1] [arg_2]	count=4
function	a sparse ||| sparse	count=1
function	covariance m step ||| covar	count=2
arg	1 iteration ||| x total_samples batch_update parallel	count=1
arg	and ||| x y sample_weight random_state	count=1
function	call predict_log_proba ||| predict log proba	count=1
class	generate train ||| split	count=1
arg	orthogonal matching pursuit ||| n_nonzero_coefs tol	count=1
function	compute the median ||| get median	count=1
function	from the c and ||| from c and	count=1
function	mean [function_2] ||| [function_1] [function_2] n_past mu var x	count=1
function	reproducibility flips the sign ||| deterministic vector sign flip	count=1
function	the wild lfw pairs ||| lfw pairs	count=1
module	to ||| externals	count=4
class	to avoid ||| func	count=1
arg	[arg_1] y ||| [arg_2] [arg_1]	count=25
class	estimator has been refit ||| base search cv	count=1
class	generate train ||| base shuffle split	count=1
function	is not found and ||| search	count=1
function_arg	[function_1] [arg_2] ||| [function_1] estimator [arg_2]	count=32
function	fit [function_2] ||| [function_1] ovo [function_2]	count=1
function	extract ||| extract	count=1
arg	conversion [arg_2] ||| [arg_2] [arg_1]	count=2
class	em ||| dirichlet allocation	count=1
arg	of famous people ||| funneled resize	count=1
function	sparse random matrix given ||| random choice	count=1
class	estimator ||| estimator	count=2
arg	in x and y ||| x y sum_over_features size_threshold	count=1
function	[function_1] parameters of ||| [function_1] [function_2]	count=4
class	to the cache for ||| memorized	count=1
arg	non-negative matrices w h ||| w h n_components	count=1
function_arg	training [arg_2] ||| bagging [function_1] [arg_2]	count=2
function	for the california housing ||| california housing	count=1
arg	is the ||| y_true y_pred beta	count=1
function	a grid [function_2] ||| [function_2] [function_1]	count=1
class	decision ||| ada boost classifier	count=1
function	free energy f v ||| free energy	count=1
arg	estimates for each input ||| x	count=1
arg	arrays ||| arrays out	count=1
function_arg	cholesky decomposition [arg_2] ||| [function_1] matrix_chol [arg_2]	count=1
arg	in n_jobs even slices ||| n_jobs	count=1
module	process or thread pool ||| joblib	count=1
function	batch ||| one batch	count=1
class	gradient ||| gradient	count=2
arg	for x ||| x	count=13
function	ovr [function_2] ||| [function_2] [function_1]	count=2
arg	fileobj ||| fileobj	count=2
function	the score on the ||| score	count=1
function	validity of ||| params	count=1
arg	apply transforms and ||| x y sample_weight	count=1
function	[function_1] the breast ||| [function_2] [function_1]	count=1
function	[function_1] and cpp ||| [function_1] [function_2]	count=5
function	log probability ||| log multivariate	count=1
function	submatrix corresponding to ||| get submatrix	count=1
function	check x ||| check	count=1
function	first [function_2] ||| [function_2] [function_1]	count=1
class	exception types ||| backend	count=1
arg	input validation ||| x y accept_sparse dtype	count=1
function	[function_1] iris ||| [function_2] [function_1]	count=1
function_arg	loss [arg_2] ||| [arg_2] [function_1]	count=6
arg	[arg_1] h ||| [arg_2] [arg_1]	count=6
arg	matching pursuit ||| n_nonzero_coefs tol	count=1
class	[class_1] the ||| [class_2] [class_1]	count=1
function	load the kddcup99 dataset ||| fetch brute kddcup99	count=1
function	multinomial [function_2] ||| [function_2] [function_1]	count=1
function_arg	[function_1] model and ||| [function_1] [arg_2]	count=1
arg	parameters for an estimator ||| estimator	count=1
arg	given type in ||| type	count=1
class	[class_1] naive bayes ||| [class_1] [class_2]	count=1
function	the shortest [function_2] ||| [function_1] [function_2]	count=2
function_arg	and predict [arg_2] ||| [arg_2] [function_1]	count=8
class	[class_1] model parameters ||| [class_2] [class_1]	count=1
function	means ||| means	count=1
arg	data samples in x ||| x	count=1
class	scaler ||| scaler	count=3
arg	matching pursuit ||| y n_nonzero_coefs	count=1
function	load sample [function_2] ||| [function_2] [function_1]	count=4
module	convert coefficient ||| linear_model	count=1
function	[function_1] backend ||| [function_1] [function_2]	count=2
function_arg	[function_1] lrd of ||| [function_1] [arg_2]	count=2
arg	classification ||| y_true y_pred labels	count=1
function_arg	[function_1] positive-definite ||| [arg_2] [function_1]	count=1
class	ridge regression ||| ridge	count=2
module	we don't ||| externals joblib	count=2
class	undo ||| min max	count=1
function_arg	[function_1] theta ||| [arg_2] [function_1]	count=2
function_arg	get parameters [arg_2] ||| [function_1] [arg_2]	count=4
module	don't store the ||| externals	count=2
function	normalized mutual information ||| normalized mutual info	count=3
function	find the ||| find	count=1
function	update [function_2] ||| [function_1] [function_2]	count=2
class	cache for the ||| memorized func	count=1
function	full ||| multivariate normal density full	count=2
class	kernel ||| normalized kernel	count=1
function	online computation of ||| partial	count=2
arg	sample from a ||| a size replace p	count=1
function	compute [function_1] [function_2] ||| [function_1] [function_2]	count=2
function_arg	and maximum [arg_2] ||| [arg_2] [function_1]	count=1
arg	is meant to be ||| index_file_path data_folder_path slice_ color	count=1
function	input data ||| cross val predict	count=1
function	of a multinomial ||| multinomial	count=1
arg	[arg_1] kwargs using ||| [arg_1] [arg_2]	count=3
arg	with n_zeros for the ||| n_zeros	count=1
module	a new ||| utils	count=1
function	the feature ||| feature	count=1
arg	x and y ||| x y sum_over_features	count=1
class	avoid ||| memorized	count=1
class	the hash ||| func	count=1
function	finds indices ||| indices	count=1
function	[function_1] density lrd ||| [function_1] [function_2]	count=1
function	right [function] all ||| generate [function]	count=1
function	pairs dataset this dataset ||| pairs	count=1
function	log of probability estimates ||| predict log proba	count=2
arg	each ||| estimator x	count=1
arg	to x ||| x y	count=1
arg	dictionary factor in ||| dictionary y	count=1
function	sizes of training subsets ||| sizes	count=1
module	distance matrix ||| cluster	count=1
arg	categories ||| categories load_content	count=1
function_arg	[function_1] the validity ||| [function_1] [arg_2]	count=1
function_arg	[function_1] continuous ||| [function_1] [arg_2]	count=1
arg	[arg_1] from distances ||| [arg_2] neighbors [arg_1]	count=1
function_arg	[function_1] validity ||| [function_1] [arg_2]	count=1
function	parallel ||| parallel	count=2
module	features are selected returns ||| feature_selection	count=1
function	predict is ||| predict	count=1
class	the backend and ||| parallel backend	count=1
function	name for ||| get func name	count=1
class	kernel ||| kernel operator	count=1
function_arg	binary and [arg_2] ||| [arg_2] [function_1]	count=1
function	importances ||| importances	count=3
arg	doc_topic_distr ||| doc_topic_distr sub_sampling	count=1
arg	each ||| x	count=1
arg	validation ||| dtype	count=1
function	a platform independent representation ||| shape	count=1
function	paired cosine [function_2] ||| [function_1] [function_2]	count=1
function	check ||| check	count=13
module	get ||| externals joblib	count=1
function	and maximum ||| max	count=1
function	full covariance ||| multivariate normal density full	count=1
module	to [module] batch ||| [module]	count=1
arg	elastic net optimization ||| l1_ratio	count=1
function	each input ||| cross val	count=1
function	[function] parameters with ||| [function]	count=2
function_arg	vector [arg_2] ||| [arg_2] [function_1]	count=1
arg	sparse and dense ||| x y sample_weight random_state	count=1
arg	orthogonal matching pursuit ||| x y n_nonzero_coefs tol	count=1
arg	[arg_1] gradient and ||| [arg_2] [arg_1]	count=4
arg	with n_zeros ||| n_zeros	count=1
function	[function_1] distances between ||| [function_1] [function_2]	count=12
function_arg	directory corresponding to ||| func dir mkdir	count=1
module	[module_1] between labels ||| [module_2] [module_1]	count=2
class	init ||| gradient boosting	count=1
module_class	number [module_1] [class_2] ||| [module_1] parameter [class_2] len	count=1
function	the neighbors within ||| neighbors	count=1
function	[function_1] function to ||| [function_1] [function_2]	count=1
function	recall the recall is ||| recall	count=1
function	embedding analysis ||| embedding	count=1
arg	unit ||| axis copy	count=1
class	the trained ||| base multilayer perceptron	count=1
function	element in ||| in	count=1
function	each input ||| cross val predict	count=1
function_arg	[function_1] the data ||| [function_1] zfile file_handle [arg_2]	count=1
class	list of exception ||| backend	count=1
function	and cpp ||| and cpp	count=2
function	and ||| beta divergence	count=1
class	[class_1] scaling ||| [class_1] [class_2]	count=1
module	model ||| linear_model	count=5
function	huber loss [function_2] ||| [function_1] [function_2]	count=3
function_arg	[function_1] dense dictionary ||| [function_1] [arg_2]	count=1
function	weiszfeld step ||| weiszfeld step	count=2
function	clustering for ||| clustering	count=1
arg	[arg_1] kwargs ||| [arg_1] [arg_2]	count=3
function	return the shortest ||| single source shortest	count=1
class	each sample ||| vs	count=1
class	covered ||| hungarian state	count=1
arg	self ||| x_test	count=1
function_arg	[function_1] of x ||| [function_1] [arg_2]	count=9
class	local outlier ||| local outlier	count=2
function	memory text [function] its ||| memstr [function]	count=1
class	the ||| mixture	count=1
arg	case method='lasso' is : ||| y xy gram	count=1
function	breiman [2] ||| friedman3	count=1
arg	each input data point ||| y	count=1
arg	w to ||| x w ht	count=1
function_arg	[function_1] [arg_2] ||| [function_1] fit estimator estimator [arg_2]	count=3
module_class	a byte [class_2] ||| [module_1] [class_2]	count=2
arg	compute ||| x	count=1
function	delete ||| delete	count=1
function	performs clustering on ||| fit predict	count=1
function	seeds ||| seeds	count=1
arg	model to the data ||| y	count=1
function	and return a reference ||| and shelve	count=1
function_arg	[function_1] a given ||| [function_1] estimator [arg_2]	count=2
function_arg	estimators between jobs ||| estimators n_estimators n_jobs	count=1
class	convert coefficient matrix to ||| coef mixin	count=1
function	lfw people dataset ||| fetch lfw people	count=2
function	predict is ||| labels predict	count=1
class	exception types to ||| parallel backend	count=1
arg	to capture the arguments ||| check_pickle	count=1
function	by scaling each ||| scale	count=1
arg	given mapping ||| y class_mapping	count=1
function	c in (l1_min_c infinity) ||| c	count=1
function	similarity coefficient score ||| score	count=1
function_arg	a binary [arg_2] ||| [arg_2] [function_1]	count=2
function	of a logistic ||| logistic	count=1
function	the number of ||| effective n	count=1
arg	perform the ||| x responsibilities params	count=1
function_arg	[function_1] [arg_2] are restricted the points ||| [function_1] [arg_2]	count=60
function	training subsets incrementally ||| incremental fit	count=2
arg	generate a random ||| n_samples n_features	count=3
function	random matrix given ||| random choice csc	count=1
arg	orthogonal matching pursuit step ||| n_nonzero_coefs tol	count=1
function_arg	a [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
class	the process or ||| backend	count=1
function_arg	[function_1] mean_shift ||| [function_1] [arg_2]	count=2
class	to bicluster ||| bicluster mixin	count=1
function	binarize labels ||| label binarize	count=2
function_arg	[function_1] estimator and ||| [arg_2] [function_1]	count=1
arg	squared [arg_2] ||| [arg_2] [arg_1]	count=2
function	cholesky decomposition of ||| cholesky	count=1
arg	the similarity of ||| a b similarity	count=1
function	labels in a ||| label	count=1
function	model by computing truncated ||| truncated	count=1
function	the gradient ||| gradient	count=1
arg	on a given ||| scorer	count=2
class	the search ||| base search	count=1
class	bicluster ||| bicluster	count=3
class	the ||| empirical	count=1
arg	h whose ||| h	count=1
arg	given text in ||| text	count=2
arg	validation ||| directed dtype	count=1
module	and return the ||| externals joblib	count=4
function	from the c ||| from c	count=3
arg	for this ||| deep	count=1
function_arg	score [arg_2] ||| [function_1] [arg_2] average sample_weight	count=4
arg	x using the ||| x y	count=1
arg	based on a feature ||| x connectivity n_clusters return_distance	count=1
function	a grid [function_2] ||| [function_1] [function_2]	count=1
function_arg	run score function [function_1] [arg_2] ||| feature_selection base filter [function_1] [arg_2]	count=3
class	of the scaler ||| standard scaler	count=1
module	in bytes_limit ||| joblib	count=1
function	of neighbors for ||| neighbors	count=2
arg	estimates ||| estimator x y	count=1
arg	to edges weighted ||| edges weights	count=2
arg	lrd of a sample ||| distances_x neighbors_indices	count=1
function_arg	determine the number [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
module_class	[module_1] [class_2] ||| [module_1] numpy array [class_2]	count=2
function	precision matrix ||| precision	count=2
function	ovr decision function ||| ovr decision function	count=3
function	the derivative ||| derivative	count=1
arg	[arg_1] the function ||| [arg_2] [arg_1]	count=2
class	of ||| parallel	count=1
arg	approximation of ||| n_samples n_subsamples	count=1
function	active default backend ||| active backend	count=2
module	in ||| externals joblib	count=2
arg	y is ||| y	count=1
arg	x ||| x doc_topic_distr sub_sampling	count=1
function	points based on ||| from	count=1
function	distances between the ||| distances	count=2
function	decision path ||| decision path	count=2
arg	samples of length dimensions ||| samples dimensions	count=1
function	directory ||| func dir	count=1
function	first to assert that ||| check	count=1
function	get [function_2] ||| [function_1] [function_2]	count=15
function_arg	kernel between [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	[function_1] positive-definite ||| [function_1] precision [arg_2]	count=1
class	to sparse ||| sparse	count=1
function	graph of neighbors ||| neighbors graph	count=2
arg	in n_jobs ||| n_jobs	count=1
arg	by its spectrum spectrum ||| spectrum	count=1
function	sign ||| sign	count=1
function	multiprocessing ||| safe multiprocessing	count=1
function	data ||| clear data	count=1
arg	transforms features ||| x feature_range axis copy	count=1
arg	matrices w h ||| w h n_components	count=1
module	types ||| externals joblib	count=2
arg	data point ||| estimator x y	count=1
function	for the lfw people ||| lfw people	count=1
function_arg	[function_1] [arg_2] are restricted the points ||| [function_1] graph [arg_2]	count=12
arg	is invariant of compute_labels ||| name clusterer	count=1
arg	binary classification ||| y_true y_score pos_label sample_weight	count=1
class	predict using the gaussian ||| gaussian	count=1
module	a byte ||| externals	count=1
function_arg	[function_1] and apply ||| [arg_2] [function_1]	count=1
module	or thread pool ||| externals	count=1
function	wild lfw pairs dataset ||| fetch lfw pairs	count=1
function	folders ||| reduce	count=1
class	whether the kernel ||| dot product	count=1
function_arg	[function_1] [arg_2] ||| metrics [function_1] predictions y_true [arg_2]	count=1
function	data point ||| cross val	count=1
function_arg	[function_1] x as ||| [arg_2] [function_1]	count=2
function	for the precision matrix ||| precision	count=1
function	the reduced [function_2] ||| [function_2] [function_1]	count=7
function	a mostly low ||| low	count=1
function	points based on the ||| from	count=1
function	the sign ||| sign flip	count=1
function_arg	the residues [arg_2] ||| [function_1] [arg_2]	count=2
function	determine absolute sizes of ||| train sizes	count=1
function	check the ||| check params	count=1
function_arg	patches [arg_2] ||| [function_1] [arg_2]	count=1
function	of loss ||| loss grad	count=1
function	bound ||| bound	count=2
module	update and a youngs ||| utils	count=1
arg	- y_[i]) ** 2 ||| y sample_weight y_min y_max	count=1
function	blobs for clustering ||| blobs	count=1
module	returns cluster labels ||| cluster	count=1
class	each sample ||| one vs	count=1
module	introduces an ||| utils	count=1
class	undo the scaling ||| min max scaler	count=3
module	we don't store the ||| externals	count=2
arg	cross-validated ||| y cv	count=2
module	remove cache ||| externals	count=1
arg	conversion [arg_2] ||| [arg_2] dtype [arg_1]	count=2
class	with all ||| cv	count=1
function	for the lfw pairs ||| fetch lfw pairs	count=1
function	gradient ||| grad	count=1
function	biclusters ||| consensus	count=1
function	the kddcup99 dataset ||| fetch brute kddcup99	count=1
function	transform ||| transform	count=14
class	or ||| backend	count=1
function_arg	[function_1] [arg_2] ||| [function_1] x y [arg_2]	count=4
arg	set of points ||| axis metric	count=1
arg	text in ||| text	count=2
function	matrix in-place ||| inplace swap	count=2
function	[function_1] binary ||| [function_1] [function_2]	count=1
function	[function_1] the gradient ||| [function_2] [function_1]	count=5
function	a name for the ||| get func name	count=1
function_arg	[function_1] [arg_2] ||| [function_1] auc score [arg_2]	count=2
function_arg	random matrix [arg_2] ||| [arg_2] [function_1]	count=1
arg	is computed between each [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=1
class	whether the kernel ||| kernel mixin	count=1
function	likelihood of ||| likelihood	count=1
arg	x from y ||| x z	count=1
class	convert coefficient matrix ||| sparse	count=1
function	suffix when using ||| shape	count=1
class	the ||| memory	count=2
module	a size limit ||| externals joblib	count=1
function	handle the callable case ||| pairwise callable	count=1
function	paired [function_2] ||| [function_2] [function_1]	count=3
function	[function_1] uncorrelated design ||| [function_1] [function_2]	count=4
function	one set of ||| point	count=2
arg	for ridge and ||| y	count=1
function	the log of the ||| log	count=1
function	return feature [function_2] ||| [function_2] [function_1]	count=2
module	type ||| utils	count=1
class	parallel ||| parallel backend	count=1
function	full covariance ||| density full	count=1
arg	if y [arg_2] ||| [arg_1] [arg_2]	count=1
arg	and configure a ||| append random_state	count=2
arg	implement a single ||| iboost x y	count=2
class	the graphlasso ||| graph lasso cv	count=1
function	given cache [function_2] ||| [function_2] [function_1]	count=1
function_arg	pairs dataset [arg_2] ||| [function_1] [arg_2]	count=1
module	with ||| joblib	count=1
function	predict on the estimator ||| predict	count=1
arg	list of regularization parameters ||| y pos_class cs	count=1
class	"returns ||| multi output classifier	count=1
function	placeholder for fit ||| fit	count=1
module	a [module] of documents ||| [module]	count=1
function	and column [function] of ||| get [function]	count=1
function	the lfw pairs ||| lfw pairs	count=1
class	regression target ||| gradient boosting regressor	count=1
arg	matrices w h ||| x w h	count=1
arg	lrd of a ||| distances_x neighbors_indices	count=1
class	generate ||| base shuffle	count=1
function	back the data to ||| inverse transform	count=2
class	reporter ||| verbose reporter	count=1
class	actually run in parallel ||| parallel	count=1
arg	python object ||| filename	count=1
arg	cross-validated estimates for each ||| y cv	count=1
function	fit the model ||| fit transform	count=1
class	constructs signature ||| signature	count=1
arg	h ||| h	count=3
class	or thread ||| backend	count=1
class	to ||| sparse	count=1
arg	x as a ||| x y iter_offset	count=1
class	[class_1] naive bayes ||| [class_2] [class_1]	count=1
function	log [function_2] ||| [function_1] [function_2]	count=4
class	workers requested by the ||| backend base	count=1
function	active default [function_2] ||| [function_2] [function_1]	count=1
module	cache folders to ||| externals	count=1
arg	and return that transformed ||| y	count=1
function	of np dot ||| dot	count=1
function	cache folders to ||| reduce	count=1
class	position of the points ||| mds	count=1
arg	log sum_h exp(-e v ||| v	count=1
function	a text report ||| report	count=1
function	on the training set ||| fit predict	count=1
arg	w h whose ||| w h	count=1
function	model parameters with ||| fit	count=1
function	housing dataset ||| housing	count=1
module	perform the ||| mixture	count=2
class	kernel ||| kernel	count=17
class	the ||| backend base	count=2
class	thread ||| multiprocessing backend	count=1
function_arg	loss for classification ||| loss y_true	count=1
function	diagonal model ||| diag	count=1
function	that for c ||| c	count=1
function	then dtype ||| dtype	count=1
function_arg	[function_1] w ||| [arg_2] [function_1]	count=5
function_arg	[function_1] batch_size elements ||| [function_1] n [arg_2]	count=2
function	average of the decision ||| decision	count=1
class	or thread pool ||| backend	count=1
function	approximates the range of ||| range	count=1
class	force the execution ||| memorized	count=1
function	set the sample ||| sample	count=1
class	[class_1] kernel ||| [class_2] [class_1]	count=1
arg	beta-divergence of [arg_2] ||| [arg_2] w h [arg_1]	count=1
function	factorization nmf ||| factorization	count=1
function	random multilabel ||| make multilabel	count=1
function	transform is sometimes referred ||| transform	count=1
class	then return the ||| rfe	count=1
function	[function] all ||| generate [function]	count=1
class	be used for scaling ||| scaler	count=1
function	labels in ||| label	count=1
function	predict ||| predict	count=41
function_arg	[function_1] for x ||| [arg_2] [function_1]	count=10
arg	loader ||| subset data_home	count=1
function	estimates for each input ||| cross val	count=1
arg	matrices from a ||| covariance_type n_components	count=1
arg	batch_size elements from 0 ||| batch_size	count=1
arg	function func with arguments ||| func	count=1
function	[function_1] names ||| [function_1] [function_2]	count=2
function	of the log of ||| log	count=1
function	skip test ||| check skip	count=1
module	to retrieve a reliable ||| externals joblib	count=1
function	log-likelihood of a gaussian ||| score	count=1
function	np arange(n_samples) ||| permutation	count=1
function	[function] the ||| get [function]	count=6
function_arg	[function_1] squared ||| [arg_2] [function_1]	count=1
function	create all the covariance ||| match covariance	count=1
function	lars path parameters ||| path	count=1
module	getter for ||| covariance	count=1
class	list of exception types ||| backend base	count=1
function	path with coordinate descent ||| enet path	count=1
function	likelihood [function_2] ||| [function_2] [function_1]	count=5
function	log probability for ||| log	count=1
function_arg	[function_1] the laplacian ||| [function_1] [arg_2]	count=3
module	is ||| externals joblib	count=1
function_arg	[function_1] y_prob ||| metrics [function_1] predictions y_true [arg_2]	count=1
arg	[arg_1] dimensions ||| [arg_2] [arg_1]	count=1
function	[function_1] from ||| [function_2] [function_1]	count=3
function	corresponding to test sets ||| iter test	count=1
arg	rows of u ||| u	count=1
function	and cluster ||| and cluster	count=2
module	or thread ||| externals	count=1
function	reduced [function_2] ||| [function_1] [function_2]	count=2
class	the scaler ||| max abs scaler	count=1
function_arg	[function_1] and class ||| [function_1] [arg_2]	count=2
function	path with ||| path	count=1
arg	elastic net parameter search ||| l1_ratio	count=1
function	the paired [function_2] ||| [function_1] [function_2]	count=3
arg	random_state and ||| random_state	count=1
module	to run ||| externals joblib	count=1
function	elastic net path ||| enet path	count=1
arg	to the data x ||| x y	count=1
function	blobs ||| blobs	count=1
arg	to x return ||| x	count=1
arg	x as a ||| x	count=1
function_arg	truncated [arg_2] ||| [function_1] [arg_2]	count=2
function	kl divergence of ||| kl divergence	count=2
function	[function] pixel-to-pixel connections ||| [function]	count=1
function	[function_1] predict ||| [function_2] [function_1]	count=2
module	depending from ||| externals joblib	count=2
module	return the number ||| externals joblib	count=3
function	platform independent ||| repr	count=1
function	fit the model with ||| fit	count=3
arg	to a ||| a	count=1
arg	k [arg] ||| [arg]	count=1
function	squared logarithmic ||| squared	count=1
arg	[arg_1] isotropic gaussian ||| [arg_2] [arg_1]	count=1
function	sparse matrix ||| sparse	count=1
function	[function_1] weiszfeld step ||| [function_2] [function_1]	count=1
function	l1 distances between the ||| manhattan distances	count=1
module	test ||| core	count=6
module_class	[module_1] the file ||| [module_1] [class_2]	count=2
class	for each class ||| classifier	count=1
arg	given parameter ||| parameter	count=1
function	multinomial ||| multinomial	count=2
arg	input data ||| x	count=1
class	depending from ||| memory	count=1
function	[function_1] back to ||| [function_2] [function_1]	count=2
arg	an arbitrary python object ||| filename	count=1
class	the position ||| mds	count=1
function	is the depth ||| check previous func code	count=1
function	independent representation of ||| shape	count=1
arg	matrices w h whose ||| w h n_components	count=1
function	multilabel [function_2] ||| [function_2] [function_1]	count=2
module	don't ||| externals	count=2
arg	persist [arg_2] ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] is the ||| [arg_2] [function_1]	count=1
module	cluster ||| cluster	count=3
class	outlier [class_2] ||| [class_2] [class_1]	count=2
function	repr ||| safe repr	count=1
arg	negative value in ||| whom	count=1
function_arg	perplexity [arg_2] ||| [function_1] [arg_2]	count=1
arg	[arg_1] note this ||| [arg_2] [arg_1]	count=2
function_arg	[function_1] [arg_2] ||| [function_1] distances [arg_2]	count=5
arg	operation is meant ||| data_folder_path slice_ color resize	count=1
module_class	[module_1] vectors ||| [module_1] [class_2]	count=10
class	a decision ||| decision	count=1
class	the scaling ||| scaler	count=1
arg	is inefficient to ||| classes	count=1
arg	the data in the ||| data compress	count=1
function	[function_1] cluster the ||| [function_2] [function_1]	count=1
function_arg	[function_1] x using ||| [arg_2] [function_1]	count=1
function	range of ||| randomized range	count=1
arg	multi-class labels parameters ||| threshold	count=1
function	reconfigure ||| configure	count=1
module	avoid the hash ||| externals joblib	count=2
function	pairwise matrix in ||| parallel pairwise	count=1
function_arg	[function_1] validity of ||| [arg_2] [function_1]	count=1
arg	with stochastic gradient descent ||| y coef_init intercept_init	count=1
function_arg	[function_1] of this ||| [arg_2] [function_1]	count=4
arg	to n ||| n	count=1
function	number of [function_2] ||| [function_1] [function_2]	count=1
function	the curve auc using ||| auc	count=1
function	init ||| validate shuffle split init	count=1
function	and dispatch them ||| dispatch	count=1
function	for the one-vs-one ||| one vs one	count=1
arg	apply transforms and ||| x	count=1
arg	w to minimize ||| w ht l1_reg	count=1
function	create all the covariance ||| covariance	count=1
class	the fastmcd algorithm ||| cov	count=1
arg	unpickler ||| unpickler	count=1
class	points in the grid ||| parameter grid	count=1
module	process ||| joblib	count=1
function_arg	text files [arg_2] ||| [function_1] [arg_2]	count=1
arg	after the other and ||| x y	count=1
function	check validity ||| check params	count=2
function	[function_1] update ||| [function_1] [function_2]	count=2
class	[class_1] model ||| [class_1] [class_2]	count=1
function	the long ||| repr	count=1
function	folder ||| folder	count=2
arg	any axis center to ||| x axis	count=2
function	ledoit-wolf ||| ledoit wolf shrinkage	count=2
function	modified weiszfeld step ||| modified weiszfeld step	count=3
arg	[arg_1] of x ||| [arg_2] w h [arg_1]	count=3
function	this ||| params	count=3
class	raw minimum ||| min	count=1
function	to partition [function_2] ||| [function_1] [function_2]	count=1
function	[function_1] estimators within ||| [function_2] [function_1]	count=1
function	the reduced ||| reduced	count=2
function_arg	a buffered [arg_2] ||| [arg_2] [function_1]	count=3
function	mutual [function_2] ||| [function_1] [function_2]	count=2
function	rand index adjusted ||| adjusted rand score	count=1
function	[function_1] number ||| [function_2] [function_1]	count=1
function	update terminal [function_2] ||| [function_2] [function_1]	count=1
arg	x [arg_2] ||| metrics additive chi2 kernel [arg_1] [arg_2]	count=1
arg	regression ||| y_pred	count=1
function_arg	[function_1] data x ||| [function_1] [arg_2]	count=1
arg	classification ||| y_true y_pred labels sample_weight	count=1
class	of exception ||| parallel	count=1
function	covariance matrix [function_2] ||| [function_2] [function_1]	count=8
function	probabilities for ||| proba	count=4
module	the ||| covariance	count=1
function	non-negative matrix factorization nmf ||| negative factorization	count=1
arg	x parameters ||| x n_neighbors reg n_jobs	count=1
function	divergence of p_ijs ||| divergence	count=1
function	the 20 newsgroups ||| 20newsgroups	count=1
module	[module_1] reliable ||| [module_1] [module_2]	count=8
function_arg	covariance [arg_2] ||| [function_1] type tied_cv [arg_2]	count=3
function	pairwise matrix ||| pairwise	count=1
function	should contain a partial ||| partial	count=1
function	people ||| people	count=1
function	exception types ||| get	count=1
function	platform independent ||| shape	count=1
class	return whether the file ||| binary zlib file	count=2
function	[function_1] graph ||| [function_1] kneighbors [function_2]	count=3
arg	the lrd ||| distances_x neighbors_indices	count=1
class	[class_1] grid ||| [class_1] [class_2]	count=2
function	variance regression score function ||| variance	count=1
function_arg	regression [arg_2] ||| [function_1] n_samples n_features [arg_2]	count=1
function	truncated ||| truncated	count=1
function	a read file object ||| read file	count=1
class	of the mixture parameters ||| bayesian gaussian mixture	count=1
arg	training set x ||| x	count=1
class	outlier on ||| outlier	count=1
arg	random_state and sets ||| random_state	count=1
function	posterior probability of data ||| proba	count=1
function_arg	validation of [arg_2] ||| [arg_2] [function_1]	count=1
class	exception ||| backend base	count=2
function	pipeline ||| pipeline	count=1
class	the shrunk ||| shrunk	count=1
function	matrix [function_2] ||| [function_2] [function_1]	count=1
function	with ||| get	count=1
arg	image samples in x ||| x	count=1
function	logistic loss and ||| logistic loss and	count=3
module	of [module] vectors ||| [module]	count=1
function	priors from multioutput-multiclass target ||| distribution	count=1
function	error regression ||| error	count=3
function	the query ||| query	count=1
module_class	[module_1] polynomial features ||| [module_1] [class_2]	count=2
function_arg	[function_1] and q_ijs ||| [arg_2] [function_1]	count=8
class	mlp ||| multilayer perceptron	count=1
arg	data to vectors ||| data vectors n_clusters	count=2
arg	of y ||| y	count=1
function_arg	[function_1] data x ||| [function_1] precomp distr [arg_2]	count=1
class	can be different from ||| calibrated classifier cv	count=1
class	the local [class_2] ||| [class_2] [class_1]	count=3
arg	input ||| estimator	count=1
function	the gradient of loss ||| loss	count=1
class	of patch ||| patch extractor	count=1
function	from the [function_2] ||| [function_1] [function_2]	count=4
arg	famous people ||| funneled resize	count=1
arg	class or regression value ||| check_input	count=1
function	compute class covariance ||| class cov	count=2
function	[function_1] [function_2] ||| [function_1] kneighbors [function_2]	count=12
function	of transform ||| transform	count=1
function	an 'l' ||| repr	count=1
arg	min_value ||| min_value	count=1
function	check according to ||| check	count=1
arg	for each input data ||| y	count=1
arg	[arg_1] y ||| fit [arg_1] [arg_2]	count=1
function	the rcv1 multilabel ||| rcv1	count=1
function	the kl divergence ||| kl divergence	count=2
module	a cluster ||| metrics cluster	count=1
function	[function_1] [function_2] line information from the ||| [function_1] [function_2] line func_code	count=1
arg	returns first [arg] left ||| [arg]	count=1
function	one-vs-one ||| ovo	count=1
class	to ||| backend	count=1
arg	cross-validated estimates for ||| x y cv	count=1
function	verbose message on ||| verbose msg init	count=4
arg	using x as ||| x	count=2
function	sizes ||| sizes	count=1
module	with joblib dump ||| externals joblib	count=1
function	covariance with ||| covariance	count=2
function	'l' suffix when ||| shape	count=1
function	reproducibility flips [function_2] ||| [function_1] [function_2]	count=3
class	opposite of the local ||| local	count=1
class	least ||| least	count=1
class	a sparse ||| sparse	count=1
arg	data and parameters ||| x y	count=5
arg	finds ||| x n_neighbors return_distance	count=1
class	search ||| base search	count=1
arg	random_state and sets them ||| random_state	count=1
class	predict ||| base decision tree	count=1
arg	and scaling parameters ||| y	count=1
arg	parameters ||| compute_sources	count=1
arg	perform ||| x responsibilities params min_covar	count=1
function	importances the ||| importances	count=2
function	the maximizer [function_2] ||| [function_1] [function_2]	count=3
arg	data set with self ||| x_test	count=1
class	process ||| process	count=2
module	to avoid the hash ||| externals	count=2
function	[function_1] mutual information ||| [function_1] [function_2]	count=1
class	scaler ||| max abs scaler	count=1
function	the callable case for ||| pairwise callable	count=1
function	names and a name ||| name	count=1
function_arg	[function_1] svd ||| [function_1] [arg_2]	count=5
arg	of the given data ||| y	count=1
function_arg	update for [arg_2] ||| [function_1] [arg_2]	count=1
function	evaluates the reduced ||| reduced	count=1
class	matrix ||| mixin	count=1
function	ovr [function_2] ||| [function_1] [function_2]	count=2
arg	and binary classification ||| y	count=1
function_arg	[function_1] matrices ||| [arg_2] [function_1]	count=6
function	modified weiszfeld ||| modified weiszfeld	count=2
function	predict_log_proba on the estimator ||| predict log proba	count=1
arg	samples in x into ||| x	count=1
function	absolute error [function_2] ||| [function_2] [function_1]	count=9
function	the number of patches ||| n patches	count=1
class	multi-class targets using ||| output code	count=1
class	parameters for the voting ||| voting	count=1
arg	parameter weights and ||| x y	count=1
function	that for c in ||| c	count=1
class	matrix to ||| sparse	count=1
function_arg	[function_1] keep ||| [arg_2] [function_1]	count=2
function	a sparse ||| make sparse	count=2
function	[function_1] housing ||| [function_1] [function_2]	count=3
function	sizes of ||| sizes	count=1
arg	[arg_1] <mean_absolute_error> ||| [arg_1] [arg_2]	count=2
function	using ||| shape	count=1
arg	x to the ||| x	count=2
function	type introduces ||| repr	count=1
class	[class] for ||| radius neighbors [class]	count=1
function	compute mean and ||| mean	count=1
function	the c [function_2] ||| [function_2] [function_1]	count=3
function	under the ||| score	count=1
function	report showing ||| report	count=1
function	[function_1] [function_2] ||| [function_1] mstep [function_2]	count=8
function	shortest ||| single source shortest	count=1
class	trained ||| multilayer perceptron	count=1
arg	[arg_1] multi-outputs ||| [arg_1] l1_ratio [arg_2]	count=4
function	boolean masks ||| masks	count=1
class	fit ||| linear svc	count=1
function	grid of [function_2] ||| [function_2] [function_1]	count=2
function	return the shortest path ||| single source shortest path	count=1
class	convert coefficient matrix ||| coef	count=1
function	cache folders ||| reduce	count=1
arg	arbitrary python object into ||| filename	count=1
class	getter ||| covariance	count=1
function	log of probability estimates ||| log proba	count=2
function	of probability estimates ||| proba	count=2
module	suffix ||| utils	count=1
arg	transform ||| x transform	count=1
arg	[arg_1] transformed data ||| [arg_2] [arg_1]	count=6
arg	0 to n ||| n	count=1
class	exception types to ||| backend	count=1
function	function the objective ||| objective	count=1
arg	the kernel k x ||| x	count=4
function	log of [function_2] ||| [function_2] [function_1]	count=2
function	minimum and maximum ||| min max axis	count=3
function	on training ||| fit	count=2
function	to build from ||| build from	count=2
function	sample ||| sample	count=4
function_arg	[function_1] x for ||| [function_1] spherical [arg_2]	count=1
function	reproducibility flips ||| deterministic vector	count=1
arg	columns of ||| x columns	count=1
function	generator to create ||| gen	count=1
function	[function_1] error regression ||| [function_2] [function_1]	count=4
function	of transform is ||| transform	count=1
function	the decision functions of ||| decision function	count=1
function	computes the barycenter ||| barycenter	count=1
function	[function_1] gradient ||| [function_1] [function_2]	count=9
function	graph of neighbors for ||| radius neighbors graph	count=2
class	to ||| memory	count=2
function	maximizer [function_2] ||| [function_2] [function_1]	count=3
function	estimate sample weights by ||| compute sample	count=1
function	each input data ||| val predict	count=1
function	aligned ||| aligned	count=1
class	whether the [class_2] ||| [class_2] [class_1]	count=1
arg	the data onto the ||| ridge_alpha	count=1
function	optimal ||| compute	count=1
arg	of u such ||| u	count=1
class	we don't ||| memorized	count=1
function	print verbose message on ||| print verbose msg init	count=2
class	parallel processing ||| parallel	count=1
function	fit for one mini-batch ||| fit	count=1
arg	for ||| estimator x y	count=1
arg	the model using x ||| x	count=4
function	squared [function_2] ||| [function_2] [function_1]	count=1
function	returns the score on ||| score	count=1
function	covariance m [function_2] ||| [function_2] [function_1]	count=2
function	matrix [function_2] ||| [function_1] [function_2]	count=1
function	is not found ||| search	count=1
arg	w ||| x w ht l1_reg	count=1
arg	batch_size elements [arg_2] ||| [arg_2] [arg_1]	count=2
function	graph of the ||| grid to graph	count=1
function	paired cosine ||| paired cosine	count=2
arg	generate ||| n_samples n_features n_classes	count=1
function	query ||| query	count=1
function	platform independent representation of ||| shape	count=1
arg	from source to all ||| source	count=1
class	center ||| robust	count=1
function_arg	kddcup99 dataset [arg_2] ||| [arg_2] [function_1]	count=3
function_arg	an unfitted [arg_2] ||| [function_1] [arg_2]	count=1
function	compute [function_2] ||| [function_2] [function_1]	count=2
function	for reproducibility flips ||| deterministic vector	count=1
arg	target variable ||| discrete_features	count=2
function_arg	single [arg_2] ||| [arg_2] [function_1]	count=1
function	precisions parameters ||| precisions	count=1
module	dataset in ||| datasets	count=1
function	estimate [function] parameters with ||| [function]	count=1
function	[function_1] this ||| [function_1] [function_2]	count=3
arg	pair [arg] ||| [arg]	count=1
function	in the wild lfw ||| fetch lfw	count=1
function	compute joint [function_2] ||| [function_1] [function_2]	count=2
arg	a given radius ||| x radius	count=1
function_arg	[function_1] estimator ||| [arg_2] [function_1]	count=19
function	predict_log_proba on ||| predict log proba	count=1
function_arg	files [arg_2] ||| [function_1] [arg_2]	count=1
function	assignment problem using ||| assignment	count=1
arg	a given dataset split ||| x y scorer	count=1
arg	voxels [arg] connected ||| n_x n_y n_z [arg]	count=1
arg	the gradient and the ||| w x y	count=2
function	the free energy f ||| free energy	count=1
function	for species ||| species	count=1
function	[function_1] linear embedding ||| [function_1] [function_2]	count=3
function_arg	[function_1] [arg_2] ||| utils [function_1] slices [arg_2]	count=1
function	test indices ||| indices	count=1
function	path with coordinate ||| path	count=1
module	remove ||| externals	count=1
arg	target variable ||| y discrete_features	count=2
function_arg	[function_1] [arg_2] ||| [function_1] predict [arg_2]	count=5
class	we don't store the ||| memorized func	count=1
arg	x (as ||| x	count=1
function_arg	[function_1] [arg_2] ||| [function_1] read file [arg_2]	count=6
class	as a sparse ||| sparse	count=1
class	process [class_2] ||| [class_1] [class_2]	count=4
function	error between ||| error	count=1
function	of feature [function_2] ||| [function_1] [function_2]	count=1
function	terminal regions to ||| terminal region	count=1
function	diagonal ||| diag	count=8
module	return the ||| externals	count=1
function	mean absolute ||| mean absolute	count=2
class	the best found ||| search cv	count=8
class	model ||| base pca	count=2
arg	for validation ||| directed dtype	count=1
function	rcv1 multilabel ||| rcv1	count=1
function	paired [function_2] ||| [function_1] [function_2]	count=3
arg	model according to ||| y sample_weight	count=2
function	compute class [function_2] ||| [function_1] [function_2]	count=2
module_class	[module_1] for scaling ||| [module_1] [class_2]	count=1
module	the hash ||| joblib	count=2
function_arg	[function_1] call ||| [arg_2] [function_1]	count=1
function	reduced ||| reduced	count=2
class	exception types ||| parallel backend	count=1
arg	of the laplacian matrix ||| laplacian	count=1
class	product with the ||| projection	count=1
function	memmap [function_2] ||| [function_1] [function_2]	count=1
function	number of estimators ||| len	count=1
arg	with categories ||| categories load_content	count=1
arg	and validate 'train_sizes' ||| train_sizes n_max_training_samples	count=1
module_class	to [class_2] ||| [module_1] robust [class_2]	count=1
arg	data point ||| estimator	count=1
function	finds seeds for ||| get bin seeds	count=1
function_arg	of loss [arg_2] ||| [function_1] layer [arg_2]	count=3
arg	to pickler file ||| pickler	count=1
function	files with ||| files	count=1
arg	ensemble to [arg] return ||| [arg]	count=2
function	be captured ||| exceptions	count=1
arg	[arg_1] y as ||| [arg_1] [arg_2]	count=4
function	contains valid ||| probabilistic predictions	count=1
class	to the cache for ||| memorized func	count=1
function_arg	[function_1] filename ||| [arg_2] [function_1]	count=4
function	boost using ||| boost	count=1
function	[function_1] number of ||| [function_2] [function_1]	count=2
arg	learn a nmf [arg_1] [arg_2] ||| [arg_1] [arg_2]	count=8
arg	for data x ||| x doc_topic_distr sub_sampling	count=1
arg	is the ||| y_true y_pred	count=1
arg	y ||| y max_samples max_depth	count=1
function_arg	[function_1] from sklearn ||| [arg_2] [function_1]	count=2
function_arg	is [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
function	single ||| build trees	count=1
function	sparse [function_2] ||| [function_1] [function_2]	count=1
function	the objective ||| objective	count=1
class	hash ||| memory	count=1
arg	prediction ||| y sample_weight	count=1
arg	loss ||| loss	count=1
function	terminal regions ||| terminal regions	count=2
module	with the ||| decomposition	count=1
arg	[arg_1] x ||| [arg_2] y [arg_1]	count=2
function	[function_1] batch size ||| [function_1] [function_2]	count=1
arg	compute ||| x y	count=1
arg	[arg_1] edges weighted ||| [arg_2] [arg_1]	count=2
arg	and [arg_2] ||| [arg_1] l1_ratio [arg_2]	count=1
function	perform mean ||| mean	count=1
arg	a biclustering for x ||| x	count=1
arg	matching pursuit ||| x y n_nonzero_coefs	count=1
arg	sample from [arg_2] ||| [arg_2] [arg_1]	count=2
module	and return ||| externals	count=1
function	input data point ||| cross val predict	count=1
function	the directory ||| dir	count=1
arg	x from y along ||| x	count=1
class	convert ||| mixin	count=1
class	density model ||| density	count=1
arg	x x ||| x	count=8
arg	in the given file ||| compress	count=1
arg	x and ||| x y	count=5
module	thread pool ||| externals	count=1
module_class	with the [class_2] ||| [module_1] [class_2]	count=4
function	[function_1] kernel ||| [function_2] [function_1]	count=3
function	absolute ||| absolute	count=2
class	hide warnings ||| warnings	count=1
function	subsets incrementally ||| incremental	count=1
module	with joblib ||| externals joblib	count=1
arg	the percentiles of ||| percentiles grid_resolution	count=1
function	objective function the objective ||| objective	count=1
arg	the provided ||| n_components	count=1
function	gaussian [function_2] ||| [function_1] [function_2]	count=1
arg	n_jobs even ||| y func n_jobs	count=1
arg	mcd from ||| x n_support	count=1
arg	conversion of [arg_2] ||| [arg_2] [arg_1]	count=1
arg	transform [arg] to ||| [arg]	count=1
arg	with categories ||| categories	count=1
arg	for mean_shift ||| bin_size min_bin_freq	count=1
arg	and q_ijs ||| params p neighbors degrees_of_freedom	count=1
function_arg	loads data [arg_2] ||| [function_1] [arg_2]	count=1
function	opening the right fileobject ||| fileobject	count=1
function	process or thread pool ||| backend	count=1
arg	transforms and ||| x	count=1
module	under a size ||| externals	count=1
arg	pickler ||| pickler	count=1
function	unfitted ||| unfitted	count=1
arg	using x as training ||| x skip_num_points	count=1
function	of biclusters ||| consensus	count=1
function	matrix to dense array ||| densify	count=1
class	mlp loss function ||| multilayer perceptron	count=1
function	the paired [function_2] ||| [function_2] [function_1]	count=3
function	the covertype ||| covtype	count=1
function	binary classifier ||| binary	count=1
function	by scaling each feature ||| scale	count=1
function	the leaves of ||| leaves	count=1
function	[function_1] probabilities of ||| [function_1] [function_2]	count=2
arg	validate the provided ||| n_components	count=1
function	[function_1] function for ||| [function_2] [function_1]	count=5
arg	array [arg_2] ||| [arg_2] [arg_1]	count=1
class	the density model ||| density	count=1
module	store ||| joblib	count=2
module	the ||| mixture	count=11
arg	estimates for each ||| estimator	count=1
function	minimum and maximum ||| min max	count=1
function	boost ||| boost	count=3
function	parameters ||| random	count=1
function	build [function_2] ||| [function_1] [function_2]	count=6
function	the leaves of the ||| leaves	count=1
function	returns the huber ||| huber	count=1
module	array [module] unique ||| [module]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] transform [arg_2]	count=17
function	[function_1] validity of ||| [function_2] [function_1]	count=1
arg	org data set ||| dataname target_name data_name transpose_data	count=1
arg	and concatenate results ||| y	count=1
function	sizes of ||| translate train sizes	count=1
class	getter ||| empirical covariance	count=2
function	type introduces an 'l' ||| repr	count=1
function	[function_1] 20 newsgroups ||| [function_2] [function_1]	count=1
function_arg	[function_1] of compute_labels ||| [arg_2] [function_1]	count=1
module	of exception types to ||| joblib	count=1
arg	nmf ||| h beta_loss	count=1
arg	using the gp prior ||| return_std return_cov	count=1
function_arg	checkerboard [arg_2] ||| [arg_2] [function_1]	count=3
function	a mostly low ||| make low	count=1
class	the hash ||| memory	count=1
module	estimates for each input ||| core	count=1
function	a partial ||| partial	count=1
function_arg	estimators [arg_2] ||| [arg_2] [function_1]	count=2
function	a binary ||| average binary	count=1
function	each input data ||| val	count=1
function	parameters are well defined ||| parameters	count=2
function	multilabel [function_2] ||| [function_1] [function_2]	count=2
function	initialization ||| initialize	count=3
arg	learn vocabulary and idf ||| raw_documents y	count=1
function	time ||| time	count=1
arg	the binary ||| y_score average	count=1
function	estimate class weights for ||| compute class	count=1
class	multi-class targets ||| output code classifier	count=1
function_arg	[function_1] given radius ||| [arg_2] [function_1]	count=2
function_arg	[function_1] dictionary ||| [arg_2] [function_1]	count=1
function	the data ||| clear data	count=1
function	perform affinity ||| affinity	count=1
function	estimates for ||| cross	count=1
arg	by a random ||| n_samples	count=1
module	compute ||| metrics	count=1
function	loss and the gradient ||| loss and gradient	count=1
function	coverage file from ||| coverage	count=1
arg	with n_zeros additional zeros ||| n_zeros	count=1
function	multilabel classification ||| multilabel classification	count=1
module	metrics read ||| metrics	count=1
module_class	to polynomial features ||| preprocessing polynomial features	count=1
arg	given test ||| y_test scorer	count=4
module	relationship between labels ||| metrics cluster	count=2
function_arg	compressor matching [arg_2] ||| [function_1] [arg_2]	count=1
arg	and smooth feature occurrences ||| y	count=2
arg	x y as ||| x y xy	count=3
function	covariance matrix shrunk on ||| shrunk covariance	count=1
function	[function] of ||| [function]	count=4
function	prediction of init ||| init decision function	count=1
function_arg	fit estimator [arg_2] ||| [arg_2] [function_1]	count=1
function	the directory in ||| get output dir	count=1
function	compute log [function_2] ||| [function_1] [function_2]	count=2
arg	and conversion of ||| csr_output	count=1
module	model parameters ||| linear_model	count=2
function_arg	and predict [arg_2] ||| [function_1] estimator [arg_2]	count=8
arg	in n_jobs even ||| y func n_jobs	count=1
class	kernel [class_2] ||| [class_2] [class_1]	count=10
arg	points in ||| n_neighbors mode	count=1
function	in svmlight ||| svmlight	count=1
arg	and return ||| y	count=3
module	with the ||| mixture	count=1
function	or jaccard [function] coefficient defined ||| jaccard [function]	count=1
arg	discrete target variable ||| y discrete_features n_neighbors	count=1
function	array-like or scipy sparse ||| binarize	count=1
function	pairwise matrix ||| parallel pairwise	count=1
function_arg	[function_1] set x ||| [function_1] [arg_2]	count=12
class	[class_1] [class_2] ||| [class_1] [class_2]	count=280
arg	update h ||| w h beta_loss	count=1
function	used by parallel ||| parallel	count=1
function	batch [function_2] ||| [function_2] [function_1]	count=2
function	compute log probabilities within ||| parallel predict log proba	count=1
class	don't ||| memorized func	count=1
arg	restricted to the binary ||| y_score average	count=1
function	fit is on grid ||| fit	count=1
function_arg	people dataset [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] and gradient ||| [function_2] [function_1]	count=3
function	[function_1] curve ||| [function_2] [function_1]	count=4
function	scores note ||| roc	count=1
function	gaussian [function_2] ||| [function_2] [function_1]	count=1
function	[function_1] absolute ||| [function_1] [function_2]	count=2
arg	writes an [arg] into ||| [arg]	count=1
function	compute incremental mean ||| incr mean	count=1
module	hash depending from it ||| joblib	count=2
class	generative ||| base	count=1
arg	x ||| x n_neighbors reg n_jobs	count=1
module	we don't ||| externals	count=2
class	determine [class_2] ||| [class_2] [class_1]	count=1
function	and transform with the ||| transform	count=1
arg	this operation is meant ||| data_folder_path slice_ color resize	count=1
function_arg	a buffered [arg_2] ||| [function_1] read file [arg_2]	count=3
arg	other and transforms ||| x y	count=1
function	_fit_coordinate_descent update ||| update	count=1
arg	[arg_1] and y ||| [arg_1] [arg_2]	count=23
arg	connectivity matrix ||| connectivity n_components affinity	count=1
function	feature [function_2] ||| [function_1] [function_2]	count=5
arg	categories as subfolder names ||| container_path description categories	count=1
class	to ||| coef mixin	count=1
function	reconstruct the [function_2] ||| [function_1] [function_2]	count=3
function	predict ||| labels predict	count=1
arg	train_size ||| train_size	count=1
module	the ||| externals	count=5
arg	that x ||| x	count=1
function_arg	[function_1] of parameters ||| [function_1] [arg_2]	count=2
function	average path [function_2] ||| [function_1] [function_2]	count=2
function	introduces an 'l' ||| shape	count=1
function	[function_1] the iris ||| [function_2] [function_1]	count=1
module	execution ||| externals joblib	count=1
function	log of the ||| log	count=1
function	input data point ||| predict	count=1
function	connected ||| connected	count=1
function	input data point ||| val	count=1
arg	length dimensions ||| dimensions rng	count=1
function_arg	on [arg_2] ||| [function_1] [arg_2]	count=7
class	file ||| zlib file	count=3
class	coefficient matrix ||| sparse coef	count=1
class	trained model parameters ||| base multilayer perceptron	count=1
function	[function_1] variance regression ||| [function_1] [function_2]	count=1
function_arg	score [arg_2] ||| [function_1] [arg_2]	count=2
function	return feature names ||| get feature names	count=3
function	measure the similarity ||| fowlkes mallows	count=1
arg	model using x ||| x	count=4
function	call transform on the ||| transform	count=1
function	the ||| shape repr	count=2
function	neighbors within ||| radius neighbors	count=1
arg	[arg] is ||| [arg]	count=2
class	with the generative model ||| base	count=1
function_arg	backend [arg_2] ||| [arg_2] [function_1]	count=1
function_arg	[function_1] x y ||| bagging [function_1] [arg_2]	count=8
function_arg	[function_1] using x ||| [arg_2] [function_1]	count=3
module	coefficient matrix to ||| linear_model	count=1
class	the search ||| search	count=1
arg	of x [arg_2] ||| [arg_1] [arg_2]	count=3
arg	significance of a cross-validated ||| cv	count=1
arg	the descriptors of a ||| a	count=1
function	c and ||| c and	count=2
function	the logistic loss and ||| logistic loss and	count=1
arg	and a set ||| x y axis	count=1
arg	prediction ||| sample_weight	count=1
function_arg	[function_1] 1 iteration ||| [arg_2] [function_1]	count=2
class	search over parameters ||| search	count=1
class	coefficient ||| mixin	count=1
function	each input data ||| predict	count=1
function	multilabel ||| multilabel	count=1
function	linear [function_2] ||| [function_2] [function_1]	count=6
function	locally [function_2] ||| [function_1] [function_2]	count=5
function	generative ||| get	count=1
class	the backend and ||| parallel backend base	count=1
function	update the ||| update dict	count=1
arg	parameters ||| y estimator parameters	count=2
arg	column class distributions ||| classes class_probability	count=1
arg	and y ||| y dense_output	count=1
arg	mean_shift ||| bin_size min_bin_freq	count=1
function	fit linear ||| fit	count=5
function	prediction scores note ||| roc	count=1
class	project ||| spectral biclustering	count=1
function	error of ||| error	count=1
function	[function] the ensemble ||| [function]	count=1
function_arg	slices containing [arg_2] ||| [function_1] n [arg_2]	count=4
function	with sparse [function_2] ||| [function_2] [function_1]	count=1
class	[class_1] squares ||| [class_2] [class_1]	count=1
class	arguments ||| func	count=1
function_arg	parallel backend [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] density ||| [function_1] [function_2]	count=1
function	[function_1] and variance ||| [function_1] [function_2]	count=5
function	'l' ||| shape	count=1
function	mean and variance ||| mean variance	count=5
function	matrix factorization ||| negative factorization	count=1
function	[function_1] images ||| [function_2] [function_1]	count=2
function_arg	[function_1] between x ||| [function_1] [arg_2]	count=4
function	reachability [function] ||| local reachability [function]	count=2
function_arg	determine the number of [function_1] [arg_2] ||| n [function_1] [arg_2]	count=1
function	single ||| trees	count=1
function	mean update and ||| mean	count=1
function	reduced likelihood [function_2] ||| [function_1] [function_2]	count=5
arg	based on ||| connectivity n_clusters	count=1
function	callable case for ||| callable	count=1
arg	does not need ||| x y residual	count=1
arg	in n_jobs even ||| x y func n_jobs	count=1
arg	u such ||| u	count=1
class	write ||| numpy array wrapper	count=1
function_arg	[function_1] between jobs ||| [function_1] [arg_2]	count=5
module	if ||| utils	count=3
module	we don't store the ||| externals joblib	count=2
arg	random n-class ||| n_informative n_redundant	count=1
function	[function_1] feature names ||| [function_1] [function_2]	count=1
arg	the data and concatenate ||| x y	count=1
arg	matching pursuit problems ||| n_nonzero_coefs tol	count=1
function	functions of the base ||| function	count=1
arg	returns [arg_2] ||| [arg_2] [arg_1]	count=2
arg	dictionary ||| dictionary y	count=1
arg	euclidean norm of x ||| x	count=1
function	of the kl ||| kl	count=1
module	type introduces ||| utils	count=1
function	and cluster the result ||| and cluster	count=1
class	for ||| empirical	count=1
module	a size limit ||| externals	count=1
function_arg	[function_1] [arg_2] ||| [function_1] called str function_name [arg_2]	count=1
function	in multiplicative update ||| multiplicative update	count=2
function	the l1 ||| paired manhattan	count=1
arg	to multi-class ||| y threshold	count=1
function	pairs ||| pairs	count=2
module	to run in parallel ||| joblib	count=1
arg	generate ||| n_samples n_components n_features n_nonzero_coefs	count=1
class	a minimum ||| min	count=1
function	time [function_2] ||| [function_2] [function_1]	count=2
arg	from features ||| sample_weight	count=1
arg	negative value in x ||| x whom	count=1
function	terminal regions to ||| terminal	count=1
function	initialize ||| initialize	count=1
function	path [function_2] ||| [function_2] [function_1]	count=3
class	with all ||| search cv	count=1
arg	of parameters ||| estimator parameters	count=2
arg	<affinity_propagation> ||| s preference convergence_iter max_iter	count=1
arg	w to minimize ||| x w	count=1
function	[function_1] clustering for ||| [function_2] [function_1]	count=1
class	the process or thread ||| multiprocessing backend	count=1
function	format check ||| check	count=1
function_arg	[function_1] [arg_2] and ||| [function_1] [arg_2] y	count=2
function	retrieve the leaves ||| get leaves	count=1
function	the smacof ||| smacof	count=1
function	[function_1] [function_2] ||| [function_2] [function_1]	count=348
function	[function_1] gradient ||| [function_2] [function_1]	count=9
arg	for validation and ||| directed dtype	count=1
arg	for validation and conversion ||| directed dtype csr_output	count=1
function	precision matrix with ||| precision	count=1
arg	classification ||| y_true	count=8
function	a name ||| name	count=1
arg	decisions within a job ||| estimators_features x	count=1
arg	to ||| weights	count=1
class	to avoid the hash ||| memorized func	count=1
arg	x ||| x y iter_offset	count=1
class	[class_1] the file ||| [class_2] [class_1]	count=1
function	species ||| species	count=1
function	fit the rfe model ||| fit	count=1
class	wrapper ||| wrapper	count=1
function	eval ||| eval	count=1
function	the california [function_2] ||| [function_1] [function_2]	count=4
arg	input ||| x y	count=1
arg	iterable [arg] to ||| [arg]	count=1
function	independent ||| shape repr	count=1
function	normalize rows and columns ||| normalize	count=1
function	dtype ||| dtype	count=1
arg	of x according to ||| x	count=1
function	[function_1] indicating which ||| [function_2] [function_1]	count=4
function	check that the ||| check	count=1
arg	[arg_1] [arg_2] ||| [arg_2] w h [arg_1]	count=6
function	randomized [function_2] ||| [function_1] [function_2]	count=2
arg	of data [arg_2] ||| [arg_2] [arg_1]	count=1
arg	x from y ||| x	count=1
arg	a cross-validated ||| x y cv	count=1
function	[function_1] graph ||| [function_2] [function_1]	count=3
class	cache folders to ||| memory	count=1
class	avoid the hash depending ||| memorized	count=1
module	clustering on ||| cluster	count=1
arg	pickler file handle ||| pickler	count=1
arg	mono and [arg_2] ||| [arg_2] [arg_1]	count=1
function	low [function_2] ||| [function_2] [function_1]	count=2
arg	subcluster ||| subcluster new_subcluster1	count=1
function	[function_1] the diagonal ||| [function_1] [function_2]	count=1
function	function of ||| function	count=5
arg	given column class distributions ||| classes class_probability random_state	count=1
function	estimates for each ||| val predict	count=1
function	implement [function] ||| [function]	count=2
function	transform ||| fit transform	count=1
function_arg	[function_1] [arg_2] ||| [function_1] diag [arg_2]	count=3
function	cache ||| reduce	count=1
function	a logistic [function_2] ||| [function_1] [function_2]	count=1
function	patches ||| patches	count=2
class	for ||| boost classifier	count=2
function	in hastie ||| hastie	count=1
arg	given training data and ||| x y	count=1
class	the kernel k ||| white kernel	count=2
arg	gradient and ||| x y	count=2
function	[function] jaccard index ||| jaccard similarity [function]	count=3
arg	to the binary classification ||| y_true y_score pos_label sample_weight	count=1
function_arg	[function_1] from module_path/data/data_file_name ||| [arg_2] [function_1]	count=2
arg	sample from ||| size replace p	count=1
function	[function_1] [function_2] ||| [function_1] ovo [function_2]	count=4
class	hash ||| memorized	count=1
function	and evaluates the reduced ||| reduced	count=1
class	features parameters ||| features	count=1
module	folders ||| joblib	count=1
function	the laplacian [function_2] ||| [function_2] [function_1]	count=2
function	[function] have mean ||| preprocess [function]	count=1
class	check ||| dirichlet allocation	count=1
function	the barycenter [function_2] ||| [function_1] [function_2]	count=1
module	on ||| model_selection	count=1
function	issue #1240 [function] can't be ||| [function]	count=1
function	[function_1] weighted graph ||| [function_2] [function_1]	count=3
function	the directory ||| func dir	count=1
function	local ||| local	count=1
function_arg	parameters for [arg_2] ||| [function_1] [arg_2]	count=1
function	x ||| scale xy	count=1
class	uncompressed bytes ||| binary zlib	count=1
function	path length of ||| path length	count=2
function	for later ||| fit	count=1
function	alpha ||| alpha	count=1
function	and ||| call	count=1
function	clustering for the ||| clustering	count=1
arg	to ||| sample_weight	count=1
arg	in n_jobs even slices ||| x y func n_jobs	count=1
arg	when memory is inefficient ||| y classes	count=1
arg	validity of the ||| metric p metric_params	count=1
arg	transformed ||| h	count=1
arg	of a classification ||| y_true y_pred labels sample_weight	count=1
arg	a job ||| estimators estimators_features x n_classes	count=1
function	[function_1] discrete ||| [function_1] [function_2] iboost x y sample_weight	count=2
function	mostly low ||| make low	count=1
function	incremental mean [function_2] ||| [function_2] [function_1]	count=1
class	voting classifier valid ||| voting classifier	count=2
function	memmap instance ||| memmap	count=1
function	load output ||| load output	count=1
function	for the california housing ||| fetch california housing	count=1
class	and hide warnings ||| warnings	count=1
class	for the voting ||| voting	count=1
arg	persist an [arg_2] ||| [arg_2] [arg_1]	count=4
function_arg	probabilities [arg_2] ||| [function_1] [arg_2]	count=5
function	get the parameters ||| get	count=1
function	parallel [function_2] ||| [function_1] [function_2]	count=1
function	indicating which ||| support	count=1
function	matrix factorization nmf find ||| negative factorization	count=1
function	adjusted for chance ||| adjusted	count=1
function	estimate class ||| class	count=1
arg	clusterings ||| labels_true labels_pred	count=2
function	function ||| decision function	count=1
function	scores this score ||| score	count=1
class	matrix ||| sparse coef mixin	count=1
arg	axis center to the ||| axis	count=2
function_arg	[function_1] w ||| [function_1] x [arg_2]	count=1
function	and ||| divergence	count=1
function_arg	of neighbors [arg_2] ||| [arg_2] [function_1]	count=6
arg	x as ||| x y	count=1
arg	dense dictionary factor in ||| dictionary	count=1
class	list of exception ||| base	count=1
function	a grid of points ||| grid	count=1
function	center ||| center scale	count=1
arg	value of verbose ||| verbose	count=1
function	returns [function] the ||| [function]	count=1
function	[function_1] [function_2] to ||| utils gen [function_2] [function_1]	count=1
module	a ||| utils	count=5
arg	using x y ||| x y sample_weight	count=2
function	rand index adjusted ||| adjusted rand	count=1
class	the cf ||| birch	count=1
function	[function_1] length of ||| [function_1] [function_2]	count=5
function	[function_1] wishart distribution ||| [function_2] [function_1]	count=2
arg	returns n_neighbors of ||| x n_neighbors return_distance	count=1
function	being run on travis ||| travis	count=1
function	load [function_2] ||| [function_2] [function_1]	count=9
class	[class_1] [class_2] ||| [class_2] [class_1]	count=98
function	introduces an 'l' suffix ||| shape repr	count=1
module	a which ||| externals joblib	count=1
arg	array is ||| array	count=1
function	samme [function] algorithm ||| boost [function]	count=1
function	wine ||| wine	count=1
arg	input validation for ||| x y accept_sparse dtype	count=1
module	to retrieve a ||| externals	count=1
arg	meant to ||| data_folder_path slice_ color resize	count=1
function	parallel ||| parallel build	count=1
function	logistic regression ||| logistic regression	count=1
arg	[arg_1] h ||| [arg_1] [arg_2]	count=6
class	multi-class targets using underlying ||| output code classifier	count=1
function	files ||| files	count=2
module	returns cluster ||| cluster	count=1
module	label ||| preprocessing	count=2
arg	actual fitting performing ||| x y parameter_iterable	count=1
module	as a ||| externals	count=1
arg	validation and ||| dtype	count=1
function	[function_1] 1d ||| [function_2] [function_1]	count=1
class	estimator with randomly drawn ||| randomized search cv	count=1
arg	for each ||| estimator	count=1
arg	and a set of ||| y axis	count=1
function_arg	row-wise [arg_2] ||| [function_1] [arg_2]	count=1
arg	for data x ||| x doc_topic_distr	count=1
function	value ||| value	count=1
class	[class_1] encoder ||| [class_2] [class_1]	count=1
function	shrunk on the diagonal ||| shrunk	count=1
arg	a transform ||| x transform	count=1
class	avoid the hash depending ||| memory	count=1
module	the long ||| utils	count=1
function	lfw people ||| lfw people	count=1
function	fit a single ||| trees	count=1
class	of exception ||| backend base	count=1
module	a which this function ||| externals	count=1
arg	w to minimize the ||| w ht	count=1
function_arg	all estimators [arg_2] ||| [function_1] [arg_2]	count=1
arg	perform the ||| x responsibilities	count=1
arg	and concatenate results ||| x y	count=1
arg	generate [arg_2] ||| [arg_2] [arg_1]	count=3
arg	sparse and dense inputs ||| x y sample_weight random_state	count=1
class	types ||| parallel backend	count=1
arg	estimator ||| estimator x y	count=4
function_arg	[function_1] dictionary factor ||| [arg_2] [function_1]	count=1
class	shrunk ||| shrunk	count=1
function	boolean mask indicating which ||| support mask	count=1
arg	x ||| x n_neighbors reg	count=1
class	the [class_2] ||| [class_2] [class_1]	count=4
class	exception types ||| parallel	count=1
arg	mono and [arg_2] ||| [arg_1] l1_ratio [arg_2]	count=1
function	the california housing ||| fetch california housing	count=2
module	compute data ||| decomposition	count=1
arg	svd ||| n_components	count=1
module	it ||| externals joblib	count=4
function	loss and gradient ||| loss and grad	count=3
function	parameters for ||| params	count=1
arg	of length dimensions ||| dimensions rng	count=1
function	to update ||| update	count=1
module	of exception types to ||| externals	count=1
function	mostly low [function_2] ||| [function_2] [function_1]	count=2
arg	and [arg_2] ||| [arg_2] [arg_1]	count=13
class	the ||| base	count=7
class	are going ||| multiprocessing	count=1
function	print verbose [function_2] ||| [function_2] [function_1]	count=3
function	lower bound ||| bound	count=1
class	of the gradient ||| base gradient	count=2
arg	x by ||| x y	count=2
function	mean absolute [function_2] ||| [function_2] [function_1]	count=4
function	to ||| transform	count=3
class	convert coefficient matrix to ||| sparse	count=1
arg	case method='lasso' is ||| x y xy gram	count=1
class	kernel ridge regression ||| kernel ridge	count=2
arg	capture the [arg_2] ||| [arg_2] [arg_1]	count=2
arg	function output for x ||| x	count=1
function_arg	determine the [function_1] [arg_2] ||| [function_1] [arg_2]	count=2
function	indices ||| find matching indices	count=1
arg	is the ||| y_true	count=1
class	exception types to ||| base	count=1
function	remove cache ||| reduce	count=1
function	absolute sizes ||| train sizes	count=1
module	classification on test ||| core	count=1
function	l1 [function_2] ||| [function_1] [function_2]	count=6
arg	matrices from ||| covariance_type n_components	count=1
function	of the log ||| log	count=1
function	[function] line ||| [function]	count=1
function	loss and ||| loss and	count=4
function	wise scale ||| robust scale	count=1
class	or thread pool and ||| multiprocessing backend	count=1
module	introduces an 'l' suffix ||| utils	count=1
function	score the ||| score	count=1
class	the cache for ||| memorized	count=1
class	we ||| memory	count=1
function	lfw pairs ||| fetch lfw pairs	count=4
arg	and scale the data ||| y	count=1
arg	in the given ||| compress	count=1
function	blobs ||| make blobs	count=1
module	to be used ||| preprocessing	count=2
arg	memory is inefficient to ||| y classes	count=1
function	contains valid probabilities ||| probabilistic predictions	count=1
function	sizes of training ||| sizes	count=1
class	local [class_2] ||| [class_1] [class_2]	count=3
class	[class_1] absolute value ||| [class_2] [class_1]	count=6
arg	x y ||| fit x y	count=1
arg	computes ||| y alpha	count=2
function	method for updating terminal ||| terminal	count=1
function	parallel [function_2] ||| [function_2] [function_1]	count=1
module	platform ||| utils	count=1
function_arg	[function_1] x for ||| [function_1] [arg_2]	count=1
function	be captured ||| get exceptions	count=1
function	or [function] numpy array ||| column or [function]	count=1
arg	from a ||| a size replace	count=1
arg	vectors individually to unit ||| copy	count=1
function	scores note this ||| roc	count=1
function	dump ||| dump	count=1
class	em algorithm and return ||| gmmbase	count=1
function	[function_1] diagonal of ||| [function_1] [function_2]	count=1
function_arg	slices containing batch_size ||| batches n batch_size	count=1
arg	generate cross-validated estimates for ||| y cv	count=1
class	determine ||| backend	count=1
arg	standardize a dataset along ||| with_mean with_std	count=1
class	train test ||| base	count=1
arg	accuracy of a classification ||| y_true	count=1
arg	each input data ||| estimator	count=1
function_arg	x [arg_2] ||| decomposition nmf [function_1] x [arg_2]	count=5
function	for ||| cross val predict	count=2
arg	api and ||| x y	count=3
class	test ||| split	count=1
function	type suitable for scipy ||| int	count=1
function	diagonal of the ||| diag	count=5
function	binarize [function_2] ||| [function_2] [function_1]	count=6
function_arg	read [arg_2] ||| [function_1] [arg_2]	count=1
function	[function_1] the kl ||| [function_2] divergence [function_1]	count=3
class	[class_1] the kernel ||| [class_2] [class_1]	count=1
arg	data to vectors ||| data vectors	count=1
module	thread ||| externals	count=1
arg	to [arg_2] ||| [arg_2] [arg_1]	count=4
function	fitted model parameters ||| fit	count=1
function	[function_1] multiclass ||| [function_2] [function_1]	count=1
arg	estimator and ||| x y sample_weight	count=1
function	score of ||| score	count=3
module	matrix ||| cluster	count=1
class	store ||| func	count=1
function	connected graph ||| graph	count=1
arg	matrices w h whose ||| x w h	count=1
class	depending from it ||| memory	count=1
function	transform binary ||| transform	count=1
arg	input validation ||| y accept_sparse dtype	count=1
function	update the dense ||| update	count=1
function	path ||| enet path	count=2
function_arg	kernel [arg_2] ||| [arg_2] [function_1]	count=4
function	feature importances ||| feature importances	count=1
module	to be ||| preprocessing	count=2
function	score with ||| score	count=1
class	check ||| base mixture	count=2
arg	the binary classification ||| y_true	count=2
arg	matrix ||| n_components	count=1
arg	and transforms the ||| y	count=1
function	grid [function_2] ||| [function_1] [function_2]	count=1
class	process ||| multiprocessing	count=1
function_arg	[function_1] given ||| [arg_2] [function_1]	count=2
arg	data ||| x	count=4
function	graph of [function_2] ||| [function_2] [function_1]	count=18
function	of ||| repr	count=1
function	[function_1] absolute ||| [function_2] [function_1]	count=2
function	grid of points ||| grid	count=1
function	the maximizer ||| arg max	count=1
function	the range of ||| range	count=1
arg	remove a subcluster from ||| subcluster new_subcluster1	count=1
function	the generative ||| get	count=1
function	[function_1] embedding analysis ||| [function_2] [function_1]	count=4
function_arg	clustering on [arg_2] ||| [arg_2] [function_1]	count=2
function	randomized ||| randomized	count=1
function	[function] reachability ||| [function] reachability	count=1
function	fit a multi-class classifier ||| fit	count=1
module	object in ||| externals	count=1
arg	exp(-e v ||| v	count=1
arg	cross-validated estimates for ||| y cv	count=1
function	compute log probabilities ||| parallel predict log proba	count=1
function	first prime [function_2] ||| [function_2] [function_1]	count=3
arg	the lrd of a ||| distances_x neighbors_indices	count=1
arg	algorithms ||| n_components init eps	count=1
arg	x which ||| x	count=1
function	each ||| predict	count=1
function	input data point ||| cross val	count=1
function	grid ||| grid	count=1
function_arg	transform [arg_2] ||| [function_1] [arg_2]	count=5
arg	check if fileobj ||| fileobj	count=1
function	of neighbors ||| neighbors	count=2
function_arg	predict class [arg_2] ||| [function_1] x [arg_2]	count=2
module	adjusted ||| metrics cluster	count=1
class	the best found parameters ||| base search cv	count=2
function	net path with coordinate ||| path	count=1
function	[function_1] a gaussian ||| [function_2] [function_1]	count=1
arg	data [arg] ||| [arg]	count=2
arg	discrete target variable ||| x y discrete_features n_neighbors	count=1
class	classifier from ||| classifier	count=1
function	using the ||| shape	count=1
function	laplacian ||| laplacian	count=1
function	distributions for the precisions ||| precisions	count=1
arg	in n_jobs ||| x y func n_jobs	count=1
function	data precision matrix with ||| precision	count=1
function	'l' suffix when using ||| shape repr	count=1
arg	its spectrum spectrum ||| spectrum n_samples n_features	count=1
arg	actual fitting performing the ||| parameter_iterable	count=1
arg	mcd from ||| n_support	count=1
arg	an arbitrary python object ||| value filename	count=1
arg	filename ||| fileobj filename mmap_mode	count=1
arg	keep ||| root_path bytes_limit	count=1
function	and dot ||| divergence	count=1
arg	matrices w ||| x w	count=1
function_arg	parameters of this ||| params deep	count=4
class	generate ||| split	count=1
function	trace [function_2] ||| [function_1] [function_2]	count=1
module	avoid the hash depending ||| externals joblib	count=2
arg	given mapping ||| class_mapping	count=1
arg	the case method='lasso' is ||| y xy gram	count=1
function	a name for ||| func name	count=1
function	call predict ||| predict	count=1
function	[function_1] importances ||| [function_2] [function_1]	count=1
function	tolerance which ||| tolerance	count=1
function	[function_1] variance regression ||| [function_2] [function_1]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] type tied_cv [arg_2]	count=12
function	and right [function] all hash ||| generate [function]	count=1
arg	each ||| x y	count=1
function	points ||| len	count=1
function	introduces an ||| shape	count=1
function	[function_1] sample ||| [function_1] [function_2]	count=1
function	all the covariance ||| covariance	count=1
module	convert coefficient matrix ||| linear_model	count=1
arg	sparse matrix ||| dtype	count=1
function	for each input data ||| val	count=1
function	[function] line information ||| [function]	count=1
function_arg	accept precomputed [arg_2] ||| [arg_2] [function_1]	count=1
function	[function_1] 20 newsgroups ||| [function_1] [function_2]	count=1
function	covariance m step for ||| covar	count=2
class	process or thread ||| backend	count=1
function	[function_1] and ||| [function_2] [function_1]	count=13
class	fit ||| lasso lars ic	count=1
function	regression problem with sparse ||| sparse	count=1
class	exception types ||| base	count=1
class	compute ||| pca	count=1
class	reporter ||| reporter	count=1
module	reliable ||| joblib	count=1
function	point ||| cross	count=1
arg	x and ||| x y sample_weight	count=2
class	list of exception types ||| base	count=1
arg	columns ||| x columns	count=1
function_arg	run score function [function_1] [arg_2] appropriate features ||| feature_selection base filter [function_1] [arg_2]	count=1
function	helper to ||| parallel helper	count=1
function	log probabilities within a ||| predict log proba	count=1
function	with sparse uncorrelated design ||| make sparse uncorrelated	count=1
function_arg	[function_1] q_ijs ||| [arg_2] [function_1]	count=8
arg	dense dictionary ||| dictionary	count=1
function	factorization nmf find two ||| non negative factorization	count=1
function	regression ||| make regression	count=1
function	lfw pairs dataset this ||| lfw pairs	count=2
arg	n_jobs ||| x y func n_jobs	count=1
arg	dispatch table ||| reduce_func	count=1
function	the average [function_2] ||| [function_2] [function_1]	count=3
module	to run ||| joblib	count=1
function	compute elastic net path ||| path	count=1
function	memmap instance to ||| reduce memmap	count=1
function	helper ||| helper	count=2
function	lfw people dataset this ||| fetch lfw people	count=1
function_arg	predict is [arg_2] ||| [arg_2] [function_1]	count=1
function	the breakdown ||| breakdown	count=1
function	full covariance matrices ||| density full	count=1
class	best found ||| search cv	count=8
function	l1 distances between the ||| paired manhattan distances	count=1
function_arg	the diagonal [arg_2] ||| [function_1] [arg_2]	count=2
arg	as training ||| xy	count=1
function	[function_1] subsets incrementally ||| [function_2] [function_1]	count=4
arg	average ||| y_score average	count=1
class	fit ||| linear svr	count=1
module_class	transform [module_1] [class_2] matrix ||| [module_1] [class_2]	count=2
function	load the rcv1 multilabel ||| rcv1	count=1
function	of alpha ||| alpha	count=1
function	the curve auc ||| auc	count=2
function	step for diagonal ||| diag	count=1
function	an ||| shape repr	count=1
function	gaussian and label samples ||| make gaussian	count=1
function	for full covariance matrices ||| normal density full	count=1
function	[function_1] computing truncated ||| [function_1] [function_2]	count=1
function	score on the ||| score	count=1
function	the training set according ||| fit	count=1
function	get parameters of ||| get params	count=8
function_arg	[function_1] [arg_2] ||| [function_1] w [arg_2]	count=1
function	modified ||| modified	count=1
function	inplace column ||| inplace column scale	count=1
function	for each input data ||| val predict	count=1
function	exception in an unfitted ||| unfitted	count=1
module	do nothing and return ||| feature_extraction	count=1
arg	decisions within a ||| estimators_features x	count=1
function	write the [function_2] ||| [function_2] [function_1]	count=2
function	estimate sample weights by ||| sample	count=1
function	data ||| load data	count=1
function_arg	based on [arg_2] ||| [function_1] x x [arg_2]	count=2
class	generative model ||| base	count=1
function	[function_1] fit ||| [function_2] [function_1]	count=7
function	[function_1] [function_2] ||| metrics [function_1] [function_2]	count=2
function_arg	to [arg_2] ||| [arg_2] [function_1]	count=4
arg	a large sparse ||| a	count=1
module	update and a ||| utils	count=1
function	lfw people dataset ||| lfw people	count=1
function_arg	multinomial loss [arg_2] ||| [function_1] [arg_2]	count=3
function	shutdown the process or ||| terminate	count=1
arg	conversion ||| csr_output	count=1
function	coverage file ||| coverage	count=1
function	covariance ||| to match covariance	count=1
function	[function_1] compute scores ||| [function_1] [function_2]	count=1
class	process or thread pool ||| backend	count=1
function_arg	[function_1] [arg_2] ||| [function_1] auc score y_true [arg_2]	count=1
function	back ||| inverse	count=3
arg	in the dispatch table ||| reduce_func	count=1
module	avoid the hash ||| joblib	count=2
function	a platform ||| shape	count=1
class	outlier on ||| outlier factor	count=1
function	[function_1] image from ||| [function_1] [function_2]	count=1
module	[module_1] [module_2] ||| [module_1] [module_2]	count=16
function	parallel backend ||| parallel backend	count=2
class	the process ||| multiprocessing	count=1
arg	discrete target variable ||| discrete_features n_neighbors	count=1
function	directory in which are ||| output dir	count=1
function	compute data precision matrix ||| precision	count=1
module	covariance model to ||| covariance	count=1
module	cache ||| externals joblib	count=5
arg	validation and conversion ||| dtype csr_output	count=1
arg	matrices ||| covariance_type n_components	count=1
arg	between x [arg_2] ||| [arg_1] [arg_2]	count=1
function	average path [function_2] ||| [function_2] [function_1]	count=2
function	of the reduced ||| reduced	count=1
arg	data [arg_2] ||| [arg_2] [arg_1]	count=17
class	new ||| locally linear	count=1
function	coefficient of determination ||| r2	count=1
arg	of verbose ||| verbose	count=1
function	partial ||| partial	count=3
function	write the ||| write	count=2
function	absolute sizes of training ||| translate train sizes	count=1
function_arg	predict [arg_2] ||| [function_1] [arg_2]	count=1
arg	the gradient and the ||| x y	count=2
function_arg	transform x ||| fit transform x	count=1
arg	to compute [arg] ||| [arg] n_trials	count=1
class	with the generative ||| base pca	count=1
class	of exception types to ||| backend base	count=1
arg	build ||| sample_weight check_input	count=1
function	mean and [function_2] ||| [function_2] [function_1]	count=3
class	string to the file ||| zlib file	count=1
function	incremental mean ||| mean	count=1
arg	data and concatenate results ||| x y	count=1
function_arg	function [arg_2] ||| [function_1] [arg_2]	count=4
arg	on x ||| x n_components	count=2
function	display ||| print	count=1
function	generate ||| choice csc	count=1
module	execution only a fraction ||| externals joblib	count=1
module	cluster ||| metrics cluster	count=1
function	california [function_2] ||| [function_2] [function_1]	count=4
class	force the ||| memorized	count=1
class	write ||| array wrapper	count=1
arg	k x [arg_2] ||| [arg_1] [arg_2]	count=8
function	covertype ||| covtype	count=1
module	avoid the hash ||| externals	count=2
function	load sample images for ||| load sample images	count=1
function	generate an array ||| make	count=2
arg	a [arg] ||| [arg]	count=5
function	dummy [function_2] ||| [function_1] [function_2]	count=1
class	best found parameters ||| search cv	count=2
function	neighbors for ||| radius neighbors	count=2
class	computation of max ||| max	count=1
function	multilabel classification problem ||| multilabel classification	count=1
module	nothing and return ||| feature_extraction	count=1
class	for ||| classifier mixin	count=1
function	x ||| fit predict	count=1
function	absolute sizes ||| sizes	count=1
class	for ||| ada boost classifier	count=2
function	edges for a ||| edges	count=1
class	we don't store the ||| func	count=1
function	verbose message on the ||| verbose msg init	count=1
arg	standardize a [arg_2] ||| [arg_2] [arg_1]	count=4
class	the loss ||| loss	count=1
function	indicating which features ||| support	count=1
function	to build a batch ||| parallel build	count=1
function	get number ||| get n	count=2
function_arg	vector is positive-definite ||| positivity precision covariance_type	count=2
class	[class_1] are going ||| [class_2] [class_1]	count=2
function_arg	x [arg_2] ||| [function_1] x [arg_2]	count=3
function	return a reference ||| and shelve	count=1
function_arg	eval [arg_2] ||| [function_1] [arg_2]	count=3
function	return a ||| repr	count=1
function	csc matrix ||| csc	count=1
function	list of ||| get	count=1
class	[class_1] grid ||| [class_2] [class_1]	count=2
function	m step for full ||| full	count=1
function	list of exception ||| get	count=1
function	[function_1] linear ||| [function_1] [function_2]	count=3
module	given training ||| core	count=1
function	aligned memory ||| aligned	count=1
function	load the kddcup99 dataset ||| kddcup99	count=1
function	[function_1] names from ||| [function_2] [function_1]	count=2
arg	svd ||| x n_components	count=1
function	neighbors for points in ||| neighbors	count=2
function	[function_1] length ||| [function_2] [function_1]	count=9
class	to sparse [class_2] ||| [class_1] [class_2]	count=1
arg	and a ||| y axis	count=1
function	sample from the ||| sample	count=2
function	compute prediction of init ||| init decision	count=1
class	underlying estimators should ||| one vs one classifier	count=1
function	nans ||| nans	count=1
function	using the ||| shape repr	count=1
function	validity of parameters ||| params	count=1
arg	actual fitting performing ||| y parameter_iterable	count=1
function_arg	log-probabilities [arg_2] ||| [function_1] [arg_2]	count=2
function	element in the ||| in	count=1
function	to compute log probabilities ||| predict log proba	count=1
arg	[arg_1] by ||| [arg_2] [arg_1]	count=1
function_arg	mldata [arg_2] ||| [function_1] [arg_2]	count=1
function_arg	[function_1] [arg_2] ||| [function_1] matrix_chol [arg_2]	count=5
function	output ||| called str	count=1
function	[function_1] functions of ||| [function_1] [function_2]	count=4
arg	batch_size elements ||| batch_size	count=1
function	of the data ||| clear data	count=1
function	to partition [function_2] ||| [function_2] [function_1]	count=1
function	of exception types to ||| get	count=1
function	note ||| roc	count=1
function_arg	[function_1] [arg_2] ||| [function_1] predict proba [arg_2]	count=2
function	of array-like or scipy ||| binarize	count=1
function	jobs ||| jobs	count=2
arg	test vectors x ||| x	count=1
function	is the depth ||| previous func code	count=1
function	perform a locally linear ||| locally linear	count=1
arg	the validity of the ||| x metric p metric_params	count=1
function	"news" format ||| newsgroup	count=2
arg	:ref user guide <sparse_inverse_covariance> ||| emp_cov alpha cov_init mode	count=1
arg	x (as bigger ||| x	count=1
class	train test ||| split	count=1
function	fit the model to ||| fit	count=5
function_arg	gaussian [arg_2] ||| [function_1] [arg_2]	count=1
function	[function_1] clustering ||| [function_2] [function_1]	count=1
arg	meant to be ||| index_file_path data_folder_path slice_ color	count=1
function	predict ||| compute labels predict	count=1
function	set the diagonal of ||| set diag	count=1
class	convert coefficient ||| coef mixin	count=1
arg	[arg_1] a dense ||| [arg_1] [arg_2]	count=1
function	content of the data ||| clear data	count=1
class	constructs signature from the ||| signature	count=1
function	long type introduces an ||| shape	count=1
function_arg	np dot x ||| dot w x	count=1
module	and return the number ||| externals joblib	count=3
function	explained variance ||| explained variance	count=2
arg	api and ||| y	count=3
arg	to the binary ||| y_score average	count=1
function	a single boost ||| boost	count=1
function	mstep ||| do mstep	count=2
function	right [function] all hash ||| generate [function]	count=1
arg	likelihood of the data ||| x	count=2
arg	[arg_1] matrix ||| [arg_1] [arg_2]	count=1
class	trained ||| base multilayer perceptron	count=1
class	the trained model parameters ||| base multilayer perceptron	count=1
arg	x y as ||| x y copy_x	count=3
function	[function_1] main classification ||| [function_2] [function_1]	count=4
function	an 'l' suffix ||| repr	count=1
function	single binary ||| binary	count=4
function	determinant ||| det	count=1
arg	does not need to ||| tree x y residual	count=1
arg	samples [arg_2] ||| [arg_2] [arg_1]	count=1
function_arg	likelihood of [arg_2] ||| [arg_2] [function_1]	count=1
module_class	of [module_1] [class_2] ||| [module_1] [class_2]	count=6
function	neighbors for ||| neighbors	count=2
arg	note ||| sample_weight	count=1
function	the california housing ||| california housing	count=1
function	binary ||| binary	count=5
class	data as a sparse ||| sparse	count=1
function	[function_1] path length ||| [function_2] [function_1]	count=7
function	explained variance regression ||| explained variance	count=2
function	error regression loss ||| error	count=3
function	samples in ||| predict	count=1
arg	of data ||| data	count=1
function	in multiplicative ||| multiplicative	count=2
class	the model ||| randomized linear model	count=1
function	to update terminal regions ||| update terminal regions	count=1
function	construct a featureunion from ||| make union	count=1
module	as a ||| externals joblib	count=1
arg	downloading it if necessary ||| data_home subset download_if_missing random_state	count=1
arg	from features or distance ||| sample_weight	count=1
function	average path length ||| average path length	count=3
arg	[arg_1] <classification_report> ||| [arg_1] [arg_2]	count=2
function	the submatrix corresponding ||| submatrix	count=1
module	data point ||| core	count=1
arg	log-det of ||| matrix_chol	count=1
arg	rfe model and ||| x y	count=1
function	platform independent representation ||| repr	count=1
class	documents to [class] ||| [class]	count=1
function_arg	[function_1] and returns ||| decomposition nmf [function_1] x [arg_2]	count=1
function	sparse random matrix given ||| random choice csc	count=1
arg	vectors rows of u ||| u	count=1
class	to sparse [class_2] ||| [class_2] [class_1]	count=1
class	aggressive algorithm ||| aggressive regressor	count=1
function	finds seeds ||| seeds	count=1
arg	filters ||| func ignore_lst	count=1
arg	continuous ||| n_neighbors	count=2
arg	and compute ||| y classes	count=2
function	[function_1] regression ||| [function_1] [function_2]	count=3
function_arg	probabilities for [arg_2] ||| [arg_2] [function_1]	count=4
arg	specified layer ||| layer	count=1
function	[function_1] probability estimates ||| [function_2] [function_1]	count=2
class	ridge regression ||| ridge cv	count=1
class	[class_1] using numpy ||| [class_2] [class_1]	count=2
function_arg	[function_1] to multi-class ||| [arg_2] [function_1]	count=3
class	to ||| memorized	count=1
function	paired cosine [function_2] ||| [function_2] [function_1]	count=1
function	error of [function_2] ||| [function_2] divergence [function_1]	count=1
arg	the loss is ||| loss	count=1
function_arg	[function_1] and concatenate ||| [function_1] [arg_2]	count=1
arg	and y read ||| y	count=1
function	sizes ||| train sizes	count=1
function	to update [function_2] ||| [function_2] [function_1]	count=2
class	linear ||| linear	count=1
function	a covariance [function_2] ||| [function_2] [function_1]	count=6
function	incremental mean ||| incr mean	count=1
arg	prediction ||| x y sample_weight	count=1
function	of the cholesky decomposition ||| cholesky	count=1
arg	point ||| estimator x	count=1
arg	validation and [arg_2] ||| [arg_1] [arg_2]	count=2
function	the reduced [function_2] ||| [function_1] [function_2]	count=7
function	normalize rows ||| normalize	count=1
module	representation of ||| utils	count=1
arg	sum_h exp(-e v h ||| v	count=1
function	and gradient ||| and grad	count=2
arg	and scaling parameters ||| x y	count=1
module	minimum covariance ||| covariance	count=1
module	to run in ||| joblib	count=1
function	median of ||| median	count=1
function	the decision function ||| decision function	count=2
class	the search over parameters ||| search cv	count=1
function	names ||| name	count=1
function	found and raise ||| search	count=1
class	generate train ||| shuffle	count=1
class	to avoid ||| memory	count=1
arg	cross-validated estimates for each ||| estimator x y cv	count=1
arg	and ||| y	count=59
function	predict is invariant of ||| compute labels predict	count=1
arg	[arg_1] m ||| [arg_2] [arg_1]	count=2
function	functions of ||| function	count=1
function	introduces ||| shape	count=1
function_arg	residues [arg_2] ||| [function_1] [arg_2]	count=2
function_arg	[function_1] neighbors ||| [function_1] distances [arg_2]	count=1
function	in an unfitted ||| estimators unfitted	count=1
arg	and scale ||| y	count=1
function	normalized [function_2] ||| [function_2] [function_1]	count=2
arg	biclustering for x ||| x	count=1
class	state [class] if necessary ||| [class]	count=3
module	metrics read more in ||| metrics	count=1
arg	dictionary factor in place ||| dictionary y code verbose	count=1
arg	[arg_1] conversion ||| [arg_1] [arg_2]	count=3
arg	gradient and ||| w x y	count=2
class	detects ||| class svm	count=1
function	decision functions of the ||| decision function	count=1
function_arg	function of [arg_2] ||| [arg_2] [function_1]	count=4
function	patches of any ||| patches	count=1
function	randomized svd parameters ||| randomized svd	count=2
function	training set according ||| fit predict	count=1
arg	generate cross-validated ||| estimator x y cv	count=1
function	bias vectors ||| backprop	count=1
class	hash depending ||| func	count=1
arg	inefficient to train all ||| classes	count=1
function	features ||| features	count=2
function	set the ||| set	count=6
module_class	with the em ||| mixture gmmbase	count=1
arg	given test [arg] ||| [arg]	count=3
function	within a job ||| parallel	count=1
arg	a zipped pickle ||| target_dir cache_path	count=1
function	cache key ||| cache key	count=1
class	coefficient ||| sparse coef	count=1
arg	and concatenate ||| y	count=1
arg	determine whether y ||| y	count=1
class	the backend and ||| backend	count=1
function	for each input ||| cross val predict	count=1
class	gaussian process regression ||| gaussian process regressor	count=3
function	partition [function_2] ||| [function_1] [function_2]	count=1
class	generate train test ||| shuffle	count=1
arg	apply transforms and ||| y sample_weight	count=1
function	[function_1] feature names ||| [function_2] [function_1]	count=1
function_arg	[function_1] values ||| [function_1] estimator [arg_2]	count=4
function	perplexity for ||| perplexity	count=2
function	predict_log_proba on the ||| predict log proba	count=1
function	the local ||| local	count=1
class	for scaling ||| scaler	count=1
arg	compute decisions within a ||| estimators_features	count=1
arg	are ||| mask	count=1
class	cache for the ||| memorized	count=1
arg	the gp prior ||| return_std return_cov	count=1
arg	the binary classification task ||| y_true y_score pos_label sample_weight	count=1
function_arg	[function_1] [arg_2] ||| regressor sample [function_1] [arg_2] random_state	count=1
function	c [function_2] ||| [function_2] [function_1]	count=3
class	reduced ||| gaussian process	count=1
arg	binary classification task ||| y_true y_score average	count=1
function	return the shortest ||| source shortest	count=1
function	sample weights by ||| sample	count=1
function	of the cholesky decomposition ||| det cholesky	count=1
function	decision functions ||| decision function	count=2
module	the generative model ||| decomposition	count=1
function	lfw pairs dataset this ||| fetch lfw pairs	count=2
function	the number of estimators ||| len	count=1
function	neighbors for points in ||| radius neighbors	count=2
arg	x from y ||| x z reg	count=1
